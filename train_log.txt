################################################################################
                      [1m Learning iteration 0/2000 [0m                       

                       Computation: 1108 steps/s (collection: 5.784s, learning 0.710s)
               Value function loss: 87.6143
                    Surrogate loss: -0.0028
             Mean action noise std: 1.00
                       Mean reward: -55.21
               Mean episode length: 43.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7200
                    Iteration time: 6.49s
                        Total time: 6.49s
                               ETA: 12987.3s
################################################################################
                      [1m Learning iteration 1/2000 [0m                       

                       Computation: 1768 steps/s (collection: 3.435s, learning 0.637s)
               Value function loss: 60.9052
                    Surrogate loss: -0.0024
             Mean action noise std: 1.00
                       Mean reward: -55.22
               Mean episode length: 43.67
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 14400
                    Iteration time: 4.07s
                        Total time: 10.57s
                               ETA: 10560.3s
################################################################################
                      [1m Learning iteration 2/2000 [0m                       

                       Computation: 1852 steps/s (collection: 3.230s, learning 0.656s)
               Value function loss: 87.3786
                    Surrogate loss: -0.0007
             Mean action noise std: 1.00
                       Mean reward: -55.43
               Mean episode length: 44.20
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 21600
                    Iteration time: 3.89s
                        Total time: 14.45s
                               ETA: 9624.8s
################################################################################
                      [1m Learning iteration 3/2000 [0m                       

                       Computation: 1787 steps/s (collection: 3.302s, learning 0.727s)
               Value function loss: 69.4787
                    Surrogate loss: -0.0035
             Mean action noise std: 1.00
                       Mean reward: -55.55
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 28800
                    Iteration time: 4.03s
                        Total time: 18.48s
                               ETA: 9226.5s
################################################################################
                      [1m Learning iteration 4/2000 [0m                       

                       Computation: 1777 steps/s (collection: 3.431s, learning 0.618s)
               Value function loss: 76.6303
                    Surrogate loss: -0.0057
             Mean action noise std: 1.00
                       Mean reward: -55.72
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 36000
                    Iteration time: 4.05s
                        Total time: 22.53s
                               ETA: 8994.1s
################################################################################
                      [1m Learning iteration 5/2000 [0m                       

                       Computation: 1820 steps/s (collection: 3.188s, learning 0.766s)
               Value function loss: 59.9183
                    Surrogate loss: 0.0016
             Mean action noise std: 1.00
                       Mean reward: -55.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 43200
                    Iteration time: 3.95s
                        Total time: 26.48s
                               ETA: 8806.0s
################################################################################
                      [1m Learning iteration 6/2000 [0m                       

                       Computation: 1767 steps/s (collection: 3.297s, learning 0.777s)
               Value function loss: 58.3303
                    Surrogate loss: -0.0043
             Mean action noise std: 1.00
                       Mean reward: -55.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 50400
                    Iteration time: 4.07s
                        Total time: 30.56s
                               ETA: 8704.8s
################################################################################
                      [1m Learning iteration 7/2000 [0m                       

                       Computation: 1806 steps/s (collection: 3.177s, learning 0.808s)
               Value function loss: 50.1596
                    Surrogate loss: -0.0037
             Mean action noise std: 1.00
                       Mean reward: -55.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 57600
                    Iteration time: 3.99s
                        Total time: 34.54s
                               ETA: 8605.7s
################################################################################
                      [1m Learning iteration 8/2000 [0m                       

                       Computation: 1779 steps/s (collection: 3.234s, learning 0.812s)
               Value function loss: 48.1750
                    Surrogate loss: -0.0042
             Mean action noise std: 0.99
                       Mean reward: -55.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 64800
                    Iteration time: 4.05s
                        Total time: 38.59s
                               ETA: 8541.2s
################################################################################
                      [1m Learning iteration 9/2000 [0m                       

                       Computation: 1781 steps/s (collection: 3.272s, learning 0.769s)
               Value function loss: 46.1737
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -55.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 72000
                    Iteration time: 4.04s
                        Total time: 42.63s
                               ETA: 8487.9s
################################################################################
                      [1m Learning iteration 10/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.190s, learning 0.714s)
               Value function loss: 49.5829
                    Surrogate loss: -0.0049
             Mean action noise std: 0.99
                       Mean reward: -55.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 79200
                    Iteration time: 3.90s
                        Total time: 46.54s
                               ETA: 8418.6s
################################################################################
                      [1m Learning iteration 11/2000 [0m                      

                       Computation: 1732 steps/s (collection: 3.315s, learning 0.841s)
               Value function loss: 58.2134
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -55.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 86400
                    Iteration time: 4.16s
                        Total time: 50.69s
                               ETA: 8402.0s
################################################################################
                      [1m Learning iteration 12/2000 [0m                      

                       Computation: 1815 steps/s (collection: 3.164s, learning 0.802s)
               Value function loss: 47.5025
                    Surrogate loss: 0.0007
             Mean action noise std: 0.99
                       Mean reward: -56.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 93600
                    Iteration time: 3.97s
                        Total time: 54.66s
                               ETA: 8358.3s
################################################################################
                      [1m Learning iteration 13/2000 [0m                      

                       Computation: 1747 steps/s (collection: 3.316s, learning 0.804s)
               Value function loss: 52.7263
                    Surrogate loss: -0.0032
             Mean action noise std: 0.99
                       Mean reward: -56.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 100800
                    Iteration time: 4.12s
                        Total time: 58.78s
                               ETA: 8342.0s
################################################################################
                      [1m Learning iteration 14/2000 [0m                      

                       Computation: 1745 steps/s (collection: 3.352s, learning 0.773s)
               Value function loss: 57.3124
                    Surrogate loss: -0.0038
             Mean action noise std: 0.99
                       Mean reward: -56.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 108000
                    Iteration time: 4.12s
                        Total time: 62.90s
                               ETA: 8328.1s
################################################################################
                      [1m Learning iteration 15/2000 [0m                      

                       Computation: 1860 steps/s (collection: 3.212s, learning 0.658s)
               Value function loss: 43.4845
                    Surrogate loss: -0.0045
             Mean action noise std: 0.99
                       Mean reward: -56.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 115200
                    Iteration time: 3.87s
                        Total time: 66.77s
                               ETA: 8283.7s
################################################################################
                      [1m Learning iteration 16/2000 [0m                      

                       Computation: 1805 steps/s (collection: 3.335s, learning 0.652s)
               Value function loss: 44.4359
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 122400
                    Iteration time: 3.99s
                        Total time: 70.76s
                               ETA: 8257.8s
################################################################################
                      [1m Learning iteration 17/2000 [0m                      

                       Computation: 1830 steps/s (collection: 3.155s, learning 0.778s)
               Value function loss: 42.2122
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -54.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 129600
                    Iteration time: 3.93s
                        Total time: 74.69s
                               ETA: 8228.4s
################################################################################
                      [1m Learning iteration 18/2000 [0m                      

                       Computation: 1770 steps/s (collection: 3.268s, learning 0.799s)
               Value function loss: 41.1112
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -54.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 136800
                    Iteration time: 4.07s
                        Total time: 78.76s
                               ETA: 8215.6s
################################################################################
                      [1m Learning iteration 19/2000 [0m                      

                       Computation: 1803 steps/s (collection: 3.306s, learning 0.688s)
               Value function loss: 43.5620
                    Surrogate loss: -0.0051
             Mean action noise std: 0.99
                       Mean reward: -54.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 144000
                    Iteration time: 3.99s
                        Total time: 82.75s
                               ETA: 8196.4s
################################################################################
                      [1m Learning iteration 20/2000 [0m                      

                       Computation: 1805 steps/s (collection: 3.213s, learning 0.776s)
               Value function loss: 34.2933
                    Surrogate loss: 0.0097
             Mean action noise std: 0.99
                       Mean reward: -54.33
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 151200
                    Iteration time: 3.99s
                        Total time: 86.74s
                               ETA: 8178.3s
################################################################################
                      [1m Learning iteration 21/2000 [0m                      

                       Computation: 1762 steps/s (collection: 3.363s, learning 0.724s)
               Value function loss: 46.9817
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -54.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 158400
                    Iteration time: 4.09s
                        Total time: 90.83s
                               ETA: 8170.2s
################################################################################
                      [1m Learning iteration 22/2000 [0m                      

                       Computation: 1867 steps/s (collection: 3.217s, learning 0.639s)
               Value function loss: 48.4932
                    Surrogate loss: 0.0012
             Mean action noise std: 0.99
                       Mean reward: -55.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 165600
                    Iteration time: 3.86s
                        Total time: 94.68s
                               ETA: 8142.6s
################################################################################
                      [1m Learning iteration 23/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.312s, learning 0.623s)
               Value function loss: 43.2159
                    Surrogate loss: -0.0033
             Mean action noise std: 0.99
                       Mean reward: -55.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 172800
                    Iteration time: 3.93s
                        Total time: 98.62s
                               ETA: 8123.5s
################################################################################
                      [1m Learning iteration 24/2000 [0m                      

                       Computation: 1832 steps/s (collection: 3.307s, learning 0.622s)
               Value function loss: 47.0554
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 180000
                    Iteration time: 3.93s
                        Total time: 102.55s
                               ETA: 8105.2s
################################################################################
                      [1m Learning iteration 25/2000 [0m                      

                       Computation: 1868 steps/s (collection: 3.230s, learning 0.624s)
               Value function loss: 47.8379
                    Surrogate loss: -0.0025
             Mean action noise std: 0.99
                       Mean reward: -55.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 187200
                    Iteration time: 3.85s
                        Total time: 106.40s
                               ETA: 8082.2s
################################################################################
                      [1m Learning iteration 26/2000 [0m                      

                       Computation: 1802 steps/s (collection: 3.365s, learning 0.629s)
               Value function loss: 38.4298
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -55.53
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 194400
                    Iteration time: 3.99s
                        Total time: 110.39s
                               ETA: 8071.0s
################################################################################
                      [1m Learning iteration 27/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.192s, learning 0.642s)
               Value function loss: 39.0335
                    Surrogate loss: -0.0024
             Mean action noise std: 0.99
                       Mean reward: -54.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 201600
                    Iteration time: 3.83s
                        Total time: 114.23s
                               ETA: 8048.9s
################################################################################
                      [1m Learning iteration 28/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.323s, learning 0.628s)
               Value function loss: 33.7753
                    Surrogate loss: -0.0058
             Mean action noise std: 0.99
                       Mean reward: -54.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 208800
                    Iteration time: 3.95s
                        Total time: 118.18s
                               ETA: 8036.1s
################################################################################
                      [1m Learning iteration 29/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.308s, learning 0.592s)
               Value function loss: 40.2645
                    Surrogate loss: -0.0073
             Mean action noise std: 0.99
                       Mean reward: -53.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 216000
                    Iteration time: 3.90s
                        Total time: 122.08s
                               ETA: 8020.6s
################################################################################
                      [1m Learning iteration 30/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.240s, learning 0.603s)
               Value function loss: 38.1285
                    Surrogate loss: -0.0027
             Mean action noise std: 0.99
                       Mean reward: -53.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 223200
                    Iteration time: 3.84s
                        Total time: 125.92s
                               ETA: 8002.1s
################################################################################
                      [1m Learning iteration 31/2000 [0m                      

                       Computation: 1816 steps/s (collection: 3.361s, learning 0.603s)
               Value function loss: 41.0155
                    Surrogate loss: -0.0043
             Mean action noise std: 0.99
                       Mean reward: -52.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 230400
                    Iteration time: 3.96s
                        Total time: 129.89s
                               ETA: 7992.1s
################################################################################
                      [1m Learning iteration 32/2000 [0m                      

                       Computation: 1852 steps/s (collection: 3.288s, learning 0.598s)
               Value function loss: 40.3199
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -53.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 237600
                    Iteration time: 3.89s
                        Total time: 133.77s
                               ETA: 7977.7s
################################################################################
                      [1m Learning iteration 33/2000 [0m                      

                       Computation: 1812 steps/s (collection: 3.357s, learning 0.615s)
               Value function loss: 38.3529
                    Surrogate loss: -0.0039
             Mean action noise std: 0.99
                       Mean reward: -52.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 244800
                    Iteration time: 3.97s
                        Total time: 137.74s
                               ETA: 7968.9s
################################################################################
                      [1m Learning iteration 34/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.269s, learning 0.631s)
               Value function loss: 38.4416
                    Surrogate loss: 0.0076
             Mean action noise std: 0.99
                       Mean reward: -53.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 252000
                    Iteration time: 3.90s
                        Total time: 141.64s
                               ETA: 7956.4s
################################################################################
                      [1m Learning iteration 35/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.344s, learning 0.609s)
               Value function loss: 39.5888
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -53.10
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 259200
                    Iteration time: 3.95s
                        Total time: 145.60s
                               ETA: 7947.2s
################################################################################
                      [1m Learning iteration 36/2000 [0m                      

                       Computation: 1777 steps/s (collection: 3.449s, learning 0.602s)
               Value function loss: 41.4946
                    Surrogate loss: -0.0040
             Mean action noise std: 0.99
                       Mean reward: -53.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 266400
                    Iteration time: 4.05s
                        Total time: 149.65s
                               ETA: 7943.5s
################################################################################
                      [1m Learning iteration 37/2000 [0m                      

                       Computation: 1848 steps/s (collection: 3.276s, learning 0.618s)
               Value function loss: 38.0765
                    Surrogate loss: -0.0061
             Mean action noise std: 0.99
                       Mean reward: -52.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 273600
                    Iteration time: 3.89s
                        Total time: 153.54s
                               ETA: 7931.7s
################################################################################
                      [1m Learning iteration 38/2000 [0m                      

                       Computation: 1814 steps/s (collection: 3.339s, learning 0.630s)
               Value function loss: 44.5340
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -52.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 280800
                    Iteration time: 3.97s
                        Total time: 157.51s
                               ETA: 7924.1s
################################################################################
                      [1m Learning iteration 39/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.278s, learning 0.623s)
               Value function loss: 36.2183
                    Surrogate loss: 0.0018
             Mean action noise std: 0.99
                       Mean reward: -52.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 288000
                    Iteration time: 3.90s
                        Total time: 161.41s
                               ETA: 7913.3s
################################################################################
                      [1m Learning iteration 40/2000 [0m                      

                       Computation: 1842 steps/s (collection: 3.275s, learning 0.631s)
               Value function loss: 34.4764
                    Surrogate loss: -0.0010
             Mean action noise std: 0.99
                       Mean reward: -51.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 295200
                    Iteration time: 3.91s
                        Total time: 165.32s
                               ETA: 7903.1s
################################################################################
                      [1m Learning iteration 41/2000 [0m                      

                       Computation: 1808 steps/s (collection: 3.353s, learning 0.628s)
               Value function loss: 36.5184
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -51.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 302400
                    Iteration time: 3.98s
                        Total time: 169.30s
                               ETA: 7896.7s
################################################################################
                      [1m Learning iteration 42/2000 [0m                      

                       Computation: 1860 steps/s (collection: 3.241s, learning 0.628s)
               Value function loss: 39.0004
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -51.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 309600
                    Iteration time: 3.87s
                        Total time: 173.17s
                               ETA: 7885.3s
################################################################################
                      [1m Learning iteration 43/2000 [0m                      

                       Computation: 1802 steps/s (collection: 3.369s, learning 0.624s)
               Value function loss: 42.0665
                    Surrogate loss: -0.0017
             Mean action noise std: 0.99
                       Mean reward: -52.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 316800
                    Iteration time: 3.99s
                        Total time: 177.16s
                               ETA: 7879.8s
################################################################################
                      [1m Learning iteration 44/2000 [0m                      

                       Computation: 1854 steps/s (collection: 3.280s, learning 0.602s)
               Value function loss: 41.4940
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -52.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 324000
                    Iteration time: 3.88s
                        Total time: 181.05s
                               ETA: 7869.5s
################################################################################
                      [1m Learning iteration 45/2000 [0m                      

                       Computation: 1879 steps/s (collection: 3.202s, learning 0.629s)
               Value function loss: 33.4112
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -52.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 331200
                    Iteration time: 3.83s
                        Total time: 184.88s
                               ETA: 7857.3s
################################################################################
                      [1m Learning iteration 46/2000 [0m                      

                       Computation: 1810 steps/s (collection: 3.356s, learning 0.620s)
               Value function loss: 29.0818
                    Surrogate loss: 0.0185
             Mean action noise std: 0.99
                       Mean reward: -52.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 338400
                    Iteration time: 3.98s
                        Total time: 188.85s
                               ETA: 7851.5s
################################################################################
                      [1m Learning iteration 47/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.230s, learning 0.610s)
               Value function loss: 35.3084
                    Surrogate loss: 0.0096
             Mean action noise std: 0.99
                       Mean reward: -52.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 345600
                    Iteration time: 3.84s
                        Total time: 192.69s
                               ETA: 7840.2s
################################################################################
                      [1m Learning iteration 48/2000 [0m                      

                       Computation: 1798 steps/s (collection: 3.372s, learning 0.632s)
               Value function loss: 35.7524
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -51.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 352800
                    Iteration time: 4.00s
                        Total time: 196.70s
                               ETA: 7835.8s
################################################################################
                      [1m Learning iteration 49/2000 [0m                      

                       Computation: 1812 steps/s (collection: 3.339s, learning 0.633s)
               Value function loss: 33.0440
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -51.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 360000
                    Iteration time: 3.97s
                        Total time: 200.67s
                               ETA: 7830.2s
################################################################################
                      [1m Learning iteration 50/2000 [0m                      

                       Computation: 1775 steps/s (collection: 3.362s, learning 0.693s)
               Value function loss: 34.2946
                    Surrogate loss: -0.0047
             Mean action noise std: 0.99
                       Mean reward: -51.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 367200
                    Iteration time: 4.06s
                        Total time: 204.73s
                               ETA: 7827.7s
################################################################################
                      [1m Learning iteration 51/2000 [0m                      

                       Computation: 1791 steps/s (collection: 3.417s, learning 0.602s)
               Value function loss: 33.1621
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -51.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 374400
                    Iteration time: 4.02s
                        Total time: 208.74s
                               ETA: 7823.9s
################################################################################
                      [1m Learning iteration 52/2000 [0m                      

                       Computation: 1819 steps/s (collection: 3.327s, learning 0.631s)
               Value function loss: 33.1356
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -51.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 381600
                    Iteration time: 3.96s
                        Total time: 212.70s
                               ETA: 7817.8s
################################################################################
                      [1m Learning iteration 53/2000 [0m                      

                       Computation: 1719 steps/s (collection: 3.434s, learning 0.753s)
               Value function loss: 34.3554
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -51.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 388800
                    Iteration time: 4.19s
                        Total time: 216.89s
                               ETA: 7820.1s
################################################################################
                      [1m Learning iteration 54/2000 [0m                      

                       Computation: 1793 steps/s (collection: 3.370s, learning 0.644s)
               Value function loss: 32.2024
                    Surrogate loss: -0.0022
             Mean action noise std: 0.99
                       Mean reward: -51.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 396000
                    Iteration time: 4.01s
                        Total time: 220.90s
                               ETA: 7816.0s
################################################################################
                      [1m Learning iteration 55/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.222s, learning 0.621s)
               Value function loss: 33.4714
                    Surrogate loss: 0.0039
             Mean action noise std: 0.99
                       Mean reward: -51.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 403200
                    Iteration time: 3.84s
                        Total time: 224.75s
                               ETA: 7805.9s
################################################################################
                      [1m Learning iteration 56/2000 [0m                      

                       Computation: 1830 steps/s (collection: 3.306s, learning 0.628s)
               Value function loss: 29.8262
                    Surrogate loss: -0.0002
             Mean action noise std: 0.99
                       Mean reward: -51.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 410400
                    Iteration time: 3.93s
                        Total time: 228.68s
                               ETA: 7799.2s
################################################################################
                      [1m Learning iteration 57/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.204s, learning 0.633s)
               Value function loss: 32.3009
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -50.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 417600
                    Iteration time: 3.84s
                        Total time: 232.52s
                               ETA: 7789.3s
################################################################################
                      [1m Learning iteration 58/2000 [0m                      

                       Computation: 1808 steps/s (collection: 3.343s, learning 0.640s)
               Value function loss: 29.6770
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -50.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 424800
                    Iteration time: 3.98s
                        Total time: 236.50s
                               ETA: 7784.4s
################################################################################
                      [1m Learning iteration 59/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.228s, learning 0.624s)
               Value function loss: 27.6777
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -50.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 432000
                    Iteration time: 3.85s
                        Total time: 240.35s
                               ETA: 7775.4s
################################################################################
                      [1m Learning iteration 60/2000 [0m                      

                       Computation: 1820 steps/s (collection: 3.235s, learning 0.720s)
               Value function loss: 30.1422
                    Surrogate loss: -0.0003
             Mean action noise std: 0.99
                       Mean reward: -50.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 439200
                    Iteration time: 3.96s
                        Total time: 244.31s
                               ETA: 7769.7s
################################################################################
                      [1m Learning iteration 61/2000 [0m                      

                       Computation: 1820 steps/s (collection: 3.338s, learning 0.617s)
               Value function loss: 31.8961
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -50.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 446400
                    Iteration time: 3.95s
                        Total time: 248.26s
                               ETA: 7764.2s
################################################################################
                      [1m Learning iteration 62/2000 [0m                      

                       Computation: 1877 steps/s (collection: 3.202s, learning 0.632s)
               Value function loss: 33.4506
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -50.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 453600
                    Iteration time: 3.83s
                        Total time: 252.10s
                               ETA: 7754.9s
################################################################################
                      [1m Learning iteration 63/2000 [0m                      

                       Computation: 1807 steps/s (collection: 3.356s, learning 0.627s)
               Value function loss: 30.5063
                    Surrogate loss: -0.0029
             Mean action noise std: 0.98
                       Mean reward: -49.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 460800
                    Iteration time: 3.98s
                        Total time: 256.08s
                               ETA: 7750.4s
################################################################################
                      [1m Learning iteration 64/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.244s, learning 0.639s)
               Value function loss: 33.2652
                    Surrogate loss: -0.0063
             Mean action noise std: 0.98
                       Mean reward: -49.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 468000
                    Iteration time: 3.88s
                        Total time: 259.96s
                               ETA: 7742.9s
################################################################################
                      [1m Learning iteration 65/2000 [0m                      

                       Computation: 1812 steps/s (collection: 3.358s, learning 0.616s)
               Value function loss: 31.3134
                    Surrogate loss: -0.0074
             Mean action noise std: 0.98
                       Mean reward: -50.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 475200
                    Iteration time: 3.97s
                        Total time: 263.94s
                               ETA: 7738.1s
################################################################################
                      [1m Learning iteration 66/2000 [0m                      

                       Computation: 1840 steps/s (collection: 3.282s, learning 0.629s)
               Value function loss: 35.0529
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 482400
                    Iteration time: 3.91s
                        Total time: 267.85s
                               ETA: 7731.6s
################################################################################
                      [1m Learning iteration 67/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.209s, learning 0.677s)
               Value function loss: 30.9591
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -50.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 489600
                    Iteration time: 3.89s
                        Total time: 271.73s
                               ETA: 7724.4s
################################################################################
                      [1m Learning iteration 68/2000 [0m                      

                       Computation: 1823 steps/s (collection: 3.324s, learning 0.625s)
               Value function loss: 31.7109
                    Surrogate loss: -0.0084
             Mean action noise std: 0.98
                       Mean reward: -49.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 496800
                    Iteration time: 3.95s
                        Total time: 275.68s
                               ETA: 7719.1s
################################################################################
                      [1m Learning iteration 69/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.220s, learning 0.631s)
               Value function loss: 29.9669
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 504000
                    Iteration time: 3.85s
                        Total time: 279.53s
                               ETA: 7711.1s
################################################################################
                      [1m Learning iteration 70/2000 [0m                      

                       Computation: 1810 steps/s (collection: 3.361s, learning 0.615s)
               Value function loss: 30.2034
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 511200
                    Iteration time: 3.98s
                        Total time: 283.51s
                               ETA: 7706.6s
################################################################################
                      [1m Learning iteration 71/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.227s, learning 0.597s)
               Value function loss: 32.5000
                    Surrogate loss: -0.0026
             Mean action noise std: 0.98
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 518400
                    Iteration time: 3.82s
                        Total time: 287.33s
                               ETA: 7698.1s
################################################################################
                      [1m Learning iteration 72/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.210s, learning 0.627s)
               Value function loss: 34.1269
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 525600
                    Iteration time: 3.84s
                        Total time: 291.17s
                               ETA: 7690.0s
################################################################################
                      [1m Learning iteration 73/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.329s, learning 0.624s)
               Value function loss: 31.0529
                    Surrogate loss: -0.0057
             Mean action noise std: 0.98
                       Mean reward: -50.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 532800
                    Iteration time: 3.95s
                        Total time: 295.12s
                               ETA: 7685.1s
################################################################################
                      [1m Learning iteration 74/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.192s, learning 0.631s)
               Value function loss: 28.5101
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -49.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 540000
                    Iteration time: 3.82s
                        Total time: 298.94s
                               ETA: 7676.9s
################################################################################
                      [1m Learning iteration 75/2000 [0m                      

                       Computation: 1818 steps/s (collection: 3.331s, learning 0.628s)
               Value function loss: 32.0992
                    Surrogate loss: -0.0059
             Mean action noise std: 0.98
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 547200
                    Iteration time: 3.96s
                        Total time: 302.90s
                               ETA: 7672.2s
################################################################################
                      [1m Learning iteration 76/2000 [0m                      

                       Computation: 1813 steps/s (collection: 3.224s, learning 0.745s)
               Value function loss: 31.4500
                    Surrogate loss: -0.0063
             Mean action noise std: 0.98
                       Mean reward: -49.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 554400
                    Iteration time: 3.97s
                        Total time: 306.87s
                               ETA: 7667.8s
################################################################################
                      [1m Learning iteration 77/2000 [0m                      

                       Computation: 1774 steps/s (collection: 3.265s, learning 0.794s)
               Value function loss: 30.3769
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 561600
                    Iteration time: 4.06s
                        Total time: 310.93s
                               ETA: 7665.6s
################################################################################
                      [1m Learning iteration 78/2000 [0m                      

                       Computation: 1752 steps/s (collection: 3.317s, learning 0.791s)
               Value function loss: 32.6787
                    Surrogate loss: -0.0048
             Mean action noise std: 0.98
                       Mean reward: -49.25
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 568800
                    Iteration time: 4.11s
                        Total time: 315.04s
                               ETA: 7664.6s
################################################################################
                      [1m Learning iteration 79/2000 [0m                      

                       Computation: 1828 steps/s (collection: 3.188s, learning 0.748s)
               Value function loss: 29.4594
                    Surrogate loss: -0.0066
             Mean action noise std: 0.98
                       Mean reward: -49.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 576000
                    Iteration time: 3.94s
                        Total time: 318.98s
                               ETA: 7659.4s
################################################################################
                      [1m Learning iteration 80/2000 [0m                      

                       Computation: 1828 steps/s (collection: 3.300s, learning 0.636s)
               Value function loss: 31.4366
                    Surrogate loss: -0.0033
             Mean action noise std: 0.98
                       Mean reward: -50.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 583200
                    Iteration time: 3.94s
                        Total time: 322.91s
                               ETA: 7654.2s
################################################################################
                      [1m Learning iteration 81/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.202s, learning 0.623s)
               Value function loss: 31.4435
                    Surrogate loss: 0.0025
             Mean action noise std: 0.97
                       Mean reward: -50.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 590400
                    Iteration time: 3.82s
                        Total time: 326.74s
                               ETA: 7646.4s
################################################################################
                      [1m Learning iteration 82/2000 [0m                      

                       Computation: 1863 steps/s (collection: 3.241s, learning 0.622s)
               Value function loss: 27.2720
                    Surrogate loss: -0.0026
             Mean action noise std: 0.97
                       Mean reward: -50.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 597600
                    Iteration time: 3.86s
                        Total time: 330.60s
                               ETA: 7639.7s
################################################################################
                      [1m Learning iteration 83/2000 [0m                      

                       Computation: 1822 steps/s (collection: 3.308s, learning 0.641s)
               Value function loss: 24.7333
                    Surrogate loss: 0.0035
             Mean action noise std: 0.97
                       Mean reward: -50.28
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 604800
                    Iteration time: 3.95s
                        Total time: 334.55s
                               ETA: 7634.9s
################################################################################
                      [1m Learning iteration 84/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.192s, learning 0.630s)
               Value function loss: 30.4519
                    Surrogate loss: -0.0006
             Mean action noise std: 0.97
                       Mean reward: -49.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 612000
                    Iteration time: 3.82s
                        Total time: 338.37s
                               ETA: 7627.3s
################################################################################
                      [1m Learning iteration 85/2000 [0m                      

                       Computation: 1804 steps/s (collection: 3.356s, learning 0.635s)
               Value function loss: 27.7287
                    Surrogate loss: 0.0006
             Mean action noise std: 0.97
                       Mean reward: -49.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 619200
                    Iteration time: 3.99s
                        Total time: 342.36s
                               ETA: 7623.6s
################################################################################
                      [1m Learning iteration 86/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.179s, learning 0.617s)
               Value function loss: 24.4723
                    Surrogate loss: -0.0016
             Mean action noise std: 0.97
                       Mean reward: -49.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 626400
                    Iteration time: 3.80s
                        Total time: 346.16s
                               ETA: 7615.5s
################################################################################
                      [1m Learning iteration 87/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.278s, learning 0.621s)
               Value function loss: 32.0193
                    Surrogate loss: -0.0001
             Mean action noise std: 0.97
                       Mean reward: -48.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 633600
                    Iteration time: 3.90s
                        Total time: 350.06s
                               ETA: 7609.8s
################################################################################
                      [1m Learning iteration 0/2000 [0m                       

                       Computation: 1184 steps/s (collection: 5.425s, learning 0.651s)
               Value function loss: 87.6143
                    Surrogate loss: -0.0028
             Mean action noise std: 1.00
                       Mean reward: -55.21
               Mean episode length: 43.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7200
                    Iteration time: 6.08s
                        Total time: 6.08s
                               ETA: 12153.0s
################################################################################
                      [1m Learning iteration 1/2000 [0m                       

                       Computation: 1909 steps/s (collection: 3.149s, learning 0.621s)
               Value function loss: 60.9052
                    Surrogate loss: -0.0024
             Mean action noise std: 1.00
                       Mean reward: -55.22
               Mean episode length: 43.67
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 14400
                    Iteration time: 3.77s
                        Total time: 9.85s
                               ETA: 9841.7s
################################################################################
                      [1m Learning iteration 2/2000 [0m                       

                       Computation: 1852 steps/s (collection: 3.188s, learning 0.697s)
               Value function loss: 87.3786
                    Surrogate loss: -0.0007
             Mean action noise std: 1.00
                       Mean reward: -55.43
               Mean episode length: 44.20
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 21600
                    Iteration time: 3.89s
                        Total time: 13.73s
                               ETA: 9145.9s
################################################################################
                      [1m Learning iteration 3/2000 [0m                       

                       Computation: 1839 steps/s (collection: 3.132s, learning 0.782s)
               Value function loss: 69.4787
                    Surrogate loss: -0.0035
             Mean action noise std: 1.00
                       Mean reward: -55.55
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 28800
                    Iteration time: 3.91s
                        Total time: 17.65s
                               ETA: 8810.1s
################################################################################
                      [1m Learning iteration 4/2000 [0m                       

                       Computation: 1901 steps/s (collection: 3.042s, learning 0.745s)
               Value function loss: 76.6303
                    Surrogate loss: -0.0057
             Mean action noise std: 1.00
                       Mean reward: -55.72
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 36000
                    Iteration time: 3.79s
                        Total time: 21.43s
                               ETA: 8556.3s
################################################################################
                      [1m Learning iteration 5/2000 [0m                       

                       Computation: 1838 steps/s (collection: 3.048s, learning 0.868s)
               Value function loss: 59.9183
                    Surrogate loss: 0.0016
             Mean action noise std: 1.00
                       Mean reward: -55.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 43200
                    Iteration time: 3.92s
                        Total time: 25.35s
                               ETA: 8428.7s
################################################################################
                      [1m Learning iteration 6/2000 [0m                       

                       Computation: 1916 steps/s (collection: 3.136s, learning 0.622s)
               Value function loss: 58.3303
                    Surrogate loss: -0.0043
             Mean action noise std: 1.00
                       Mean reward: -55.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 50400
                    Iteration time: 3.76s
                        Total time: 29.11s
                               ETA: 8291.3s
################################################################################
                      [1m Learning iteration 7/2000 [0m                       

                       Computation: 1881 steps/s (collection: 3.212s, learning 0.615s)
               Value function loss: 50.1596
                    Surrogate loss: -0.0037
             Mean action noise std: 1.00
                       Mean reward: -55.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 57600
                    Iteration time: 3.83s
                        Total time: 32.93s
                               ETA: 8204.6s
################################################################################
                      [1m Learning iteration 8/2000 [0m                       

                       Computation: 1932 steps/s (collection: 3.098s, learning 0.627s)
               Value function loss: 48.1750
                    Surrogate loss: -0.0042
             Mean action noise std: 0.99
                       Mean reward: -55.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 64800
                    Iteration time: 3.72s
                        Total time: 36.66s
                               ETA: 8113.7s
################################################################################
                      [1m Learning iteration 9/2000 [0m                       

                       Computation: 1894 steps/s (collection: 3.177s, learning 0.624s)
               Value function loss: 46.1737
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -55.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 72000
                    Iteration time: 3.80s
                        Total time: 40.46s
                               ETA: 8055.5s
################################################################################
                      [1m Learning iteration 10/2000 [0m                      

                       Computation: 1924 steps/s (collection: 3.122s, learning 0.619s)
               Value function loss: 49.5829
                    Surrogate loss: -0.0049
             Mean action noise std: 0.99
                       Mean reward: -55.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 79200
                    Iteration time: 3.74s
                        Total time: 44.20s
                               ETA: 7996.3s
################################################################################
                      [1m Learning iteration 11/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.111s, learning 0.616s)
               Value function loss: 58.2134
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -55.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 86400
                    Iteration time: 3.73s
                        Total time: 47.93s
                               ETA: 7944.0s
################################################################################
                      [1m Learning iteration 12/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.102s, learning 0.659s)
               Value function loss: 47.5025
                    Surrogate loss: 0.0007
             Mean action noise std: 0.99
                       Mean reward: -56.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 93600
                    Iteration time: 3.76s
                        Total time: 51.69s
                               ETA: 7904.4s
################################################################################
                      [1m Learning iteration 13/2000 [0m                      

                       Computation: 1932 steps/s (collection: 3.129s, learning 0.596s)
               Value function loss: 52.7263
                    Surrogate loss: -0.0032
             Mean action noise std: 0.99
                       Mean reward: -56.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 100800
                    Iteration time: 3.73s
                        Total time: 55.41s
                               ETA: 7864.8s
################################################################################
                      [1m Learning iteration 14/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.113s, learning 0.754s)
               Value function loss: 57.3124
                    Surrogate loss: -0.0038
             Mean action noise std: 0.99
                       Mean reward: -56.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 108000
                    Iteration time: 3.87s
                        Total time: 59.28s
                               ETA: 7848.8s
################################################################################
                      [1m Learning iteration 15/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.062s, learning 0.675s)
               Value function loss: 43.4845
                    Surrogate loss: -0.0045
             Mean action noise std: 0.99
                       Mean reward: -56.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 115200
                    Iteration time: 3.74s
                        Total time: 63.02s
                               ETA: 7818.2s
################################################################################
                      [1m Learning iteration 16/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.176s, learning 0.640s)
               Value function loss: 44.4359
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 122400
                    Iteration time: 3.82s
                        Total time: 66.83s
                               ETA: 7800.0s
################################################################################
                      [1m Learning iteration 17/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.056s, learning 0.671s)
               Value function loss: 42.2122
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -54.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 129600
                    Iteration time: 3.73s
                        Total time: 70.56s
                               ETA: 7773.6s
################################################################################
                      [1m Learning iteration 18/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.127s, learning 0.669s)
               Value function loss: 41.1112
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -54.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 136800
                    Iteration time: 3.80s
                        Total time: 74.36s
                               ETA: 7756.7s
################################################################################
                      [1m Learning iteration 19/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.149s, learning 0.693s)
               Value function loss: 43.5620
                    Surrogate loss: -0.0051
             Mean action noise std: 0.99
                       Mean reward: -54.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 144000
                    Iteration time: 3.84s
                        Total time: 78.20s
                               ETA: 7745.7s
################################################################################
                      [1m Learning iteration 20/2000 [0m                      

                       Computation: 1919 steps/s (collection: 3.120s, learning 0.631s)
               Value function loss: 34.2933
                    Surrogate loss: 0.0097
             Mean action noise std: 0.99
                       Mean reward: -54.33
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 151200
                    Iteration time: 3.75s
                        Total time: 81.95s
                               ETA: 7726.9s
################################################################################
                      [1m Learning iteration 21/2000 [0m                      

                       Computation: 1841 steps/s (collection: 3.278s, learning 0.631s)
               Value function loss: 46.9817
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -54.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 158400
                    Iteration time: 3.91s
                        Total time: 85.86s
                               ETA: 7723.6s
################################################################################
                      [1m Learning iteration 22/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.099s, learning 0.636s)
               Value function loss: 48.4932
                    Surrogate loss: 0.0012
             Mean action noise std: 0.99
                       Mean reward: -55.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 165600
                    Iteration time: 3.74s
                        Total time: 89.60s
                               ETA: 7705.3s
################################################################################
                      [1m Learning iteration 23/2000 [0m                      

                       Computation: 1877 steps/s (collection: 3.162s, learning 0.672s)
               Value function loss: 43.2159
                    Surrogate loss: -0.0033
             Mean action noise std: 0.99
                       Mean reward: -55.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 172800
                    Iteration time: 3.83s
                        Total time: 93.43s
                               ETA: 7696.3s
################################################################################
                      [1m Learning iteration 24/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.190s, learning 0.613s)
               Value function loss: 47.0554
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 180000
                    Iteration time: 3.80s
                        Total time: 97.23s
                               ETA: 7685.4s
################################################################################
                      [1m Learning iteration 25/2000 [0m                      

                       Computation: 1924 steps/s (collection: 3.124s, learning 0.617s)
               Value function loss: 47.8379
                    Surrogate loss: -0.0025
             Mean action noise std: 0.99
                       Mean reward: -55.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 187200
                    Iteration time: 3.74s
                        Total time: 100.98s
                               ETA: 7670.3s
################################################################################
                      [1m Learning iteration 26/2000 [0m                      

                       Computation: 1864 steps/s (collection: 3.126s, learning 0.736s)
               Value function loss: 38.4298
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -55.53
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 194400
                    Iteration time: 3.86s
                        Total time: 104.84s
                               ETA: 7664.9s
################################################################################
                      [1m Learning iteration 27/2000 [0m                      

                       Computation: 1919 steps/s (collection: 3.091s, learning 0.661s)
               Value function loss: 39.0335
                    Surrogate loss: -0.0024
             Mean action noise std: 0.99
                       Mean reward: -54.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 201600
                    Iteration time: 3.75s
                        Total time: 108.59s
                               ETA: 7651.7s
################################################################################
                      [1m Learning iteration 28/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.272s, learning 0.618s)
               Value function loss: 33.7753
                    Surrogate loss: -0.0058
             Mean action noise std: 0.99
                       Mean reward: -54.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 208800
                    Iteration time: 3.89s
                        Total time: 112.48s
                               ETA: 7648.6s
################################################################################
                      [1m Learning iteration 29/2000 [0m                      

                       Computation: 1912 steps/s (collection: 3.139s, learning 0.625s)
               Value function loss: 40.2645
                    Surrogate loss: -0.0073
             Mean action noise std: 0.99
                       Mean reward: -53.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 216000
                    Iteration time: 3.76s
                        Total time: 116.24s
                               ETA: 7637.3s
################################################################################
                      [1m Learning iteration 30/2000 [0m                      

                       Computation: 1902 steps/s (collection: 3.147s, learning 0.638s)
               Value function loss: 38.1285
                    Surrogate loss: -0.0027
             Mean action noise std: 0.99
                       Mean reward: -53.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 223200
                    Iteration time: 3.78s
                        Total time: 120.03s
                               ETA: 7627.7s
################################################################################
                      [1m Learning iteration 31/2000 [0m                      

                       Computation: 1901 steps/s (collection: 3.168s, learning 0.618s)
               Value function loss: 41.0155
                    Surrogate loss: -0.0043
             Mean action noise std: 0.99
                       Mean reward: -52.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 230400
                    Iteration time: 3.79s
                        Total time: 123.82s
                               ETA: 7618.6s
################################################################################
                      [1m Learning iteration 32/2000 [0m                      

                       Computation: 1917 steps/s (collection: 3.130s, learning 0.625s)
               Value function loss: 40.3199
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -53.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 237600
                    Iteration time: 3.75s
                        Total time: 127.57s
                               ETA: 7607.8s
################################################################################
                      [1m Learning iteration 33/2000 [0m                      

                       Computation: 1823 steps/s (collection: 3.284s, learning 0.665s)
               Value function loss: 38.3529
                    Surrogate loss: -0.0039
             Mean action noise std: 0.99
                       Mean reward: -52.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 244800
                    Iteration time: 3.95s
                        Total time: 131.52s
                               ETA: 7608.8s
################################################################################
                      [1m Learning iteration 0/2000 [0m                       

                       Computation: 1114 steps/s (collection: 5.711s, learning 0.746s)
               Value function loss: 87.6143
                    Surrogate loss: -0.0028
             Mean action noise std: 1.00
                       Mean reward: -55.21
               Mean episode length: 43.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7200
                    Iteration time: 6.46s
                        Total time: 6.46s
                               ETA: 12915.0s
################################################################################
                      [1m Learning iteration 1/2000 [0m                       

                       Computation: 1755 steps/s (collection: 3.290s, learning 0.811s)
               Value function loss: 60.9052
                    Surrogate loss: -0.0024
             Mean action noise std: 1.00
                       Mean reward: -55.22
               Mean episode length: 43.67
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 14400
                    Iteration time: 4.10s
                        Total time: 10.56s
                               ETA: 10553.9s
################################################################################
                      [1m Learning iteration 2/2000 [0m                       

                       Computation: 1798 steps/s (collection: 3.126s, learning 0.877s)
               Value function loss: 87.3786
                    Surrogate loss: -0.0007
             Mean action noise std: 1.00
                       Mean reward: -55.43
               Mean episode length: 44.20
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 21600
                    Iteration time: 4.00s
                        Total time: 14.56s
                               ETA: 9698.7s
################################################################################
                      [1m Learning iteration 3/2000 [0m                       

                       Computation: 1790 steps/s (collection: 3.165s, learning 0.856s)
               Value function loss: 69.4787
                    Surrogate loss: -0.0035
             Mean action noise std: 1.00
                       Mean reward: -55.55
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 28800
                    Iteration time: 4.02s
                        Total time: 18.58s
                               ETA: 9277.9s
################################################################################
                      [1m Learning iteration 4/2000 [0m                       

                       Computation: 1762 steps/s (collection: 3.114s, learning 0.970s)
               Value function loss: 76.6303
                    Surrogate loss: -0.0057
             Mean action noise std: 1.00
                       Mean reward: -55.72
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 36000
                    Iteration time: 4.08s
                        Total time: 22.67s
                               ETA: 9049.1s
################################################################################
                      [1m Learning iteration 5/2000 [0m                       

                       Computation: 1876 steps/s (collection: 3.106s, learning 0.731s)
               Value function loss: 59.9183
                    Surrogate loss: 0.0016
             Mean action noise std: 1.00
                       Mean reward: -55.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 43200
                    Iteration time: 3.84s
                        Total time: 26.51s
                               ETA: 8813.0s
################################################################################
                      [1m Learning iteration 6/2000 [0m                       

                       Computation: 1835 steps/s (collection: 3.249s, learning 0.673s)
               Value function loss: 58.3303
                    Surrogate loss: -0.0043
             Mean action noise std: 1.00
                       Mean reward: -55.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 50400
                    Iteration time: 3.92s
                        Total time: 30.43s
                               ETA: 8667.5s
################################################################################
                      [1m Learning iteration 7/2000 [0m                       

                       Computation: 1853 steps/s (collection: 3.077s, learning 0.808s)
               Value function loss: 50.1596
                    Surrogate loss: -0.0037
             Mean action noise std: 1.00
                       Mean reward: -55.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 57600
                    Iteration time: 3.88s
                        Total time: 34.31s
                               ETA: 8548.1s
################################################################################
                      [1m Learning iteration 8/2000 [0m                       

                       Computation: 1860 steps/s (collection: 3.174s, learning 0.696s)
               Value function loss: 48.1750
                    Surrogate loss: -0.0042
             Mean action noise std: 0.99
                       Mean reward: -55.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 64800
                    Iteration time: 3.87s
                        Total time: 38.18s
                               ETA: 8451.2s
################################################################################
                      [1m Learning iteration 9/2000 [0m                       

                       Computation: 1898 steps/s (collection: 3.114s, learning 0.679s)
               Value function loss: 46.1737
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -55.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 72000
                    Iteration time: 3.79s
                        Total time: 41.98s
                               ETA: 8357.4s
################################################################################
                      [1m Learning iteration 10/2000 [0m                      

                       Computation: 1911 steps/s (collection: 3.084s, learning 0.681s)
               Value function loss: 49.5829
                    Surrogate loss: -0.0049
             Mean action noise std: 0.99
                       Mean reward: -55.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 79200
                    Iteration time: 3.77s
                        Total time: 45.74s
                               ETA: 8275.1s
################################################################################
                      [1m Learning iteration 11/2000 [0m                      

                       Computation: 1827 steps/s (collection: 3.251s, learning 0.688s)
               Value function loss: 58.2134
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -55.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 86400
                    Iteration time: 3.94s
                        Total time: 49.68s
                               ETA: 8234.6s
################################################################################
                      [1m Learning iteration 12/2000 [0m                      

                       Computation: 1906 steps/s (collection: 3.100s, learning 0.676s)
               Value function loss: 47.5025
                    Surrogate loss: 0.0007
             Mean action noise std: 0.99
                       Mean reward: -56.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 93600
                    Iteration time: 3.78s
                        Total time: 53.46s
                               ETA: 8174.8s
################################################################################
                      [1m Learning iteration 13/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.212s, learning 0.640s)
               Value function loss: 52.7263
                    Surrogate loss: -0.0032
             Mean action noise std: 0.99
                       Mean reward: -56.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 100800
                    Iteration time: 3.85s
                        Total time: 57.31s
                               ETA: 8133.7s
################################################################################
                      [1m Learning iteration 14/2000 [0m                      

                       Computation: 1907 steps/s (collection: 3.097s, learning 0.678s)
               Value function loss: 57.3124
                    Surrogate loss: -0.0038
             Mean action noise std: 0.99
                       Mean reward: -56.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 108000
                    Iteration time: 3.78s
                        Total time: 61.08s
                               ETA: 8087.4s
################################################################################
                      [1m Learning iteration 15/2000 [0m                      

                       Computation: 1908 steps/s (collection: 3.123s, learning 0.650s)
               Value function loss: 43.4845
                    Surrogate loss: -0.0045
             Mean action noise std: 0.99
                       Mean reward: -56.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 115200
                    Iteration time: 3.77s
                        Total time: 64.86s
                               ETA: 8046.2s
################################################################################
                      [1m Learning iteration 16/2000 [0m                      

                       Computation: 1890 steps/s (collection: 3.164s, learning 0.645s)
               Value function loss: 44.4359
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 122400
                    Iteration time: 3.81s
                        Total time: 68.66s
                               ETA: 8013.6s
################################################################################
                      [1m Learning iteration 17/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.108s, learning 0.711s)
               Value function loss: 42.2122
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -54.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 129600
                    Iteration time: 3.82s
                        Total time: 72.48s
                               ETA: 7985.2s
################################################################################
                      [1m Learning iteration 18/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.184s, learning 0.769s)
               Value function loss: 41.1112
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -54.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 136800
                    Iteration time: 3.95s
                        Total time: 76.44s
                               ETA: 7973.6s
################################################################################
                      [1m Learning iteration 19/2000 [0m                      

                       Computation: 1847 steps/s (collection: 3.132s, learning 0.766s)
               Value function loss: 43.5620
                    Surrogate loss: -0.0051
             Mean action noise std: 0.99
                       Mean reward: -54.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 144000
                    Iteration time: 3.90s
                        Total time: 80.33s
                               ETA: 7957.1s
################################################################################
                      [1m Learning iteration 20/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.187s, learning 0.641s)
               Value function loss: 34.2933
                    Surrogate loss: 0.0097
             Mean action noise std: 0.99
                       Mean reward: -54.33
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 151200
                    Iteration time: 3.83s
                        Total time: 84.16s
                               ETA: 7935.4s
################################################################################
                      [1m Learning iteration 21/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.137s, learning 0.706s)
               Value function loss: 46.9817
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -54.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 158400
                    Iteration time: 3.84s
                        Total time: 88.01s
                               ETA: 7916.5s
################################################################################
                      [1m Learning iteration 22/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.076s, learning 0.740s)
               Value function loss: 48.4932
                    Surrogate loss: 0.0012
             Mean action noise std: 0.99
                       Mean reward: -55.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 165600
                    Iteration time: 3.82s
                        Total time: 91.82s
                               ETA: 7896.8s
################################################################################
                      [1m Learning iteration 23/2000 [0m                      

                       Computation: 1828 steps/s (collection: 3.188s, learning 0.749s)
               Value function loss: 43.2159
                    Surrogate loss: -0.0033
             Mean action noise std: 0.99
                       Mean reward: -55.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 172800
                    Iteration time: 3.94s
                        Total time: 95.76s
                               ETA: 7888.3s
################################################################################
                      [1m Learning iteration 24/2000 [0m                      

                       Computation: 1895 steps/s (collection: 3.150s, learning 0.647s)
               Value function loss: 47.0554
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 180000
                    Iteration time: 3.80s
                        Total time: 99.56s
                               ETA: 7869.1s
################################################################################
                      [1m Learning iteration 25/2000 [0m                      

                       Computation: 1842 steps/s (collection: 3.226s, learning 0.682s)
               Value function loss: 47.8379
                    Surrogate loss: -0.0025
             Mean action noise std: 0.99
                       Mean reward: -55.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 187200
                    Iteration time: 3.91s
                        Total time: 103.47s
                               ETA: 7859.5s
################################################################################
                      [1m Learning iteration 26/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.134s, learning 0.646s)
               Value function loss: 38.4298
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -55.53
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 194400
                    Iteration time: 3.78s
                        Total time: 107.25s
                               ETA: 7840.9s
################################################################################
                      [1m Learning iteration 27/2000 [0m                      

                       Computation: 1857 steps/s (collection: 3.134s, learning 0.742s)
               Value function loss: 39.0335
                    Surrogate loss: -0.0024
             Mean action noise std: 0.99
                       Mean reward: -54.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 201600
                    Iteration time: 3.88s
                        Total time: 111.12s
                               ETA: 7830.2s
################################################################################
                      [1m Learning iteration 28/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.162s, learning 0.722s)
               Value function loss: 33.7753
                    Surrogate loss: -0.0058
             Mean action noise std: 0.99
                       Mean reward: -54.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 208800
                    Iteration time: 3.88s
                        Total time: 115.01s
                               ETA: 7820.5s
################################################################################
                      [1m Learning iteration 29/2000 [0m                      

                       Computation: 1836 steps/s (collection: 3.139s, learning 0.781s)
               Value function loss: 40.2645
                    Surrogate loss: -0.0073
             Mean action noise std: 0.99
                       Mean reward: -53.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 216000
                    Iteration time: 3.92s
                        Total time: 118.93s
                               ETA: 7813.5s
################################################################################
                      [1m Learning iteration 30/2000 [0m                      

                       Computation: 1789 steps/s (collection: 3.223s, learning 0.801s)
               Value function loss: 38.1285
                    Surrogate loss: -0.0027
             Mean action noise std: 0.99
                       Mean reward: -53.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 223200
                    Iteration time: 4.02s
                        Total time: 122.95s
                               ETA: 7813.3s
################################################################################
                      [1m Learning iteration 31/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.119s, learning 0.708s)
               Value function loss: 41.0155
                    Surrogate loss: -0.0043
             Mean action noise std: 0.99
                       Mean reward: -52.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 230400
                    Iteration time: 3.83s
                        Total time: 126.78s
                               ETA: 7800.8s
################################################################################
                      [1m Learning iteration 32/2000 [0m                      

                       Computation: 1782 steps/s (collection: 3.211s, learning 0.829s)
               Value function loss: 40.3199
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -53.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 237600
                    Iteration time: 4.04s
                        Total time: 130.82s
                               ETA: 7801.5s
################################################################################
                      [1m Learning iteration 33/2000 [0m                      

                       Computation: 1801 steps/s (collection: 3.213s, learning 0.783s)
               Value function loss: 38.3529
                    Surrogate loss: -0.0039
             Mean action noise std: 0.99
                       Mean reward: -52.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 244800
                    Iteration time: 4.00s
                        Total time: 134.81s
                               ETA: 7799.4s
################################################################################
                      [1m Learning iteration 34/2000 [0m                      

                       Computation: 1890 steps/s (collection: 3.133s, learning 0.675s)
               Value function loss: 38.4416
                    Surrogate loss: 0.0076
             Mean action noise std: 0.99
                       Mean reward: -53.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 252000
                    Iteration time: 3.81s
                        Total time: 138.62s
                               ETA: 7786.6s
################################################################################
                      [1m Learning iteration 35/2000 [0m                      

                       Computation: 1784 steps/s (collection: 3.216s, learning 0.818s)
               Value function loss: 39.5888
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -53.10
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 259200
                    Iteration time: 4.03s
                        Total time: 142.66s
                               ETA: 7786.6s
################################################################################
                      [1m Learning iteration 36/2000 [0m                      

                       Computation: 1824 steps/s (collection: 3.125s, learning 0.822s)
               Value function loss: 41.4946
                    Surrogate loss: -0.0040
             Mean action noise std: 0.99
                       Mean reward: -53.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 266400
                    Iteration time: 3.95s
                        Total time: 146.60s
                               ETA: 7781.8s
################################################################################
                      [1m Learning iteration 37/2000 [0m                      

                       Computation: 1793 steps/s (collection: 3.179s, learning 0.836s)
               Value function loss: 38.0765
                    Surrogate loss: -0.0061
             Mean action noise std: 0.99
                       Mean reward: -52.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 273600
                    Iteration time: 4.01s
                        Total time: 150.62s
                               ETA: 7780.6s
################################################################################
                      [1m Learning iteration 38/2000 [0m                      

                       Computation: 1796 steps/s (collection: 3.159s, learning 0.848s)
               Value function loss: 44.5340
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -52.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 280800
                    Iteration time: 4.01s
                        Total time: 154.62s
                               ETA: 7778.8s
################################################################################
                      [1m Learning iteration 39/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.126s, learning 0.775s)
               Value function loss: 36.2183
                    Surrogate loss: 0.0018
             Mean action noise std: 0.99
                       Mean reward: -52.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 288000
                    Iteration time: 3.90s
                        Total time: 158.53s
                               ETA: 7771.7s
################################################################################
                      [1m Learning iteration 40/2000 [0m                      

                       Computation: 1770 steps/s (collection: 3.236s, learning 0.830s)
               Value function loss: 34.4764
                    Surrogate loss: -0.0010
             Mean action noise std: 0.99
                       Mean reward: -51.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 295200
                    Iteration time: 4.07s
                        Total time: 162.59s
                               ETA: 7772.7s
################################################################################
                      [1m Learning iteration 41/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.140s, learning 0.711s)
               Value function loss: 36.5184
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -51.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 302400
                    Iteration time: 3.85s
                        Total time: 166.44s
                               ETA: 7763.4s
################################################################################
                      [1m Learning iteration 42/2000 [0m                      

                       Computation: 1772 steps/s (collection: 3.199s, learning 0.863s)
               Value function loss: 39.0004
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -51.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 309600
                    Iteration time: 4.06s
                        Total time: 170.51s
                               ETA: 7764.0s
################################################################################
                      [1m Learning iteration 43/2000 [0m                      

                       Computation: 1795 steps/s (collection: 3.153s, learning 0.857s)
               Value function loss: 42.0665
                    Surrogate loss: -0.0017
             Mean action noise std: 0.99
                       Mean reward: -52.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 316800
                    Iteration time: 4.01s
                        Total time: 174.52s
                               ETA: 7762.0s
################################################################################
                      [1m Learning iteration 44/2000 [0m                      

                       Computation: 1831 steps/s (collection: 3.122s, learning 0.809s)
               Value function loss: 41.4940
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -52.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 324000
                    Iteration time: 3.93s
                        Total time: 178.45s
                               ETA: 7756.5s
################################################################################
                      [1m Learning iteration 45/2000 [0m                      

                       Computation: 1826 steps/s (collection: 3.178s, learning 0.764s)
               Value function loss: 33.4112
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -52.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 331200
                    Iteration time: 3.94s
                        Total time: 182.39s
                               ETA: 7751.5s
################################################################################
                      [1m Learning iteration 46/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.135s, learning 0.629s)
               Value function loss: 29.0818
                    Surrogate loss: 0.0185
             Mean action noise std: 0.99
                       Mean reward: -52.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 338400
                    Iteration time: 3.76s
                        Total time: 186.15s
                               ETA: 7739.2s
################################################################################
                      [1m Learning iteration 47/2000 [0m                      

                       Computation: 1831 steps/s (collection: 3.144s, learning 0.787s)
               Value function loss: 35.3084
                    Surrogate loss: 0.0096
             Mean action noise std: 0.99
                       Mean reward: -52.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 345600
                    Iteration time: 3.93s
                        Total time: 190.08s
                               ETA: 7734.0s
################################################################################
                      [1m Learning iteration 48/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.135s, learning 0.657s)
               Value function loss: 35.7524
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -51.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 352800
                    Iteration time: 3.79s
                        Total time: 193.88s
                               ETA: 7723.4s
################################################################################
                      [1m Learning iteration 49/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.128s, learning 0.740s)
               Value function loss: 33.0440
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -51.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 360000
                    Iteration time: 3.87s
                        Total time: 197.74s
                               ETA: 7716.0s
################################################################################
                      [1m Learning iteration 50/2000 [0m                      

                       Computation: 1837 steps/s (collection: 3.226s, learning 0.693s)
               Value function loss: 34.2946
                    Surrogate loss: -0.0047
             Mean action noise std: 0.99
                       Mean reward: -51.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 367200
                    Iteration time: 3.92s
                        Total time: 201.66s
                               ETA: 7710.7s
################################################################################
                      [1m Learning iteration 51/2000 [0m                      

                       Computation: 1851 steps/s (collection: 3.105s, learning 0.783s)
               Value function loss: 33.1621
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -51.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 374400
                    Iteration time: 3.89s
                        Total time: 205.55s
                               ETA: 7704.3s
################################################################################
                      [1m Learning iteration 52/2000 [0m                      

                       Computation: 1823 steps/s (collection: 3.154s, learning 0.795s)
               Value function loss: 33.1356
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -51.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 381600
                    Iteration time: 3.95s
                        Total time: 209.50s
                               ETA: 7700.2s
################################################################################
                      [1m Learning iteration 53/2000 [0m                      

                       Computation: 1893 steps/s (collection: 3.138s, learning 0.665s)
               Value function loss: 34.3554
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -51.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 388800
                    Iteration time: 3.80s
                        Total time: 213.30s
                               ETA: 7690.8s
################################################################################
                      [1m Learning iteration 54/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.129s, learning 0.761s)
               Value function loss: 32.2024
                    Surrogate loss: -0.0022
             Mean action noise std: 0.99
                       Mean reward: -51.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 396000
                    Iteration time: 3.89s
                        Total time: 217.19s
                               ETA: 7684.7s
################################################################################
                      [1m Learning iteration 55/2000 [0m                      

                       Computation: 1879 steps/s (collection: 3.143s, learning 0.687s)
               Value function loss: 33.4714
                    Surrogate loss: 0.0039
             Mean action noise std: 0.99
                       Mean reward: -51.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 403200
                    Iteration time: 3.83s
                        Total time: 221.02s
                               ETA: 7676.7s
################################################################################
                      [1m Learning iteration 56/2000 [0m                      

                       Computation: 1901 steps/s (collection: 3.118s, learning 0.669s)
               Value function loss: 29.8262
                    Surrogate loss: -0.0002
             Mean action noise std: 0.99
                       Mean reward: -51.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 410400
                    Iteration time: 3.79s
                        Total time: 224.81s
                               ETA: 7667.3s
################################################################################
                      [1m Learning iteration 57/2000 [0m                      

                       Computation: 1839 steps/s (collection: 3.195s, learning 0.719s)
               Value function loss: 32.3009
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -50.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 417600
                    Iteration time: 3.91s
                        Total time: 228.73s
                               ETA: 7662.3s
################################################################################
                      [1m Learning iteration 58/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.141s, learning 0.652s)
               Value function loss: 29.6770
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -50.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 424800
                    Iteration time: 3.79s
                        Total time: 232.52s
                               ETA: 7653.4s
################################################################################
                      [1m Learning iteration 59/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.184s, learning 0.720s)
               Value function loss: 27.6777
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -50.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 432000
                    Iteration time: 3.90s
                        Total time: 236.42s
                               ETA: 7648.3s
################################################################################
                      [1m Learning iteration 60/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.139s, learning 0.798s)
               Value function loss: 30.1422
                    Surrogate loss: -0.0003
             Mean action noise std: 0.99
                       Mean reward: -50.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 439200
                    Iteration time: 3.94s
                        Total time: 240.36s
                               ETA: 7644.2s
################################################################################
                      [1m Learning iteration 61/2000 [0m                      

                       Computation: 1866 steps/s (collection: 3.147s, learning 0.711s)
               Value function loss: 31.8961
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -50.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 446400
                    Iteration time: 3.86s
                        Total time: 244.22s
                               ETA: 7637.7s
################################################################################
                      [1m Learning iteration 62/2000 [0m                      

                       Computation: 1815 steps/s (collection: 3.135s, learning 0.832s)
               Value function loss: 33.4506
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -50.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 453600
                    Iteration time: 3.97s
                        Total time: 248.18s
                               ETA: 7634.6s
################################################################################
                      [1m Learning iteration 63/2000 [0m                      

                       Computation: 1856 steps/s (collection: 3.158s, learning 0.721s)
               Value function loss: 30.5063
                    Surrogate loss: -0.0029
             Mean action noise std: 0.98
                       Mean reward: -49.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 460800
                    Iteration time: 3.88s
                        Total time: 252.06s
                               ETA: 7628.8s
################################################################################
                      [1m Learning iteration 64/2000 [0m                      

                       Computation: 1789 steps/s (collection: 3.264s, learning 0.760s)
               Value function loss: 33.2652
                    Surrogate loss: -0.0063
             Mean action noise std: 0.98
                       Mean reward: -49.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 468000
                    Iteration time: 4.02s
                        Total time: 256.09s
                               ETA: 7627.4s
################################################################################
                      [1m Learning iteration 65/2000 [0m                      

                       Computation: 1835 steps/s (collection: 3.149s, learning 0.773s)
               Value function loss: 31.3134
                    Surrogate loss: -0.0074
             Mean action noise std: 0.98
                       Mean reward: -50.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 475200
                    Iteration time: 3.92s
                        Total time: 260.01s
                               ETA: 7623.0s
################################################################################
                      [1m Learning iteration 66/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.155s, learning 0.698s)
               Value function loss: 35.0529
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 482400
                    Iteration time: 3.85s
                        Total time: 263.86s
                               ETA: 7616.5s
################################################################################
                      [1m Learning iteration 67/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.232s, learning 0.671s)
               Value function loss: 30.9591
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -50.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 489600
                    Iteration time: 3.90s
                        Total time: 267.76s
                               ETA: 7611.6s
################################################################################
                      [1m Learning iteration 68/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.148s, learning 0.675s)
               Value function loss: 31.7109
                    Surrogate loss: -0.0084
             Mean action noise std: 0.98
                       Mean reward: -49.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 496800
                    Iteration time: 3.82s
                        Total time: 271.59s
                               ETA: 7604.4s
################################################################################
                      [1m Learning iteration 69/2000 [0m                      

                       Computation: 1828 steps/s (collection: 3.253s, learning 0.686s)
               Value function loss: 29.9669
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 504000
                    Iteration time: 3.94s
                        Total time: 275.53s
                               ETA: 7600.6s
################################################################################
                      [1m Learning iteration 70/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.145s, learning 0.665s)
               Value function loss: 30.2034
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 511200
                    Iteration time: 3.81s
                        Total time: 279.33s
                               ETA: 7593.2s
################################################################################
                      [1m Learning iteration 71/2000 [0m                      

                       Computation: 1857 steps/s (collection: 3.171s, learning 0.705s)
               Value function loss: 32.5000
                    Surrogate loss: -0.0026
             Mean action noise std: 0.98
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 518400
                    Iteration time: 3.88s
                        Total time: 283.21s
                               ETA: 7587.7s
################################################################################
                      [1m Learning iteration 72/2000 [0m                      

                       Computation: 1856 steps/s (collection: 3.233s, learning 0.644s)
               Value function loss: 34.1269
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 525600
                    Iteration time: 3.88s
                        Total time: 287.09s
                               ETA: 7582.3s
################################################################################
                      [1m Learning iteration 73/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.141s, learning 0.672s)
               Value function loss: 31.0529
                    Surrogate loss: -0.0057
             Mean action noise std: 0.98
                       Mean reward: -50.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 532800
                    Iteration time: 3.81s
                        Total time: 290.90s
                               ETA: 7575.2s
################################################################################
                      [1m Learning iteration 74/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.278s, learning 0.676s)
               Value function loss: 28.5101
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -49.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 540000
                    Iteration time: 3.95s
                        Total time: 294.85s
                               ETA: 7571.9s
################################################################################
                      [1m Learning iteration 75/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.157s, learning 0.659s)
               Value function loss: 32.0992
                    Surrogate loss: -0.0059
             Mean action noise std: 0.98
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 547200
                    Iteration time: 3.82s
                        Total time: 298.67s
                               ETA: 7565.0s
################################################################################
                      [1m Learning iteration 76/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.214s, learning 0.703s)
               Value function loss: 31.4500
                    Surrogate loss: -0.0063
             Mean action noise std: 0.98
                       Mean reward: -49.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 554400
                    Iteration time: 3.92s
                        Total time: 302.59s
                               ETA: 7560.8s
################################################################################
                      [1m Learning iteration 77/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.151s, learning 0.682s)
               Value function loss: 30.3769
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 561600
                    Iteration time: 3.83s
                        Total time: 306.42s
                               ETA: 7554.4s
################################################################################
                      [1m Learning iteration 78/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.170s, learning 0.678s)
               Value function loss: 32.6787
                    Surrogate loss: -0.0048
             Mean action noise std: 0.98
                       Mean reward: -49.25
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 568800
                    Iteration time: 3.85s
                        Total time: 310.27s
                               ETA: 7548.5s
################################################################################
                      [1m Learning iteration 79/2000 [0m                      

                       Computation: 1841 steps/s (collection: 3.234s, learning 0.677s)
               Value function loss: 29.4594
                    Surrogate loss: -0.0066
             Mean action noise std: 0.98
                       Mean reward: -49.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 576000
                    Iteration time: 3.91s
                        Total time: 314.18s
                               ETA: 7544.2s
################################################################################
                      [1m Learning iteration 80/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.085s, learning 0.741s)
               Value function loss: 31.4366
                    Surrogate loss: -0.0033
             Mean action noise std: 0.98
                       Mean reward: -50.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 583200
                    Iteration time: 3.83s
                        Total time: 318.00s
                               ETA: 7537.9s
################################################################################
                      [1m Learning iteration 81/2000 [0m                      

                       Computation: 1817 steps/s (collection: 3.277s, learning 0.685s)
               Value function loss: 31.4435
                    Surrogate loss: 0.0025
             Mean action noise std: 0.97
                       Mean reward: -50.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 590400
                    Iteration time: 3.96s
                        Total time: 321.97s
                               ETA: 7534.8s
################################################################################
                      [1m Learning iteration 82/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.132s, learning 0.629s)
               Value function loss: 27.2720
                    Surrogate loss: -0.0026
             Mean action noise std: 0.97
                       Mean reward: -50.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 597600
                    Iteration time: 3.76s
                        Total time: 325.73s
                               ETA: 7527.1s
################################################################################
                      [1m Learning iteration 83/2000 [0m                      

                       Computation: 1849 steps/s (collection: 3.157s, learning 0.736s)
               Value function loss: 24.7333
                    Surrogate loss: 0.0035
             Mean action noise std: 0.97
                       Mean reward: -50.28
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 604800
                    Iteration time: 3.89s
                        Total time: 329.62s
                               ETA: 7522.4s
################################################################################
                      [1m Learning iteration 84/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.131s, learning 0.740s)
               Value function loss: 30.4519
                    Surrogate loss: -0.0006
             Mean action noise std: 0.97
                       Mean reward: -49.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 612000
                    Iteration time: 3.87s
                        Total time: 333.49s
                               ETA: 7517.3s
################################################################################
                      [1m Learning iteration 85/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.133s, learning 0.691s)
               Value function loss: 27.7287
                    Surrogate loss: 0.0006
             Mean action noise std: 0.97
                       Mean reward: -49.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 619200
                    Iteration time: 3.82s
                        Total time: 337.32s
                               ETA: 7511.2s
################################################################################
                      [1m Learning iteration 86/2000 [0m                      

                       Computation: 1824 steps/s (collection: 3.262s, learning 0.684s)
               Value function loss: 24.4723
                    Surrogate loss: -0.0016
             Mean action noise std: 0.97
                       Mean reward: -49.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 626400
                    Iteration time: 3.95s
                        Total time: 341.26s
                               ETA: 7507.8s
################################################################################
                      [1m Learning iteration 87/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.131s, learning 0.717s)
               Value function loss: 32.0193
                    Surrogate loss: -0.0001
             Mean action noise std: 0.97
                       Mean reward: -48.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 633600
                    Iteration time: 3.85s
                        Total time: 345.11s
                               ETA: 7502.2s
################################################################################
                      [1m Learning iteration 88/2000 [0m                      

                       Computation: 1841 steps/s (collection: 3.250s, learning 0.658s)
               Value function loss: 28.3677
                    Surrogate loss: -0.0040
             Mean action noise std: 0.97
                       Mean reward: -49.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 640800
                    Iteration time: 3.91s
                        Total time: 349.02s
                               ETA: 7498.0s
################################################################################
                      [1m Learning iteration 89/2000 [0m                      

                       Computation: 1858 steps/s (collection: 3.169s, learning 0.705s)
               Value function loss: 29.8453
                    Surrogate loss: -0.0028
             Mean action noise std: 0.97
                       Mean reward: -50.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 648000
                    Iteration time: 3.87s
                        Total time: 352.89s
                               ETA: 7493.1s
################################################################################
                      [1m Learning iteration 90/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.136s, learning 0.702s)
               Value function loss: 25.7069
                    Surrogate loss: -0.0019
             Mean action noise std: 0.97
                       Mean reward: -49.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 655200
                    Iteration time: 3.84s
                        Total time: 356.73s
                               ETA: 7487.4s
################################################################################
                      [1m Learning iteration 91/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.139s, learning 0.699s)
               Value function loss: 28.5759
                    Surrogate loss: -0.0049
             Mean action noise std: 0.97
                       Mean reward: -49.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 662400
                    Iteration time: 3.84s
                        Total time: 360.57s
                               ETA: 7481.8s
################################################################################
                      [1m Learning iteration 92/2000 [0m                      

                       Computation: 1900 steps/s (collection: 3.147s, learning 0.642s)
               Value function loss: 25.1321
                    Surrogate loss: -0.0003
             Mean action noise std: 0.97
                       Mean reward: -50.02
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 669600
                    Iteration time: 3.79s
                        Total time: 364.36s
                               ETA: 7475.2s
################################################################################
                      [1m Learning iteration 93/2000 [0m                      

                       Computation: 1831 steps/s (collection: 3.274s, learning 0.656s)
               Value function loss: 26.4642
                    Surrogate loss: -0.0053
             Mean action noise std: 0.97
                       Mean reward: -49.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 676800
                    Iteration time: 3.93s
                        Total time: 368.29s
                               ETA: 7471.6s
################################################################################
                      [1m Learning iteration 94/2000 [0m                      

                       Computation: 1858 steps/s (collection: 3.136s, learning 0.738s)
               Value function loss: 26.6313
                    Surrogate loss: -0.0059
             Mean action noise std: 0.97
                       Mean reward: -48.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 684000
                    Iteration time: 3.87s
                        Total time: 372.16s
                               ETA: 7466.8s
################################################################################
                      [1m Learning iteration 95/2000 [0m                      

                       Computation: 1830 steps/s (collection: 3.227s, learning 0.707s)
               Value function loss: 25.3491
                    Surrogate loss: 0.0016
             Mean action noise std: 0.97
                       Mean reward: -49.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 691200
                    Iteration time: 3.93s
                        Total time: 376.10s
                               ETA: 7463.2s
################################################################################
                      [1m Learning iteration 96/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.118s, learning 0.629s)
               Value function loss: 28.1155
                    Surrogate loss: 0.0093
             Mean action noise std: 0.98
                       Mean reward: -49.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 698400
                    Iteration time: 3.75s
                        Total time: 379.84s
                               ETA: 7455.9s
################################################################################
                      [1m Learning iteration 97/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.171s, learning 0.676s)
               Value function loss: 23.7082
                    Surrogate loss: -0.0052
             Mean action noise std: 0.98
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 705600
                    Iteration time: 3.85s
                        Total time: 383.69s
                               ETA: 7450.6s
################################################################################
                      [1m Learning iteration 98/2000 [0m                      

                       Computation: 1831 steps/s (collection: 3.249s, learning 0.681s)
               Value function loss: 26.0409
                    Surrogate loss: -0.0017
             Mean action noise std: 0.98
                       Mean reward: -49.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 712800
                    Iteration time: 3.93s
                        Total time: 387.62s
                               ETA: 7447.0s
################################################################################
                      [1m Learning iteration 99/2000 [0m                      

                       Computation: 1901 steps/s (collection: 3.131s, learning 0.656s)
               Value function loss: 27.1381
                    Surrogate loss: 0.0020
             Mean action noise std: 0.98
                       Mean reward: -49.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 720000
                    Iteration time: 3.79s
                        Total time: 391.41s
                               ETA: 7440.7s
################################################################################
                     [1m Learning iteration 100/2000 [0m                      

                       Computation: 1833 steps/s (collection: 3.260s, learning 0.668s)
               Value function loss: 26.2942
                    Surrogate loss: -0.0006
             Mean action noise std: 0.98
                       Mean reward: -49.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 727200
                    Iteration time: 3.93s
                        Total time: 395.33s
                               ETA: 7437.0s
################################################################################
                     [1m Learning iteration 101/2000 [0m                      

                       Computation: 1894 steps/s (collection: 3.119s, learning 0.681s)
               Value function loss: 28.5187
                    Surrogate loss: 0.0052
             Mean action noise std: 0.98
                       Mean reward: -48.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 734400
                    Iteration time: 3.80s
                        Total time: 399.13s
                               ETA: 7430.9s
################################################################################
                     [1m Learning iteration 102/2000 [0m                      

                       Computation: 1835 steps/s (collection: 3.154s, learning 0.769s)
               Value function loss: 27.8748
                    Surrogate loss: 0.0123
             Mean action noise std: 0.98
                       Mean reward: -48.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 741600
                    Iteration time: 3.92s
                        Total time: 403.06s
                               ETA: 7427.2s
################################################################################
                     [1m Learning iteration 103/2000 [0m                      

                       Computation: 1864 steps/s (collection: 3.172s, learning 0.691s)
               Value function loss: 25.6303
                    Surrogate loss: -0.0047
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 748800
                    Iteration time: 3.86s
                        Total time: 406.92s
                               ETA: 7422.4s
################################################################################
                     [1m Learning iteration 104/2000 [0m                      

                       Computation: 1833 steps/s (collection: 3.147s, learning 0.781s)
               Value function loss: 26.0222
                    Surrogate loss: -0.0057
             Mean action noise std: 0.98
                       Mean reward: -48.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 756000
                    Iteration time: 3.93s
                        Total time: 410.85s
                               ETA: 7418.7s
################################################################################
                     [1m Learning iteration 105/2000 [0m                      

                       Computation: 1833 steps/s (collection: 3.291s, learning 0.636s)
               Value function loss: 23.4744
                    Surrogate loss: -0.0027
             Mean action noise std: 0.98
                       Mean reward: -48.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 763200
                    Iteration time: 3.93s
                        Total time: 414.78s
                               ETA: 7415.1s
################################################################################
                     [1m Learning iteration 106/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.154s, learning 0.675s)
               Value function loss: 24.8079
                    Surrogate loss: 0.0012
             Mean action noise std: 0.98
                       Mean reward: -49.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 770400
                    Iteration time: 3.83s
                        Total time: 418.60s
                               ETA: 7409.7s
################################################################################
                     [1m Learning iteration 107/2000 [0m                      

                       Computation: 1817 steps/s (collection: 3.281s, learning 0.681s)
               Value function loss: 24.6536
                    Surrogate loss: -0.0047
             Mean action noise std: 0.98
                       Mean reward: -49.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 777600
                    Iteration time: 3.96s
                        Total time: 422.57s
                               ETA: 7406.6s
################################################################################
                     [1m Learning iteration 108/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.160s, learning 0.707s)
               Value function loss: 23.5256
                    Surrogate loss: -0.0065
             Mean action noise std: 0.98
                       Mean reward: -49.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 784800
                    Iteration time: 3.87s
                        Total time: 426.43s
                               ETA: 7401.9s
################################################################################
                     [1m Learning iteration 109/2000 [0m                      

                       Computation: 1872 steps/s (collection: 3.163s, learning 0.683s)
               Value function loss: 26.3820
                    Surrogate loss: -0.0037
             Mean action noise std: 0.98
                       Mean reward: -49.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 792000
                    Iteration time: 3.85s
                        Total time: 430.28s
                               ETA: 7396.9s
################################################################################
                     [1m Learning iteration 110/2000 [0m                      

                       Computation: 1831 steps/s (collection: 3.240s, learning 0.692s)
               Value function loss: 25.5668
                    Surrogate loss: -0.0080
             Mean action noise std: 0.98
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 799200
                    Iteration time: 3.93s
                        Total time: 434.21s
                               ETA: 7393.3s
################################################################################
                     [1m Learning iteration 111/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.133s, learning 0.672s)
               Value function loss: 26.6566
                    Surrogate loss: -0.0052
             Mean action noise std: 0.98
                       Mean reward: -48.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 806400
                    Iteration time: 3.81s
                        Total time: 438.02s
                               ETA: 7387.6s
################################################################################
                     [1m Learning iteration 112/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.249s, learning 0.667s)
               Value function loss: 27.0673
                    Surrogate loss: -0.0049
             Mean action noise std: 0.98
                       Mean reward: -49.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 813600
                    Iteration time: 3.92s
                        Total time: 441.93s
                               ETA: 7383.8s
################################################################################
                     [1m Learning iteration 113/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.188s, learning 0.633s)
               Value function loss: 24.0829
                    Surrogate loss: -0.0058
             Mean action noise std: 0.98
                       Mean reward: -50.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 820800
                    Iteration time: 3.82s
                        Total time: 445.75s
                               ETA: 7378.4s
################################################################################
                     [1m Learning iteration 114/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.139s, learning 0.708s)
               Value function loss: 23.7772
                    Surrogate loss: -0.0040
             Mean action noise std: 0.98
                       Mean reward: -50.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 828000
                    Iteration time: 3.85s
                        Total time: 449.60s
                               ETA: 7373.4s
################################################################################
                     [1m Learning iteration 115/2000 [0m                      

                       Computation: 1774 steps/s (collection: 3.263s, learning 0.794s)
               Value function loss: 24.7225
                    Surrogate loss: -0.0034
             Mean action noise std: 0.98
                       Mean reward: -50.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 835200
                    Iteration time: 4.06s
                        Total time: 453.66s
                               ETA: 7371.9s
################################################################################
                     [1m Learning iteration 116/2000 [0m                      

                       Computation: 1830 steps/s (collection: 3.135s, learning 0.799s)
               Value function loss: 27.2398
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -50.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 842400
                    Iteration time: 3.93s
                        Total time: 457.59s
                               ETA: 7368.4s
################################################################################
                     [1m Learning iteration 117/2000 [0m                      

                       Computation: 1766 steps/s (collection: 3.243s, learning 0.833s)
               Value function loss: 24.7676
                    Surrogate loss: -0.0052
             Mean action noise std: 0.98
                       Mean reward: -49.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 849600
                    Iteration time: 4.08s
                        Total time: 461.67s
                               ETA: 7367.1s
################################################################################
                     [1m Learning iteration 118/2000 [0m                      

                       Computation: 1806 steps/s (collection: 3.163s, learning 0.822s)
               Value function loss: 23.6692
                    Surrogate loss: -0.0036
             Mean action noise std: 0.98
                       Mean reward: -49.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 856800
                    Iteration time: 3.99s
                        Total time: 465.65s
                               ETA: 7364.3s
################################################################################
                     [1m Learning iteration 119/2000 [0m                      

                       Computation: 1824 steps/s (collection: 3.155s, learning 0.792s)
               Value function loss: 26.7770
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 864000
                    Iteration time: 3.95s
                        Total time: 469.60s
                               ETA: 7360.9s
################################################################################
                     [1m Learning iteration 120/2000 [0m                      

                       Computation: 1773 steps/s (collection: 3.296s, learning 0.763s)
               Value function loss: 25.6117
                    Surrogate loss: -0.0023
             Mean action noise std: 0.98
                       Mean reward: -49.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 871200
                    Iteration time: 4.06s
                        Total time: 473.66s
                               ETA: 7359.3s
################################################################################
                     [1m Learning iteration 121/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.138s, learning 0.683s)
               Value function loss: 24.0778
                    Surrogate loss: -0.0024
             Mean action noise std: 0.98
                       Mean reward: -49.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 878400
                    Iteration time: 3.82s
                        Total time: 477.48s
                               ETA: 7353.9s
################################################################################
                     [1m Learning iteration 122/2000 [0m                      

                       Computation: 1825 steps/s (collection: 3.287s, learning 0.657s)
               Value function loss: 26.9927
                    Surrogate loss: -0.0057
             Mean action noise std: 0.98
                       Mean reward: -49.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 885600
                    Iteration time: 3.94s
                        Total time: 481.42s
                               ETA: 7350.5s
################################################################################
                     [1m Learning iteration 123/2000 [0m                      

                       Computation: 1868 steps/s (collection: 3.158s, learning 0.695s)
               Value function loss: 26.7252
                    Surrogate loss: -0.0059
             Mean action noise std: 0.98
                       Mean reward: -49.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 892800
                    Iteration time: 3.85s
                        Total time: 485.27s
                               ETA: 7345.6s
################################################################################
                     [1m Learning iteration 124/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.149s, learning 0.742s)
               Value function loss: 27.0006
                    Surrogate loss: -0.0048
             Mean action noise std: 0.98
                       Mean reward: -49.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 900000
                    Iteration time: 3.89s
                        Total time: 489.17s
                               ETA: 7341.4s
################################################################################
                     [1m Learning iteration 125/2000 [0m                      

                       Computation: 1792 steps/s (collection: 3.133s, learning 0.884s)
               Value function loss: 27.6821
                    Surrogate loss: -0.0002
             Mean action noise std: 0.98
                       Mean reward: -49.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 907200
                    Iteration time: 4.02s
                        Total time: 493.18s
                               ETA: 7339.0s
################################################################################
                     [1m Learning iteration 126/2000 [0m                      

                       Computation: 1834 steps/s (collection: 3.164s, learning 0.760s)
               Value function loss: 25.2490
                    Surrogate loss: -0.0013
             Mean action noise std: 0.98
                       Mean reward: -49.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 914400
                    Iteration time: 3.92s
                        Total time: 497.11s
                               ETA: 7335.2s
################################################################################
                     [1m Learning iteration 127/2000 [0m                      

                       Computation: 1767 steps/s (collection: 3.279s, learning 0.794s)
               Value function loss: 23.9829
                    Surrogate loss: -0.0044
             Mean action noise std: 0.98
                       Mean reward: -50.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 921600
                    Iteration time: 4.07s
                        Total time: 501.18s
                               ETA: 7333.7s
################################################################################
                     [1m Learning iteration 128/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.157s, learning 0.745s)
               Value function loss: 26.1981
                    Surrogate loss: 0.0020
             Mean action noise std: 0.98
                       Mean reward: -49.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 928800
                    Iteration time: 3.90s
                        Total time: 505.08s
                               ETA: 7329.6s
################################################################################
                     [1m Learning iteration 129/2000 [0m                      

                       Computation: 1815 steps/s (collection: 3.180s, learning 0.785s)
               Value function loss: 24.2423
                    Surrogate loss: 0.0080
             Mean action noise std: 0.98
                       Mean reward: -49.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 936000
                    Iteration time: 3.96s
                        Total time: 509.05s
                               ETA: 7326.4s
################################################################################
                     [1m Learning iteration 130/2000 [0m                      

                       Computation: 1801 steps/s (collection: 3.162s, learning 0.835s)
               Value function loss: 24.1949
                    Surrogate loss: 0.0060
             Mean action noise std: 0.98
                       Mean reward: -50.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 943200
                    Iteration time: 4.00s
                        Total time: 513.04s
                               ETA: 7323.6s
################################################################################
                     [1m Learning iteration 131/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.106s, learning 0.707s)
               Value function loss: 25.2905
                    Surrogate loss: -0.0003
             Mean action noise std: 0.99
                       Mean reward: -49.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 950400
                    Iteration time: 3.81s
                        Total time: 516.86s
                               ETA: 7318.2s
################################################################################
                     [1m Learning iteration 132/2000 [0m                      

                       Computation: 1806 steps/s (collection: 3.273s, learning 0.713s)
               Value function loss: 26.7670
                    Surrogate loss: -0.0029
             Mean action noise std: 0.98
                       Mean reward: -49.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 957600
                    Iteration time: 3.99s
                        Total time: 520.84s
                               ETA: 7315.3s
################################################################################
                     [1m Learning iteration 133/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.148s, learning 0.700s)
               Value function loss: 28.2369
                    Surrogate loss: -0.0070
             Mean action noise std: 0.98
                       Mean reward: -50.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 964800
                    Iteration time: 3.85s
                        Total time: 524.69s
                               ETA: 7310.4s
################################################################################
                     [1m Learning iteration 134/2000 [0m                      

                       Computation: 1774 steps/s (collection: 3.245s, learning 0.812s)
               Value function loss: 24.7809
                    Surrogate loss: -0.0086
             Mean action noise std: 0.98
                       Mean reward: -50.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 972000
                    Iteration time: 4.06s
                        Total time: 528.75s
                               ETA: 7308.5s
################################################################################
                     [1m Learning iteration 135/2000 [0m                      

                       Computation: 1826 steps/s (collection: 3.157s, learning 0.785s)
               Value function loss: 26.0732
                    Surrogate loss: 0.0021
             Mean action noise std: 0.98
                       Mean reward: -49.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 979200
                    Iteration time: 3.94s
                        Total time: 532.69s
                               ETA: 7304.9s
################################################################################
                     [1m Learning iteration 136/2000 [0m                      

                       Computation: 1863 steps/s (collection: 3.119s, learning 0.745s)
               Value function loss: 25.9407
                    Surrogate loss: -0.0010
             Mean action noise std: 0.98
                       Mean reward: -49.14
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 986400
                    Iteration time: 3.86s
                        Total time: 536.55s
                               ETA: 7300.2s
################################################################################
                     [1m Learning iteration 137/2000 [0m                      

                       Computation: 1809 steps/s (collection: 3.260s, learning 0.719s)
               Value function loss: 25.3057
                    Surrogate loss: -0.0069
             Mean action noise std: 0.98
                       Mean reward: -49.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 993600
                    Iteration time: 3.98s
                        Total time: 540.53s
                               ETA: 7297.2s
################################################################################
                     [1m Learning iteration 138/2000 [0m                      

                       Computation: 1783 steps/s (collection: 3.142s, learning 0.895s)
               Value function loss: 21.5821
                    Surrogate loss: -0.0022
             Mean action noise std: 0.98
                       Mean reward: -49.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1000800
                    Iteration time: 4.04s
                        Total time: 544.57s
                               ETA: 7294.9s
################################################################################
                     [1m Learning iteration 139/2000 [0m                      

                       Computation: 1751 steps/s (collection: 3.247s, learning 0.863s)
               Value function loss: 25.2801
                    Surrogate loss: -0.0004
             Mean action noise std: 0.98
                       Mean reward: -48.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1008000
                    Iteration time: 4.11s
                        Total time: 548.68s
                               ETA: 7293.5s
################################################################################
                     [1m Learning iteration 140/2000 [0m                      

                       Computation: 1814 steps/s (collection: 3.178s, learning 0.791s)
               Value function loss: 24.5242
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -48.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1015200
                    Iteration time: 3.97s
                        Total time: 552.65s
                               ETA: 7290.2s
################################################################################
                     [1m Learning iteration 141/2000 [0m                      

                       Computation: 1836 steps/s (collection: 3.158s, learning 0.763s)
               Value function loss: 24.3534
                    Surrogate loss: -0.0042
             Mean action noise std: 0.98
                       Mean reward: -49.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1022400
                    Iteration time: 3.92s
                        Total time: 556.57s
                               ETA: 7286.3s
################################################################################
                     [1m Learning iteration 142/2000 [0m                      

                       Computation: 1761 steps/s (collection: 3.241s, learning 0.845s)
               Value function loss: 23.2714
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.57
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1029600
                    Iteration time: 4.09s
                        Total time: 560.65s
                               ETA: 7284.6s
################################################################################
                     [1m Learning iteration 143/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.148s, learning 0.695s)
               Value function loss: 20.0844
                    Surrogate loss: -0.0080
             Mean action noise std: 0.98
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1036800
                    Iteration time: 3.84s
                        Total time: 564.50s
                               ETA: 7279.7s
################################################################################
                     [1m Learning iteration 144/2000 [0m                      

                       Computation: 1776 steps/s (collection: 3.239s, learning 0.814s)
               Value function loss: 25.0813
                    Surrogate loss: 0.0005
             Mean action noise std: 0.98
                       Mean reward: -48.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1044000
                    Iteration time: 4.05s
                        Total time: 568.55s
                               ETA: 7277.5s
################################################################################
                     [1m Learning iteration 145/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.173s, learning 0.728s)
               Value function loss: 26.3893
                    Surrogate loss: -0.0056
             Mean action noise std: 0.98
                       Mean reward: -49.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1051200
                    Iteration time: 3.90s
                        Total time: 572.45s
                               ETA: 7273.3s
################################################################################
                     [1m Learning iteration 146/2000 [0m                      

                       Computation: 1834 steps/s (collection: 3.185s, learning 0.740s)
               Value function loss: 27.5452
                    Surrogate loss: -0.0001
             Mean action noise std: 0.98
                       Mean reward: -48.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1058400
                    Iteration time: 3.93s
                        Total time: 576.38s
                               ETA: 7269.4s
################################################################################
                     [1m Learning iteration 147/2000 [0m                      

                       Computation: 1834 steps/s (collection: 3.283s, learning 0.642s)
               Value function loss: 25.5431
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -48.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1065600
                    Iteration time: 3.92s
                        Total time: 580.30s
                               ETA: 7265.5s
################################################################################
                     [1m Learning iteration 148/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.157s, learning 0.659s)
               Value function loss: 27.0503
                    Surrogate loss: 0.0057
             Mean action noise std: 0.98
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1072800
                    Iteration time: 3.82s
                        Total time: 584.12s
                               ETA: 7260.3s
################################################################################
                     [1m Learning iteration 149/2000 [0m                      

                       Computation: 1830 steps/s (collection: 3.280s, learning 0.653s)
               Value function loss: 25.9118
                    Surrogate loss: -0.0055
             Mean action noise std: 0.98
                       Mean reward: -50.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1080000
                    Iteration time: 3.93s
                        Total time: 588.05s
                               ETA: 7256.5s
################################################################################
                     [1m Learning iteration 150/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.158s, learning 0.659s)
               Value function loss: 24.2447
                    Surrogate loss: -0.0069
             Mean action noise std: 0.98
                       Mean reward: -49.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1087200
                    Iteration time: 3.82s
                        Total time: 591.87s
                               ETA: 7251.4s
################################################################################
                     [1m Learning iteration 151/2000 [0m                      

                       Computation: 1863 steps/s (collection: 3.183s, learning 0.681s)
               Value function loss: 26.4226
                    Surrogate loss: 0.0092
             Mean action noise std: 0.98
                       Mean reward: -49.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1094400
                    Iteration time: 3.86s
                        Total time: 595.73s
                               ETA: 7246.8s
################################################################################
                     [1m Learning iteration 152/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.126s, learning 0.694s)
               Value function loss: 22.4295
                    Surrogate loss: 0.0011
             Mean action noise std: 0.98
                       Mean reward: -49.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1101600
                    Iteration time: 3.82s
                        Total time: 599.55s
                               ETA: 7241.7s
################################################################################
                     [1m Learning iteration 153/2000 [0m                      

                       Computation: 1897 steps/s (collection: 3.147s, learning 0.647s)
               Value function loss: 23.1539
                    Surrogate loss: -0.0036
             Mean action noise std: 0.98
                       Mean reward: -49.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1108800
                    Iteration time: 3.79s
                        Total time: 603.35s
                               ETA: 7236.2s
################################################################################
                     [1m Learning iteration 154/2000 [0m                      

                       Computation: 1825 steps/s (collection: 3.257s, learning 0.687s)
               Value function loss: 27.7175
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -49.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1116000
                    Iteration time: 3.94s
                        Total time: 607.29s
                               ETA: 7232.6s
################################################################################
                     [1m Learning iteration 155/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.143s, learning 0.704s)
               Value function loss: 24.1345
                    Surrogate loss: -0.0072
             Mean action noise std: 0.98
                       Mean reward: -49.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1123200
                    Iteration time: 3.85s
                        Total time: 611.14s
                               ETA: 7227.9s
################################################################################
                     [1m Learning iteration 156/2000 [0m                      

                       Computation: 1837 steps/s (collection: 3.200s, learning 0.719s)
               Value function loss: 22.0083
                    Surrogate loss: -0.0025
             Mean action noise std: 0.98
                       Mean reward: -50.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1130400
                    Iteration time: 3.92s
                        Total time: 615.06s
                               ETA: 7224.0s
################################################################################
                     [1m Learning iteration 157/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.103s, learning 0.711s)
               Value function loss: 23.9514
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -49.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1137600
                    Iteration time: 3.81s
                        Total time: 618.87s
                               ETA: 7218.9s
################################################################################
                     [1m Learning iteration 158/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.132s, learning 0.701s)
               Value function loss: 25.4504
                    Surrogate loss: 0.0003
             Mean action noise std: 0.98
                       Mean reward: -49.33
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1144800
                    Iteration time: 3.83s
                        Total time: 622.70s
                               ETA: 7214.0s
################################################################################
                     [1m Learning iteration 159/2000 [0m                      

                       Computation: 1824 steps/s (collection: 3.153s, learning 0.794s)
               Value function loss: 27.5835
                    Surrogate loss: -0.0025
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1152000
                    Iteration time: 3.95s
                        Total time: 626.65s
                               ETA: 7210.4s
################################################################################
                     [1m Learning iteration 160/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.152s, learning 0.630s)
               Value function loss: 23.5132
                    Surrogate loss: 0.0008
             Mean action noise std: 0.98
                       Mean reward: -48.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1159200
                    Iteration time: 3.78s
                        Total time: 630.43s
                               ETA: 7204.9s
################################################################################
                     [1m Learning iteration 161/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.270s, learning 0.629s)
               Value function loss: 22.6475
                    Surrogate loss: 0.0022
             Mean action noise std: 0.98
                       Mean reward: -48.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1166400
                    Iteration time: 3.90s
                        Total time: 634.33s
                               ETA: 7200.8s
################################################################################
                     [1m Learning iteration 162/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.150s, learning 0.632s)
               Value function loss: 24.6285
                    Surrogate loss: -0.0047
             Mean action noise std: 0.99
                       Mean reward: -48.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1173600
                    Iteration time: 3.78s
                        Total time: 638.11s
                               ETA: 7195.4s
################################################################################
                     [1m Learning iteration 163/2000 [0m                      

                       Computation: 1868 steps/s (collection: 3.196s, learning 0.657s)
               Value function loss: 23.4110
                    Surrogate loss: -0.0028
             Mean action noise std: 0.98
                       Mean reward: -49.06
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1180800
                    Iteration time: 3.85s
                        Total time: 641.97s
                               ETA: 7190.8s
################################################################################
                     [1m Learning iteration 164/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.180s, learning 0.664s)
               Value function loss: 23.4650
                    Surrogate loss: 0.0057
             Mean action noise std: 0.99
                       Mean reward: -49.02
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1188000
                    Iteration time: 3.84s
                        Total time: 645.81s
                               ETA: 7186.1s
################################################################################
                     [1m Learning iteration 165/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.160s, learning 0.647s)
               Value function loss: 22.0317
                    Surrogate loss: -0.0012
             Mean action noise std: 0.99
                       Mean reward: -48.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1195200
                    Iteration time: 3.81s
                        Total time: 649.62s
                               ETA: 7181.0s
################################################################################
                     [1m Learning iteration 166/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.237s, learning 0.699s)
               Value function loss: 27.3392
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -48.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1202400
                    Iteration time: 3.94s
                        Total time: 653.55s
                               ETA: 7177.3s
################################################################################
                     [1m Learning iteration 167/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.145s, learning 0.650s)
               Value function loss: 27.9535
                    Surrogate loss: -0.0048
             Mean action noise std: 0.99
                       Mean reward: -49.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1209600
                    Iteration time: 3.80s
                        Total time: 657.35s
                               ETA: 7172.1s
################################################################################
                     [1m Learning iteration 168/2000 [0m                      

                       Computation: 1839 steps/s (collection: 3.219s, learning 0.695s)
               Value function loss: 25.2779
                    Surrogate loss: -0.0063
             Mean action noise std: 0.99
                       Mean reward: -49.12
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1216800
                    Iteration time: 3.91s
                        Total time: 661.26s
                               ETA: 7168.2s
################################################################################
                     [1m Learning iteration 169/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.135s, learning 0.707s)
               Value function loss: 25.4004
                    Surrogate loss: -0.0058
             Mean action noise std: 0.99
                       Mean reward: -49.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1224000
                    Iteration time: 3.84s
                        Total time: 665.10s
                               ETA: 7163.5s
################################################################################
                     [1m Learning iteration 170/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.117s, learning 0.703s)
               Value function loss: 23.0949
                    Surrogate loss: -0.0073
             Mean action noise std: 0.99
                       Mean reward: -49.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1231200
                    Iteration time: 3.82s
                        Total time: 668.92s
                               ETA: 7158.6s
################################################################################
                     [1m Learning iteration 171/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.214s, learning 0.670s)
               Value function loss: 21.6251
                    Surrogate loss: -0.0053
             Mean action noise std: 0.99
                       Mean reward: -49.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1238400
                    Iteration time: 3.88s
                        Total time: 672.81s
                               ETA: 7154.4s
################################################################################
                     [1m Learning iteration 172/2000 [0m                      

                       Computation: 1866 steps/s (collection: 3.235s, learning 0.622s)
               Value function loss: 21.9461
                    Surrogate loss: -0.0035
             Mean action noise std: 0.99
                       Mean reward: -49.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1245600
                    Iteration time: 3.86s
                        Total time: 676.66s
                               ETA: 7149.9s
################################################################################
                     [1m Learning iteration 173/2000 [0m                      

                       Computation: 1813 steps/s (collection: 3.281s, learning 0.690s)
               Value function loss: 22.4251
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -48.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1252800
                    Iteration time: 3.97s
                        Total time: 680.63s
                               ETA: 7146.7s
################################################################################
                     [1m Learning iteration 174/2000 [0m                      

                       Computation: 1906 steps/s (collection: 3.131s, learning 0.645s)
               Value function loss: 23.9181
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -48.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1260000
                    Iteration time: 3.78s
                        Total time: 684.41s
                               ETA: 7141.3s
################################################################################
                     [1m Learning iteration 175/2000 [0m                      

                       Computation: 1840 steps/s (collection: 3.130s, learning 0.782s)
               Value function loss: 23.4596
                    Surrogate loss: -0.0062
             Mean action noise std: 0.99
                       Mean reward: -48.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1267200
                    Iteration time: 3.91s
                        Total time: 688.32s
                               ETA: 7137.4s
################################################################################
                     [1m Learning iteration 176/2000 [0m                      

                       Computation: 1840 steps/s (collection: 3.156s, learning 0.755s)
               Value function loss: 21.7822
                    Surrogate loss: -0.0063
             Mean action noise std: 0.99
                       Mean reward: -49.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1274400
                    Iteration time: 3.91s
                        Total time: 692.23s
                               ETA: 7133.5s
################################################################################
                     [1m Learning iteration 177/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.154s, learning 0.668s)
               Value function loss: 25.5504
                    Surrogate loss: -0.0018
             Mean action noise std: 0.99
                       Mean reward: -49.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1281600
                    Iteration time: 3.82s
                        Total time: 696.05s
                               ETA: 7128.7s
################################################################################
                     [1m Learning iteration 178/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.266s, learning 0.687s)
               Value function loss: 24.1356
                    Surrogate loss: -0.0032
             Mean action noise std: 0.99
                       Mean reward: -49.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1288800
                    Iteration time: 3.95s
                        Total time: 700.01s
                               ETA: 7125.2s
################################################################################
                     [1m Learning iteration 179/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.191s, learning 0.622s)
               Value function loss: 25.0832
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -49.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1296000
                    Iteration time: 3.81s
                        Total time: 703.82s
                               ETA: 7120.3s
################################################################################
                     [1m Learning iteration 180/2000 [0m                      

                       Computation: 1800 steps/s (collection: 3.381s, learning 0.617s)
               Value function loss: 24.8530
                    Surrogate loss: -0.0038
             Mean action noise std: 0.99
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1303200
                    Iteration time: 4.00s
                        Total time: 707.82s
                               ETA: 7117.3s
################################################################################
                     [1m Learning iteration 181/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.154s, learning 0.638s)
               Value function loss: 23.5585
                    Surrogate loss: 0.0131
             Mean action noise std: 0.99
                       Mean reward: -48.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1310400
                    Iteration time: 3.79s
                        Total time: 711.61s
                               ETA: 7112.2s
################################################################################
                     [1m Learning iteration 182/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.146s, learning 0.753s)
               Value function loss: 27.4653
                    Surrogate loss: -0.0031
             Mean action noise std: 0.99
                       Mean reward: -48.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1317600
                    Iteration time: 3.90s
                        Total time: 715.51s
                               ETA: 7108.2s
################################################################################
                     [1m Learning iteration 183/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.240s, learning 0.650s)
               Value function loss: 22.3123
                    Surrogate loss: -0.0042
             Mean action noise std: 0.99
                       Mean reward: -48.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1324800
                    Iteration time: 3.89s
                        Total time: 719.40s
                               ETA: 7104.1s
################################################################################
                     [1m Learning iteration 184/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.150s, learning 0.646s)
               Value function loss: 23.4091
                    Surrogate loss: -0.0063
             Mean action noise std: 0.99
                       Mean reward: -48.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1332000
                    Iteration time: 3.80s
                        Total time: 723.19s
                               ETA: 7099.0s
################################################################################
                     [1m Learning iteration 185/2000 [0m                      

                       Computation: 1827 steps/s (collection: 3.255s, learning 0.685s)
               Value function loss: 23.6082
                    Surrogate loss: -0.0072
             Mean action noise std: 1.00
                       Mean reward: -48.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1339200
                    Iteration time: 3.94s
                        Total time: 727.13s
                               ETA: 7095.4s
################################################################################
                     [1m Learning iteration 186/2000 [0m                      

                       Computation: 1877 steps/s (collection: 3.148s, learning 0.686s)
               Value function loss: 22.5121
                    Surrogate loss: -0.0058
             Mean action noise std: 1.00
                       Mean reward: -49.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1346400
                    Iteration time: 3.83s
                        Total time: 730.97s
                               ETA: 7090.8s
################################################################################
                     [1m Learning iteration 187/2000 [0m                      

                       Computation: 1872 steps/s (collection: 3.195s, learning 0.650s)
               Value function loss: 23.5580
                    Surrogate loss: -0.0047
             Mean action noise std: 1.00
                       Mean reward: -49.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1353600
                    Iteration time: 3.85s
                        Total time: 734.81s
                               ETA: 7086.3s
################################################################################
                     [1m Learning iteration 188/2000 [0m                      

                       Computation: 1830 steps/s (collection: 3.129s, learning 0.804s)
               Value function loss: 25.0229
                    Surrogate loss: -0.0059
             Mean action noise std: 1.00
                       Mean reward: -49.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1360800
                    Iteration time: 3.93s
                        Total time: 738.75s
                               ETA: 7082.6s
################################################################################
                     [1m Learning iteration 189/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.140s, learning 0.763s)
               Value function loss: 22.7439
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -49.57
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1368000
                    Iteration time: 3.90s
                        Total time: 742.65s
                               ETA: 7078.6s
################################################################################
                     [1m Learning iteration 190/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.077s, learning 0.791s)
               Value function loss: 22.4193
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -49.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1375200
                    Iteration time: 3.87s
                        Total time: 746.52s
                               ETA: 7074.3s
################################################################################
                     [1m Learning iteration 191/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.123s, learning 0.620s)
               Value function loss: 23.2602
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -49.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1382400
                    Iteration time: 3.74s
                        Total time: 750.26s
                               ETA: 7068.9s
################################################################################
                     [1m Learning iteration 192/2000 [0m                      

                       Computation: 1778 steps/s (collection: 3.266s, learning 0.783s)
               Value function loss: 22.3916
                    Surrogate loss: -0.0056
             Mean action noise std: 0.99
                       Mean reward: -49.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1389600
                    Iteration time: 4.05s
                        Total time: 754.31s
                               ETA: 7066.3s
################################################################################
                     [1m Learning iteration 193/2000 [0m                      

                       Computation: 1877 steps/s (collection: 3.156s, learning 0.678s)
               Value function loss: 24.1906
                    Surrogate loss: -0.0044
             Mean action noise std: 0.99
                       Mean reward: -50.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1396800
                    Iteration time: 3.83s
                        Total time: 758.15s
                               ETA: 7061.7s
################################################################################
                     [1m Learning iteration 194/2000 [0m                      

                       Computation: 1872 steps/s (collection: 3.142s, learning 0.702s)
               Value function loss: 23.0095
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -49.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1404000
                    Iteration time: 3.84s
                        Total time: 761.99s
                               ETA: 7057.2s
################################################################################
                     [1m Learning iteration 195/2000 [0m                      

                       Computation: 1895 steps/s (collection: 3.134s, learning 0.665s)
               Value function loss: 21.7467
                    Surrogate loss: -0.0061
             Mean action noise std: 0.99
                       Mean reward: -49.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1411200
                    Iteration time: 3.80s
                        Total time: 765.79s
                               ETA: 7052.3s
################################################################################
                     [1m Learning iteration 196/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.117s, learning 0.675s)
               Value function loss: 22.1022
                    Surrogate loss: -0.0065
             Mean action noise std: 0.99
                       Mean reward: -49.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1418400
                    Iteration time: 3.79s
                        Total time: 769.58s
                               ETA: 7047.3s
################################################################################
                     [1m Learning iteration 197/2000 [0m                      

                       Computation: 1836 steps/s (collection: 3.181s, learning 0.740s)
               Value function loss: 23.1021
                    Surrogate loss: -0.0013
             Mean action noise std: 0.99
                       Mean reward: -49.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1425600
                    Iteration time: 3.92s
                        Total time: 773.50s
                               ETA: 7043.6s
################################################################################
                     [1m Learning iteration 198/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.103s, learning 0.801s)
               Value function loss: 25.1243
                    Surrogate loss: 0.0016
             Mean action noise std: 0.99
                       Mean reward: -49.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1432800
                    Iteration time: 3.90s
                        Total time: 777.41s
                               ETA: 7039.6s
################################################################################
                     [1m Learning iteration 199/2000 [0m                      

                       Computation: 1823 steps/s (collection: 3.241s, learning 0.708s)
               Value function loss: 25.0668
                    Surrogate loss: -0.0001
             Mean action noise std: 0.99
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1440000
                    Iteration time: 3.95s
                        Total time: 781.35s
                               ETA: 7036.1s
################################################################################
                     [1m Learning iteration 200/2000 [0m                      

                       Computation: 1905 steps/s (collection: 3.125s, learning 0.653s)
               Value function loss: 21.4048
                    Surrogate loss: -0.0000
             Mean action noise std: 0.99
                       Mean reward: -49.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1447200
                    Iteration time: 3.78s
                        Total time: 785.13s
                               ETA: 7031.0s
################################################################################
                     [1m Learning iteration 201/2000 [0m                      

                       Computation: 1894 steps/s (collection: 3.123s, learning 0.678s)
               Value function loss: 21.6403
                    Surrogate loss: 0.0018
             Mean action noise std: 0.99
                       Mean reward: -49.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1454400
                    Iteration time: 3.80s
                        Total time: 788.93s
                               ETA: 7026.2s
################################################################################
                     [1m Learning iteration 202/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.100s, learning 0.803s)
               Value function loss: 22.4766
                    Surrogate loss: 0.0005
             Mean action noise std: 0.99
                       Mean reward: -50.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1461600
                    Iteration time: 3.90s
                        Total time: 792.84s
                               ETA: 7022.3s
################################################################################
                     [1m Learning iteration 203/2000 [0m                      

                       Computation: 1937 steps/s (collection: 3.100s, learning 0.616s)
               Value function loss: 25.6986
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -50.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1468800
                    Iteration time: 3.72s
                        Total time: 796.55s
                               ETA: 7016.7s
################################################################################
                     [1m Learning iteration 204/2000 [0m                      

                       Computation: 1862 steps/s (collection: 3.201s, learning 0.665s)
               Value function loss: 22.4942
                    Surrogate loss: -0.0039
             Mean action noise std: 0.99
                       Mean reward: -49.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1476000
                    Iteration time: 3.87s
                        Total time: 800.42s
                               ETA: 7012.5s
################################################################################
                     [1m Learning iteration 205/2000 [0m                      

                       Computation: 1906 steps/s (collection: 3.097s, learning 0.679s)
               Value function loss: 23.0014
                    Surrogate loss: -0.0051
             Mean action noise std: 0.99
                       Mean reward: -49.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1483200
                    Iteration time: 3.78s
                        Total time: 804.20s
                               ETA: 7007.4s
################################################################################
                     [1m Learning iteration 206/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.130s, learning 0.687s)
               Value function loss: 24.9075
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -49.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1490400
                    Iteration time: 3.82s
                        Total time: 808.01s
                               ETA: 7002.8s
################################################################################
                     [1m Learning iteration 207/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.099s, learning 0.711s)
               Value function loss: 22.3574
                    Surrogate loss: -0.0004
             Mean action noise std: 0.99
                       Mean reward: -49.78
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1497600
                    Iteration time: 3.81s
                        Total time: 811.82s
                               ETA: 6998.1s
################################################################################
                     [1m Learning iteration 208/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.080s, learning 0.703s)
               Value function loss: 21.9472
                    Surrogate loss: 0.0057
             Mean action noise std: 0.99
                       Mean reward: -49.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1504800
                    Iteration time: 3.78s
                        Total time: 815.60s
                               ETA: 6993.1s
################################################################################
                     [1m Learning iteration 209/2000 [0m                      

                       Computation: 1907 steps/s (collection: 3.144s, learning 0.631s)
               Value function loss: 22.0032
                    Surrogate loss: 0.0003
             Mean action noise std: 0.99
                       Mean reward: -49.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1512000
                    Iteration time: 3.78s
                        Total time: 819.38s
                               ETA: 6988.1s
################################################################################
                     [1m Learning iteration 210/2000 [0m                      

                       Computation: 1924 steps/s (collection: 3.075s, learning 0.667s)
               Value function loss: 23.0420
                    Surrogate loss: -0.0050
             Mean action noise std: 0.99
                       Mean reward: -49.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1519200
                    Iteration time: 3.74s
                        Total time: 823.12s
                               ETA: 6982.9s
################################################################################
                     [1m Learning iteration 211/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.208s, learning 0.660s)
               Value function loss: 21.1968
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -49.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1526400
                    Iteration time: 3.87s
                        Total time: 826.99s
                               ETA: 6978.7s
################################################################################
                     [1m Learning iteration 212/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.068s, learning 0.682s)
               Value function loss: 22.8399
                    Surrogate loss: -0.0061
             Mean action noise std: 0.98
                       Mean reward: -48.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1533600
                    Iteration time: 3.75s
                        Total time: 830.74s
                               ETA: 6973.5s
################################################################################
                     [1m Learning iteration 213/2000 [0m                      

                       Computation: 1858 steps/s (collection: 3.127s, learning 0.747s)
               Value function loss: 21.9394
                    Surrogate loss: -0.0009
             Mean action noise std: 0.98
                       Mean reward: -48.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1540800
                    Iteration time: 3.87s
                        Total time: 834.61s
                               ETA: 6969.4s
################################################################################
                     [1m Learning iteration 214/2000 [0m                      

                       Computation: 1908 steps/s (collection: 3.115s, learning 0.657s)
               Value function loss: 22.1092
                    Surrogate loss: -0.0047
             Mean action noise std: 0.98
                       Mean reward: -48.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1548000
                    Iteration time: 3.77s
                        Total time: 838.39s
                               ETA: 6964.5s
################################################################################
                     [1m Learning iteration 215/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.124s, learning 0.639s)
               Value function loss: 22.2267
                    Surrogate loss: -0.0032
             Mean action noise std: 0.98
                       Mean reward: -49.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1555200
                    Iteration time: 3.76s
                        Total time: 842.15s
                               ETA: 6959.4s
################################################################################
                     [1m Learning iteration 216/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.141s, learning 0.708s)
               Value function loss: 21.5600
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1562400
                    Iteration time: 3.85s
                        Total time: 846.00s
                               ETA: 6955.1s
################################################################################
                     [1m Learning iteration 217/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.089s, learning 0.740s)
               Value function loss: 22.0846
                    Surrogate loss: -0.0037
             Mean action noise std: 0.98
                       Mean reward: -49.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1569600
                    Iteration time: 3.83s
                        Total time: 849.83s
                               ETA: 6950.7s
################################################################################
                     [1m Learning iteration 218/2000 [0m                      

                       Computation: 1837 steps/s (collection: 3.221s, learning 0.697s)
               Value function loss: 21.1803
                    Surrogate loss: 0.0014
             Mean action noise std: 0.98
                       Mean reward: -49.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1576800
                    Iteration time: 3.92s
                        Total time: 853.75s
                               ETA: 6946.9s
################################################################################
                     [1m Learning iteration 219/2000 [0m                      

                       Computation: 1919 steps/s (collection: 3.103s, learning 0.649s)
               Value function loss: 20.8003
                    Surrogate loss: 0.0081
             Mean action noise std: 0.98
                       Mean reward: -49.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1584000
                    Iteration time: 3.75s
                        Total time: 857.50s
                               ETA: 6941.8s
################################################################################
                     [1m Learning iteration 220/2000 [0m                      

                       Computation: 1893 steps/s (collection: 3.133s, learning 0.669s)
               Value function loss: 25.7714
                    Surrogate loss: 0.0002
             Mean action noise std: 0.98
                       Mean reward: -48.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1591200
                    Iteration time: 3.80s
                        Total time: 861.30s
                               ETA: 6937.2s
################################################################################
                     [1m Learning iteration 221/2000 [0m                      

                       Computation: 1864 steps/s (collection: 3.126s, learning 0.735s)
               Value function loss: 25.3793
                    Surrogate loss: 0.0039
             Mean action noise std: 0.98
                       Mean reward: -48.51
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1598400
                    Iteration time: 3.86s
                        Total time: 865.16s
                               ETA: 6933.0s
################################################################################
                     [1m Learning iteration 222/2000 [0m                      

                       Computation: 1902 steps/s (collection: 3.156s, learning 0.628s)
               Value function loss: 24.1853
                    Surrogate loss: -0.0039
             Mean action noise std: 0.98
                       Mean reward: -48.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1605600
                    Iteration time: 3.78s
                        Total time: 868.94s
                               ETA: 6928.2s
################################################################################
                     [1m Learning iteration 223/2000 [0m                      

                       Computation: 1843 steps/s (collection: 3.186s, learning 0.719s)
               Value function loss: 24.0120
                    Surrogate loss: -0.0037
             Mean action noise std: 0.98
                       Mean reward: -48.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1612800
                    Iteration time: 3.90s
                        Total time: 872.85s
                               ETA: 6924.3s
################################################################################
                     [1m Learning iteration 224/2000 [0m                      

                       Computation: 1899 steps/s (collection: 3.137s, learning 0.654s)
               Value function loss: 21.1353
                    Surrogate loss: -0.0016
             Mean action noise std: 0.98
                       Mean reward: -48.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1620000
                    Iteration time: 3.79s
                        Total time: 876.64s
                               ETA: 6919.6s
################################################################################
                     [1m Learning iteration 225/2000 [0m                      

                       Computation: 1824 steps/s (collection: 3.230s, learning 0.717s)
               Value function loss: 25.1484
                    Surrogate loss: 0.0006
             Mean action noise std: 0.99
                       Mean reward: -48.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1627200
                    Iteration time: 3.95s
                        Total time: 880.59s
                               ETA: 6916.1s
################################################################################
                     [1m Learning iteration 226/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.126s, learning 0.685s)
               Value function loss: 23.8658
                    Surrogate loss: 0.0010
             Mean action noise std: 0.98
                       Mean reward: -48.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1634400
                    Iteration time: 3.81s
                        Total time: 884.40s
                               ETA: 6911.6s
################################################################################
                     [1m Learning iteration 227/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.129s, learning 0.677s)
               Value function loss: 22.0531
                    Surrogate loss: -0.0021
             Mean action noise std: 0.98
                       Mean reward: -48.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1641600
                    Iteration time: 3.81s
                        Total time: 888.20s
                               ETA: 6907.0s
################################################################################
                     [1m Learning iteration 228/2000 [0m                      

                       Computation: 1848 steps/s (collection: 3.113s, learning 0.781s)
               Value function loss: 24.8021
                    Surrogate loss: -0.0072
             Mean action noise std: 0.98
                       Mean reward: -48.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1648800
                    Iteration time: 3.89s
                        Total time: 892.10s
                               ETA: 6903.1s
################################################################################
                     [1m Learning iteration 229/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.154s, learning 0.626s)
               Value function loss: 23.2220
                    Surrogate loss: -0.0049
             Mean action noise std: 0.98
                       Mean reward: -48.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1656000
                    Iteration time: 3.78s
                        Total time: 895.88s
                               ETA: 6898.3s
################################################################################
                     [1m Learning iteration 230/2000 [0m                      

                       Computation: 1842 steps/s (collection: 3.194s, learning 0.713s)
               Value function loss: 23.0715
                    Surrogate loss: 0.0006
             Mean action noise std: 0.98
                       Mean reward: -48.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1663200
                    Iteration time: 3.91s
                        Total time: 899.79s
                               ETA: 6894.5s
################################################################################
                     [1m Learning iteration 231/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.128s, learning 0.629s)
               Value function loss: 21.6452
                    Surrogate loss: 0.0006
             Mean action noise std: 0.98
                       Mean reward: -48.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1670400
                    Iteration time: 3.76s
                        Total time: 903.54s
                               ETA: 6889.5s
################################################################################
                     [1m Learning iteration 232/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.189s, learning 0.629s)
               Value function loss: 23.9235
                    Surrogate loss: 0.0005
             Mean action noise std: 0.98
                       Mean reward: -48.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1677600
                    Iteration time: 3.82s
                        Total time: 907.36s
                               ETA: 6885.0s
################################################################################
                     [1m Learning iteration 233/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.161s, learning 0.738s)
               Value function loss: 26.4303
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -48.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1684800
                    Iteration time: 3.90s
                        Total time: 911.26s
                               ETA: 6881.2s
################################################################################
                     [1m Learning iteration 234/2000 [0m                      

                       Computation: 1902 steps/s (collection: 3.144s, learning 0.640s)
               Value function loss: 26.0548
                    Surrogate loss: -0.0012
             Mean action noise std: 0.99
                       Mean reward: -48.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1692000
                    Iteration time: 3.78s
                        Total time: 915.04s
                               ETA: 6876.5s
################################################################################
                     [1m Learning iteration 235/2000 [0m                      

                       Computation: 1822 steps/s (collection: 3.271s, learning 0.680s)
               Value function loss: 25.6000
                    Surrogate loss: -0.0066
             Mean action noise std: 0.99
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1699200
                    Iteration time: 3.95s
                        Total time: 918.99s
                               ETA: 6873.0s
################################################################################
                     [1m Learning iteration 236/2000 [0m                      

                       Computation: 1899 steps/s (collection: 3.141s, learning 0.649s)
               Value function loss: 24.9361
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -48.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1706400
                    Iteration time: 3.79s
                        Total time: 922.79s
                               ETA: 6868.3s
################################################################################
                     [1m Learning iteration 237/2000 [0m                      

                       Computation: 1833 steps/s (collection: 3.239s, learning 0.689s)
               Value function loss: 26.6330
                    Surrogate loss: -0.0026
             Mean action noise std: 0.99
                       Mean reward: -48.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1713600
                    Iteration time: 3.93s
                        Total time: 926.71s
                               ETA: 6864.7s
################################################################################
                     [1m Learning iteration 238/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.154s, learning 0.638s)
               Value function loss: 25.2448
                    Surrogate loss: -0.0023
             Mean action noise std: 0.99
                       Mean reward: -49.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1720800
                    Iteration time: 3.79s
                        Total time: 930.51s
                               ETA: 6860.0s
################################################################################
                     [1m Learning iteration 239/2000 [0m                      

                       Computation: 1860 steps/s (collection: 3.198s, learning 0.673s)
               Value function loss: 24.8098
                    Surrogate loss: -0.0068
             Mean action noise std: 0.99
                       Mean reward: -49.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1728000
                    Iteration time: 3.87s
                        Total time: 934.38s
                               ETA: 6856.0s
################################################################################
                     [1m Learning iteration 240/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.156s, learning 0.667s)
               Value function loss: 26.1251
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -49.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1735200
                    Iteration time: 3.82s
                        Total time: 938.20s
                               ETA: 6851.6s
################################################################################
                     [1m Learning iteration 241/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.120s, learning 0.685s)
               Value function loss: 23.2910
                    Surrogate loss: -0.0003
             Mean action noise std: 0.99
                       Mean reward: -48.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1742400
                    Iteration time: 3.81s
                        Total time: 942.00s
                               ETA: 6847.0s
################################################################################
                     [1m Learning iteration 242/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.149s, learning 0.718s)
               Value function loss: 23.9826
                    Surrogate loss: -0.0043
             Mean action noise std: 0.99
                       Mean reward: -49.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1749600
                    Iteration time: 3.87s
                        Total time: 945.87s
                               ETA: 6843.0s
################################################################################
                     [1m Learning iteration 243/2000 [0m                      

                       Computation: 1819 steps/s (collection: 3.202s, learning 0.755s)
               Value function loss: 29.8779
                    Surrogate loss: 0.0062
             Mean action noise std: 0.99
                       Mean reward: -49.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1756800
                    Iteration time: 3.96s
                        Total time: 949.83s
                               ETA: 6839.5s
################################################################################
                     [1m Learning iteration 244/2000 [0m                      

                       Computation: 1785 steps/s (collection: 3.217s, learning 0.814s)
               Value function loss: 23.5749
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1764000
                    Iteration time: 4.03s
                        Total time: 953.86s
                               ETA: 6836.6s
################################################################################
                     [1m Learning iteration 245/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.144s, learning 0.772s)
               Value function loss: 23.8934
                    Surrogate loss: -0.0040
             Mean action noise std: 0.99
                       Mean reward: -49.25
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1771200
                    Iteration time: 3.92s
                        Total time: 957.78s
                               ETA: 6832.9s
################################################################################
                     [1m Learning iteration 246/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.149s, learning 0.786s)
               Value function loss: 23.5059
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -49.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1778400
                    Iteration time: 3.94s
                        Total time: 961.71s
                               ETA: 6829.3s
################################################################################
                     [1m Learning iteration 247/2000 [0m                      

                       Computation: 1798 steps/s (collection: 3.114s, learning 0.891s)
               Value function loss: 21.6688
                    Surrogate loss: -0.0052
             Mean action noise std: 0.98
                       Mean reward: -49.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1785600
                    Iteration time: 4.00s
                        Total time: 965.72s
                               ETA: 6826.2s
################################################################################
                     [1m Learning iteration 248/2000 [0m                      

                       Computation: 1839 steps/s (collection: 3.108s, learning 0.806s)
               Value function loss: 24.1192
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1792800
                    Iteration time: 3.91s
                        Total time: 969.63s
                               ETA: 6822.5s
################################################################################
                     [1m Learning iteration 249/2000 [0m                      

                       Computation: 1784 steps/s (collection: 3.226s, learning 0.809s)
               Value function loss: 22.5071
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -49.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1800000
                    Iteration time: 4.04s
                        Total time: 973.67s
                               ETA: 6819.6s
################################################################################
                     [1m Learning iteration 250/2000 [0m                      

                       Computation: 1858 steps/s (collection: 3.123s, learning 0.751s)
               Value function loss: 22.8507
                    Surrogate loss: 0.0011
             Mean action noise std: 0.98
                       Mean reward: -48.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1807200
                    Iteration time: 3.87s
                        Total time: 977.54s
                               ETA: 6815.5s
################################################################################
                     [1m Learning iteration 251/2000 [0m                      

                       Computation: 1879 steps/s (collection: 3.131s, learning 0.699s)
               Value function loss: 23.1898
                    Surrogate loss: -0.0040
             Mean action noise std: 0.98
                       Mean reward: -48.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1814400
                    Iteration time: 3.83s
                        Total time: 981.37s
                               ETA: 6811.2s
################################################################################
                     [1m Learning iteration 252/2000 [0m                      

                       Computation: 1865 steps/s (collection: 3.138s, learning 0.721s)
               Value function loss: 37.5236
                    Surrogate loss: 0.0044
             Mean action noise std: 0.98
                       Mean reward: -49.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1821600
                    Iteration time: 3.86s
                        Total time: 985.23s
                               ETA: 6807.0s
################################################################################
                     [1m Learning iteration 253/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.130s, learning 0.674s)
               Value function loss: 28.5306
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1828800
                    Iteration time: 3.80s
                        Total time: 989.03s
                               ETA: 6802.5s
################################################################################
                     [1m Learning iteration 254/2000 [0m                      

                       Computation: 1865 steps/s (collection: 3.217s, learning 0.642s)
               Value function loss: 25.6968
                    Surrogate loss: -0.0015
             Mean action noise std: 0.98
                       Mean reward: -50.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1836000
                    Iteration time: 3.86s
                        Total time: 992.89s
                               ETA: 6798.4s
################################################################################
                     [1m Learning iteration 255/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.203s, learning 0.618s)
               Value function loss: 25.1534
                    Surrogate loss: -0.0056
             Mean action noise std: 0.98
                       Mean reward: -50.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1843200
                    Iteration time: 3.82s
                        Total time: 996.71s
                               ETA: 6794.0s
################################################################################
                     [1m Learning iteration 256/2000 [0m                      

                       Computation: 1780 steps/s (collection: 3.189s, learning 0.854s)
               Value function loss: 22.6175
                    Surrogate loss: -0.0030
             Mean action noise std: 0.98
                       Mean reward: -51.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1850400
                    Iteration time: 4.04s
                        Total time: 1000.76s
                               ETA: 6791.1s
################################################################################
                     [1m Learning iteration 257/2000 [0m                      

                       Computation: 1824 steps/s (collection: 3.134s, learning 0.812s)
               Value function loss: 21.6485
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -50.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1857600
                    Iteration time: 3.95s
                        Total time: 1004.70s
                               ETA: 6787.6s
################################################################################
                     [1m Learning iteration 258/2000 [0m                      

                       Computation: 1832 steps/s (collection: 3.135s, learning 0.794s)
               Value function loss: 24.4532
                    Surrogate loss: -0.0035
             Mean action noise std: 0.98
                       Mean reward: -49.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1864800
                    Iteration time: 3.93s
                        Total time: 1008.63s
                               ETA: 6783.9s
################################################################################
                     [1m Learning iteration 259/2000 [0m                      

                       Computation: 1800 steps/s (collection: 3.155s, learning 0.842s)
               Value function loss: 23.0100
                    Surrogate loss: -0.0013
             Mean action noise std: 0.98
                       Mean reward: -49.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1872000
                    Iteration time: 4.00s
                        Total time: 1012.63s
                               ETA: 6780.7s
################################################################################
                     [1m Learning iteration 260/2000 [0m                      

                       Computation: 1855 steps/s (collection: 3.127s, learning 0.753s)
               Value function loss: 21.3587
                    Surrogate loss: 0.0107
             Mean action noise std: 0.98
                       Mean reward: -49.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1879200
                    Iteration time: 3.88s
                        Total time: 1016.51s
                               ETA: 6776.7s
################################################################################
                     [1m Learning iteration 261/2000 [0m                      

                       Computation: 1852 steps/s (collection: 3.167s, learning 0.719s)
               Value function loss: 20.4422
                    Surrogate loss: 0.0072
             Mean action noise std: 0.98
                       Mean reward: -48.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1886400
                    Iteration time: 3.89s
                        Total time: 1020.40s
                               ETA: 6772.8s
################################################################################
                     [1m Learning iteration 262/2000 [0m                      

                       Computation: 1841 steps/s (collection: 3.150s, learning 0.760s)
               Value function loss: 20.3537
                    Surrogate loss: 0.0003
             Mean action noise std: 0.98
                       Mean reward: -48.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1893600
                    Iteration time: 3.91s
                        Total time: 1024.31s
                               ETA: 6769.0s
################################################################################
                     [1m Learning iteration 263/2000 [0m                      

                       Computation: 1915 steps/s (collection: 3.138s, learning 0.621s)
               Value function loss: 24.2994
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1900800
                    Iteration time: 3.76s
                        Total time: 1028.07s
                               ETA: 6764.2s
################################################################################
                     [1m Learning iteration 264/2000 [0m                      

                       Computation: 1862 steps/s (collection: 3.137s, learning 0.729s)
               Value function loss: 23.5149
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -48.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1908000
                    Iteration time: 3.87s
                        Total time: 1031.93s
                               ETA: 6760.1s
################################################################################
                     [1m Learning iteration 265/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.157s, learning 0.626s)
               Value function loss: 22.3087
                    Surrogate loss: -0.0034
             Mean action noise std: 0.98
                       Mean reward: -48.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1915200
                    Iteration time: 3.78s
                        Total time: 1035.72s
                               ETA: 6755.5s
################################################################################
                     [1m Learning iteration 266/2000 [0m                      

                       Computation: 1852 steps/s (collection: 3.221s, learning 0.665s)
               Value function loss: 22.6762
                    Surrogate loss: -0.0048
             Mean action noise std: 0.98
                       Mean reward: -48.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1922400
                    Iteration time: 3.89s
                        Total time: 1039.60s
                               ETA: 6751.6s
################################################################################
                     [1m Learning iteration 267/2000 [0m                      

                       Computation: 1901 steps/s (collection: 3.163s, learning 0.623s)
               Value function loss: 23.9864
                    Surrogate loss: 0.0081
             Mean action noise std: 0.98
                       Mean reward: -48.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1929600
                    Iteration time: 3.79s
                        Total time: 1043.39s
                               ETA: 6747.0s
################################################################################
                     [1m Learning iteration 268/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.161s, learning 0.689s)
               Value function loss: 24.1072
                    Surrogate loss: 0.0037
             Mean action noise std: 0.98
                       Mean reward: -48.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1936800
                    Iteration time: 3.85s
                        Total time: 1047.24s
                               ETA: 6742.8s
################################################################################
                     [1m Learning iteration 269/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.151s, learning 0.682s)
               Value function loss: 25.2979
                    Surrogate loss: 0.0019
             Mean action noise std: 0.98
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1944000
                    Iteration time: 3.83s
                        Total time: 1051.07s
                               ETA: 6738.5s
################################################################################
                     [1m Learning iteration 270/2000 [0m                      

                       Computation: 1906 steps/s (collection: 3.151s, learning 0.625s)
               Value function loss: 26.4653
                    Surrogate loss: -0.0036
             Mean action noise std: 0.98
                       Mean reward: -50.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1951200
                    Iteration time: 3.78s
                        Total time: 1054.85s
                               ETA: 6733.9s
################################################################################
                     [1m Learning iteration 271/2000 [0m                      

                       Computation: 1901 steps/s (collection: 3.133s, learning 0.653s)
               Value function loss: 23.3921
                    Surrogate loss: -0.0044
             Mean action noise std: 0.98
                       Mean reward: -50.39
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1958400
                    Iteration time: 3.79s
                        Total time: 1058.63s
                               ETA: 6729.3s
################################################################################
                     [1m Learning iteration 272/2000 [0m                      

                       Computation: 1893 steps/s (collection: 3.134s, learning 0.668s)
               Value function loss: 24.8940
                    Surrogate loss: -0.0009
             Mean action noise std: 0.98
                       Mean reward: -50.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1965600
                    Iteration time: 3.80s
                        Total time: 1062.44s
                               ETA: 6724.9s
################################################################################
                     [1m Learning iteration 273/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.215s, learning 0.687s)
               Value function loss: 23.2045
                    Surrogate loss: -0.0049
             Mean action noise std: 0.98
                       Mean reward: -50.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1972800
                    Iteration time: 3.90s
                        Total time: 1066.34s
                               ETA: 6721.0s
################################################################################
                     [1m Learning iteration 274/2000 [0m                      

                       Computation: 1895 steps/s (collection: 3.126s, learning 0.671s)
               Value function loss: 23.3671
                    Surrogate loss: -0.0032
             Mean action noise std: 0.98
                       Mean reward: -49.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1980000
                    Iteration time: 3.80s
                        Total time: 1070.14s
                               ETA: 6716.6s
################################################################################
                     [1m Learning iteration 275/2000 [0m                      

                       Computation: 1875 steps/s (collection: 3.166s, learning 0.672s)
               Value function loss: 22.4145
                    Surrogate loss: 0.0005
             Mean action noise std: 0.98
                       Mean reward: -49.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1987200
                    Iteration time: 3.84s
                        Total time: 1073.97s
                               ETA: 6712.3s
################################################################################
                     [1m Learning iteration 276/2000 [0m                      

                       Computation: 1893 steps/s (collection: 3.151s, learning 0.650s)
               Value function loss: 19.7985
                    Surrogate loss: -0.0082
             Mean action noise std: 0.98
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1994400
                    Iteration time: 3.80s
                        Total time: 1077.78s
                               ETA: 6707.9s
################################################################################
                     [1m Learning iteration 277/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.123s, learning 0.660s)
               Value function loss: 20.9885
                    Surrogate loss: -0.0056
             Mean action noise std: 0.98
                       Mean reward: -48.68
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2001600
                    Iteration time: 3.78s
                        Total time: 1081.56s
                               ETA: 6703.3s
################################################################################
                     [1m Learning iteration 278/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.134s, learning 0.694s)
               Value function loss: 24.2448
                    Surrogate loss: -0.0002
             Mean action noise std: 0.98
                       Mean reward: -48.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2008800
                    Iteration time: 3.83s
                        Total time: 1085.39s
                               ETA: 6699.1s
################################################################################
                     [1m Learning iteration 279/2000 [0m                      

                       Computation: 1893 steps/s (collection: 3.129s, learning 0.674s)
               Value function loss: 21.9236
                    Surrogate loss: -0.0033
             Mean action noise std: 0.98
                       Mean reward: -48.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2016000
                    Iteration time: 3.80s
                        Total time: 1089.19s
                               ETA: 6694.6s
################################################################################
                     [1m Learning iteration 280/2000 [0m                      

                       Computation: 1837 steps/s (collection: 3.265s, learning 0.655s)
               Value function loss: 24.8706
                    Surrogate loss: -0.0074
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2023200
                    Iteration time: 3.92s
                        Total time: 1093.11s
                               ETA: 6690.9s
################################################################################
                     [1m Learning iteration 281/2000 [0m                      

                       Computation: 1905 steps/s (collection: 3.128s, learning 0.651s)
               Value function loss: 25.0024
                    Surrogate loss: 0.0022
             Mean action noise std: 0.98
                       Mean reward: -48.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2030400
                    Iteration time: 3.78s
                        Total time: 1096.89s
                               ETA: 6686.4s
################################################################################
                     [1m Learning iteration 282/2000 [0m                      

                       Computation: 1855 steps/s (collection: 3.179s, learning 0.702s)
               Value function loss: 24.9283
                    Surrogate loss: 0.0051
             Mean action noise std: 0.99
                       Mean reward: -49.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2037600
                    Iteration time: 3.88s
                        Total time: 1100.77s
                               ETA: 6682.4s
################################################################################
                     [1m Learning iteration 283/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.184s, learning 0.628s)
               Value function loss: 24.5556
                    Surrogate loss: -0.0014
             Mean action noise std: 0.99
                       Mean reward: -49.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2044800
                    Iteration time: 3.81s
                        Total time: 1104.58s
                               ETA: 6678.0s
################################################################################
                     [1m Learning iteration 284/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.164s, learning 0.629s)
               Value function loss: 24.1487
                    Surrogate loss: -0.0077
             Mean action noise std: 0.99
                       Mean reward: -49.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2052000
                    Iteration time: 3.79s
                        Total time: 1108.37s
                               ETA: 6673.6s
################################################################################
                     [1m Learning iteration 285/2000 [0m                      

                       Computation: 1866 steps/s (collection: 3.207s, learning 0.650s)
               Value function loss: 22.2641
                    Surrogate loss: -0.0062
             Mean action noise std: 0.99
                       Mean reward: -50.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2059200
                    Iteration time: 3.86s
                        Total time: 1112.23s
                               ETA: 6669.5s
################################################################################
                     [1m Learning iteration 286/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.140s, learning 0.682s)
               Value function loss: 25.7941
                    Surrogate loss: 0.0024
             Mean action noise std: 0.99
                       Mean reward: -49.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2066400
                    Iteration time: 3.82s
                        Total time: 1116.05s
                               ETA: 6665.2s
################################################################################
                     [1m Learning iteration 287/2000 [0m                      

                       Computation: 1836 steps/s (collection: 3.259s, learning 0.661s)
               Value function loss: 24.5523
                    Surrogate loss: -0.0045
             Mean action noise std: 0.99
                       Mean reward: -49.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2073600
                    Iteration time: 3.92s
                        Total time: 1119.97s
                               ETA: 6661.5s
################################################################################
                     [1m Learning iteration 288/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.143s, learning 0.673s)
               Value function loss: 26.5085
                    Surrogate loss: -0.0086
             Mean action noise std: 0.99
                       Mean reward: -49.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2080800
                    Iteration time: 3.82s
                        Total time: 1123.79s
                               ETA: 6657.2s
################################################################################
                     [1m Learning iteration 289/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.158s, learning 0.667s)
               Value function loss: 22.9385
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -48.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2088000
                    Iteration time: 3.82s
                        Total time: 1127.61s
                               ETA: 6652.9s
################################################################################
                     [1m Learning iteration 290/2000 [0m                      

                       Computation: 1839 steps/s (collection: 3.246s, learning 0.669s)
               Value function loss: 24.5835
                    Surrogate loss: -0.0027
             Mean action noise std: 0.99
                       Mean reward: -48.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2095200
                    Iteration time: 3.91s
                        Total time: 1131.53s
                               ETA: 6649.2s
################################################################################
                     [1m Learning iteration 291/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.155s, learning 0.693s)
               Value function loss: 23.8659
                    Surrogate loss: -0.0036
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2102400
                    Iteration time: 3.85s
                        Total time: 1135.38s
                               ETA: 6645.1s
################################################################################
                     [1m Learning iteration 292/2000 [0m                      

                       Computation: 1811 steps/s (collection: 3.253s, learning 0.722s)
               Value function loss: 22.8394
                    Surrogate loss: -0.0006
             Mean action noise std: 0.99
                       Mean reward: -48.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2109600
                    Iteration time: 3.98s
                        Total time: 1139.35s
                               ETA: 6641.7s
################################################################################
                     [1m Learning iteration 293/2000 [0m                      

                       Computation: 1847 steps/s (collection: 3.099s, learning 0.798s)
               Value function loss: 21.6723
                    Surrogate loss: -0.0034
             Mean action noise std: 0.98
                       Mean reward: -48.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2116800
                    Iteration time: 3.90s
                        Total time: 1143.25s
                               ETA: 6637.8s
################################################################################
                     [1m Learning iteration 294/2000 [0m                      

                       Computation: 1828 steps/s (collection: 3.154s, learning 0.785s)
               Value function loss: 24.1306
                    Surrogate loss: 0.0116
             Mean action noise std: 0.98
                       Mean reward: -48.36
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2124000
                    Iteration time: 3.94s
                        Total time: 1147.19s
                               ETA: 6634.2s
################################################################################
                     [1m Learning iteration 295/2000 [0m                      

                       Computation: 1834 steps/s (collection: 3.186s, learning 0.738s)
               Value function loss: 22.0499
                    Surrogate loss: -0.0045
             Mean action noise std: 0.98
                       Mean reward: -48.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2131200
                    Iteration time: 3.92s
                        Total time: 1151.11s
                               ETA: 6630.6s
################################################################################
                     [1m Learning iteration 296/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.142s, learning 0.729s)
               Value function loss: 22.5580
                    Surrogate loss: -0.0015
             Mean action noise std: 0.98
                       Mean reward: -47.98
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2138400
                    Iteration time: 3.87s
                        Total time: 1154.98s
                               ETA: 6626.6s
################################################################################
                     [1m Learning iteration 297/2000 [0m                      

                       Computation: 1765 steps/s (collection: 3.208s, learning 0.870s)
               Value function loss: 22.6305
                    Surrogate loss: -0.0073
             Mean action noise std: 0.98
                       Mean reward: -47.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2145600
                    Iteration time: 4.08s
                        Total time: 1159.06s
                               ETA: 6623.8s
################################################################################
                     [1m Learning iteration 298/2000 [0m                      

                       Computation: 1899 steps/s (collection: 3.121s, learning 0.669s)
               Value function loss: 23.5003
                    Surrogate loss: -0.0075
             Mean action noise std: 0.99
                       Mean reward: -47.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2152800
                    Iteration time: 3.79s
                        Total time: 1162.85s
                               ETA: 6619.3s
################################################################################
                     [1m Learning iteration 299/2000 [0m                      

                       Computation: 1784 steps/s (collection: 3.211s, learning 0.823s)
               Value function loss: 21.1185
                    Surrogate loss: -0.0080
             Mean action noise std: 0.99
                       Mean reward: -48.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2160000
                    Iteration time: 4.03s
                        Total time: 1166.89s
                               ETA: 6616.2s
################################################################################
                     [1m Learning iteration 300/2000 [0m                      

                       Computation: 1820 steps/s (collection: 3.124s, learning 0.832s)
               Value function loss: 23.4866
                    Surrogate loss: -0.0049
             Mean action noise std: 0.99
                       Mean reward: -48.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2167200
                    Iteration time: 3.96s
                        Total time: 1170.84s
                               ETA: 6612.7s
################################################################################
                     [1m Learning iteration 301/2000 [0m                      

                       Computation: 1811 steps/s (collection: 3.142s, learning 0.833s)
               Value function loss: 23.1504
                    Surrogate loss: 0.0014
             Mean action noise std: 0.98
                       Mean reward: -48.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2174400
                    Iteration time: 3.98s
                        Total time: 1174.82s
                               ETA: 6609.3s
################################################################################
                     [1m Learning iteration 302/2000 [0m                      

                       Computation: 1778 steps/s (collection: 3.170s, learning 0.877s)
               Value function loss: 24.5832
                    Surrogate loss: 0.0195
             Mean action noise std: 0.99
                       Mean reward: -48.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2181600
                    Iteration time: 4.05s
                        Total time: 1178.86s
                               ETA: 6606.3s
################################################################################
                     [1m Learning iteration 303/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.149s, learning 0.754s)
               Value function loss: 25.0824
                    Surrogate loss: -0.0050
             Mean action noise std: 0.99
                       Mean reward: -49.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2188800
                    Iteration time: 3.90s
                        Total time: 1182.77s
                               ETA: 6602.5s
################################################################################
                     [1m Learning iteration 304/2000 [0m                      

                       Computation: 1778 steps/s (collection: 3.231s, learning 0.817s)
               Value function loss: 27.1040
                    Surrogate loss: 0.0085
             Mean action noise std: 0.98
                       Mean reward: -48.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2196000
                    Iteration time: 4.05s
                        Total time: 1186.82s
                               ETA: 6599.5s
################################################################################
                     [1m Learning iteration 305/2000 [0m                      

                       Computation: 1800 steps/s (collection: 3.168s, learning 0.830s)
               Value function loss: 27.6650
                    Surrogate loss: -0.0001
             Mean action noise std: 0.98
                       Mean reward: -49.26
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2203200
                    Iteration time: 4.00s
                        Total time: 1190.81s
                               ETA: 6596.2s
################################################################################
                     [1m Learning iteration 306/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.140s, learning 0.675s)
               Value function loss: 26.0118
                    Surrogate loss: -0.0016
             Mean action noise std: 0.98
                       Mean reward: -49.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2210400
                    Iteration time: 3.82s
                        Total time: 1194.63s
                               ETA: 6591.9s
################################################################################
                     [1m Learning iteration 307/2000 [0m                      

                       Computation: 1780 steps/s (collection: 3.279s, learning 0.764s)
               Value function loss: 26.8548
                    Surrogate loss: -0.0010
             Mean action noise std: 0.99
                       Mean reward: -49.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2217600
                    Iteration time: 4.04s
                        Total time: 1198.67s
                               ETA: 6588.8s
################################################################################
                     [1m Learning iteration 308/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.138s, learning 0.734s)
               Value function loss: 24.3430
                    Surrogate loss: -0.0001
             Mean action noise std: 0.99
                       Mean reward: -49.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2224800
                    Iteration time: 3.87s
                        Total time: 1202.54s
                               ETA: 6584.8s
################################################################################
                     [1m Learning iteration 309/2000 [0m                      

                       Computation: 1794 steps/s (collection: 3.178s, learning 0.835s)
               Value function loss: 24.7785
                    Surrogate loss: -0.0061
             Mean action noise std: 0.99
                       Mean reward: -49.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2232000
                    Iteration time: 4.01s
                        Total time: 1206.56s
                               ETA: 6581.6s
################################################################################
                     [1m Learning iteration 310/2000 [0m                      

                       Computation: 1770 steps/s (collection: 3.203s, learning 0.863s)
               Value function loss: 25.6623
                    Surrogate loss: 0.0043
             Mean action noise std: 0.99
                       Mean reward: -49.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2239200
                    Iteration time: 4.07s
                        Total time: 1210.62s
                               ETA: 6578.6s
################################################################################
                     [1m Learning iteration 311/2000 [0m                      

                       Computation: 1815 steps/s (collection: 3.180s, learning 0.785s)
               Value function loss: 28.0493
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -49.12
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2246400
                    Iteration time: 3.97s
                        Total time: 1214.59s
                               ETA: 6575.1s
################################################################################
                     [1m Learning iteration 312/2000 [0m                      

                       Computation: 1735 steps/s (collection: 3.348s, learning 0.801s)
               Value function loss: 25.0996
                    Surrogate loss: -0.0076
             Mean action noise std: 0.99
                       Mean reward: -49.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2253600
                    Iteration time: 4.15s
                        Total time: 1218.74s
                               ETA: 6572.6s
################################################################################
                     [1m Learning iteration 313/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.166s, learning 0.654s)
               Value function loss: 24.5458
                    Surrogate loss: -0.0071
             Mean action noise std: 0.99
                       Mean reward: -48.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2260800
                    Iteration time: 3.82s
                        Total time: 1222.56s
                               ETA: 6568.3s
################################################################################
                     [1m Learning iteration 314/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.204s, learning 0.712s)
               Value function loss: 25.5399
                    Surrogate loss: 0.0100
             Mean action noise std: 0.99
                       Mean reward: -49.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2268000
                    Iteration time: 3.92s
                        Total time: 1226.47s
                               ETA: 6564.6s
################################################################################
                     [1m Learning iteration 315/2000 [0m                      

                       Computation: 1791 steps/s (collection: 3.239s, learning 0.780s)
               Value function loss: 26.5048
                    Surrogate loss: -0.0087
             Mean action noise std: 0.99
                       Mean reward: -48.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2275200
                    Iteration time: 4.02s
                        Total time: 1230.49s
                               ETA: 6561.3s
################################################################################
                     [1m Learning iteration 316/2000 [0m                      

                       Computation: 1856 steps/s (collection: 3.133s, learning 0.745s)
               Value function loss: 27.2158
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -49.25
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2282400
                    Iteration time: 3.88s
                        Total time: 1234.37s
                               ETA: 6557.3s
################################################################################
                     [1m Learning iteration 317/2000 [0m                      

                       Computation: 1749 steps/s (collection: 3.304s, learning 0.812s)
               Value function loss: 25.8812
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -49.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2289600
                    Iteration time: 4.12s
                        Total time: 1238.49s
                               ETA: 6554.6s
################################################################################
                     [1m Learning iteration 318/2000 [0m                      

                       Computation: 1823 steps/s (collection: 3.096s, learning 0.852s)
               Value function loss: 25.4462
                    Surrogate loss: -0.0003
             Mean action noise std: 1.00
                       Mean reward: -49.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2296800
                    Iteration time: 3.95s
                        Total time: 1242.43s
                               ETA: 6551.0s
################################################################################
                     [1m Learning iteration 319/2000 [0m                      

                       Computation: 1750 steps/s (collection: 3.211s, learning 0.903s)
               Value function loss: 26.5040
                    Surrogate loss: -0.0066
             Mean action noise std: 0.99
                       Mean reward: -49.28
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2304000
                    Iteration time: 4.11s
                        Total time: 1246.55s
                               ETA: 6548.3s
################################################################################
                     [1m Learning iteration 320/2000 [0m                      

                       Computation: 1794 steps/s (collection: 3.229s, learning 0.783s)
               Value function loss: 25.4339
                    Surrogate loss: -0.0023
             Mean action noise std: 0.99
                       Mean reward: -49.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2311200
                    Iteration time: 4.01s
                        Total time: 1250.56s
                               ETA: 6545.0s
################################################################################
                     [1m Learning iteration 321/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.142s, learning 0.773s)
               Value function loss: 23.7000
                    Surrogate loss: 0.0005
             Mean action noise std: 1.00
                       Mean reward: -49.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2318400
                    Iteration time: 3.92s
                        Total time: 1254.48s
                               ETA: 6541.2s
################################################################################
                     [1m Learning iteration 322/2000 [0m                      

                       Computation: 1788 steps/s (collection: 3.249s, learning 0.778s)
               Value function loss: 25.7746
                    Surrogate loss: -0.0022
             Mean action noise std: 1.00
                       Mean reward: -48.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2325600
                    Iteration time: 4.03s
                        Total time: 1258.50s
                               ETA: 6538.0s
################################################################################
                     [1m Learning iteration 323/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.118s, learning 0.797s)
               Value function loss: 27.4068
                    Surrogate loss: -0.0042
             Mean action noise std: 1.00
                       Mean reward: -48.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2332800
                    Iteration time: 3.92s
                        Total time: 1262.42s
                               ETA: 6534.2s
################################################################################
                     [1m Learning iteration 324/2000 [0m                      

                       Computation: 1790 steps/s (collection: 3.148s, learning 0.874s)
               Value function loss: 24.0192
                    Surrogate loss: -0.0053
             Mean action noise std: 1.00
                       Mean reward: -49.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2340000
                    Iteration time: 4.02s
                        Total time: 1266.44s
                               ETA: 6530.9s
################################################################################
                     [1m Learning iteration 325/2000 [0m                      

                       Computation: 1865 steps/s (collection: 3.206s, learning 0.653s)
               Value function loss: 26.2549
                    Surrogate loss: -0.0003
             Mean action noise std: 1.00
                       Mean reward: -48.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2347200
                    Iteration time: 3.86s
                        Total time: 1270.30s
                               ETA: 6526.8s
################################################################################
                     [1m Learning iteration 326/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.138s, learning 0.686s)
               Value function loss: 23.3614
                    Surrogate loss: -0.0049
             Mean action noise std: 1.00
                       Mean reward: -48.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2354400
                    Iteration time: 3.82s
                        Total time: 1274.12s
                               ETA: 6522.6s
################################################################################
                     [1m Learning iteration 327/2000 [0m                      

                       Computation: 1825 steps/s (collection: 3.290s, learning 0.654s)
               Value function loss: 24.3731
                    Surrogate loss: -0.0020
             Mean action noise std: 1.00
                       Mean reward: -48.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2361600
                    Iteration time: 3.94s
                        Total time: 1278.07s
                               ETA: 6518.9s
################################################################################
                     [1m Learning iteration 328/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.167s, learning 0.649s)
               Value function loss: 27.2123
                    Surrogate loss: -0.0050
             Mean action noise std: 1.00
                       Mean reward: -47.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2368800
                    Iteration time: 3.82s
                        Total time: 1281.88s
                               ETA: 6514.6s
################################################################################
                     [1m Learning iteration 329/2000 [0m                      

                       Computation: 1822 steps/s (collection: 3.271s, learning 0.679s)
               Value function loss: 24.0957
                    Surrogate loss: -0.0080
             Mean action noise std: 1.00
                       Mean reward: -47.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2376000
                    Iteration time: 3.95s
                        Total time: 1285.83s
                               ETA: 6511.0s
################################################################################
                     [1m Learning iteration 330/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.181s, learning 0.636s)
               Value function loss: 25.1048
                    Surrogate loss: -0.0095
             Mean action noise std: 1.00
                       Mean reward: -47.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2383200
                    Iteration time: 3.82s
                        Total time: 1289.65s
                               ETA: 6506.7s
################################################################################
                     [1m Learning iteration 331/2000 [0m                      

                       Computation: 1879 steps/s (collection: 3.144s, learning 0.686s)
               Value function loss: 28.0447
                    Surrogate loss: 0.0053
             Mean action noise std: 1.00
                       Mean reward: -48.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2390400
                    Iteration time: 3.83s
                        Total time: 1293.48s
                               ETA: 6502.5s
################################################################################
                     [1m Learning iteration 332/2000 [0m                      

                       Computation: 1776 steps/s (collection: 3.187s, learning 0.865s)
               Value function loss: 25.5438
                    Surrogate loss: 0.0057
             Mean action noise std: 1.00
                       Mean reward: -48.73
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2397600
                    Iteration time: 4.05s
                        Total time: 1297.53s
                               ETA: 6499.4s
################################################################################
                     [1m Learning iteration 333/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.144s, learning 0.757s)
               Value function loss: 25.3527
                    Surrogate loss: -0.0021
             Mean action noise std: 1.00
                       Mean reward: -49.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2404800
                    Iteration time: 3.90s
                        Total time: 1301.43s
                               ETA: 6495.5s
################################################################################
                     [1m Learning iteration 334/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.225s, learning 0.712s)
               Value function loss: 25.1033
                    Surrogate loss: -0.0081
             Mean action noise std: 1.00
                       Mean reward: -49.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2412000
                    Iteration time: 3.94s
                        Total time: 1305.37s
                               ETA: 6491.8s
################################################################################
                     [1m Learning iteration 335/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.136s, learning 0.659s)
               Value function loss: 27.1526
                    Surrogate loss: 0.0034
             Mean action noise std: 1.00
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2419200
                    Iteration time: 3.80s
                        Total time: 1309.17s
                               ETA: 6487.4s
################################################################################
                     [1m Learning iteration 336/2000 [0m                      

                       Computation: 1857 steps/s (collection: 3.174s, learning 0.702s)
               Value function loss: 26.5627
                    Surrogate loss: 0.0015
             Mean action noise std: 1.00
                       Mean reward: -49.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2426400
                    Iteration time: 3.88s
                        Total time: 1313.04s
                               ETA: 6483.4s
################################################################################
                     [1m Learning iteration 337/2000 [0m                      

                       Computation: 1839 steps/s (collection: 3.190s, learning 0.724s)
               Value function loss: 23.1018
                    Surrogate loss: 0.0051
             Mean action noise std: 1.00
                       Mean reward: -49.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2433600
                    Iteration time: 3.91s
                        Total time: 1316.96s
                               ETA: 6479.6s
################################################################################
                     [1m Learning iteration 338/2000 [0m                      

                       Computation: 1915 steps/s (collection: 3.106s, learning 0.654s)
               Value function loss: 24.8659
                    Surrogate loss: -0.0057
             Mean action noise std: 1.00
                       Mean reward: -48.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2440800
                    Iteration time: 3.76s
                        Total time: 1320.72s
                               ETA: 6475.0s
################################################################################
                     [1m Learning iteration 339/2000 [0m                      

                       Computation: 1827 steps/s (collection: 3.163s, learning 0.778s)
               Value function loss: 26.4998
                    Surrogate loss: -0.0044
             Mean action noise std: 1.00
                       Mean reward: -48.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2448000
                    Iteration time: 3.94s
                        Total time: 1324.66s
                               ETA: 6471.3s
################################################################################
                     [1m Learning iteration 340/2000 [0m                      

                       Computation: 1834 steps/s (collection: 3.149s, learning 0.774s)
               Value function loss: 24.0434
                    Surrogate loss: -0.0030
             Mean action noise std: 1.00
                       Mean reward: -49.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2455200
                    Iteration time: 3.92s
                        Total time: 1328.58s
                               ETA: 6467.6s
################################################################################
                     [1m Learning iteration 341/2000 [0m                      

                       Computation: 1791 steps/s (collection: 3.198s, learning 0.821s)
               Value function loss: 25.5198
                    Surrogate loss: -0.0058
             Mean action noise std: 1.00
                       Mean reward: -48.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2462400
                    Iteration time: 4.02s
                        Total time: 1332.60s
                               ETA: 6464.3s
################################################################################
                      [1m Learning iteration 0/2000 [0m                       

                       Computation: 1441 steps/s (collection: 4.369s, learning 0.628s)
               Value function loss: 87.6143
                    Surrogate loss: -0.0028
             Mean action noise std: 1.00
                       Mean reward: -55.21
               Mean episode length: 43.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7200
                    Iteration time: 5.00s
                        Total time: 5.00s
                               ETA: 9992.9s
################################################################################
                      [1m Learning iteration 1/2000 [0m                       

                       Computation: 1860 steps/s (collection: 3.227s, learning 0.643s)
               Value function loss: 60.9052
                    Surrogate loss: -0.0024
             Mean action noise std: 1.00
                       Mean reward: -55.22
               Mean episode length: 43.67
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 14400
                    Iteration time: 3.87s
                        Total time: 8.87s
                               ETA: 8862.0s
################################################################################
                      [1m Learning iteration 2/2000 [0m                       

                       Computation: 1818 steps/s (collection: 3.130s, learning 0.830s)
               Value function loss: 87.3786
                    Surrogate loss: -0.0007
             Mean action noise std: 1.00
                       Mean reward: -55.43
               Mean episode length: 44.20
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 21600
                    Iteration time: 3.96s
                        Total time: 12.83s
                               ETA: 8542.4s
################################################################################
                      [1m Learning iteration 3/2000 [0m                       

                       Computation: 1795 steps/s (collection: 3.148s, learning 0.863s)
               Value function loss: 69.4787
                    Surrogate loss: -0.0035
             Mean action noise std: 1.00
                       Mean reward: -55.55
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 28800
                    Iteration time: 4.01s
                        Total time: 16.84s
                               ETA: 8406.1s
################################################################################
                      [1m Learning iteration 4/2000 [0m                       

                       Computation: 1846 steps/s (collection: 3.180s, learning 0.719s)
               Value function loss: 76.6303
                    Surrogate loss: -0.0057
             Mean action noise std: 1.00
                       Mean reward: -55.72
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 36000
                    Iteration time: 3.90s
                        Total time: 20.74s
                               ETA: 8278.2s
################################################################################
                      [1m Learning iteration 5/2000 [0m                       

                       Computation: 1920 steps/s (collection: 3.091s, learning 0.658s)
               Value function loss: 59.9183
                    Surrogate loss: 0.0016
             Mean action noise std: 1.00
                       Mean reward: -55.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 43200
                    Iteration time: 3.75s
                        Total time: 24.49s
                               ETA: 8141.4s
################################################################################
                      [1m Learning iteration 6/2000 [0m                       

                       Computation: 1862 steps/s (collection: 3.252s, learning 0.614s)
               Value function loss: 58.3303
                    Surrogate loss: -0.0043
             Mean action noise std: 1.00
                       Mean reward: -55.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 50400
                    Iteration time: 3.87s
                        Total time: 28.35s
                               ETA: 8076.2s
################################################################################
                      [1m Learning iteration 7/2000 [0m                       

                       Computation: 1943 steps/s (collection: 3.080s, learning 0.625s)
               Value function loss: 50.1596
                    Surrogate loss: -0.0037
             Mean action noise std: 1.00
                       Mean reward: -55.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 57600
                    Iteration time: 3.70s
                        Total time: 32.06s
                               ETA: 7986.1s
################################################################################
                      [1m Learning iteration 8/2000 [0m                       

                       Computation: 1919 steps/s (collection: 3.063s, learning 0.689s)
               Value function loss: 48.1750
                    Surrogate loss: -0.0042
             Mean action noise std: 0.99
                       Mean reward: -55.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 64800
                    Iteration time: 3.75s
                        Total time: 35.81s
                               ETA: 7925.5s
################################################################################
                      [1m Learning iteration 9/2000 [0m                       

                       Computation: 1927 steps/s (collection: 3.123s, learning 0.611s)
               Value function loss: 46.1737
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -55.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 72000
                    Iteration time: 3.73s
                        Total time: 39.54s
                               ETA: 7872.9s
################################################################################
                      [1m Learning iteration 10/2000 [0m                      

                       Computation: 1942 steps/s (collection: 3.094s, learning 0.612s)
               Value function loss: 49.5829
                    Surrogate loss: -0.0049
             Mean action noise std: 0.99
                       Mean reward: -55.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 79200
                    Iteration time: 3.71s
                        Total time: 43.25s
                               ETA: 7824.2s
################################################################################
                      [1m Learning iteration 11/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.120s, learning 0.672s)
               Value function loss: 58.2134
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -55.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 86400
                    Iteration time: 3.79s
                        Total time: 47.04s
                               ETA: 7797.0s
################################################################################
                      [1m Learning iteration 12/2000 [0m                      

                       Computation: 1925 steps/s (collection: 3.032s, learning 0.709s)
               Value function loss: 47.5025
                    Surrogate loss: 0.0007
             Mean action noise std: 0.99
                       Mean reward: -56.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 93600
                    Iteration time: 3.74s
                        Total time: 50.78s
                               ETA: 7765.6s
################################################################################
                      [1m Learning iteration 13/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.218s, learning 0.625s)
               Value function loss: 52.7263
                    Surrogate loss: -0.0032
             Mean action noise std: 0.99
                       Mean reward: -56.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 100800
                    Iteration time: 3.84s
                        Total time: 54.62s
                               ETA: 7752.8s
################################################################################
                      [1m Learning iteration 14/2000 [0m                      

                       Computation: 1919 steps/s (collection: 3.120s, learning 0.631s)
               Value function loss: 57.3124
                    Surrogate loss: -0.0038
             Mean action noise std: 0.99
                       Mean reward: -56.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 108000
                    Iteration time: 3.75s
                        Total time: 58.38s
                               ETA: 7729.0s
################################################################################
                      [1m Learning iteration 15/2000 [0m                      

                       Computation: 1929 steps/s (collection: 3.114s, learning 0.618s)
               Value function loss: 43.4845
                    Surrogate loss: -0.0045
             Mean action noise std: 0.99
                       Mean reward: -56.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 115200
                    Iteration time: 3.73s
                        Total time: 62.11s
                               ETA: 7705.3s
################################################################################
                      [1m Learning iteration 16/2000 [0m                      

                       Computation: 1936 steps/s (collection: 3.108s, learning 0.611s)
               Value function loss: 44.4359
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 122400
                    Iteration time: 3.72s
                        Total time: 65.83s
                               ETA: 7682.4s
################################################################################
                      [1m Learning iteration 17/2000 [0m                      

                       Computation: 1941 steps/s (collection: 3.093s, learning 0.615s)
               Value function loss: 42.2122
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -54.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 129600
                    Iteration time: 3.71s
                        Total time: 69.54s
                               ETA: 7660.5s
################################################################################
                      [1m Learning iteration 18/2000 [0m                      

                       Computation: 1933 steps/s (collection: 3.104s, learning 0.620s)
               Value function loss: 41.1112
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -54.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 136800
                    Iteration time: 3.72s
                        Total time: 73.26s
                               ETA: 7642.1s
################################################################################
                      [1m Learning iteration 19/2000 [0m                      

                       Computation: 1945 steps/s (collection: 3.087s, learning 0.614s)
               Value function loss: 43.5620
                    Surrogate loss: -0.0051
             Mean action noise std: 0.99
                       Mean reward: -54.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 144000
                    Iteration time: 3.70s
                        Total time: 76.96s
                               ETA: 7622.9s
################################################################################
                      [1m Learning iteration 20/2000 [0m                      

                       Computation: 1900 steps/s (collection: 3.142s, learning 0.647s)
               Value function loss: 34.2933
                    Surrogate loss: 0.0097
             Mean action noise std: 0.99
                       Mean reward: -54.33
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 151200
                    Iteration time: 3.79s
                        Total time: 80.75s
                               ETA: 7613.5s
################################################################################
                      [1m Learning iteration 21/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.117s, learning 0.611s)
               Value function loss: 46.9817
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -54.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 158400
                    Iteration time: 3.73s
                        Total time: 84.48s
                               ETA: 7599.1s
################################################################################
                      [1m Learning iteration 22/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.102s, learning 0.633s)
               Value function loss: 48.4932
                    Surrogate loss: 0.0012
             Mean action noise std: 0.99
                       Mean reward: -55.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 165600
                    Iteration time: 3.73s
                        Total time: 88.21s
                               ETA: 7586.2s
################################################################################
                      [1m Learning iteration 23/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.118s, learning 0.610s)
               Value function loss: 43.2159
                    Surrogate loss: -0.0033
             Mean action noise std: 0.99
                       Mean reward: -55.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 172800
                    Iteration time: 3.73s
                        Total time: 91.94s
                               ETA: 7573.5s
################################################################################
                      [1m Learning iteration 24/2000 [0m                      

                       Computation: 1930 steps/s (collection: 3.108s, learning 0.622s)
               Value function loss: 47.0554
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 180000
                    Iteration time: 3.73s
                        Total time: 95.67s
                               ETA: 7561.8s
################################################################################
                      [1m Learning iteration 25/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.138s, learning 0.624s)
               Value function loss: 47.8379
                    Surrogate loss: -0.0025
             Mean action noise std: 0.99
                       Mean reward: -55.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 187200
                    Iteration time: 3.76s
                        Total time: 99.43s
                               ETA: 7553.0s
################################################################################
                      [1m Learning iteration 26/2000 [0m                      

                       Computation: 1928 steps/s (collection: 3.095s, learning 0.637s)
               Value function loss: 38.4298
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -55.53
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 194400
                    Iteration time: 3.73s
                        Total time: 103.16s
                               ETA: 7542.5s
################################################################################
                      [1m Learning iteration 27/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.114s, learning 0.724s)
               Value function loss: 39.0335
                    Surrogate loss: -0.0024
             Mean action noise std: 0.99
                       Mean reward: -54.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 201600
                    Iteration time: 3.84s
                        Total time: 107.00s
                               ETA: 7539.8s
################################################################################
                      [1m Learning iteration 28/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.107s, learning 0.613s)
               Value function loss: 33.7753
                    Surrogate loss: -0.0058
             Mean action noise std: 0.99
                       Mean reward: -54.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 208800
                    Iteration time: 3.72s
                        Total time: 110.72s
                               ETA: 7529.1s
################################################################################
                      [1m Learning iteration 29/2000 [0m                      

                       Computation: 1909 steps/s (collection: 3.130s, learning 0.641s)
               Value function loss: 40.2645
                    Surrogate loss: -0.0073
             Mean action noise std: 0.99
                       Mean reward: -53.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 216000
                    Iteration time: 3.77s
                        Total time: 114.49s
                               ETA: 7522.2s
################################################################################
                      [1m Learning iteration 30/2000 [0m                      

                       Computation: 1901 steps/s (collection: 3.127s, learning 0.660s)
               Value function loss: 38.1285
                    Surrogate loss: -0.0027
             Mean action noise std: 0.99
                       Mean reward: -53.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 223200
                    Iteration time: 3.79s
                        Total time: 118.28s
                               ETA: 7516.4s
################################################################################
                      [1m Learning iteration 31/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.120s, learning 0.721s)
               Value function loss: 41.0155
                    Surrogate loss: -0.0043
             Mean action noise std: 0.99
                       Mean reward: -52.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 230400
                    Iteration time: 3.84s
                        Total time: 122.12s
                               ETA: 7514.2s
################################################################################
                      [1m Learning iteration 32/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.129s, learning 0.684s)
               Value function loss: 40.3199
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -53.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 237600
                    Iteration time: 3.81s
                        Total time: 125.93s
                               ETA: 7510.1s
################################################################################
                      [1m Learning iteration 33/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.115s, learning 0.619s)
               Value function loss: 38.3529
                    Surrogate loss: -0.0039
             Mean action noise std: 0.99
                       Mean reward: -52.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 244800
                    Iteration time: 3.73s
                        Total time: 129.67s
                               ETA: 7501.6s
################################################################################
                      [1m Learning iteration 34/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.185s, learning 0.611s)
               Value function loss: 38.4416
                    Surrogate loss: 0.0076
             Mean action noise std: 0.99
                       Mean reward: -53.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 252000
                    Iteration time: 3.80s
                        Total time: 133.46s
                               ETA: 7496.8s
################################################################################
                      [1m Learning iteration 35/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.114s, learning 0.636s)
               Value function loss: 39.5888
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -53.10
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 259200
                    Iteration time: 3.75s
                        Total time: 137.21s
                               ETA: 7489.5s
################################################################################
                      [1m Learning iteration 36/2000 [0m                      

                       Computation: 1902 steps/s (collection: 3.159s, learning 0.626s)
               Value function loss: 41.4946
                    Surrogate loss: -0.0040
             Mean action noise std: 0.99
                       Mean reward: -53.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 266400
                    Iteration time: 3.78s
                        Total time: 141.00s
                               ETA: 7484.2s
################################################################################
                      [1m Learning iteration 37/2000 [0m                      

                       Computation: 1917 steps/s (collection: 3.129s, learning 0.626s)
               Value function loss: 38.0765
                    Surrogate loss: -0.0061
             Mean action noise std: 0.99
                       Mean reward: -52.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 273600
                    Iteration time: 3.75s
                        Total time: 144.75s
                               ETA: 7477.5s
################################################################################
                      [1m Learning iteration 38/2000 [0m                      

                       Computation: 1912 steps/s (collection: 3.125s, learning 0.640s)
               Value function loss: 44.5340
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -52.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 280800
                    Iteration time: 3.76s
                        Total time: 148.52s
                               ETA: 7471.5s
################################################################################
                      [1m Learning iteration 39/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.130s, learning 0.741s)
               Value function loss: 36.2183
                    Surrogate loss: 0.0018
             Mean action noise std: 0.99
                       Mean reward: -52.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 288000
                    Iteration time: 3.87s
                        Total time: 152.39s
                               ETA: 7470.8s
################################################################################
                      [1m Learning iteration 40/2000 [0m                      

                       Computation: 1930 steps/s (collection: 3.128s, learning 0.601s)
               Value function loss: 34.4764
                    Surrogate loss: -0.0010
             Mean action noise std: 0.99
                       Mean reward: -51.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 295200
                    Iteration time: 3.73s
                        Total time: 156.12s
                               ETA: 7463.1s
################################################################################
                      [1m Learning iteration 41/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.171s, learning 0.625s)
               Value function loss: 36.5184
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -51.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 302400
                    Iteration time: 3.80s
                        Total time: 159.91s
                               ETA: 7458.7s
################################################################################
                      [1m Learning iteration 42/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.102s, learning 0.710s)
               Value function loss: 39.0004
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -51.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 309600
                    Iteration time: 3.81s
                        Total time: 163.72s
                               ETA: 7455.1s
################################################################################
                      [1m Learning iteration 43/2000 [0m                      

                       Computation: 1849 steps/s (collection: 3.153s, learning 0.739s)
               Value function loss: 42.0665
                    Surrogate loss: -0.0017
             Mean action noise std: 0.99
                       Mean reward: -52.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 316800
                    Iteration time: 3.89s
                        Total time: 167.62s
                               ETA: 7455.1s
################################################################################
                      [1m Learning iteration 44/2000 [0m                      

                       Computation: 1827 steps/s (collection: 3.024s, learning 0.916s)
               Value function loss: 41.4940
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -52.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 324000
                    Iteration time: 3.94s
                        Total time: 171.55s
                               ETA: 7456.9s
################################################################################
                      [1m Learning iteration 45/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.128s, learning 0.616s)
               Value function loss: 33.4112
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -52.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 331200
                    Iteration time: 3.74s
                        Total time: 175.30s
                               ETA: 7450.2s
################################################################################
                      [1m Learning iteration 46/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.132s, learning 0.665s)
               Value function loss: 29.0818
                    Surrogate loss: 0.0185
             Mean action noise std: 0.99
                       Mean reward: -52.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 338400
                    Iteration time: 3.80s
                        Total time: 179.09s
                               ETA: 7445.8s
################################################################################
                      [1m Learning iteration 47/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.101s, learning 0.706s)
               Value function loss: 35.3084
                    Surrogate loss: 0.0096
             Mean action noise std: 0.99
                       Mean reward: -52.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 345600
                    Iteration time: 3.81s
                        Total time: 182.90s
                               ETA: 7441.8s
################################################################################
                      [1m Learning iteration 48/2000 [0m                      

                       Computation: 1900 steps/s (collection: 3.129s, learning 0.660s)
               Value function loss: 35.7524
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -51.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 352800
                    Iteration time: 3.79s
                        Total time: 186.69s
                               ETA: 7437.1s
################################################################################
                      [1m Learning iteration 49/2000 [0m                      

                       Computation: 1928 steps/s (collection: 3.086s, learning 0.647s)
               Value function loss: 33.0440
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -51.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 360000
                    Iteration time: 3.73s
                        Total time: 190.42s
                               ETA: 7430.3s
################################################################################
                      [1m Learning iteration 50/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.177s, learning 0.706s)
               Value function loss: 34.2946
                    Surrogate loss: -0.0047
             Mean action noise std: 0.99
                       Mean reward: -51.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 367200
                    Iteration time: 3.88s
                        Total time: 194.31s
                               ETA: 7429.4s
################################################################################
                      [1m Learning iteration 51/2000 [0m                      

                       Computation: 1867 steps/s (collection: 3.105s, learning 0.750s)
               Value function loss: 33.1621
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -51.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 374400
                    Iteration time: 3.86s
                        Total time: 198.16s
                               ETA: 7427.3s
################################################################################
                      [1m Learning iteration 52/2000 [0m                      

                       Computation: 1868 steps/s (collection: 3.104s, learning 0.750s)
               Value function loss: 33.1356
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -51.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 381600
                    Iteration time: 3.85s
                        Total time: 202.02s
                               ETA: 7425.0s
################################################################################
                      [1m Learning iteration 53/2000 [0m                      

                       Computation: 1856 steps/s (collection: 3.119s, learning 0.758s)
               Value function loss: 34.3554
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -51.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 388800
                    Iteration time: 3.88s
                        Total time: 205.89s
                               ETA: 7423.6s
################################################################################
                      [1m Learning iteration 54/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.131s, learning 0.618s)
               Value function loss: 32.2024
                    Surrogate loss: -0.0022
             Mean action noise std: 0.99
                       Mean reward: -51.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 396000
                    Iteration time: 3.75s
                        Total time: 209.64s
                               ETA: 7417.5s
################################################################################
                      [1m Learning iteration 55/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.129s, learning 0.769s)
               Value function loss: 33.4714
                    Surrogate loss: 0.0039
             Mean action noise std: 0.99
                       Mean reward: -51.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 403200
                    Iteration time: 3.90s
                        Total time: 213.54s
                               ETA: 7416.7s
################################################################################
                      [1m Learning iteration 56/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.125s, learning 0.596s)
               Value function loss: 29.8262
                    Surrogate loss: -0.0002
             Mean action noise std: 0.99
                       Mean reward: -51.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 410400
                    Iteration time: 3.72s
                        Total time: 217.26s
                               ETA: 7409.8s
################################################################################
                      [1m Learning iteration 57/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.143s, learning 0.669s)
               Value function loss: 32.3009
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -50.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 417600
                    Iteration time: 3.81s
                        Total time: 221.07s
                               ETA: 7406.0s
################################################################################
                      [1m Learning iteration 58/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.140s, learning 0.618s)
               Value function loss: 29.6770
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -50.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 424800
                    Iteration time: 3.76s
                        Total time: 224.83s
                               ETA: 7400.4s
################################################################################
                      [1m Learning iteration 59/2000 [0m                      

                       Computation: 1936 steps/s (collection: 3.105s, learning 0.614s)
               Value function loss: 27.6777
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -50.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 432000
                    Iteration time: 3.72s
                        Total time: 228.55s
                               ETA: 7393.6s
################################################################################
                      [1m Learning iteration 60/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.126s, learning 0.725s)
               Value function loss: 30.1422
                    Surrogate loss: -0.0003
             Mean action noise std: 0.99
                       Mean reward: -50.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 439200
                    Iteration time: 3.85s
                        Total time: 232.40s
                               ETA: 7391.1s
################################################################################
                      [1m Learning iteration 61/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.112s, learning 0.615s)
               Value function loss: 31.8961
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -50.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 446400
                    Iteration time: 3.73s
                        Total time: 236.13s
                               ETA: 7384.7s
################################################################################
                      [1m Learning iteration 62/2000 [0m                      

                       Computation: 1833 steps/s (collection: 3.101s, learning 0.825s)
               Value function loss: 33.4506
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -50.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 453600
                    Iteration time: 3.93s
                        Total time: 240.05s
                               ETA: 7384.5s
################################################################################
                      [1m Learning iteration 63/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.146s, learning 0.664s)
               Value function loss: 30.5063
                    Surrogate loss: -0.0029
             Mean action noise std: 0.98
                       Mean reward: -49.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 460800
                    Iteration time: 3.81s
                        Total time: 243.86s
                               ETA: 7380.7s
################################################################################
                      [1m Learning iteration 64/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.168s, learning 0.612s)
               Value function loss: 33.2652
                    Surrogate loss: -0.0063
             Mean action noise std: 0.98
                       Mean reward: -49.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 468000
                    Iteration time: 3.78s
                        Total time: 247.64s
                               ETA: 7376.0s
################################################################################
                      [1m Learning iteration 65/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.143s, learning 0.614s)
               Value function loss: 31.3134
                    Surrogate loss: -0.0074
             Mean action noise std: 0.98
                       Mean reward: -50.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 475200
                    Iteration time: 3.76s
                        Total time: 251.40s
                               ETA: 7370.7s
################################################################################
                      [1m Learning iteration 66/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.185s, learning 0.607s)
               Value function loss: 35.0529
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 482400
                    Iteration time: 3.79s
                        Total time: 255.19s
                               ETA: 7366.4s
################################################################################
                      [1m Learning iteration 67/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.175s, learning 0.644s)
               Value function loss: 30.9591
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -50.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 489600
                    Iteration time: 3.82s
                        Total time: 259.01s
                               ETA: 7362.8s
################################################################################
                      [1m Learning iteration 68/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.115s, learning 0.631s)
               Value function loss: 31.7109
                    Surrogate loss: -0.0084
             Mean action noise std: 0.98
                       Mean reward: -49.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 496800
                    Iteration time: 3.75s
                        Total time: 262.76s
                               ETA: 7357.3s
################################################################################
                      [1m Learning iteration 69/2000 [0m                      

                       Computation: 1862 steps/s (collection: 3.196s, learning 0.670s)
               Value function loss: 29.9669
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 504000
                    Iteration time: 3.87s
                        Total time: 266.63s
                               ETA: 7355.1s
################################################################################
                      [1m Learning iteration 70/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.147s, learning 0.658s)
               Value function loss: 30.2034
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 511200
                    Iteration time: 3.81s
                        Total time: 270.43s
                               ETA: 7351.2s
################################################################################
                      [1m Learning iteration 71/2000 [0m                      

                       Computation: 1852 steps/s (collection: 3.107s, learning 0.781s)
               Value function loss: 32.5000
                    Surrogate loss: -0.0026
             Mean action noise std: 0.98
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 518400
                    Iteration time: 3.89s
                        Total time: 274.32s
                               ETA: 7349.5s
################################################################################
                      [1m Learning iteration 72/2000 [0m                      

                       Computation: 1820 steps/s (collection: 3.168s, learning 0.788s)
               Value function loss: 34.1269
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 525600
                    Iteration time: 3.96s
                        Total time: 278.27s
                               ETA: 7349.5s
################################################################################
                      [1m Learning iteration 73/2000 [0m                      

                       Computation: 1817 steps/s (collection: 3.087s, learning 0.874s)
               Value function loss: 31.0529
                    Surrogate loss: -0.0057
             Mean action noise std: 0.98
                       Mean reward: -50.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 532800
                    Iteration time: 3.96s
                        Total time: 282.24s
                               ETA: 7349.6s
################################################################################
                      [1m Learning iteration 74/2000 [0m                      

                       Computation: 1775 steps/s (collection: 3.129s, learning 0.927s)
               Value function loss: 28.5101
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -49.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 540000
                    Iteration time: 4.06s
                        Total time: 286.29s
                               ETA: 7352.0s
