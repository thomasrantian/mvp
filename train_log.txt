################################################################################
                      [1m Learning iteration 0/2000 [0m                       

                       Computation: 1108 steps/s (collection: 5.784s, learning 0.710s)
               Value function loss: 87.6143
                    Surrogate loss: -0.0028
             Mean action noise std: 1.00
                       Mean reward: -55.21
               Mean episode length: 43.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7200
                    Iteration time: 6.49s
                        Total time: 6.49s
                               ETA: 12987.3s
################################################################################
                      [1m Learning iteration 1/2000 [0m                       

                       Computation: 1768 steps/s (collection: 3.435s, learning 0.637s)
               Value function loss: 60.9052
                    Surrogate loss: -0.0024
             Mean action noise std: 1.00
                       Mean reward: -55.22
               Mean episode length: 43.67
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 14400
                    Iteration time: 4.07s
                        Total time: 10.57s
                               ETA: 10560.3s
################################################################################
                      [1m Learning iteration 2/2000 [0m                       

                       Computation: 1852 steps/s (collection: 3.230s, learning 0.656s)
               Value function loss: 87.3786
                    Surrogate loss: -0.0007
             Mean action noise std: 1.00
                       Mean reward: -55.43
               Mean episode length: 44.20
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 21600
                    Iteration time: 3.89s
                        Total time: 14.45s
                               ETA: 9624.8s
################################################################################
                      [1m Learning iteration 3/2000 [0m                       

                       Computation: 1787 steps/s (collection: 3.302s, learning 0.727s)
               Value function loss: 69.4787
                    Surrogate loss: -0.0035
             Mean action noise std: 1.00
                       Mean reward: -55.55
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 28800
                    Iteration time: 4.03s
                        Total time: 18.48s
                               ETA: 9226.5s
################################################################################
                      [1m Learning iteration 4/2000 [0m                       

                       Computation: 1777 steps/s (collection: 3.431s, learning 0.618s)
               Value function loss: 76.6303
                    Surrogate loss: -0.0057
             Mean action noise std: 1.00
                       Mean reward: -55.72
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 36000
                    Iteration time: 4.05s
                        Total time: 22.53s
                               ETA: 8994.1s
################################################################################
                      [1m Learning iteration 5/2000 [0m                       

                       Computation: 1820 steps/s (collection: 3.188s, learning 0.766s)
               Value function loss: 59.9183
                    Surrogate loss: 0.0016
             Mean action noise std: 1.00
                       Mean reward: -55.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 43200
                    Iteration time: 3.95s
                        Total time: 26.48s
                               ETA: 8806.0s
################################################################################
                      [1m Learning iteration 6/2000 [0m                       

                       Computation: 1767 steps/s (collection: 3.297s, learning 0.777s)
               Value function loss: 58.3303
                    Surrogate loss: -0.0043
             Mean action noise std: 1.00
                       Mean reward: -55.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 50400
                    Iteration time: 4.07s
                        Total time: 30.56s
                               ETA: 8704.8s
################################################################################
                      [1m Learning iteration 7/2000 [0m                       

                       Computation: 1806 steps/s (collection: 3.177s, learning 0.808s)
               Value function loss: 50.1596
                    Surrogate loss: -0.0037
             Mean action noise std: 1.00
                       Mean reward: -55.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 57600
                    Iteration time: 3.99s
                        Total time: 34.54s
                               ETA: 8605.7s
################################################################################
                      [1m Learning iteration 8/2000 [0m                       

                       Computation: 1779 steps/s (collection: 3.234s, learning 0.812s)
               Value function loss: 48.1750
                    Surrogate loss: -0.0042
             Mean action noise std: 0.99
                       Mean reward: -55.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 64800
                    Iteration time: 4.05s
                        Total time: 38.59s
                               ETA: 8541.2s
################################################################################
                      [1m Learning iteration 9/2000 [0m                       

                       Computation: 1781 steps/s (collection: 3.272s, learning 0.769s)
               Value function loss: 46.1737
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -55.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 72000
                    Iteration time: 4.04s
                        Total time: 42.63s
                               ETA: 8487.9s
################################################################################
                      [1m Learning iteration 10/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.190s, learning 0.714s)
               Value function loss: 49.5829
                    Surrogate loss: -0.0049
             Mean action noise std: 0.99
                       Mean reward: -55.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 79200
                    Iteration time: 3.90s
                        Total time: 46.54s
                               ETA: 8418.6s
################################################################################
                      [1m Learning iteration 11/2000 [0m                      

                       Computation: 1732 steps/s (collection: 3.315s, learning 0.841s)
               Value function loss: 58.2134
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -55.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 86400
                    Iteration time: 4.16s
                        Total time: 50.69s
                               ETA: 8402.0s
################################################################################
                      [1m Learning iteration 12/2000 [0m                      

                       Computation: 1815 steps/s (collection: 3.164s, learning 0.802s)
               Value function loss: 47.5025
                    Surrogate loss: 0.0007
             Mean action noise std: 0.99
                       Mean reward: -56.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 93600
                    Iteration time: 3.97s
                        Total time: 54.66s
                               ETA: 8358.3s
################################################################################
                      [1m Learning iteration 13/2000 [0m                      

                       Computation: 1747 steps/s (collection: 3.316s, learning 0.804s)
               Value function loss: 52.7263
                    Surrogate loss: -0.0032
             Mean action noise std: 0.99
                       Mean reward: -56.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 100800
                    Iteration time: 4.12s
                        Total time: 58.78s
                               ETA: 8342.0s
################################################################################
                      [1m Learning iteration 14/2000 [0m                      

                       Computation: 1745 steps/s (collection: 3.352s, learning 0.773s)
               Value function loss: 57.3124
                    Surrogate loss: -0.0038
             Mean action noise std: 0.99
                       Mean reward: -56.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 108000
                    Iteration time: 4.12s
                        Total time: 62.90s
                               ETA: 8328.1s
################################################################################
                      [1m Learning iteration 15/2000 [0m                      

                       Computation: 1860 steps/s (collection: 3.212s, learning 0.658s)
               Value function loss: 43.4845
                    Surrogate loss: -0.0045
             Mean action noise std: 0.99
                       Mean reward: -56.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 115200
                    Iteration time: 3.87s
                        Total time: 66.77s
                               ETA: 8283.7s
################################################################################
                      [1m Learning iteration 16/2000 [0m                      

                       Computation: 1805 steps/s (collection: 3.335s, learning 0.652s)
               Value function loss: 44.4359
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 122400
                    Iteration time: 3.99s
                        Total time: 70.76s
                               ETA: 8257.8s
################################################################################
                      [1m Learning iteration 17/2000 [0m                      

                       Computation: 1830 steps/s (collection: 3.155s, learning 0.778s)
               Value function loss: 42.2122
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -54.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 129600
                    Iteration time: 3.93s
                        Total time: 74.69s
                               ETA: 8228.4s
################################################################################
                      [1m Learning iteration 18/2000 [0m                      

                       Computation: 1770 steps/s (collection: 3.268s, learning 0.799s)
               Value function loss: 41.1112
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -54.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 136800
                    Iteration time: 4.07s
                        Total time: 78.76s
                               ETA: 8215.6s
################################################################################
                      [1m Learning iteration 19/2000 [0m                      

                       Computation: 1803 steps/s (collection: 3.306s, learning 0.688s)
               Value function loss: 43.5620
                    Surrogate loss: -0.0051
             Mean action noise std: 0.99
                       Mean reward: -54.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 144000
                    Iteration time: 3.99s
                        Total time: 82.75s
                               ETA: 8196.4s
################################################################################
                      [1m Learning iteration 20/2000 [0m                      

                       Computation: 1805 steps/s (collection: 3.213s, learning 0.776s)
               Value function loss: 34.2933
                    Surrogate loss: 0.0097
             Mean action noise std: 0.99
                       Mean reward: -54.33
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 151200
                    Iteration time: 3.99s
                        Total time: 86.74s
                               ETA: 8178.3s
################################################################################
                      [1m Learning iteration 21/2000 [0m                      

                       Computation: 1762 steps/s (collection: 3.363s, learning 0.724s)
               Value function loss: 46.9817
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -54.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 158400
                    Iteration time: 4.09s
                        Total time: 90.83s
                               ETA: 8170.2s
################################################################################
                      [1m Learning iteration 22/2000 [0m                      

                       Computation: 1867 steps/s (collection: 3.217s, learning 0.639s)
               Value function loss: 48.4932
                    Surrogate loss: 0.0012
             Mean action noise std: 0.99
                       Mean reward: -55.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 165600
                    Iteration time: 3.86s
                        Total time: 94.68s
                               ETA: 8142.6s
################################################################################
                      [1m Learning iteration 23/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.312s, learning 0.623s)
               Value function loss: 43.2159
                    Surrogate loss: -0.0033
             Mean action noise std: 0.99
                       Mean reward: -55.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 172800
                    Iteration time: 3.93s
                        Total time: 98.62s
                               ETA: 8123.5s
################################################################################
                      [1m Learning iteration 24/2000 [0m                      

                       Computation: 1832 steps/s (collection: 3.307s, learning 0.622s)
               Value function loss: 47.0554
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 180000
                    Iteration time: 3.93s
                        Total time: 102.55s
                               ETA: 8105.2s
################################################################################
                      [1m Learning iteration 25/2000 [0m                      

                       Computation: 1868 steps/s (collection: 3.230s, learning 0.624s)
               Value function loss: 47.8379
                    Surrogate loss: -0.0025
             Mean action noise std: 0.99
                       Mean reward: -55.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 187200
                    Iteration time: 3.85s
                        Total time: 106.40s
                               ETA: 8082.2s
################################################################################
                      [1m Learning iteration 26/2000 [0m                      

                       Computation: 1802 steps/s (collection: 3.365s, learning 0.629s)
               Value function loss: 38.4298
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -55.53
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 194400
                    Iteration time: 3.99s
                        Total time: 110.39s
                               ETA: 8071.0s
################################################################################
                      [1m Learning iteration 27/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.192s, learning 0.642s)
               Value function loss: 39.0335
                    Surrogate loss: -0.0024
             Mean action noise std: 0.99
                       Mean reward: -54.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 201600
                    Iteration time: 3.83s
                        Total time: 114.23s
                               ETA: 8048.9s
################################################################################
                      [1m Learning iteration 28/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.323s, learning 0.628s)
               Value function loss: 33.7753
                    Surrogate loss: -0.0058
             Mean action noise std: 0.99
                       Mean reward: -54.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 208800
                    Iteration time: 3.95s
                        Total time: 118.18s
                               ETA: 8036.1s
################################################################################
                      [1m Learning iteration 29/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.308s, learning 0.592s)
               Value function loss: 40.2645
                    Surrogate loss: -0.0073
             Mean action noise std: 0.99
                       Mean reward: -53.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 216000
                    Iteration time: 3.90s
                        Total time: 122.08s
                               ETA: 8020.6s
################################################################################
                      [1m Learning iteration 30/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.240s, learning 0.603s)
               Value function loss: 38.1285
                    Surrogate loss: -0.0027
             Mean action noise std: 0.99
                       Mean reward: -53.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 223200
                    Iteration time: 3.84s
                        Total time: 125.92s
                               ETA: 8002.1s
################################################################################
                      [1m Learning iteration 31/2000 [0m                      

                       Computation: 1816 steps/s (collection: 3.361s, learning 0.603s)
               Value function loss: 41.0155
                    Surrogate loss: -0.0043
             Mean action noise std: 0.99
                       Mean reward: -52.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 230400
                    Iteration time: 3.96s
                        Total time: 129.89s
                               ETA: 7992.1s
################################################################################
                      [1m Learning iteration 32/2000 [0m                      

                       Computation: 1852 steps/s (collection: 3.288s, learning 0.598s)
               Value function loss: 40.3199
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -53.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 237600
                    Iteration time: 3.89s
                        Total time: 133.77s
                               ETA: 7977.7s
################################################################################
                      [1m Learning iteration 33/2000 [0m                      

                       Computation: 1812 steps/s (collection: 3.357s, learning 0.615s)
               Value function loss: 38.3529
                    Surrogate loss: -0.0039
             Mean action noise std: 0.99
                       Mean reward: -52.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 244800
                    Iteration time: 3.97s
                        Total time: 137.74s
                               ETA: 7968.9s
################################################################################
                      [1m Learning iteration 34/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.269s, learning 0.631s)
               Value function loss: 38.4416
                    Surrogate loss: 0.0076
             Mean action noise std: 0.99
                       Mean reward: -53.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 252000
                    Iteration time: 3.90s
                        Total time: 141.64s
                               ETA: 7956.4s
################################################################################
                      [1m Learning iteration 35/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.344s, learning 0.609s)
               Value function loss: 39.5888
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -53.10
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 259200
                    Iteration time: 3.95s
                        Total time: 145.60s
                               ETA: 7947.2s
################################################################################
                      [1m Learning iteration 36/2000 [0m                      

                       Computation: 1777 steps/s (collection: 3.449s, learning 0.602s)
               Value function loss: 41.4946
                    Surrogate loss: -0.0040
             Mean action noise std: 0.99
                       Mean reward: -53.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 266400
                    Iteration time: 4.05s
                        Total time: 149.65s
                               ETA: 7943.5s
################################################################################
                      [1m Learning iteration 37/2000 [0m                      

                       Computation: 1848 steps/s (collection: 3.276s, learning 0.618s)
               Value function loss: 38.0765
                    Surrogate loss: -0.0061
             Mean action noise std: 0.99
                       Mean reward: -52.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 273600
                    Iteration time: 3.89s
                        Total time: 153.54s
                               ETA: 7931.7s
################################################################################
                      [1m Learning iteration 38/2000 [0m                      

                       Computation: 1814 steps/s (collection: 3.339s, learning 0.630s)
               Value function loss: 44.5340
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -52.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 280800
                    Iteration time: 3.97s
                        Total time: 157.51s
                               ETA: 7924.1s
################################################################################
                      [1m Learning iteration 39/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.278s, learning 0.623s)
               Value function loss: 36.2183
                    Surrogate loss: 0.0018
             Mean action noise std: 0.99
                       Mean reward: -52.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 288000
                    Iteration time: 3.90s
                        Total time: 161.41s
                               ETA: 7913.3s
################################################################################
                      [1m Learning iteration 40/2000 [0m                      

                       Computation: 1842 steps/s (collection: 3.275s, learning 0.631s)
               Value function loss: 34.4764
                    Surrogate loss: -0.0010
             Mean action noise std: 0.99
                       Mean reward: -51.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 295200
                    Iteration time: 3.91s
                        Total time: 165.32s
                               ETA: 7903.1s
################################################################################
                      [1m Learning iteration 41/2000 [0m                      

                       Computation: 1808 steps/s (collection: 3.353s, learning 0.628s)
               Value function loss: 36.5184
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -51.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 302400
                    Iteration time: 3.98s
                        Total time: 169.30s
                               ETA: 7896.7s
################################################################################
                      [1m Learning iteration 42/2000 [0m                      

                       Computation: 1860 steps/s (collection: 3.241s, learning 0.628s)
               Value function loss: 39.0004
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -51.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 309600
                    Iteration time: 3.87s
                        Total time: 173.17s
                               ETA: 7885.3s
################################################################################
                      [1m Learning iteration 43/2000 [0m                      

                       Computation: 1802 steps/s (collection: 3.369s, learning 0.624s)
               Value function loss: 42.0665
                    Surrogate loss: -0.0017
             Mean action noise std: 0.99
                       Mean reward: -52.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 316800
                    Iteration time: 3.99s
                        Total time: 177.16s
                               ETA: 7879.8s
################################################################################
                      [1m Learning iteration 44/2000 [0m                      

                       Computation: 1854 steps/s (collection: 3.280s, learning 0.602s)
               Value function loss: 41.4940
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -52.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 324000
                    Iteration time: 3.88s
                        Total time: 181.05s
                               ETA: 7869.5s
################################################################################
                      [1m Learning iteration 45/2000 [0m                      

                       Computation: 1879 steps/s (collection: 3.202s, learning 0.629s)
               Value function loss: 33.4112
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -52.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 331200
                    Iteration time: 3.83s
                        Total time: 184.88s
                               ETA: 7857.3s
################################################################################
                      [1m Learning iteration 46/2000 [0m                      

                       Computation: 1810 steps/s (collection: 3.356s, learning 0.620s)
               Value function loss: 29.0818
                    Surrogate loss: 0.0185
             Mean action noise std: 0.99
                       Mean reward: -52.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 338400
                    Iteration time: 3.98s
                        Total time: 188.85s
                               ETA: 7851.5s
################################################################################
                      [1m Learning iteration 47/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.230s, learning 0.610s)
               Value function loss: 35.3084
                    Surrogate loss: 0.0096
             Mean action noise std: 0.99
                       Mean reward: -52.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 345600
                    Iteration time: 3.84s
                        Total time: 192.69s
                               ETA: 7840.2s
################################################################################
                      [1m Learning iteration 48/2000 [0m                      

                       Computation: 1798 steps/s (collection: 3.372s, learning 0.632s)
               Value function loss: 35.7524
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -51.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 352800
                    Iteration time: 4.00s
                        Total time: 196.70s
                               ETA: 7835.8s
################################################################################
                      [1m Learning iteration 49/2000 [0m                      

                       Computation: 1812 steps/s (collection: 3.339s, learning 0.633s)
               Value function loss: 33.0440
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -51.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 360000
                    Iteration time: 3.97s
                        Total time: 200.67s
                               ETA: 7830.2s
################################################################################
                      [1m Learning iteration 50/2000 [0m                      

                       Computation: 1775 steps/s (collection: 3.362s, learning 0.693s)
               Value function loss: 34.2946
                    Surrogate loss: -0.0047
             Mean action noise std: 0.99
                       Mean reward: -51.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 367200
                    Iteration time: 4.06s
                        Total time: 204.73s
                               ETA: 7827.7s
################################################################################
                      [1m Learning iteration 51/2000 [0m                      

                       Computation: 1791 steps/s (collection: 3.417s, learning 0.602s)
               Value function loss: 33.1621
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -51.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 374400
                    Iteration time: 4.02s
                        Total time: 208.74s
                               ETA: 7823.9s
################################################################################
                      [1m Learning iteration 52/2000 [0m                      

                       Computation: 1819 steps/s (collection: 3.327s, learning 0.631s)
               Value function loss: 33.1356
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -51.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 381600
                    Iteration time: 3.96s
                        Total time: 212.70s
                               ETA: 7817.8s
################################################################################
                      [1m Learning iteration 53/2000 [0m                      

                       Computation: 1719 steps/s (collection: 3.434s, learning 0.753s)
               Value function loss: 34.3554
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -51.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 388800
                    Iteration time: 4.19s
                        Total time: 216.89s
                               ETA: 7820.1s
################################################################################
                      [1m Learning iteration 54/2000 [0m                      

                       Computation: 1793 steps/s (collection: 3.370s, learning 0.644s)
               Value function loss: 32.2024
                    Surrogate loss: -0.0022
             Mean action noise std: 0.99
                       Mean reward: -51.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 396000
                    Iteration time: 4.01s
                        Total time: 220.90s
                               ETA: 7816.0s
################################################################################
                      [1m Learning iteration 55/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.222s, learning 0.621s)
               Value function loss: 33.4714
                    Surrogate loss: 0.0039
             Mean action noise std: 0.99
                       Mean reward: -51.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 403200
                    Iteration time: 3.84s
                        Total time: 224.75s
                               ETA: 7805.9s
################################################################################
                      [1m Learning iteration 56/2000 [0m                      

                       Computation: 1830 steps/s (collection: 3.306s, learning 0.628s)
               Value function loss: 29.8262
                    Surrogate loss: -0.0002
             Mean action noise std: 0.99
                       Mean reward: -51.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 410400
                    Iteration time: 3.93s
                        Total time: 228.68s
                               ETA: 7799.2s
################################################################################
                      [1m Learning iteration 57/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.204s, learning 0.633s)
               Value function loss: 32.3009
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -50.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 417600
                    Iteration time: 3.84s
                        Total time: 232.52s
                               ETA: 7789.3s
################################################################################
                      [1m Learning iteration 58/2000 [0m                      

                       Computation: 1808 steps/s (collection: 3.343s, learning 0.640s)
               Value function loss: 29.6770
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -50.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 424800
                    Iteration time: 3.98s
                        Total time: 236.50s
                               ETA: 7784.4s
################################################################################
                      [1m Learning iteration 59/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.228s, learning 0.624s)
               Value function loss: 27.6777
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -50.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 432000
                    Iteration time: 3.85s
                        Total time: 240.35s
                               ETA: 7775.4s
################################################################################
                      [1m Learning iteration 60/2000 [0m                      

                       Computation: 1820 steps/s (collection: 3.235s, learning 0.720s)
               Value function loss: 30.1422
                    Surrogate loss: -0.0003
             Mean action noise std: 0.99
                       Mean reward: -50.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 439200
                    Iteration time: 3.96s
                        Total time: 244.31s
                               ETA: 7769.7s
################################################################################
                      [1m Learning iteration 61/2000 [0m                      

                       Computation: 1820 steps/s (collection: 3.338s, learning 0.617s)
               Value function loss: 31.8961
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -50.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 446400
                    Iteration time: 3.95s
                        Total time: 248.26s
                               ETA: 7764.2s
################################################################################
                      [1m Learning iteration 62/2000 [0m                      

                       Computation: 1877 steps/s (collection: 3.202s, learning 0.632s)
               Value function loss: 33.4506
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -50.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 453600
                    Iteration time: 3.83s
                        Total time: 252.10s
                               ETA: 7754.9s
################################################################################
                      [1m Learning iteration 63/2000 [0m                      

                       Computation: 1807 steps/s (collection: 3.356s, learning 0.627s)
               Value function loss: 30.5063
                    Surrogate loss: -0.0029
             Mean action noise std: 0.98
                       Mean reward: -49.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 460800
                    Iteration time: 3.98s
                        Total time: 256.08s
                               ETA: 7750.4s
################################################################################
                      [1m Learning iteration 64/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.244s, learning 0.639s)
               Value function loss: 33.2652
                    Surrogate loss: -0.0063
             Mean action noise std: 0.98
                       Mean reward: -49.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 468000
                    Iteration time: 3.88s
                        Total time: 259.96s
                               ETA: 7742.9s
################################################################################
                      [1m Learning iteration 65/2000 [0m                      

                       Computation: 1812 steps/s (collection: 3.358s, learning 0.616s)
               Value function loss: 31.3134
                    Surrogate loss: -0.0074
             Mean action noise std: 0.98
                       Mean reward: -50.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 475200
                    Iteration time: 3.97s
                        Total time: 263.94s
                               ETA: 7738.1s
################################################################################
                      [1m Learning iteration 66/2000 [0m                      

                       Computation: 1840 steps/s (collection: 3.282s, learning 0.629s)
               Value function loss: 35.0529
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 482400
                    Iteration time: 3.91s
                        Total time: 267.85s
                               ETA: 7731.6s
################################################################################
                      [1m Learning iteration 67/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.209s, learning 0.677s)
               Value function loss: 30.9591
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -50.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 489600
                    Iteration time: 3.89s
                        Total time: 271.73s
                               ETA: 7724.4s
################################################################################
                      [1m Learning iteration 68/2000 [0m                      

                       Computation: 1823 steps/s (collection: 3.324s, learning 0.625s)
               Value function loss: 31.7109
                    Surrogate loss: -0.0084
             Mean action noise std: 0.98
                       Mean reward: -49.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 496800
                    Iteration time: 3.95s
                        Total time: 275.68s
                               ETA: 7719.1s
################################################################################
                      [1m Learning iteration 69/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.220s, learning 0.631s)
               Value function loss: 29.9669
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 504000
                    Iteration time: 3.85s
                        Total time: 279.53s
                               ETA: 7711.1s
################################################################################
                      [1m Learning iteration 70/2000 [0m                      

                       Computation: 1810 steps/s (collection: 3.361s, learning 0.615s)
               Value function loss: 30.2034
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 511200
                    Iteration time: 3.98s
                        Total time: 283.51s
                               ETA: 7706.6s
################################################################################
                      [1m Learning iteration 71/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.227s, learning 0.597s)
               Value function loss: 32.5000
                    Surrogate loss: -0.0026
             Mean action noise std: 0.98
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 518400
                    Iteration time: 3.82s
                        Total time: 287.33s
                               ETA: 7698.1s
################################################################################
                      [1m Learning iteration 72/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.210s, learning 0.627s)
               Value function loss: 34.1269
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 525600
                    Iteration time: 3.84s
                        Total time: 291.17s
                               ETA: 7690.0s
################################################################################
                      [1m Learning iteration 73/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.329s, learning 0.624s)
               Value function loss: 31.0529
                    Surrogate loss: -0.0057
             Mean action noise std: 0.98
                       Mean reward: -50.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 532800
                    Iteration time: 3.95s
                        Total time: 295.12s
                               ETA: 7685.1s
################################################################################
                      [1m Learning iteration 74/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.192s, learning 0.631s)
               Value function loss: 28.5101
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -49.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 540000
                    Iteration time: 3.82s
                        Total time: 298.94s
                               ETA: 7676.9s
################################################################################
                      [1m Learning iteration 75/2000 [0m                      

                       Computation: 1818 steps/s (collection: 3.331s, learning 0.628s)
               Value function loss: 32.0992
                    Surrogate loss: -0.0059
             Mean action noise std: 0.98
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 547200
                    Iteration time: 3.96s
                        Total time: 302.90s
                               ETA: 7672.2s
################################################################################
                      [1m Learning iteration 76/2000 [0m                      

                       Computation: 1813 steps/s (collection: 3.224s, learning 0.745s)
               Value function loss: 31.4500
                    Surrogate loss: -0.0063
             Mean action noise std: 0.98
                       Mean reward: -49.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 554400
                    Iteration time: 3.97s
                        Total time: 306.87s
                               ETA: 7667.8s
################################################################################
                      [1m Learning iteration 77/2000 [0m                      

                       Computation: 1774 steps/s (collection: 3.265s, learning 0.794s)
               Value function loss: 30.3769
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 561600
                    Iteration time: 4.06s
                        Total time: 310.93s
                               ETA: 7665.6s
################################################################################
                      [1m Learning iteration 78/2000 [0m                      

                       Computation: 1752 steps/s (collection: 3.317s, learning 0.791s)
               Value function loss: 32.6787
                    Surrogate loss: -0.0048
             Mean action noise std: 0.98
                       Mean reward: -49.25
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 568800
                    Iteration time: 4.11s
                        Total time: 315.04s
                               ETA: 7664.6s
################################################################################
                      [1m Learning iteration 79/2000 [0m                      

                       Computation: 1828 steps/s (collection: 3.188s, learning 0.748s)
               Value function loss: 29.4594
                    Surrogate loss: -0.0066
             Mean action noise std: 0.98
                       Mean reward: -49.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 576000
                    Iteration time: 3.94s
                        Total time: 318.98s
                               ETA: 7659.4s
################################################################################
                      [1m Learning iteration 80/2000 [0m                      

                       Computation: 1828 steps/s (collection: 3.300s, learning 0.636s)
               Value function loss: 31.4366
                    Surrogate loss: -0.0033
             Mean action noise std: 0.98
                       Mean reward: -50.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 583200
                    Iteration time: 3.94s
                        Total time: 322.91s
                               ETA: 7654.2s
################################################################################
                      [1m Learning iteration 81/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.202s, learning 0.623s)
               Value function loss: 31.4435
                    Surrogate loss: 0.0025
             Mean action noise std: 0.97
                       Mean reward: -50.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 590400
                    Iteration time: 3.82s
                        Total time: 326.74s
                               ETA: 7646.4s
################################################################################
                      [1m Learning iteration 82/2000 [0m                      

                       Computation: 1863 steps/s (collection: 3.241s, learning 0.622s)
               Value function loss: 27.2720
                    Surrogate loss: -0.0026
             Mean action noise std: 0.97
                       Mean reward: -50.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 597600
                    Iteration time: 3.86s
                        Total time: 330.60s
                               ETA: 7639.7s
################################################################################
                      [1m Learning iteration 83/2000 [0m                      

                       Computation: 1822 steps/s (collection: 3.308s, learning 0.641s)
               Value function loss: 24.7333
                    Surrogate loss: 0.0035
             Mean action noise std: 0.97
                       Mean reward: -50.28
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 604800
                    Iteration time: 3.95s
                        Total time: 334.55s
                               ETA: 7634.9s
################################################################################
                      [1m Learning iteration 84/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.192s, learning 0.630s)
               Value function loss: 30.4519
                    Surrogate loss: -0.0006
             Mean action noise std: 0.97
                       Mean reward: -49.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 612000
                    Iteration time: 3.82s
                        Total time: 338.37s
                               ETA: 7627.3s
################################################################################
                      [1m Learning iteration 85/2000 [0m                      

                       Computation: 1804 steps/s (collection: 3.356s, learning 0.635s)
               Value function loss: 27.7287
                    Surrogate loss: 0.0006
             Mean action noise std: 0.97
                       Mean reward: -49.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 619200
                    Iteration time: 3.99s
                        Total time: 342.36s
                               ETA: 7623.6s
################################################################################
                      [1m Learning iteration 86/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.179s, learning 0.617s)
               Value function loss: 24.4723
                    Surrogate loss: -0.0016
             Mean action noise std: 0.97
                       Mean reward: -49.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 626400
                    Iteration time: 3.80s
                        Total time: 346.16s
                               ETA: 7615.5s
################################################################################
                      [1m Learning iteration 87/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.278s, learning 0.621s)
               Value function loss: 32.0193
                    Surrogate loss: -0.0001
             Mean action noise std: 0.97
                       Mean reward: -48.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 633600
                    Iteration time: 3.90s
                        Total time: 350.06s
                               ETA: 7609.8s
################################################################################
                      [1m Learning iteration 0/2000 [0m                       

                       Computation: 1184 steps/s (collection: 5.425s, learning 0.651s)
               Value function loss: 87.6143
                    Surrogate loss: -0.0028
             Mean action noise std: 1.00
                       Mean reward: -55.21
               Mean episode length: 43.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7200
                    Iteration time: 6.08s
                        Total time: 6.08s
                               ETA: 12153.0s
################################################################################
                      [1m Learning iteration 1/2000 [0m                       

                       Computation: 1909 steps/s (collection: 3.149s, learning 0.621s)
               Value function loss: 60.9052
                    Surrogate loss: -0.0024
             Mean action noise std: 1.00
                       Mean reward: -55.22
               Mean episode length: 43.67
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 14400
                    Iteration time: 3.77s
                        Total time: 9.85s
                               ETA: 9841.7s
################################################################################
                      [1m Learning iteration 2/2000 [0m                       

                       Computation: 1852 steps/s (collection: 3.188s, learning 0.697s)
               Value function loss: 87.3786
                    Surrogate loss: -0.0007
             Mean action noise std: 1.00
                       Mean reward: -55.43
               Mean episode length: 44.20
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 21600
                    Iteration time: 3.89s
                        Total time: 13.73s
                               ETA: 9145.9s
################################################################################
                      [1m Learning iteration 3/2000 [0m                       

                       Computation: 1839 steps/s (collection: 3.132s, learning 0.782s)
               Value function loss: 69.4787
                    Surrogate loss: -0.0035
             Mean action noise std: 1.00
                       Mean reward: -55.55
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 28800
                    Iteration time: 3.91s
                        Total time: 17.65s
                               ETA: 8810.1s
################################################################################
                      [1m Learning iteration 4/2000 [0m                       

                       Computation: 1901 steps/s (collection: 3.042s, learning 0.745s)
               Value function loss: 76.6303
                    Surrogate loss: -0.0057
             Mean action noise std: 1.00
                       Mean reward: -55.72
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 36000
                    Iteration time: 3.79s
                        Total time: 21.43s
                               ETA: 8556.3s
################################################################################
                      [1m Learning iteration 5/2000 [0m                       

                       Computation: 1838 steps/s (collection: 3.048s, learning 0.868s)
               Value function loss: 59.9183
                    Surrogate loss: 0.0016
             Mean action noise std: 1.00
                       Mean reward: -55.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 43200
                    Iteration time: 3.92s
                        Total time: 25.35s
                               ETA: 8428.7s
################################################################################
                      [1m Learning iteration 6/2000 [0m                       

                       Computation: 1916 steps/s (collection: 3.136s, learning 0.622s)
               Value function loss: 58.3303
                    Surrogate loss: -0.0043
             Mean action noise std: 1.00
                       Mean reward: -55.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 50400
                    Iteration time: 3.76s
                        Total time: 29.11s
                               ETA: 8291.3s
################################################################################
                      [1m Learning iteration 7/2000 [0m                       

                       Computation: 1881 steps/s (collection: 3.212s, learning 0.615s)
               Value function loss: 50.1596
                    Surrogate loss: -0.0037
             Mean action noise std: 1.00
                       Mean reward: -55.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 57600
                    Iteration time: 3.83s
                        Total time: 32.93s
                               ETA: 8204.6s
################################################################################
                      [1m Learning iteration 8/2000 [0m                       

                       Computation: 1932 steps/s (collection: 3.098s, learning 0.627s)
               Value function loss: 48.1750
                    Surrogate loss: -0.0042
             Mean action noise std: 0.99
                       Mean reward: -55.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 64800
                    Iteration time: 3.72s
                        Total time: 36.66s
                               ETA: 8113.7s
################################################################################
                      [1m Learning iteration 9/2000 [0m                       

                       Computation: 1894 steps/s (collection: 3.177s, learning 0.624s)
               Value function loss: 46.1737
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -55.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 72000
                    Iteration time: 3.80s
                        Total time: 40.46s
                               ETA: 8055.5s
################################################################################
                      [1m Learning iteration 10/2000 [0m                      

                       Computation: 1924 steps/s (collection: 3.122s, learning 0.619s)
               Value function loss: 49.5829
                    Surrogate loss: -0.0049
             Mean action noise std: 0.99
                       Mean reward: -55.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 79200
                    Iteration time: 3.74s
                        Total time: 44.20s
                               ETA: 7996.3s
################################################################################
                      [1m Learning iteration 11/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.111s, learning 0.616s)
               Value function loss: 58.2134
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -55.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 86400
                    Iteration time: 3.73s
                        Total time: 47.93s
                               ETA: 7944.0s
################################################################################
                      [1m Learning iteration 12/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.102s, learning 0.659s)
               Value function loss: 47.5025
                    Surrogate loss: 0.0007
             Mean action noise std: 0.99
                       Mean reward: -56.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 93600
                    Iteration time: 3.76s
                        Total time: 51.69s
                               ETA: 7904.4s
################################################################################
                      [1m Learning iteration 13/2000 [0m                      

                       Computation: 1932 steps/s (collection: 3.129s, learning 0.596s)
               Value function loss: 52.7263
                    Surrogate loss: -0.0032
             Mean action noise std: 0.99
                       Mean reward: -56.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 100800
                    Iteration time: 3.73s
                        Total time: 55.41s
                               ETA: 7864.8s
################################################################################
                      [1m Learning iteration 14/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.113s, learning 0.754s)
               Value function loss: 57.3124
                    Surrogate loss: -0.0038
             Mean action noise std: 0.99
                       Mean reward: -56.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 108000
                    Iteration time: 3.87s
                        Total time: 59.28s
                               ETA: 7848.8s
################################################################################
                      [1m Learning iteration 15/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.062s, learning 0.675s)
               Value function loss: 43.4845
                    Surrogate loss: -0.0045
             Mean action noise std: 0.99
                       Mean reward: -56.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 115200
                    Iteration time: 3.74s
                        Total time: 63.02s
                               ETA: 7818.2s
################################################################################
                      [1m Learning iteration 16/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.176s, learning 0.640s)
               Value function loss: 44.4359
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 122400
                    Iteration time: 3.82s
                        Total time: 66.83s
                               ETA: 7800.0s
################################################################################
                      [1m Learning iteration 17/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.056s, learning 0.671s)
               Value function loss: 42.2122
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -54.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 129600
                    Iteration time: 3.73s
                        Total time: 70.56s
                               ETA: 7773.6s
################################################################################
                      [1m Learning iteration 18/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.127s, learning 0.669s)
               Value function loss: 41.1112
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -54.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 136800
                    Iteration time: 3.80s
                        Total time: 74.36s
                               ETA: 7756.7s
################################################################################
                      [1m Learning iteration 19/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.149s, learning 0.693s)
               Value function loss: 43.5620
                    Surrogate loss: -0.0051
             Mean action noise std: 0.99
                       Mean reward: -54.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 144000
                    Iteration time: 3.84s
                        Total time: 78.20s
                               ETA: 7745.7s
################################################################################
                      [1m Learning iteration 20/2000 [0m                      

                       Computation: 1919 steps/s (collection: 3.120s, learning 0.631s)
               Value function loss: 34.2933
                    Surrogate loss: 0.0097
             Mean action noise std: 0.99
                       Mean reward: -54.33
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 151200
                    Iteration time: 3.75s
                        Total time: 81.95s
                               ETA: 7726.9s
################################################################################
                      [1m Learning iteration 21/2000 [0m                      

                       Computation: 1841 steps/s (collection: 3.278s, learning 0.631s)
               Value function loss: 46.9817
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -54.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 158400
                    Iteration time: 3.91s
                        Total time: 85.86s
                               ETA: 7723.6s
################################################################################
                      [1m Learning iteration 22/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.099s, learning 0.636s)
               Value function loss: 48.4932
                    Surrogate loss: 0.0012
             Mean action noise std: 0.99
                       Mean reward: -55.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 165600
                    Iteration time: 3.74s
                        Total time: 89.60s
                               ETA: 7705.3s
################################################################################
                      [1m Learning iteration 23/2000 [0m                      

                       Computation: 1877 steps/s (collection: 3.162s, learning 0.672s)
               Value function loss: 43.2159
                    Surrogate loss: -0.0033
             Mean action noise std: 0.99
                       Mean reward: -55.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 172800
                    Iteration time: 3.83s
                        Total time: 93.43s
                               ETA: 7696.3s
################################################################################
                      [1m Learning iteration 24/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.190s, learning 0.613s)
               Value function loss: 47.0554
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 180000
                    Iteration time: 3.80s
                        Total time: 97.23s
                               ETA: 7685.4s
################################################################################
                      [1m Learning iteration 25/2000 [0m                      

                       Computation: 1924 steps/s (collection: 3.124s, learning 0.617s)
               Value function loss: 47.8379
                    Surrogate loss: -0.0025
             Mean action noise std: 0.99
                       Mean reward: -55.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 187200
                    Iteration time: 3.74s
                        Total time: 100.98s
                               ETA: 7670.3s
################################################################################
                      [1m Learning iteration 26/2000 [0m                      

                       Computation: 1864 steps/s (collection: 3.126s, learning 0.736s)
               Value function loss: 38.4298
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -55.53
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 194400
                    Iteration time: 3.86s
                        Total time: 104.84s
                               ETA: 7664.9s
################################################################################
                      [1m Learning iteration 27/2000 [0m                      

                       Computation: 1919 steps/s (collection: 3.091s, learning 0.661s)
               Value function loss: 39.0335
                    Surrogate loss: -0.0024
             Mean action noise std: 0.99
                       Mean reward: -54.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 201600
                    Iteration time: 3.75s
                        Total time: 108.59s
                               ETA: 7651.7s
################################################################################
                      [1m Learning iteration 28/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.272s, learning 0.618s)
               Value function loss: 33.7753
                    Surrogate loss: -0.0058
             Mean action noise std: 0.99
                       Mean reward: -54.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 208800
                    Iteration time: 3.89s
                        Total time: 112.48s
                               ETA: 7648.6s
################################################################################
                      [1m Learning iteration 29/2000 [0m                      

                       Computation: 1912 steps/s (collection: 3.139s, learning 0.625s)
               Value function loss: 40.2645
                    Surrogate loss: -0.0073
             Mean action noise std: 0.99
                       Mean reward: -53.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 216000
                    Iteration time: 3.76s
                        Total time: 116.24s
                               ETA: 7637.3s
################################################################################
                      [1m Learning iteration 30/2000 [0m                      

                       Computation: 1902 steps/s (collection: 3.147s, learning 0.638s)
               Value function loss: 38.1285
                    Surrogate loss: -0.0027
             Mean action noise std: 0.99
                       Mean reward: -53.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 223200
                    Iteration time: 3.78s
                        Total time: 120.03s
                               ETA: 7627.7s
################################################################################
                      [1m Learning iteration 31/2000 [0m                      

                       Computation: 1901 steps/s (collection: 3.168s, learning 0.618s)
               Value function loss: 41.0155
                    Surrogate loss: -0.0043
             Mean action noise std: 0.99
                       Mean reward: -52.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 230400
                    Iteration time: 3.79s
                        Total time: 123.82s
                               ETA: 7618.6s
################################################################################
                      [1m Learning iteration 32/2000 [0m                      

                       Computation: 1917 steps/s (collection: 3.130s, learning 0.625s)
               Value function loss: 40.3199
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -53.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 237600
                    Iteration time: 3.75s
                        Total time: 127.57s
                               ETA: 7607.8s
################################################################################
                      [1m Learning iteration 33/2000 [0m                      

                       Computation: 1823 steps/s (collection: 3.284s, learning 0.665s)
               Value function loss: 38.3529
                    Surrogate loss: -0.0039
             Mean action noise std: 0.99
                       Mean reward: -52.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 244800
                    Iteration time: 3.95s
                        Total time: 131.52s
                               ETA: 7608.8s
################################################################################
                      [1m Learning iteration 0/2000 [0m                       

                       Computation: 1114 steps/s (collection: 5.711s, learning 0.746s)
               Value function loss: 87.6143
                    Surrogate loss: -0.0028
             Mean action noise std: 1.00
                       Mean reward: -55.21
               Mean episode length: 43.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7200
                    Iteration time: 6.46s
                        Total time: 6.46s
                               ETA: 12915.0s
################################################################################
                      [1m Learning iteration 1/2000 [0m                       

                       Computation: 1755 steps/s (collection: 3.290s, learning 0.811s)
               Value function loss: 60.9052
                    Surrogate loss: -0.0024
             Mean action noise std: 1.00
                       Mean reward: -55.22
               Mean episode length: 43.67
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 14400
                    Iteration time: 4.10s
                        Total time: 10.56s
                               ETA: 10553.9s
################################################################################
                      [1m Learning iteration 2/2000 [0m                       

                       Computation: 1798 steps/s (collection: 3.126s, learning 0.877s)
               Value function loss: 87.3786
                    Surrogate loss: -0.0007
             Mean action noise std: 1.00
                       Mean reward: -55.43
               Mean episode length: 44.20
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 21600
                    Iteration time: 4.00s
                        Total time: 14.56s
                               ETA: 9698.7s
################################################################################
                      [1m Learning iteration 3/2000 [0m                       

                       Computation: 1790 steps/s (collection: 3.165s, learning 0.856s)
               Value function loss: 69.4787
                    Surrogate loss: -0.0035
             Mean action noise std: 1.00
                       Mean reward: -55.55
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 28800
                    Iteration time: 4.02s
                        Total time: 18.58s
                               ETA: 9277.9s
################################################################################
                      [1m Learning iteration 4/2000 [0m                       

                       Computation: 1762 steps/s (collection: 3.114s, learning 0.970s)
               Value function loss: 76.6303
                    Surrogate loss: -0.0057
             Mean action noise std: 1.00
                       Mean reward: -55.72
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 36000
                    Iteration time: 4.08s
                        Total time: 22.67s
                               ETA: 9049.1s
################################################################################
                      [1m Learning iteration 5/2000 [0m                       

                       Computation: 1876 steps/s (collection: 3.106s, learning 0.731s)
               Value function loss: 59.9183
                    Surrogate loss: 0.0016
             Mean action noise std: 1.00
                       Mean reward: -55.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 43200
                    Iteration time: 3.84s
                        Total time: 26.51s
                               ETA: 8813.0s
################################################################################
                      [1m Learning iteration 6/2000 [0m                       

                       Computation: 1835 steps/s (collection: 3.249s, learning 0.673s)
               Value function loss: 58.3303
                    Surrogate loss: -0.0043
             Mean action noise std: 1.00
                       Mean reward: -55.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 50400
                    Iteration time: 3.92s
                        Total time: 30.43s
                               ETA: 8667.5s
################################################################################
                      [1m Learning iteration 7/2000 [0m                       

                       Computation: 1853 steps/s (collection: 3.077s, learning 0.808s)
               Value function loss: 50.1596
                    Surrogate loss: -0.0037
             Mean action noise std: 1.00
                       Mean reward: -55.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 57600
                    Iteration time: 3.88s
                        Total time: 34.31s
                               ETA: 8548.1s
################################################################################
                      [1m Learning iteration 8/2000 [0m                       

                       Computation: 1860 steps/s (collection: 3.174s, learning 0.696s)
               Value function loss: 48.1750
                    Surrogate loss: -0.0042
             Mean action noise std: 0.99
                       Mean reward: -55.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 64800
                    Iteration time: 3.87s
                        Total time: 38.18s
                               ETA: 8451.2s
################################################################################
                      [1m Learning iteration 9/2000 [0m                       

                       Computation: 1898 steps/s (collection: 3.114s, learning 0.679s)
               Value function loss: 46.1737
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -55.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 72000
                    Iteration time: 3.79s
                        Total time: 41.98s
                               ETA: 8357.4s
################################################################################
                      [1m Learning iteration 10/2000 [0m                      

                       Computation: 1911 steps/s (collection: 3.084s, learning 0.681s)
               Value function loss: 49.5829
                    Surrogate loss: -0.0049
             Mean action noise std: 0.99
                       Mean reward: -55.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 79200
                    Iteration time: 3.77s
                        Total time: 45.74s
                               ETA: 8275.1s
################################################################################
                      [1m Learning iteration 11/2000 [0m                      

                       Computation: 1827 steps/s (collection: 3.251s, learning 0.688s)
               Value function loss: 58.2134
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -55.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 86400
                    Iteration time: 3.94s
                        Total time: 49.68s
                               ETA: 8234.6s
################################################################################
                      [1m Learning iteration 12/2000 [0m                      

                       Computation: 1906 steps/s (collection: 3.100s, learning 0.676s)
               Value function loss: 47.5025
                    Surrogate loss: 0.0007
             Mean action noise std: 0.99
                       Mean reward: -56.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 93600
                    Iteration time: 3.78s
                        Total time: 53.46s
                               ETA: 8174.8s
################################################################################
                      [1m Learning iteration 13/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.212s, learning 0.640s)
               Value function loss: 52.7263
                    Surrogate loss: -0.0032
             Mean action noise std: 0.99
                       Mean reward: -56.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 100800
                    Iteration time: 3.85s
                        Total time: 57.31s
                               ETA: 8133.7s
################################################################################
                      [1m Learning iteration 14/2000 [0m                      

                       Computation: 1907 steps/s (collection: 3.097s, learning 0.678s)
               Value function loss: 57.3124
                    Surrogate loss: -0.0038
             Mean action noise std: 0.99
                       Mean reward: -56.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 108000
                    Iteration time: 3.78s
                        Total time: 61.08s
                               ETA: 8087.4s
################################################################################
                      [1m Learning iteration 15/2000 [0m                      

                       Computation: 1908 steps/s (collection: 3.123s, learning 0.650s)
               Value function loss: 43.4845
                    Surrogate loss: -0.0045
             Mean action noise std: 0.99
                       Mean reward: -56.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 115200
                    Iteration time: 3.77s
                        Total time: 64.86s
                               ETA: 8046.2s
################################################################################
                      [1m Learning iteration 16/2000 [0m                      

                       Computation: 1890 steps/s (collection: 3.164s, learning 0.645s)
               Value function loss: 44.4359
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 122400
                    Iteration time: 3.81s
                        Total time: 68.66s
                               ETA: 8013.6s
################################################################################
                      [1m Learning iteration 17/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.108s, learning 0.711s)
               Value function loss: 42.2122
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -54.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 129600
                    Iteration time: 3.82s
                        Total time: 72.48s
                               ETA: 7985.2s
################################################################################
                      [1m Learning iteration 18/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.184s, learning 0.769s)
               Value function loss: 41.1112
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -54.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 136800
                    Iteration time: 3.95s
                        Total time: 76.44s
                               ETA: 7973.6s
################################################################################
                      [1m Learning iteration 19/2000 [0m                      

                       Computation: 1847 steps/s (collection: 3.132s, learning 0.766s)
               Value function loss: 43.5620
                    Surrogate loss: -0.0051
             Mean action noise std: 0.99
                       Mean reward: -54.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 144000
                    Iteration time: 3.90s
                        Total time: 80.33s
                               ETA: 7957.1s
################################################################################
                      [1m Learning iteration 20/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.187s, learning 0.641s)
               Value function loss: 34.2933
                    Surrogate loss: 0.0097
             Mean action noise std: 0.99
                       Mean reward: -54.33
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 151200
                    Iteration time: 3.83s
                        Total time: 84.16s
                               ETA: 7935.4s
################################################################################
                      [1m Learning iteration 21/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.137s, learning 0.706s)
               Value function loss: 46.9817
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -54.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 158400
                    Iteration time: 3.84s
                        Total time: 88.01s
                               ETA: 7916.5s
################################################################################
                      [1m Learning iteration 22/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.076s, learning 0.740s)
               Value function loss: 48.4932
                    Surrogate loss: 0.0012
             Mean action noise std: 0.99
                       Mean reward: -55.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 165600
                    Iteration time: 3.82s
                        Total time: 91.82s
                               ETA: 7896.8s
################################################################################
                      [1m Learning iteration 23/2000 [0m                      

                       Computation: 1828 steps/s (collection: 3.188s, learning 0.749s)
               Value function loss: 43.2159
                    Surrogate loss: -0.0033
             Mean action noise std: 0.99
                       Mean reward: -55.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 172800
                    Iteration time: 3.94s
                        Total time: 95.76s
                               ETA: 7888.3s
################################################################################
                      [1m Learning iteration 24/2000 [0m                      

                       Computation: 1895 steps/s (collection: 3.150s, learning 0.647s)
               Value function loss: 47.0554
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 180000
                    Iteration time: 3.80s
                        Total time: 99.56s
                               ETA: 7869.1s
################################################################################
                      [1m Learning iteration 25/2000 [0m                      

                       Computation: 1842 steps/s (collection: 3.226s, learning 0.682s)
               Value function loss: 47.8379
                    Surrogate loss: -0.0025
             Mean action noise std: 0.99
                       Mean reward: -55.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 187200
                    Iteration time: 3.91s
                        Total time: 103.47s
                               ETA: 7859.5s
################################################################################
                      [1m Learning iteration 26/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.134s, learning 0.646s)
               Value function loss: 38.4298
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -55.53
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 194400
                    Iteration time: 3.78s
                        Total time: 107.25s
                               ETA: 7840.9s
################################################################################
                      [1m Learning iteration 27/2000 [0m                      

                       Computation: 1857 steps/s (collection: 3.134s, learning 0.742s)
               Value function loss: 39.0335
                    Surrogate loss: -0.0024
             Mean action noise std: 0.99
                       Mean reward: -54.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 201600
                    Iteration time: 3.88s
                        Total time: 111.12s
                               ETA: 7830.2s
################################################################################
                      [1m Learning iteration 28/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.162s, learning 0.722s)
               Value function loss: 33.7753
                    Surrogate loss: -0.0058
             Mean action noise std: 0.99
                       Mean reward: -54.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 208800
                    Iteration time: 3.88s
                        Total time: 115.01s
                               ETA: 7820.5s
################################################################################
                      [1m Learning iteration 29/2000 [0m                      

                       Computation: 1836 steps/s (collection: 3.139s, learning 0.781s)
               Value function loss: 40.2645
                    Surrogate loss: -0.0073
             Mean action noise std: 0.99
                       Mean reward: -53.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 216000
                    Iteration time: 3.92s
                        Total time: 118.93s
                               ETA: 7813.5s
################################################################################
                      [1m Learning iteration 30/2000 [0m                      

                       Computation: 1789 steps/s (collection: 3.223s, learning 0.801s)
               Value function loss: 38.1285
                    Surrogate loss: -0.0027
             Mean action noise std: 0.99
                       Mean reward: -53.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 223200
                    Iteration time: 4.02s
                        Total time: 122.95s
                               ETA: 7813.3s
################################################################################
                      [1m Learning iteration 31/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.119s, learning 0.708s)
               Value function loss: 41.0155
                    Surrogate loss: -0.0043
             Mean action noise std: 0.99
                       Mean reward: -52.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 230400
                    Iteration time: 3.83s
                        Total time: 126.78s
                               ETA: 7800.8s
################################################################################
                      [1m Learning iteration 32/2000 [0m                      

                       Computation: 1782 steps/s (collection: 3.211s, learning 0.829s)
               Value function loss: 40.3199
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -53.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 237600
                    Iteration time: 4.04s
                        Total time: 130.82s
                               ETA: 7801.5s
################################################################################
                      [1m Learning iteration 33/2000 [0m                      

                       Computation: 1801 steps/s (collection: 3.213s, learning 0.783s)
               Value function loss: 38.3529
                    Surrogate loss: -0.0039
             Mean action noise std: 0.99
                       Mean reward: -52.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 244800
                    Iteration time: 4.00s
                        Total time: 134.81s
                               ETA: 7799.4s
################################################################################
                      [1m Learning iteration 34/2000 [0m                      

                       Computation: 1890 steps/s (collection: 3.133s, learning 0.675s)
               Value function loss: 38.4416
                    Surrogate loss: 0.0076
             Mean action noise std: 0.99
                       Mean reward: -53.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 252000
                    Iteration time: 3.81s
                        Total time: 138.62s
                               ETA: 7786.6s
################################################################################
                      [1m Learning iteration 35/2000 [0m                      

                       Computation: 1784 steps/s (collection: 3.216s, learning 0.818s)
               Value function loss: 39.5888
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -53.10
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 259200
                    Iteration time: 4.03s
                        Total time: 142.66s
                               ETA: 7786.6s
################################################################################
                      [1m Learning iteration 36/2000 [0m                      

                       Computation: 1824 steps/s (collection: 3.125s, learning 0.822s)
               Value function loss: 41.4946
                    Surrogate loss: -0.0040
             Mean action noise std: 0.99
                       Mean reward: -53.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 266400
                    Iteration time: 3.95s
                        Total time: 146.60s
                               ETA: 7781.8s
################################################################################
                      [1m Learning iteration 37/2000 [0m                      

                       Computation: 1793 steps/s (collection: 3.179s, learning 0.836s)
               Value function loss: 38.0765
                    Surrogate loss: -0.0061
             Mean action noise std: 0.99
                       Mean reward: -52.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 273600
                    Iteration time: 4.01s
                        Total time: 150.62s
                               ETA: 7780.6s
################################################################################
                      [1m Learning iteration 38/2000 [0m                      

                       Computation: 1796 steps/s (collection: 3.159s, learning 0.848s)
               Value function loss: 44.5340
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -52.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 280800
                    Iteration time: 4.01s
                        Total time: 154.62s
                               ETA: 7778.8s
################################################################################
                      [1m Learning iteration 39/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.126s, learning 0.775s)
               Value function loss: 36.2183
                    Surrogate loss: 0.0018
             Mean action noise std: 0.99
                       Mean reward: -52.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 288000
                    Iteration time: 3.90s
                        Total time: 158.53s
                               ETA: 7771.7s
################################################################################
                      [1m Learning iteration 40/2000 [0m                      

                       Computation: 1770 steps/s (collection: 3.236s, learning 0.830s)
               Value function loss: 34.4764
                    Surrogate loss: -0.0010
             Mean action noise std: 0.99
                       Mean reward: -51.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 295200
                    Iteration time: 4.07s
                        Total time: 162.59s
                               ETA: 7772.7s
################################################################################
                      [1m Learning iteration 41/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.140s, learning 0.711s)
               Value function loss: 36.5184
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -51.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 302400
                    Iteration time: 3.85s
                        Total time: 166.44s
                               ETA: 7763.4s
################################################################################
                      [1m Learning iteration 42/2000 [0m                      

                       Computation: 1772 steps/s (collection: 3.199s, learning 0.863s)
               Value function loss: 39.0004
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -51.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 309600
                    Iteration time: 4.06s
                        Total time: 170.51s
                               ETA: 7764.0s
################################################################################
                      [1m Learning iteration 43/2000 [0m                      

                       Computation: 1795 steps/s (collection: 3.153s, learning 0.857s)
               Value function loss: 42.0665
                    Surrogate loss: -0.0017
             Mean action noise std: 0.99
                       Mean reward: -52.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 316800
                    Iteration time: 4.01s
                        Total time: 174.52s
                               ETA: 7762.0s
################################################################################
                      [1m Learning iteration 44/2000 [0m                      

                       Computation: 1831 steps/s (collection: 3.122s, learning 0.809s)
               Value function loss: 41.4940
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -52.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 324000
                    Iteration time: 3.93s
                        Total time: 178.45s
                               ETA: 7756.5s
################################################################################
                      [1m Learning iteration 45/2000 [0m                      

                       Computation: 1826 steps/s (collection: 3.178s, learning 0.764s)
               Value function loss: 33.4112
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -52.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 331200
                    Iteration time: 3.94s
                        Total time: 182.39s
                               ETA: 7751.5s
################################################################################
                      [1m Learning iteration 46/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.135s, learning 0.629s)
               Value function loss: 29.0818
                    Surrogate loss: 0.0185
             Mean action noise std: 0.99
                       Mean reward: -52.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 338400
                    Iteration time: 3.76s
                        Total time: 186.15s
                               ETA: 7739.2s
################################################################################
                      [1m Learning iteration 47/2000 [0m                      

                       Computation: 1831 steps/s (collection: 3.144s, learning 0.787s)
               Value function loss: 35.3084
                    Surrogate loss: 0.0096
             Mean action noise std: 0.99
                       Mean reward: -52.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 345600
                    Iteration time: 3.93s
                        Total time: 190.08s
                               ETA: 7734.0s
################################################################################
                      [1m Learning iteration 48/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.135s, learning 0.657s)
               Value function loss: 35.7524
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -51.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 352800
                    Iteration time: 3.79s
                        Total time: 193.88s
                               ETA: 7723.4s
################################################################################
                      [1m Learning iteration 49/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.128s, learning 0.740s)
               Value function loss: 33.0440
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -51.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 360000
                    Iteration time: 3.87s
                        Total time: 197.74s
                               ETA: 7716.0s
################################################################################
                      [1m Learning iteration 50/2000 [0m                      

                       Computation: 1837 steps/s (collection: 3.226s, learning 0.693s)
               Value function loss: 34.2946
                    Surrogate loss: -0.0047
             Mean action noise std: 0.99
                       Mean reward: -51.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 367200
                    Iteration time: 3.92s
                        Total time: 201.66s
                               ETA: 7710.7s
################################################################################
                      [1m Learning iteration 51/2000 [0m                      

                       Computation: 1851 steps/s (collection: 3.105s, learning 0.783s)
               Value function loss: 33.1621
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -51.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 374400
                    Iteration time: 3.89s
                        Total time: 205.55s
                               ETA: 7704.3s
################################################################################
                      [1m Learning iteration 52/2000 [0m                      

                       Computation: 1823 steps/s (collection: 3.154s, learning 0.795s)
               Value function loss: 33.1356
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -51.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 381600
                    Iteration time: 3.95s
                        Total time: 209.50s
                               ETA: 7700.2s
################################################################################
                      [1m Learning iteration 53/2000 [0m                      

                       Computation: 1893 steps/s (collection: 3.138s, learning 0.665s)
               Value function loss: 34.3554
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -51.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 388800
                    Iteration time: 3.80s
                        Total time: 213.30s
                               ETA: 7690.8s
################################################################################
                      [1m Learning iteration 54/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.129s, learning 0.761s)
               Value function loss: 32.2024
                    Surrogate loss: -0.0022
             Mean action noise std: 0.99
                       Mean reward: -51.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 396000
                    Iteration time: 3.89s
                        Total time: 217.19s
                               ETA: 7684.7s
################################################################################
                      [1m Learning iteration 55/2000 [0m                      

                       Computation: 1879 steps/s (collection: 3.143s, learning 0.687s)
               Value function loss: 33.4714
                    Surrogate loss: 0.0039
             Mean action noise std: 0.99
                       Mean reward: -51.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 403200
                    Iteration time: 3.83s
                        Total time: 221.02s
                               ETA: 7676.7s
################################################################################
                      [1m Learning iteration 56/2000 [0m                      

                       Computation: 1901 steps/s (collection: 3.118s, learning 0.669s)
               Value function loss: 29.8262
                    Surrogate loss: -0.0002
             Mean action noise std: 0.99
                       Mean reward: -51.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 410400
                    Iteration time: 3.79s
                        Total time: 224.81s
                               ETA: 7667.3s
################################################################################
                      [1m Learning iteration 57/2000 [0m                      

                       Computation: 1839 steps/s (collection: 3.195s, learning 0.719s)
               Value function loss: 32.3009
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -50.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 417600
                    Iteration time: 3.91s
                        Total time: 228.73s
                               ETA: 7662.3s
################################################################################
                      [1m Learning iteration 58/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.141s, learning 0.652s)
               Value function loss: 29.6770
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -50.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 424800
                    Iteration time: 3.79s
                        Total time: 232.52s
                               ETA: 7653.4s
################################################################################
                      [1m Learning iteration 59/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.184s, learning 0.720s)
               Value function loss: 27.6777
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -50.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 432000
                    Iteration time: 3.90s
                        Total time: 236.42s
                               ETA: 7648.3s
################################################################################
                      [1m Learning iteration 60/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.139s, learning 0.798s)
               Value function loss: 30.1422
                    Surrogate loss: -0.0003
             Mean action noise std: 0.99
                       Mean reward: -50.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 439200
                    Iteration time: 3.94s
                        Total time: 240.36s
                               ETA: 7644.2s
################################################################################
                      [1m Learning iteration 61/2000 [0m                      

                       Computation: 1866 steps/s (collection: 3.147s, learning 0.711s)
               Value function loss: 31.8961
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -50.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 446400
                    Iteration time: 3.86s
                        Total time: 244.22s
                               ETA: 7637.7s
################################################################################
                      [1m Learning iteration 62/2000 [0m                      

                       Computation: 1815 steps/s (collection: 3.135s, learning 0.832s)
               Value function loss: 33.4506
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -50.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 453600
                    Iteration time: 3.97s
                        Total time: 248.18s
                               ETA: 7634.6s
################################################################################
                      [1m Learning iteration 63/2000 [0m                      

                       Computation: 1856 steps/s (collection: 3.158s, learning 0.721s)
               Value function loss: 30.5063
                    Surrogate loss: -0.0029
             Mean action noise std: 0.98
                       Mean reward: -49.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 460800
                    Iteration time: 3.88s
                        Total time: 252.06s
                               ETA: 7628.8s
################################################################################
                      [1m Learning iteration 64/2000 [0m                      

                       Computation: 1789 steps/s (collection: 3.264s, learning 0.760s)
               Value function loss: 33.2652
                    Surrogate loss: -0.0063
             Mean action noise std: 0.98
                       Mean reward: -49.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 468000
                    Iteration time: 4.02s
                        Total time: 256.09s
                               ETA: 7627.4s
################################################################################
                      [1m Learning iteration 65/2000 [0m                      

                       Computation: 1835 steps/s (collection: 3.149s, learning 0.773s)
               Value function loss: 31.3134
                    Surrogate loss: -0.0074
             Mean action noise std: 0.98
                       Mean reward: -50.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 475200
                    Iteration time: 3.92s
                        Total time: 260.01s
                               ETA: 7623.0s
################################################################################
                      [1m Learning iteration 66/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.155s, learning 0.698s)
               Value function loss: 35.0529
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 482400
                    Iteration time: 3.85s
                        Total time: 263.86s
                               ETA: 7616.5s
################################################################################
                      [1m Learning iteration 67/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.232s, learning 0.671s)
               Value function loss: 30.9591
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -50.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 489600
                    Iteration time: 3.90s
                        Total time: 267.76s
                               ETA: 7611.6s
################################################################################
                      [1m Learning iteration 68/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.148s, learning 0.675s)
               Value function loss: 31.7109
                    Surrogate loss: -0.0084
             Mean action noise std: 0.98
                       Mean reward: -49.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 496800
                    Iteration time: 3.82s
                        Total time: 271.59s
                               ETA: 7604.4s
################################################################################
                      [1m Learning iteration 69/2000 [0m                      

                       Computation: 1828 steps/s (collection: 3.253s, learning 0.686s)
               Value function loss: 29.9669
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 504000
                    Iteration time: 3.94s
                        Total time: 275.53s
                               ETA: 7600.6s
################################################################################
                      [1m Learning iteration 70/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.145s, learning 0.665s)
               Value function loss: 30.2034
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 511200
                    Iteration time: 3.81s
                        Total time: 279.33s
                               ETA: 7593.2s
################################################################################
                      [1m Learning iteration 71/2000 [0m                      

                       Computation: 1857 steps/s (collection: 3.171s, learning 0.705s)
               Value function loss: 32.5000
                    Surrogate loss: -0.0026
             Mean action noise std: 0.98
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 518400
                    Iteration time: 3.88s
                        Total time: 283.21s
                               ETA: 7587.7s
################################################################################
                      [1m Learning iteration 72/2000 [0m                      

                       Computation: 1856 steps/s (collection: 3.233s, learning 0.644s)
               Value function loss: 34.1269
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 525600
                    Iteration time: 3.88s
                        Total time: 287.09s
                               ETA: 7582.3s
################################################################################
                      [1m Learning iteration 73/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.141s, learning 0.672s)
               Value function loss: 31.0529
                    Surrogate loss: -0.0057
             Mean action noise std: 0.98
                       Mean reward: -50.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 532800
                    Iteration time: 3.81s
                        Total time: 290.90s
                               ETA: 7575.2s
################################################################################
                      [1m Learning iteration 74/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.278s, learning 0.676s)
               Value function loss: 28.5101
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -49.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 540000
                    Iteration time: 3.95s
                        Total time: 294.85s
                               ETA: 7571.9s
################################################################################
                      [1m Learning iteration 75/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.157s, learning 0.659s)
               Value function loss: 32.0992
                    Surrogate loss: -0.0059
             Mean action noise std: 0.98
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 547200
                    Iteration time: 3.82s
                        Total time: 298.67s
                               ETA: 7565.0s
################################################################################
                      [1m Learning iteration 76/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.214s, learning 0.703s)
               Value function loss: 31.4500
                    Surrogate loss: -0.0063
             Mean action noise std: 0.98
                       Mean reward: -49.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 554400
                    Iteration time: 3.92s
                        Total time: 302.59s
                               ETA: 7560.8s
################################################################################
                      [1m Learning iteration 77/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.151s, learning 0.682s)
               Value function loss: 30.3769
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 561600
                    Iteration time: 3.83s
                        Total time: 306.42s
                               ETA: 7554.4s
################################################################################
                      [1m Learning iteration 78/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.170s, learning 0.678s)
               Value function loss: 32.6787
                    Surrogate loss: -0.0048
             Mean action noise std: 0.98
                       Mean reward: -49.25
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 568800
                    Iteration time: 3.85s
                        Total time: 310.27s
                               ETA: 7548.5s
################################################################################
                      [1m Learning iteration 79/2000 [0m                      

                       Computation: 1841 steps/s (collection: 3.234s, learning 0.677s)
               Value function loss: 29.4594
                    Surrogate loss: -0.0066
             Mean action noise std: 0.98
                       Mean reward: -49.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 576000
                    Iteration time: 3.91s
                        Total time: 314.18s
                               ETA: 7544.2s
################################################################################
                      [1m Learning iteration 80/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.085s, learning 0.741s)
               Value function loss: 31.4366
                    Surrogate loss: -0.0033
             Mean action noise std: 0.98
                       Mean reward: -50.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 583200
                    Iteration time: 3.83s
                        Total time: 318.00s
                               ETA: 7537.9s
################################################################################
                      [1m Learning iteration 81/2000 [0m                      

                       Computation: 1817 steps/s (collection: 3.277s, learning 0.685s)
               Value function loss: 31.4435
                    Surrogate loss: 0.0025
             Mean action noise std: 0.97
                       Mean reward: -50.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 590400
                    Iteration time: 3.96s
                        Total time: 321.97s
                               ETA: 7534.8s
################################################################################
                      [1m Learning iteration 82/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.132s, learning 0.629s)
               Value function loss: 27.2720
                    Surrogate loss: -0.0026
             Mean action noise std: 0.97
                       Mean reward: -50.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 597600
                    Iteration time: 3.76s
                        Total time: 325.73s
                               ETA: 7527.1s
################################################################################
                      [1m Learning iteration 83/2000 [0m                      

                       Computation: 1849 steps/s (collection: 3.157s, learning 0.736s)
               Value function loss: 24.7333
                    Surrogate loss: 0.0035
             Mean action noise std: 0.97
                       Mean reward: -50.28
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 604800
                    Iteration time: 3.89s
                        Total time: 329.62s
                               ETA: 7522.4s
################################################################################
                      [1m Learning iteration 84/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.131s, learning 0.740s)
               Value function loss: 30.4519
                    Surrogate loss: -0.0006
             Mean action noise std: 0.97
                       Mean reward: -49.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 612000
                    Iteration time: 3.87s
                        Total time: 333.49s
                               ETA: 7517.3s
################################################################################
                      [1m Learning iteration 85/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.133s, learning 0.691s)
               Value function loss: 27.7287
                    Surrogate loss: 0.0006
             Mean action noise std: 0.97
                       Mean reward: -49.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 619200
                    Iteration time: 3.82s
                        Total time: 337.32s
                               ETA: 7511.2s
################################################################################
                      [1m Learning iteration 86/2000 [0m                      

                       Computation: 1824 steps/s (collection: 3.262s, learning 0.684s)
               Value function loss: 24.4723
                    Surrogate loss: -0.0016
             Mean action noise std: 0.97
                       Mean reward: -49.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 626400
                    Iteration time: 3.95s
                        Total time: 341.26s
                               ETA: 7507.8s
################################################################################
                      [1m Learning iteration 87/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.131s, learning 0.717s)
               Value function loss: 32.0193
                    Surrogate loss: -0.0001
             Mean action noise std: 0.97
                       Mean reward: -48.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 633600
                    Iteration time: 3.85s
                        Total time: 345.11s
                               ETA: 7502.2s
################################################################################
                      [1m Learning iteration 88/2000 [0m                      

                       Computation: 1841 steps/s (collection: 3.250s, learning 0.658s)
               Value function loss: 28.3677
                    Surrogate loss: -0.0040
             Mean action noise std: 0.97
                       Mean reward: -49.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 640800
                    Iteration time: 3.91s
                        Total time: 349.02s
                               ETA: 7498.0s
################################################################################
                      [1m Learning iteration 89/2000 [0m                      

                       Computation: 1858 steps/s (collection: 3.169s, learning 0.705s)
               Value function loss: 29.8453
                    Surrogate loss: -0.0028
             Mean action noise std: 0.97
                       Mean reward: -50.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 648000
                    Iteration time: 3.87s
                        Total time: 352.89s
                               ETA: 7493.1s
################################################################################
                      [1m Learning iteration 90/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.136s, learning 0.702s)
               Value function loss: 25.7069
                    Surrogate loss: -0.0019
             Mean action noise std: 0.97
                       Mean reward: -49.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 655200
                    Iteration time: 3.84s
                        Total time: 356.73s
                               ETA: 7487.4s
################################################################################
                      [1m Learning iteration 91/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.139s, learning 0.699s)
               Value function loss: 28.5759
                    Surrogate loss: -0.0049
             Mean action noise std: 0.97
                       Mean reward: -49.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 662400
                    Iteration time: 3.84s
                        Total time: 360.57s
                               ETA: 7481.8s
################################################################################
                      [1m Learning iteration 92/2000 [0m                      

                       Computation: 1900 steps/s (collection: 3.147s, learning 0.642s)
               Value function loss: 25.1321
                    Surrogate loss: -0.0003
             Mean action noise std: 0.97
                       Mean reward: -50.02
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 669600
                    Iteration time: 3.79s
                        Total time: 364.36s
                               ETA: 7475.2s
################################################################################
                      [1m Learning iteration 93/2000 [0m                      

                       Computation: 1831 steps/s (collection: 3.274s, learning 0.656s)
               Value function loss: 26.4642
                    Surrogate loss: -0.0053
             Mean action noise std: 0.97
                       Mean reward: -49.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 676800
                    Iteration time: 3.93s
                        Total time: 368.29s
                               ETA: 7471.6s
################################################################################
                      [1m Learning iteration 94/2000 [0m                      

                       Computation: 1858 steps/s (collection: 3.136s, learning 0.738s)
               Value function loss: 26.6313
                    Surrogate loss: -0.0059
             Mean action noise std: 0.97
                       Mean reward: -48.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 684000
                    Iteration time: 3.87s
                        Total time: 372.16s
                               ETA: 7466.8s
################################################################################
                      [1m Learning iteration 95/2000 [0m                      

                       Computation: 1830 steps/s (collection: 3.227s, learning 0.707s)
               Value function loss: 25.3491
                    Surrogate loss: 0.0016
             Mean action noise std: 0.97
                       Mean reward: -49.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 691200
                    Iteration time: 3.93s
                        Total time: 376.10s
                               ETA: 7463.2s
################################################################################
                      [1m Learning iteration 96/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.118s, learning 0.629s)
               Value function loss: 28.1155
                    Surrogate loss: 0.0093
             Mean action noise std: 0.98
                       Mean reward: -49.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 698400
                    Iteration time: 3.75s
                        Total time: 379.84s
                               ETA: 7455.9s
################################################################################
                      [1m Learning iteration 97/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.171s, learning 0.676s)
               Value function loss: 23.7082
                    Surrogate loss: -0.0052
             Mean action noise std: 0.98
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 705600
                    Iteration time: 3.85s
                        Total time: 383.69s
                               ETA: 7450.6s
################################################################################
                      [1m Learning iteration 98/2000 [0m                      

                       Computation: 1831 steps/s (collection: 3.249s, learning 0.681s)
               Value function loss: 26.0409
                    Surrogate loss: -0.0017
             Mean action noise std: 0.98
                       Mean reward: -49.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 712800
                    Iteration time: 3.93s
                        Total time: 387.62s
                               ETA: 7447.0s
################################################################################
                      [1m Learning iteration 99/2000 [0m                      

                       Computation: 1901 steps/s (collection: 3.131s, learning 0.656s)
               Value function loss: 27.1381
                    Surrogate loss: 0.0020
             Mean action noise std: 0.98
                       Mean reward: -49.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 720000
                    Iteration time: 3.79s
                        Total time: 391.41s
                               ETA: 7440.7s
################################################################################
                     [1m Learning iteration 100/2000 [0m                      

                       Computation: 1833 steps/s (collection: 3.260s, learning 0.668s)
               Value function loss: 26.2942
                    Surrogate loss: -0.0006
             Mean action noise std: 0.98
                       Mean reward: -49.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 727200
                    Iteration time: 3.93s
                        Total time: 395.33s
                               ETA: 7437.0s
################################################################################
                     [1m Learning iteration 101/2000 [0m                      

                       Computation: 1894 steps/s (collection: 3.119s, learning 0.681s)
               Value function loss: 28.5187
                    Surrogate loss: 0.0052
             Mean action noise std: 0.98
                       Mean reward: -48.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 734400
                    Iteration time: 3.80s
                        Total time: 399.13s
                               ETA: 7430.9s
################################################################################
                     [1m Learning iteration 102/2000 [0m                      

                       Computation: 1835 steps/s (collection: 3.154s, learning 0.769s)
               Value function loss: 27.8748
                    Surrogate loss: 0.0123
             Mean action noise std: 0.98
                       Mean reward: -48.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 741600
                    Iteration time: 3.92s
                        Total time: 403.06s
                               ETA: 7427.2s
################################################################################
                     [1m Learning iteration 103/2000 [0m                      

                       Computation: 1864 steps/s (collection: 3.172s, learning 0.691s)
               Value function loss: 25.6303
                    Surrogate loss: -0.0047
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 748800
                    Iteration time: 3.86s
                        Total time: 406.92s
                               ETA: 7422.4s
################################################################################
                     [1m Learning iteration 104/2000 [0m                      

                       Computation: 1833 steps/s (collection: 3.147s, learning 0.781s)
               Value function loss: 26.0222
                    Surrogate loss: -0.0057
             Mean action noise std: 0.98
                       Mean reward: -48.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 756000
                    Iteration time: 3.93s
                        Total time: 410.85s
                               ETA: 7418.7s
################################################################################
                     [1m Learning iteration 105/2000 [0m                      

                       Computation: 1833 steps/s (collection: 3.291s, learning 0.636s)
               Value function loss: 23.4744
                    Surrogate loss: -0.0027
             Mean action noise std: 0.98
                       Mean reward: -48.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 763200
                    Iteration time: 3.93s
                        Total time: 414.78s
                               ETA: 7415.1s
################################################################################
                     [1m Learning iteration 106/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.154s, learning 0.675s)
               Value function loss: 24.8079
                    Surrogate loss: 0.0012
             Mean action noise std: 0.98
                       Mean reward: -49.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 770400
                    Iteration time: 3.83s
                        Total time: 418.60s
                               ETA: 7409.7s
################################################################################
                     [1m Learning iteration 107/2000 [0m                      

                       Computation: 1817 steps/s (collection: 3.281s, learning 0.681s)
               Value function loss: 24.6536
                    Surrogate loss: -0.0047
             Mean action noise std: 0.98
                       Mean reward: -49.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 777600
                    Iteration time: 3.96s
                        Total time: 422.57s
                               ETA: 7406.6s
################################################################################
                     [1m Learning iteration 108/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.160s, learning 0.707s)
               Value function loss: 23.5256
                    Surrogate loss: -0.0065
             Mean action noise std: 0.98
                       Mean reward: -49.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 784800
                    Iteration time: 3.87s
                        Total time: 426.43s
                               ETA: 7401.9s
################################################################################
                     [1m Learning iteration 109/2000 [0m                      

                       Computation: 1872 steps/s (collection: 3.163s, learning 0.683s)
               Value function loss: 26.3820
                    Surrogate loss: -0.0037
             Mean action noise std: 0.98
                       Mean reward: -49.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 792000
                    Iteration time: 3.85s
                        Total time: 430.28s
                               ETA: 7396.9s
################################################################################
                     [1m Learning iteration 110/2000 [0m                      

                       Computation: 1831 steps/s (collection: 3.240s, learning 0.692s)
               Value function loss: 25.5668
                    Surrogate loss: -0.0080
             Mean action noise std: 0.98
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 799200
                    Iteration time: 3.93s
                        Total time: 434.21s
                               ETA: 7393.3s
################################################################################
                     [1m Learning iteration 111/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.133s, learning 0.672s)
               Value function loss: 26.6566
                    Surrogate loss: -0.0052
             Mean action noise std: 0.98
                       Mean reward: -48.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 806400
                    Iteration time: 3.81s
                        Total time: 438.02s
                               ETA: 7387.6s
################################################################################
                     [1m Learning iteration 112/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.249s, learning 0.667s)
               Value function loss: 27.0673
                    Surrogate loss: -0.0049
             Mean action noise std: 0.98
                       Mean reward: -49.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 813600
                    Iteration time: 3.92s
                        Total time: 441.93s
                               ETA: 7383.8s
################################################################################
                     [1m Learning iteration 113/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.188s, learning 0.633s)
               Value function loss: 24.0829
                    Surrogate loss: -0.0058
             Mean action noise std: 0.98
                       Mean reward: -50.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 820800
                    Iteration time: 3.82s
                        Total time: 445.75s
                               ETA: 7378.4s
################################################################################
                     [1m Learning iteration 114/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.139s, learning 0.708s)
               Value function loss: 23.7772
                    Surrogate loss: -0.0040
             Mean action noise std: 0.98
                       Mean reward: -50.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 828000
                    Iteration time: 3.85s
                        Total time: 449.60s
                               ETA: 7373.4s
################################################################################
                     [1m Learning iteration 115/2000 [0m                      

                       Computation: 1774 steps/s (collection: 3.263s, learning 0.794s)
               Value function loss: 24.7225
                    Surrogate loss: -0.0034
             Mean action noise std: 0.98
                       Mean reward: -50.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 835200
                    Iteration time: 4.06s
                        Total time: 453.66s
                               ETA: 7371.9s
################################################################################
                     [1m Learning iteration 116/2000 [0m                      

                       Computation: 1830 steps/s (collection: 3.135s, learning 0.799s)
               Value function loss: 27.2398
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -50.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 842400
                    Iteration time: 3.93s
                        Total time: 457.59s
                               ETA: 7368.4s
################################################################################
                     [1m Learning iteration 117/2000 [0m                      

                       Computation: 1766 steps/s (collection: 3.243s, learning 0.833s)
               Value function loss: 24.7676
                    Surrogate loss: -0.0052
             Mean action noise std: 0.98
                       Mean reward: -49.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 849600
                    Iteration time: 4.08s
                        Total time: 461.67s
                               ETA: 7367.1s
################################################################################
                     [1m Learning iteration 118/2000 [0m                      

                       Computation: 1806 steps/s (collection: 3.163s, learning 0.822s)
               Value function loss: 23.6692
                    Surrogate loss: -0.0036
             Mean action noise std: 0.98
                       Mean reward: -49.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 856800
                    Iteration time: 3.99s
                        Total time: 465.65s
                               ETA: 7364.3s
################################################################################
                     [1m Learning iteration 119/2000 [0m                      

                       Computation: 1824 steps/s (collection: 3.155s, learning 0.792s)
               Value function loss: 26.7770
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 864000
                    Iteration time: 3.95s
                        Total time: 469.60s
                               ETA: 7360.9s
################################################################################
                     [1m Learning iteration 120/2000 [0m                      

                       Computation: 1773 steps/s (collection: 3.296s, learning 0.763s)
               Value function loss: 25.6117
                    Surrogate loss: -0.0023
             Mean action noise std: 0.98
                       Mean reward: -49.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 871200
                    Iteration time: 4.06s
                        Total time: 473.66s
                               ETA: 7359.3s
################################################################################
                     [1m Learning iteration 121/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.138s, learning 0.683s)
               Value function loss: 24.0778
                    Surrogate loss: -0.0024
             Mean action noise std: 0.98
                       Mean reward: -49.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 878400
                    Iteration time: 3.82s
                        Total time: 477.48s
                               ETA: 7353.9s
################################################################################
                     [1m Learning iteration 122/2000 [0m                      

                       Computation: 1825 steps/s (collection: 3.287s, learning 0.657s)
               Value function loss: 26.9927
                    Surrogate loss: -0.0057
             Mean action noise std: 0.98
                       Mean reward: -49.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 885600
                    Iteration time: 3.94s
                        Total time: 481.42s
                               ETA: 7350.5s
################################################################################
                     [1m Learning iteration 123/2000 [0m                      

                       Computation: 1868 steps/s (collection: 3.158s, learning 0.695s)
               Value function loss: 26.7252
                    Surrogate loss: -0.0059
             Mean action noise std: 0.98
                       Mean reward: -49.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 892800
                    Iteration time: 3.85s
                        Total time: 485.27s
                               ETA: 7345.6s
################################################################################
                     [1m Learning iteration 124/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.149s, learning 0.742s)
               Value function loss: 27.0006
                    Surrogate loss: -0.0048
             Mean action noise std: 0.98
                       Mean reward: -49.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 900000
                    Iteration time: 3.89s
                        Total time: 489.17s
                               ETA: 7341.4s
################################################################################
                     [1m Learning iteration 125/2000 [0m                      

                       Computation: 1792 steps/s (collection: 3.133s, learning 0.884s)
               Value function loss: 27.6821
                    Surrogate loss: -0.0002
             Mean action noise std: 0.98
                       Mean reward: -49.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 907200
                    Iteration time: 4.02s
                        Total time: 493.18s
                               ETA: 7339.0s
################################################################################
                     [1m Learning iteration 126/2000 [0m                      

                       Computation: 1834 steps/s (collection: 3.164s, learning 0.760s)
               Value function loss: 25.2490
                    Surrogate loss: -0.0013
             Mean action noise std: 0.98
                       Mean reward: -49.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 914400
                    Iteration time: 3.92s
                        Total time: 497.11s
                               ETA: 7335.2s
################################################################################
                     [1m Learning iteration 127/2000 [0m                      

                       Computation: 1767 steps/s (collection: 3.279s, learning 0.794s)
               Value function loss: 23.9829
                    Surrogate loss: -0.0044
             Mean action noise std: 0.98
                       Mean reward: -50.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 921600
                    Iteration time: 4.07s
                        Total time: 501.18s
                               ETA: 7333.7s
################################################################################
                     [1m Learning iteration 128/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.157s, learning 0.745s)
               Value function loss: 26.1981
                    Surrogate loss: 0.0020
             Mean action noise std: 0.98
                       Mean reward: -49.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 928800
                    Iteration time: 3.90s
                        Total time: 505.08s
                               ETA: 7329.6s
################################################################################
                     [1m Learning iteration 129/2000 [0m                      

                       Computation: 1815 steps/s (collection: 3.180s, learning 0.785s)
               Value function loss: 24.2423
                    Surrogate loss: 0.0080
             Mean action noise std: 0.98
                       Mean reward: -49.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 936000
                    Iteration time: 3.96s
                        Total time: 509.05s
                               ETA: 7326.4s
################################################################################
                     [1m Learning iteration 130/2000 [0m                      

                       Computation: 1801 steps/s (collection: 3.162s, learning 0.835s)
               Value function loss: 24.1949
                    Surrogate loss: 0.0060
             Mean action noise std: 0.98
                       Mean reward: -50.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 943200
                    Iteration time: 4.00s
                        Total time: 513.04s
                               ETA: 7323.6s
################################################################################
                     [1m Learning iteration 131/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.106s, learning 0.707s)
               Value function loss: 25.2905
                    Surrogate loss: -0.0003
             Mean action noise std: 0.99
                       Mean reward: -49.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 950400
                    Iteration time: 3.81s
                        Total time: 516.86s
                               ETA: 7318.2s
################################################################################
                     [1m Learning iteration 132/2000 [0m                      

                       Computation: 1806 steps/s (collection: 3.273s, learning 0.713s)
               Value function loss: 26.7670
                    Surrogate loss: -0.0029
             Mean action noise std: 0.98
                       Mean reward: -49.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 957600
                    Iteration time: 3.99s
                        Total time: 520.84s
                               ETA: 7315.3s
################################################################################
                     [1m Learning iteration 133/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.148s, learning 0.700s)
               Value function loss: 28.2369
                    Surrogate loss: -0.0070
             Mean action noise std: 0.98
                       Mean reward: -50.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 964800
                    Iteration time: 3.85s
                        Total time: 524.69s
                               ETA: 7310.4s
################################################################################
                     [1m Learning iteration 134/2000 [0m                      

                       Computation: 1774 steps/s (collection: 3.245s, learning 0.812s)
               Value function loss: 24.7809
                    Surrogate loss: -0.0086
             Mean action noise std: 0.98
                       Mean reward: -50.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 972000
                    Iteration time: 4.06s
                        Total time: 528.75s
                               ETA: 7308.5s
################################################################################
                     [1m Learning iteration 135/2000 [0m                      

                       Computation: 1826 steps/s (collection: 3.157s, learning 0.785s)
               Value function loss: 26.0732
                    Surrogate loss: 0.0021
             Mean action noise std: 0.98
                       Mean reward: -49.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 979200
                    Iteration time: 3.94s
                        Total time: 532.69s
                               ETA: 7304.9s
################################################################################
                     [1m Learning iteration 136/2000 [0m                      

                       Computation: 1863 steps/s (collection: 3.119s, learning 0.745s)
               Value function loss: 25.9407
                    Surrogate loss: -0.0010
             Mean action noise std: 0.98
                       Mean reward: -49.14
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 986400
                    Iteration time: 3.86s
                        Total time: 536.55s
                               ETA: 7300.2s
################################################################################
                     [1m Learning iteration 137/2000 [0m                      

                       Computation: 1809 steps/s (collection: 3.260s, learning 0.719s)
               Value function loss: 25.3057
                    Surrogate loss: -0.0069
             Mean action noise std: 0.98
                       Mean reward: -49.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 993600
                    Iteration time: 3.98s
                        Total time: 540.53s
                               ETA: 7297.2s
################################################################################
                     [1m Learning iteration 138/2000 [0m                      

                       Computation: 1783 steps/s (collection: 3.142s, learning 0.895s)
               Value function loss: 21.5821
                    Surrogate loss: -0.0022
             Mean action noise std: 0.98
                       Mean reward: -49.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1000800
                    Iteration time: 4.04s
                        Total time: 544.57s
                               ETA: 7294.9s
################################################################################
                     [1m Learning iteration 139/2000 [0m                      

                       Computation: 1751 steps/s (collection: 3.247s, learning 0.863s)
               Value function loss: 25.2801
                    Surrogate loss: -0.0004
             Mean action noise std: 0.98
                       Mean reward: -48.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1008000
                    Iteration time: 4.11s
                        Total time: 548.68s
                               ETA: 7293.5s
################################################################################
                     [1m Learning iteration 140/2000 [0m                      

                       Computation: 1814 steps/s (collection: 3.178s, learning 0.791s)
               Value function loss: 24.5242
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -48.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1015200
                    Iteration time: 3.97s
                        Total time: 552.65s
                               ETA: 7290.2s
################################################################################
                     [1m Learning iteration 141/2000 [0m                      

                       Computation: 1836 steps/s (collection: 3.158s, learning 0.763s)
               Value function loss: 24.3534
                    Surrogate loss: -0.0042
             Mean action noise std: 0.98
                       Mean reward: -49.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1022400
                    Iteration time: 3.92s
                        Total time: 556.57s
                               ETA: 7286.3s
################################################################################
                     [1m Learning iteration 142/2000 [0m                      

                       Computation: 1761 steps/s (collection: 3.241s, learning 0.845s)
               Value function loss: 23.2714
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.57
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1029600
                    Iteration time: 4.09s
                        Total time: 560.65s
                               ETA: 7284.6s
################################################################################
                     [1m Learning iteration 143/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.148s, learning 0.695s)
               Value function loss: 20.0844
                    Surrogate loss: -0.0080
             Mean action noise std: 0.98
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1036800
                    Iteration time: 3.84s
                        Total time: 564.50s
                               ETA: 7279.7s
################################################################################
                     [1m Learning iteration 144/2000 [0m                      

                       Computation: 1776 steps/s (collection: 3.239s, learning 0.814s)
               Value function loss: 25.0813
                    Surrogate loss: 0.0005
             Mean action noise std: 0.98
                       Mean reward: -48.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1044000
                    Iteration time: 4.05s
                        Total time: 568.55s
                               ETA: 7277.5s
################################################################################
                     [1m Learning iteration 145/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.173s, learning 0.728s)
               Value function loss: 26.3893
                    Surrogate loss: -0.0056
             Mean action noise std: 0.98
                       Mean reward: -49.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1051200
                    Iteration time: 3.90s
                        Total time: 572.45s
                               ETA: 7273.3s
################################################################################
                     [1m Learning iteration 146/2000 [0m                      

                       Computation: 1834 steps/s (collection: 3.185s, learning 0.740s)
               Value function loss: 27.5452
                    Surrogate loss: -0.0001
             Mean action noise std: 0.98
                       Mean reward: -48.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1058400
                    Iteration time: 3.93s
                        Total time: 576.38s
                               ETA: 7269.4s
################################################################################
                     [1m Learning iteration 147/2000 [0m                      

                       Computation: 1834 steps/s (collection: 3.283s, learning 0.642s)
               Value function loss: 25.5431
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -48.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1065600
                    Iteration time: 3.92s
                        Total time: 580.30s
                               ETA: 7265.5s
################################################################################
                     [1m Learning iteration 148/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.157s, learning 0.659s)
               Value function loss: 27.0503
                    Surrogate loss: 0.0057
             Mean action noise std: 0.98
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1072800
                    Iteration time: 3.82s
                        Total time: 584.12s
                               ETA: 7260.3s
################################################################################
                     [1m Learning iteration 149/2000 [0m                      

                       Computation: 1830 steps/s (collection: 3.280s, learning 0.653s)
               Value function loss: 25.9118
                    Surrogate loss: -0.0055
             Mean action noise std: 0.98
                       Mean reward: -50.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1080000
                    Iteration time: 3.93s
                        Total time: 588.05s
                               ETA: 7256.5s
################################################################################
                     [1m Learning iteration 150/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.158s, learning 0.659s)
               Value function loss: 24.2447
                    Surrogate loss: -0.0069
             Mean action noise std: 0.98
                       Mean reward: -49.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1087200
                    Iteration time: 3.82s
                        Total time: 591.87s
                               ETA: 7251.4s
################################################################################
                     [1m Learning iteration 151/2000 [0m                      

                       Computation: 1863 steps/s (collection: 3.183s, learning 0.681s)
               Value function loss: 26.4226
                    Surrogate loss: 0.0092
             Mean action noise std: 0.98
                       Mean reward: -49.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1094400
                    Iteration time: 3.86s
                        Total time: 595.73s
                               ETA: 7246.8s
################################################################################
                     [1m Learning iteration 152/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.126s, learning 0.694s)
               Value function loss: 22.4295
                    Surrogate loss: 0.0011
             Mean action noise std: 0.98
                       Mean reward: -49.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1101600
                    Iteration time: 3.82s
                        Total time: 599.55s
                               ETA: 7241.7s
################################################################################
                     [1m Learning iteration 153/2000 [0m                      

                       Computation: 1897 steps/s (collection: 3.147s, learning 0.647s)
               Value function loss: 23.1539
                    Surrogate loss: -0.0036
             Mean action noise std: 0.98
                       Mean reward: -49.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1108800
                    Iteration time: 3.79s
                        Total time: 603.35s
                               ETA: 7236.2s
################################################################################
                     [1m Learning iteration 154/2000 [0m                      

                       Computation: 1825 steps/s (collection: 3.257s, learning 0.687s)
               Value function loss: 27.7175
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -49.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1116000
                    Iteration time: 3.94s
                        Total time: 607.29s
                               ETA: 7232.6s
################################################################################
                     [1m Learning iteration 155/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.143s, learning 0.704s)
               Value function loss: 24.1345
                    Surrogate loss: -0.0072
             Mean action noise std: 0.98
                       Mean reward: -49.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1123200
                    Iteration time: 3.85s
                        Total time: 611.14s
                               ETA: 7227.9s
################################################################################
                     [1m Learning iteration 156/2000 [0m                      

                       Computation: 1837 steps/s (collection: 3.200s, learning 0.719s)
               Value function loss: 22.0083
                    Surrogate loss: -0.0025
             Mean action noise std: 0.98
                       Mean reward: -50.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1130400
                    Iteration time: 3.92s
                        Total time: 615.06s
                               ETA: 7224.0s
################################################################################
                     [1m Learning iteration 157/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.103s, learning 0.711s)
               Value function loss: 23.9514
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -49.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1137600
                    Iteration time: 3.81s
                        Total time: 618.87s
                               ETA: 7218.9s
################################################################################
                     [1m Learning iteration 158/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.132s, learning 0.701s)
               Value function loss: 25.4504
                    Surrogate loss: 0.0003
             Mean action noise std: 0.98
                       Mean reward: -49.33
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1144800
                    Iteration time: 3.83s
                        Total time: 622.70s
                               ETA: 7214.0s
################################################################################
                     [1m Learning iteration 159/2000 [0m                      

                       Computation: 1824 steps/s (collection: 3.153s, learning 0.794s)
               Value function loss: 27.5835
                    Surrogate loss: -0.0025
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1152000
                    Iteration time: 3.95s
                        Total time: 626.65s
                               ETA: 7210.4s
################################################################################
                     [1m Learning iteration 160/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.152s, learning 0.630s)
               Value function loss: 23.5132
                    Surrogate loss: 0.0008
             Mean action noise std: 0.98
                       Mean reward: -48.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1159200
                    Iteration time: 3.78s
                        Total time: 630.43s
                               ETA: 7204.9s
################################################################################
                     [1m Learning iteration 161/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.270s, learning 0.629s)
               Value function loss: 22.6475
                    Surrogate loss: 0.0022
             Mean action noise std: 0.98
                       Mean reward: -48.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1166400
                    Iteration time: 3.90s
                        Total time: 634.33s
                               ETA: 7200.8s
################################################################################
                     [1m Learning iteration 162/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.150s, learning 0.632s)
               Value function loss: 24.6285
                    Surrogate loss: -0.0047
             Mean action noise std: 0.99
                       Mean reward: -48.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1173600
                    Iteration time: 3.78s
                        Total time: 638.11s
                               ETA: 7195.4s
################################################################################
                     [1m Learning iteration 163/2000 [0m                      

                       Computation: 1868 steps/s (collection: 3.196s, learning 0.657s)
               Value function loss: 23.4110
                    Surrogate loss: -0.0028
             Mean action noise std: 0.98
                       Mean reward: -49.06
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1180800
                    Iteration time: 3.85s
                        Total time: 641.97s
                               ETA: 7190.8s
################################################################################
                     [1m Learning iteration 164/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.180s, learning 0.664s)
               Value function loss: 23.4650
                    Surrogate loss: 0.0057
             Mean action noise std: 0.99
                       Mean reward: -49.02
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1188000
                    Iteration time: 3.84s
                        Total time: 645.81s
                               ETA: 7186.1s
################################################################################
                     [1m Learning iteration 165/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.160s, learning 0.647s)
               Value function loss: 22.0317
                    Surrogate loss: -0.0012
             Mean action noise std: 0.99
                       Mean reward: -48.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1195200
                    Iteration time: 3.81s
                        Total time: 649.62s
                               ETA: 7181.0s
################################################################################
                     [1m Learning iteration 166/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.237s, learning 0.699s)
               Value function loss: 27.3392
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -48.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1202400
                    Iteration time: 3.94s
                        Total time: 653.55s
                               ETA: 7177.3s
################################################################################
                     [1m Learning iteration 167/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.145s, learning 0.650s)
               Value function loss: 27.9535
                    Surrogate loss: -0.0048
             Mean action noise std: 0.99
                       Mean reward: -49.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1209600
                    Iteration time: 3.80s
                        Total time: 657.35s
                               ETA: 7172.1s
################################################################################
                     [1m Learning iteration 168/2000 [0m                      

                       Computation: 1839 steps/s (collection: 3.219s, learning 0.695s)
               Value function loss: 25.2779
                    Surrogate loss: -0.0063
             Mean action noise std: 0.99
                       Mean reward: -49.12
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1216800
                    Iteration time: 3.91s
                        Total time: 661.26s
                               ETA: 7168.2s
################################################################################
                     [1m Learning iteration 169/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.135s, learning 0.707s)
               Value function loss: 25.4004
                    Surrogate loss: -0.0058
             Mean action noise std: 0.99
                       Mean reward: -49.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1224000
                    Iteration time: 3.84s
                        Total time: 665.10s
                               ETA: 7163.5s
################################################################################
                     [1m Learning iteration 170/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.117s, learning 0.703s)
               Value function loss: 23.0949
                    Surrogate loss: -0.0073
             Mean action noise std: 0.99
                       Mean reward: -49.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1231200
                    Iteration time: 3.82s
                        Total time: 668.92s
                               ETA: 7158.6s
################################################################################
                     [1m Learning iteration 171/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.214s, learning 0.670s)
               Value function loss: 21.6251
                    Surrogate loss: -0.0053
             Mean action noise std: 0.99
                       Mean reward: -49.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1238400
                    Iteration time: 3.88s
                        Total time: 672.81s
                               ETA: 7154.4s
################################################################################
                     [1m Learning iteration 172/2000 [0m                      

                       Computation: 1866 steps/s (collection: 3.235s, learning 0.622s)
               Value function loss: 21.9461
                    Surrogate loss: -0.0035
             Mean action noise std: 0.99
                       Mean reward: -49.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1245600
                    Iteration time: 3.86s
                        Total time: 676.66s
                               ETA: 7149.9s
################################################################################
                     [1m Learning iteration 173/2000 [0m                      

                       Computation: 1813 steps/s (collection: 3.281s, learning 0.690s)
               Value function loss: 22.4251
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -48.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1252800
                    Iteration time: 3.97s
                        Total time: 680.63s
                               ETA: 7146.7s
################################################################################
                     [1m Learning iteration 174/2000 [0m                      

                       Computation: 1906 steps/s (collection: 3.131s, learning 0.645s)
               Value function loss: 23.9181
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -48.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1260000
                    Iteration time: 3.78s
                        Total time: 684.41s
                               ETA: 7141.3s
################################################################################
                     [1m Learning iteration 175/2000 [0m                      

                       Computation: 1840 steps/s (collection: 3.130s, learning 0.782s)
               Value function loss: 23.4596
                    Surrogate loss: -0.0062
             Mean action noise std: 0.99
                       Mean reward: -48.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1267200
                    Iteration time: 3.91s
                        Total time: 688.32s
                               ETA: 7137.4s
################################################################################
                     [1m Learning iteration 176/2000 [0m                      

                       Computation: 1840 steps/s (collection: 3.156s, learning 0.755s)
               Value function loss: 21.7822
                    Surrogate loss: -0.0063
             Mean action noise std: 0.99
                       Mean reward: -49.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1274400
                    Iteration time: 3.91s
                        Total time: 692.23s
                               ETA: 7133.5s
################################################################################
                     [1m Learning iteration 177/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.154s, learning 0.668s)
               Value function loss: 25.5504
                    Surrogate loss: -0.0018
             Mean action noise std: 0.99
                       Mean reward: -49.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1281600
                    Iteration time: 3.82s
                        Total time: 696.05s
                               ETA: 7128.7s
################################################################################
                     [1m Learning iteration 178/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.266s, learning 0.687s)
               Value function loss: 24.1356
                    Surrogate loss: -0.0032
             Mean action noise std: 0.99
                       Mean reward: -49.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1288800
                    Iteration time: 3.95s
                        Total time: 700.01s
                               ETA: 7125.2s
################################################################################
                     [1m Learning iteration 179/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.191s, learning 0.622s)
               Value function loss: 25.0832
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -49.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1296000
                    Iteration time: 3.81s
                        Total time: 703.82s
                               ETA: 7120.3s
################################################################################
                     [1m Learning iteration 180/2000 [0m                      

                       Computation: 1800 steps/s (collection: 3.381s, learning 0.617s)
               Value function loss: 24.8530
                    Surrogate loss: -0.0038
             Mean action noise std: 0.99
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1303200
                    Iteration time: 4.00s
                        Total time: 707.82s
                               ETA: 7117.3s
################################################################################
                     [1m Learning iteration 181/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.154s, learning 0.638s)
               Value function loss: 23.5585
                    Surrogate loss: 0.0131
             Mean action noise std: 0.99
                       Mean reward: -48.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1310400
                    Iteration time: 3.79s
                        Total time: 711.61s
                               ETA: 7112.2s
################################################################################
                     [1m Learning iteration 182/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.146s, learning 0.753s)
               Value function loss: 27.4653
                    Surrogate loss: -0.0031
             Mean action noise std: 0.99
                       Mean reward: -48.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1317600
                    Iteration time: 3.90s
                        Total time: 715.51s
                               ETA: 7108.2s
################################################################################
                     [1m Learning iteration 183/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.240s, learning 0.650s)
               Value function loss: 22.3123
                    Surrogate loss: -0.0042
             Mean action noise std: 0.99
                       Mean reward: -48.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1324800
                    Iteration time: 3.89s
                        Total time: 719.40s
                               ETA: 7104.1s
################################################################################
                     [1m Learning iteration 184/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.150s, learning 0.646s)
               Value function loss: 23.4091
                    Surrogate loss: -0.0063
             Mean action noise std: 0.99
                       Mean reward: -48.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1332000
                    Iteration time: 3.80s
                        Total time: 723.19s
                               ETA: 7099.0s
################################################################################
                     [1m Learning iteration 185/2000 [0m                      

                       Computation: 1827 steps/s (collection: 3.255s, learning 0.685s)
               Value function loss: 23.6082
                    Surrogate loss: -0.0072
             Mean action noise std: 1.00
                       Mean reward: -48.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1339200
                    Iteration time: 3.94s
                        Total time: 727.13s
                               ETA: 7095.4s
################################################################################
                     [1m Learning iteration 186/2000 [0m                      

                       Computation: 1877 steps/s (collection: 3.148s, learning 0.686s)
               Value function loss: 22.5121
                    Surrogate loss: -0.0058
             Mean action noise std: 1.00
                       Mean reward: -49.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1346400
                    Iteration time: 3.83s
                        Total time: 730.97s
                               ETA: 7090.8s
################################################################################
                     [1m Learning iteration 187/2000 [0m                      

                       Computation: 1872 steps/s (collection: 3.195s, learning 0.650s)
               Value function loss: 23.5580
                    Surrogate loss: -0.0047
             Mean action noise std: 1.00
                       Mean reward: -49.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1353600
                    Iteration time: 3.85s
                        Total time: 734.81s
                               ETA: 7086.3s
################################################################################
                     [1m Learning iteration 188/2000 [0m                      

                       Computation: 1830 steps/s (collection: 3.129s, learning 0.804s)
               Value function loss: 25.0229
                    Surrogate loss: -0.0059
             Mean action noise std: 1.00
                       Mean reward: -49.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1360800
                    Iteration time: 3.93s
                        Total time: 738.75s
                               ETA: 7082.6s
################################################################################
                     [1m Learning iteration 189/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.140s, learning 0.763s)
               Value function loss: 22.7439
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -49.57
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1368000
                    Iteration time: 3.90s
                        Total time: 742.65s
                               ETA: 7078.6s
################################################################################
                     [1m Learning iteration 190/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.077s, learning 0.791s)
               Value function loss: 22.4193
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -49.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1375200
                    Iteration time: 3.87s
                        Total time: 746.52s
                               ETA: 7074.3s
################################################################################
                     [1m Learning iteration 191/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.123s, learning 0.620s)
               Value function loss: 23.2602
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -49.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1382400
                    Iteration time: 3.74s
                        Total time: 750.26s
                               ETA: 7068.9s
################################################################################
                     [1m Learning iteration 192/2000 [0m                      

                       Computation: 1778 steps/s (collection: 3.266s, learning 0.783s)
               Value function loss: 22.3916
                    Surrogate loss: -0.0056
             Mean action noise std: 0.99
                       Mean reward: -49.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1389600
                    Iteration time: 4.05s
                        Total time: 754.31s
                               ETA: 7066.3s
################################################################################
                     [1m Learning iteration 193/2000 [0m                      

                       Computation: 1877 steps/s (collection: 3.156s, learning 0.678s)
               Value function loss: 24.1906
                    Surrogate loss: -0.0044
             Mean action noise std: 0.99
                       Mean reward: -50.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1396800
                    Iteration time: 3.83s
                        Total time: 758.15s
                               ETA: 7061.7s
################################################################################
                     [1m Learning iteration 194/2000 [0m                      

                       Computation: 1872 steps/s (collection: 3.142s, learning 0.702s)
               Value function loss: 23.0095
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -49.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1404000
                    Iteration time: 3.84s
                        Total time: 761.99s
                               ETA: 7057.2s
################################################################################
                     [1m Learning iteration 195/2000 [0m                      

                       Computation: 1895 steps/s (collection: 3.134s, learning 0.665s)
               Value function loss: 21.7467
                    Surrogate loss: -0.0061
             Mean action noise std: 0.99
                       Mean reward: -49.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1411200
                    Iteration time: 3.80s
                        Total time: 765.79s
                               ETA: 7052.3s
################################################################################
                     [1m Learning iteration 196/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.117s, learning 0.675s)
               Value function loss: 22.1022
                    Surrogate loss: -0.0065
             Mean action noise std: 0.99
                       Mean reward: -49.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1418400
                    Iteration time: 3.79s
                        Total time: 769.58s
                               ETA: 7047.3s
################################################################################
                     [1m Learning iteration 197/2000 [0m                      

                       Computation: 1836 steps/s (collection: 3.181s, learning 0.740s)
               Value function loss: 23.1021
                    Surrogate loss: -0.0013
             Mean action noise std: 0.99
                       Mean reward: -49.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1425600
                    Iteration time: 3.92s
                        Total time: 773.50s
                               ETA: 7043.6s
################################################################################
                     [1m Learning iteration 198/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.103s, learning 0.801s)
               Value function loss: 25.1243
                    Surrogate loss: 0.0016
             Mean action noise std: 0.99
                       Mean reward: -49.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1432800
                    Iteration time: 3.90s
                        Total time: 777.41s
                               ETA: 7039.6s
################################################################################
                     [1m Learning iteration 199/2000 [0m                      

                       Computation: 1823 steps/s (collection: 3.241s, learning 0.708s)
               Value function loss: 25.0668
                    Surrogate loss: -0.0001
             Mean action noise std: 0.99
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1440000
                    Iteration time: 3.95s
                        Total time: 781.35s
                               ETA: 7036.1s
################################################################################
                     [1m Learning iteration 200/2000 [0m                      

                       Computation: 1905 steps/s (collection: 3.125s, learning 0.653s)
               Value function loss: 21.4048
                    Surrogate loss: -0.0000
             Mean action noise std: 0.99
                       Mean reward: -49.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1447200
                    Iteration time: 3.78s
                        Total time: 785.13s
                               ETA: 7031.0s
################################################################################
                     [1m Learning iteration 201/2000 [0m                      

                       Computation: 1894 steps/s (collection: 3.123s, learning 0.678s)
               Value function loss: 21.6403
                    Surrogate loss: 0.0018
             Mean action noise std: 0.99
                       Mean reward: -49.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1454400
                    Iteration time: 3.80s
                        Total time: 788.93s
                               ETA: 7026.2s
################################################################################
                     [1m Learning iteration 202/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.100s, learning 0.803s)
               Value function loss: 22.4766
                    Surrogate loss: 0.0005
             Mean action noise std: 0.99
                       Mean reward: -50.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1461600
                    Iteration time: 3.90s
                        Total time: 792.84s
                               ETA: 7022.3s
################################################################################
                     [1m Learning iteration 203/2000 [0m                      

                       Computation: 1937 steps/s (collection: 3.100s, learning 0.616s)
               Value function loss: 25.6986
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -50.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1468800
                    Iteration time: 3.72s
                        Total time: 796.55s
                               ETA: 7016.7s
################################################################################
                     [1m Learning iteration 204/2000 [0m                      

                       Computation: 1862 steps/s (collection: 3.201s, learning 0.665s)
               Value function loss: 22.4942
                    Surrogate loss: -0.0039
             Mean action noise std: 0.99
                       Mean reward: -49.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1476000
                    Iteration time: 3.87s
                        Total time: 800.42s
                               ETA: 7012.5s
################################################################################
                     [1m Learning iteration 205/2000 [0m                      

                       Computation: 1906 steps/s (collection: 3.097s, learning 0.679s)
               Value function loss: 23.0014
                    Surrogate loss: -0.0051
             Mean action noise std: 0.99
                       Mean reward: -49.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1483200
                    Iteration time: 3.78s
                        Total time: 804.20s
                               ETA: 7007.4s
################################################################################
                     [1m Learning iteration 206/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.130s, learning 0.687s)
               Value function loss: 24.9075
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -49.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1490400
                    Iteration time: 3.82s
                        Total time: 808.01s
                               ETA: 7002.8s
################################################################################
                     [1m Learning iteration 207/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.099s, learning 0.711s)
               Value function loss: 22.3574
                    Surrogate loss: -0.0004
             Mean action noise std: 0.99
                       Mean reward: -49.78
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1497600
                    Iteration time: 3.81s
                        Total time: 811.82s
                               ETA: 6998.1s
################################################################################
                     [1m Learning iteration 208/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.080s, learning 0.703s)
               Value function loss: 21.9472
                    Surrogate loss: 0.0057
             Mean action noise std: 0.99
                       Mean reward: -49.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1504800
                    Iteration time: 3.78s
                        Total time: 815.60s
                               ETA: 6993.1s
################################################################################
                     [1m Learning iteration 209/2000 [0m                      

                       Computation: 1907 steps/s (collection: 3.144s, learning 0.631s)
               Value function loss: 22.0032
                    Surrogate loss: 0.0003
             Mean action noise std: 0.99
                       Mean reward: -49.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1512000
                    Iteration time: 3.78s
                        Total time: 819.38s
                               ETA: 6988.1s
################################################################################
                     [1m Learning iteration 210/2000 [0m                      

                       Computation: 1924 steps/s (collection: 3.075s, learning 0.667s)
               Value function loss: 23.0420
                    Surrogate loss: -0.0050
             Mean action noise std: 0.99
                       Mean reward: -49.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1519200
                    Iteration time: 3.74s
                        Total time: 823.12s
                               ETA: 6982.9s
################################################################################
                     [1m Learning iteration 211/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.208s, learning 0.660s)
               Value function loss: 21.1968
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -49.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1526400
                    Iteration time: 3.87s
                        Total time: 826.99s
                               ETA: 6978.7s
################################################################################
                     [1m Learning iteration 212/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.068s, learning 0.682s)
               Value function loss: 22.8399
                    Surrogate loss: -0.0061
             Mean action noise std: 0.98
                       Mean reward: -48.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1533600
                    Iteration time: 3.75s
                        Total time: 830.74s
                               ETA: 6973.5s
################################################################################
                     [1m Learning iteration 213/2000 [0m                      

                       Computation: 1858 steps/s (collection: 3.127s, learning 0.747s)
               Value function loss: 21.9394
                    Surrogate loss: -0.0009
             Mean action noise std: 0.98
                       Mean reward: -48.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1540800
                    Iteration time: 3.87s
                        Total time: 834.61s
                               ETA: 6969.4s
################################################################################
                     [1m Learning iteration 214/2000 [0m                      

                       Computation: 1908 steps/s (collection: 3.115s, learning 0.657s)
               Value function loss: 22.1092
                    Surrogate loss: -0.0047
             Mean action noise std: 0.98
                       Mean reward: -48.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1548000
                    Iteration time: 3.77s
                        Total time: 838.39s
                               ETA: 6964.5s
################################################################################
                     [1m Learning iteration 215/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.124s, learning 0.639s)
               Value function loss: 22.2267
                    Surrogate loss: -0.0032
             Mean action noise std: 0.98
                       Mean reward: -49.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1555200
                    Iteration time: 3.76s
                        Total time: 842.15s
                               ETA: 6959.4s
################################################################################
                     [1m Learning iteration 216/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.141s, learning 0.708s)
               Value function loss: 21.5600
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1562400
                    Iteration time: 3.85s
                        Total time: 846.00s
                               ETA: 6955.1s
################################################################################
                     [1m Learning iteration 217/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.089s, learning 0.740s)
               Value function loss: 22.0846
                    Surrogate loss: -0.0037
             Mean action noise std: 0.98
                       Mean reward: -49.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1569600
                    Iteration time: 3.83s
                        Total time: 849.83s
                               ETA: 6950.7s
################################################################################
                     [1m Learning iteration 218/2000 [0m                      

                       Computation: 1837 steps/s (collection: 3.221s, learning 0.697s)
               Value function loss: 21.1803
                    Surrogate loss: 0.0014
             Mean action noise std: 0.98
                       Mean reward: -49.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1576800
                    Iteration time: 3.92s
                        Total time: 853.75s
                               ETA: 6946.9s
################################################################################
                     [1m Learning iteration 219/2000 [0m                      

                       Computation: 1919 steps/s (collection: 3.103s, learning 0.649s)
               Value function loss: 20.8003
                    Surrogate loss: 0.0081
             Mean action noise std: 0.98
                       Mean reward: -49.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1584000
                    Iteration time: 3.75s
                        Total time: 857.50s
                               ETA: 6941.8s
################################################################################
                     [1m Learning iteration 220/2000 [0m                      

                       Computation: 1893 steps/s (collection: 3.133s, learning 0.669s)
               Value function loss: 25.7714
                    Surrogate loss: 0.0002
             Mean action noise std: 0.98
                       Mean reward: -48.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1591200
                    Iteration time: 3.80s
                        Total time: 861.30s
                               ETA: 6937.2s
################################################################################
                     [1m Learning iteration 221/2000 [0m                      

                       Computation: 1864 steps/s (collection: 3.126s, learning 0.735s)
               Value function loss: 25.3793
                    Surrogate loss: 0.0039
             Mean action noise std: 0.98
                       Mean reward: -48.51
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1598400
                    Iteration time: 3.86s
                        Total time: 865.16s
                               ETA: 6933.0s
################################################################################
                     [1m Learning iteration 222/2000 [0m                      

                       Computation: 1902 steps/s (collection: 3.156s, learning 0.628s)
               Value function loss: 24.1853
                    Surrogate loss: -0.0039
             Mean action noise std: 0.98
                       Mean reward: -48.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1605600
                    Iteration time: 3.78s
                        Total time: 868.94s
                               ETA: 6928.2s
################################################################################
                     [1m Learning iteration 223/2000 [0m                      

                       Computation: 1843 steps/s (collection: 3.186s, learning 0.719s)
               Value function loss: 24.0120
                    Surrogate loss: -0.0037
             Mean action noise std: 0.98
                       Mean reward: -48.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1612800
                    Iteration time: 3.90s
                        Total time: 872.85s
                               ETA: 6924.3s
################################################################################
                     [1m Learning iteration 224/2000 [0m                      

                       Computation: 1899 steps/s (collection: 3.137s, learning 0.654s)
               Value function loss: 21.1353
                    Surrogate loss: -0.0016
             Mean action noise std: 0.98
                       Mean reward: -48.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1620000
                    Iteration time: 3.79s
                        Total time: 876.64s
                               ETA: 6919.6s
################################################################################
                     [1m Learning iteration 225/2000 [0m                      

                       Computation: 1824 steps/s (collection: 3.230s, learning 0.717s)
               Value function loss: 25.1484
                    Surrogate loss: 0.0006
             Mean action noise std: 0.99
                       Mean reward: -48.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1627200
                    Iteration time: 3.95s
                        Total time: 880.59s
                               ETA: 6916.1s
################################################################################
                     [1m Learning iteration 226/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.126s, learning 0.685s)
               Value function loss: 23.8658
                    Surrogate loss: 0.0010
             Mean action noise std: 0.98
                       Mean reward: -48.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1634400
                    Iteration time: 3.81s
                        Total time: 884.40s
                               ETA: 6911.6s
################################################################################
                     [1m Learning iteration 227/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.129s, learning 0.677s)
               Value function loss: 22.0531
                    Surrogate loss: -0.0021
             Mean action noise std: 0.98
                       Mean reward: -48.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1641600
                    Iteration time: 3.81s
                        Total time: 888.20s
                               ETA: 6907.0s
################################################################################
                     [1m Learning iteration 228/2000 [0m                      

                       Computation: 1848 steps/s (collection: 3.113s, learning 0.781s)
               Value function loss: 24.8021
                    Surrogate loss: -0.0072
             Mean action noise std: 0.98
                       Mean reward: -48.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1648800
                    Iteration time: 3.89s
                        Total time: 892.10s
                               ETA: 6903.1s
################################################################################
                     [1m Learning iteration 229/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.154s, learning 0.626s)
               Value function loss: 23.2220
                    Surrogate loss: -0.0049
             Mean action noise std: 0.98
                       Mean reward: -48.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1656000
                    Iteration time: 3.78s
                        Total time: 895.88s
                               ETA: 6898.3s
################################################################################
                     [1m Learning iteration 230/2000 [0m                      

                       Computation: 1842 steps/s (collection: 3.194s, learning 0.713s)
               Value function loss: 23.0715
                    Surrogate loss: 0.0006
             Mean action noise std: 0.98
                       Mean reward: -48.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1663200
                    Iteration time: 3.91s
                        Total time: 899.79s
                               ETA: 6894.5s
################################################################################
                     [1m Learning iteration 231/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.128s, learning 0.629s)
               Value function loss: 21.6452
                    Surrogate loss: 0.0006
             Mean action noise std: 0.98
                       Mean reward: -48.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1670400
                    Iteration time: 3.76s
                        Total time: 903.54s
                               ETA: 6889.5s
################################################################################
                     [1m Learning iteration 232/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.189s, learning 0.629s)
               Value function loss: 23.9235
                    Surrogate loss: 0.0005
             Mean action noise std: 0.98
                       Mean reward: -48.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1677600
                    Iteration time: 3.82s
                        Total time: 907.36s
                               ETA: 6885.0s
################################################################################
                     [1m Learning iteration 233/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.161s, learning 0.738s)
               Value function loss: 26.4303
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -48.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1684800
                    Iteration time: 3.90s
                        Total time: 911.26s
                               ETA: 6881.2s
################################################################################
                     [1m Learning iteration 234/2000 [0m                      

                       Computation: 1902 steps/s (collection: 3.144s, learning 0.640s)
               Value function loss: 26.0548
                    Surrogate loss: -0.0012
             Mean action noise std: 0.99
                       Mean reward: -48.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1692000
                    Iteration time: 3.78s
                        Total time: 915.04s
                               ETA: 6876.5s
################################################################################
                     [1m Learning iteration 235/2000 [0m                      

                       Computation: 1822 steps/s (collection: 3.271s, learning 0.680s)
               Value function loss: 25.6000
                    Surrogate loss: -0.0066
             Mean action noise std: 0.99
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1699200
                    Iteration time: 3.95s
                        Total time: 918.99s
                               ETA: 6873.0s
################################################################################
                     [1m Learning iteration 236/2000 [0m                      

                       Computation: 1899 steps/s (collection: 3.141s, learning 0.649s)
               Value function loss: 24.9361
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -48.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1706400
                    Iteration time: 3.79s
                        Total time: 922.79s
                               ETA: 6868.3s
################################################################################
                     [1m Learning iteration 237/2000 [0m                      

                       Computation: 1833 steps/s (collection: 3.239s, learning 0.689s)
               Value function loss: 26.6330
                    Surrogate loss: -0.0026
             Mean action noise std: 0.99
                       Mean reward: -48.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1713600
                    Iteration time: 3.93s
                        Total time: 926.71s
                               ETA: 6864.7s
################################################################################
                     [1m Learning iteration 238/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.154s, learning 0.638s)
               Value function loss: 25.2448
                    Surrogate loss: -0.0023
             Mean action noise std: 0.99
                       Mean reward: -49.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1720800
                    Iteration time: 3.79s
                        Total time: 930.51s
                               ETA: 6860.0s
################################################################################
                     [1m Learning iteration 239/2000 [0m                      

                       Computation: 1860 steps/s (collection: 3.198s, learning 0.673s)
               Value function loss: 24.8098
                    Surrogate loss: -0.0068
             Mean action noise std: 0.99
                       Mean reward: -49.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1728000
                    Iteration time: 3.87s
                        Total time: 934.38s
                               ETA: 6856.0s
################################################################################
                     [1m Learning iteration 240/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.156s, learning 0.667s)
               Value function loss: 26.1251
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -49.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1735200
                    Iteration time: 3.82s
                        Total time: 938.20s
                               ETA: 6851.6s
################################################################################
                     [1m Learning iteration 241/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.120s, learning 0.685s)
               Value function loss: 23.2910
                    Surrogate loss: -0.0003
             Mean action noise std: 0.99
                       Mean reward: -48.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1742400
                    Iteration time: 3.81s
                        Total time: 942.00s
                               ETA: 6847.0s
################################################################################
                     [1m Learning iteration 242/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.149s, learning 0.718s)
               Value function loss: 23.9826
                    Surrogate loss: -0.0043
             Mean action noise std: 0.99
                       Mean reward: -49.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1749600
                    Iteration time: 3.87s
                        Total time: 945.87s
                               ETA: 6843.0s
################################################################################
                     [1m Learning iteration 243/2000 [0m                      

                       Computation: 1819 steps/s (collection: 3.202s, learning 0.755s)
               Value function loss: 29.8779
                    Surrogate loss: 0.0062
             Mean action noise std: 0.99
                       Mean reward: -49.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1756800
                    Iteration time: 3.96s
                        Total time: 949.83s
                               ETA: 6839.5s
################################################################################
                     [1m Learning iteration 244/2000 [0m                      

                       Computation: 1785 steps/s (collection: 3.217s, learning 0.814s)
               Value function loss: 23.5749
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1764000
                    Iteration time: 4.03s
                        Total time: 953.86s
                               ETA: 6836.6s
################################################################################
                     [1m Learning iteration 245/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.144s, learning 0.772s)
               Value function loss: 23.8934
                    Surrogate loss: -0.0040
             Mean action noise std: 0.99
                       Mean reward: -49.25
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1771200
                    Iteration time: 3.92s
                        Total time: 957.78s
                               ETA: 6832.9s
################################################################################
                     [1m Learning iteration 246/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.149s, learning 0.786s)
               Value function loss: 23.5059
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -49.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1778400
                    Iteration time: 3.94s
                        Total time: 961.71s
                               ETA: 6829.3s
################################################################################
                     [1m Learning iteration 247/2000 [0m                      

                       Computation: 1798 steps/s (collection: 3.114s, learning 0.891s)
               Value function loss: 21.6688
                    Surrogate loss: -0.0052
             Mean action noise std: 0.98
                       Mean reward: -49.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1785600
                    Iteration time: 4.00s
                        Total time: 965.72s
                               ETA: 6826.2s
################################################################################
                     [1m Learning iteration 248/2000 [0m                      

                       Computation: 1839 steps/s (collection: 3.108s, learning 0.806s)
               Value function loss: 24.1192
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1792800
                    Iteration time: 3.91s
                        Total time: 969.63s
                               ETA: 6822.5s
################################################################################
                     [1m Learning iteration 249/2000 [0m                      

                       Computation: 1784 steps/s (collection: 3.226s, learning 0.809s)
               Value function loss: 22.5071
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -49.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1800000
                    Iteration time: 4.04s
                        Total time: 973.67s
                               ETA: 6819.6s
################################################################################
                     [1m Learning iteration 250/2000 [0m                      

                       Computation: 1858 steps/s (collection: 3.123s, learning 0.751s)
               Value function loss: 22.8507
                    Surrogate loss: 0.0011
             Mean action noise std: 0.98
                       Mean reward: -48.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1807200
                    Iteration time: 3.87s
                        Total time: 977.54s
                               ETA: 6815.5s
################################################################################
                     [1m Learning iteration 251/2000 [0m                      

                       Computation: 1879 steps/s (collection: 3.131s, learning 0.699s)
               Value function loss: 23.1898
                    Surrogate loss: -0.0040
             Mean action noise std: 0.98
                       Mean reward: -48.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1814400
                    Iteration time: 3.83s
                        Total time: 981.37s
                               ETA: 6811.2s
################################################################################
                     [1m Learning iteration 252/2000 [0m                      

                       Computation: 1865 steps/s (collection: 3.138s, learning 0.721s)
               Value function loss: 37.5236
                    Surrogate loss: 0.0044
             Mean action noise std: 0.98
                       Mean reward: -49.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1821600
                    Iteration time: 3.86s
                        Total time: 985.23s
                               ETA: 6807.0s
################################################################################
                     [1m Learning iteration 253/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.130s, learning 0.674s)
               Value function loss: 28.5306
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1828800
                    Iteration time: 3.80s
                        Total time: 989.03s
                               ETA: 6802.5s
################################################################################
                     [1m Learning iteration 254/2000 [0m                      

                       Computation: 1865 steps/s (collection: 3.217s, learning 0.642s)
               Value function loss: 25.6968
                    Surrogate loss: -0.0015
             Mean action noise std: 0.98
                       Mean reward: -50.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1836000
                    Iteration time: 3.86s
                        Total time: 992.89s
                               ETA: 6798.4s
################################################################################
                     [1m Learning iteration 255/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.203s, learning 0.618s)
               Value function loss: 25.1534
                    Surrogate loss: -0.0056
             Mean action noise std: 0.98
                       Mean reward: -50.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1843200
                    Iteration time: 3.82s
                        Total time: 996.71s
                               ETA: 6794.0s
################################################################################
                     [1m Learning iteration 256/2000 [0m                      

                       Computation: 1780 steps/s (collection: 3.189s, learning 0.854s)
               Value function loss: 22.6175
                    Surrogate loss: -0.0030
             Mean action noise std: 0.98
                       Mean reward: -51.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1850400
                    Iteration time: 4.04s
                        Total time: 1000.76s
                               ETA: 6791.1s
################################################################################
                     [1m Learning iteration 257/2000 [0m                      

                       Computation: 1824 steps/s (collection: 3.134s, learning 0.812s)
               Value function loss: 21.6485
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -50.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1857600
                    Iteration time: 3.95s
                        Total time: 1004.70s
                               ETA: 6787.6s
################################################################################
                     [1m Learning iteration 258/2000 [0m                      

                       Computation: 1832 steps/s (collection: 3.135s, learning 0.794s)
               Value function loss: 24.4532
                    Surrogate loss: -0.0035
             Mean action noise std: 0.98
                       Mean reward: -49.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1864800
                    Iteration time: 3.93s
                        Total time: 1008.63s
                               ETA: 6783.9s
################################################################################
                     [1m Learning iteration 259/2000 [0m                      

                       Computation: 1800 steps/s (collection: 3.155s, learning 0.842s)
               Value function loss: 23.0100
                    Surrogate loss: -0.0013
             Mean action noise std: 0.98
                       Mean reward: -49.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1872000
                    Iteration time: 4.00s
                        Total time: 1012.63s
                               ETA: 6780.7s
################################################################################
                     [1m Learning iteration 260/2000 [0m                      

                       Computation: 1855 steps/s (collection: 3.127s, learning 0.753s)
               Value function loss: 21.3587
                    Surrogate loss: 0.0107
             Mean action noise std: 0.98
                       Mean reward: -49.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1879200
                    Iteration time: 3.88s
                        Total time: 1016.51s
                               ETA: 6776.7s
################################################################################
                     [1m Learning iteration 261/2000 [0m                      

                       Computation: 1852 steps/s (collection: 3.167s, learning 0.719s)
               Value function loss: 20.4422
                    Surrogate loss: 0.0072
             Mean action noise std: 0.98
                       Mean reward: -48.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1886400
                    Iteration time: 3.89s
                        Total time: 1020.40s
                               ETA: 6772.8s
################################################################################
                     [1m Learning iteration 262/2000 [0m                      

                       Computation: 1841 steps/s (collection: 3.150s, learning 0.760s)
               Value function loss: 20.3537
                    Surrogate loss: 0.0003
             Mean action noise std: 0.98
                       Mean reward: -48.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1893600
                    Iteration time: 3.91s
                        Total time: 1024.31s
                               ETA: 6769.0s
################################################################################
                     [1m Learning iteration 263/2000 [0m                      

                       Computation: 1915 steps/s (collection: 3.138s, learning 0.621s)
               Value function loss: 24.2994
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1900800
                    Iteration time: 3.76s
                        Total time: 1028.07s
                               ETA: 6764.2s
################################################################################
                     [1m Learning iteration 264/2000 [0m                      

                       Computation: 1862 steps/s (collection: 3.137s, learning 0.729s)
               Value function loss: 23.5149
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -48.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1908000
                    Iteration time: 3.87s
                        Total time: 1031.93s
                               ETA: 6760.1s
################################################################################
                     [1m Learning iteration 265/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.157s, learning 0.626s)
               Value function loss: 22.3087
                    Surrogate loss: -0.0034
             Mean action noise std: 0.98
                       Mean reward: -48.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1915200
                    Iteration time: 3.78s
                        Total time: 1035.72s
                               ETA: 6755.5s
################################################################################
                     [1m Learning iteration 266/2000 [0m                      

                       Computation: 1852 steps/s (collection: 3.221s, learning 0.665s)
               Value function loss: 22.6762
                    Surrogate loss: -0.0048
             Mean action noise std: 0.98
                       Mean reward: -48.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1922400
                    Iteration time: 3.89s
                        Total time: 1039.60s
                               ETA: 6751.6s
################################################################################
                     [1m Learning iteration 267/2000 [0m                      

                       Computation: 1901 steps/s (collection: 3.163s, learning 0.623s)
               Value function loss: 23.9864
                    Surrogate loss: 0.0081
             Mean action noise std: 0.98
                       Mean reward: -48.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1929600
                    Iteration time: 3.79s
                        Total time: 1043.39s
                               ETA: 6747.0s
################################################################################
                     [1m Learning iteration 268/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.161s, learning 0.689s)
               Value function loss: 24.1072
                    Surrogate loss: 0.0037
             Mean action noise std: 0.98
                       Mean reward: -48.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1936800
                    Iteration time: 3.85s
                        Total time: 1047.24s
                               ETA: 6742.8s
################################################################################
                     [1m Learning iteration 269/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.151s, learning 0.682s)
               Value function loss: 25.2979
                    Surrogate loss: 0.0019
             Mean action noise std: 0.98
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1944000
                    Iteration time: 3.83s
                        Total time: 1051.07s
                               ETA: 6738.5s
################################################################################
                     [1m Learning iteration 270/2000 [0m                      

                       Computation: 1906 steps/s (collection: 3.151s, learning 0.625s)
               Value function loss: 26.4653
                    Surrogate loss: -0.0036
             Mean action noise std: 0.98
                       Mean reward: -50.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1951200
                    Iteration time: 3.78s
                        Total time: 1054.85s
                               ETA: 6733.9s
################################################################################
                     [1m Learning iteration 271/2000 [0m                      

                       Computation: 1901 steps/s (collection: 3.133s, learning 0.653s)
               Value function loss: 23.3921
                    Surrogate loss: -0.0044
             Mean action noise std: 0.98
                       Mean reward: -50.39
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1958400
                    Iteration time: 3.79s
                        Total time: 1058.63s
                               ETA: 6729.3s
################################################################################
                     [1m Learning iteration 272/2000 [0m                      

                       Computation: 1893 steps/s (collection: 3.134s, learning 0.668s)
               Value function loss: 24.8940
                    Surrogate loss: -0.0009
             Mean action noise std: 0.98
                       Mean reward: -50.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1965600
                    Iteration time: 3.80s
                        Total time: 1062.44s
                               ETA: 6724.9s
################################################################################
                     [1m Learning iteration 273/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.215s, learning 0.687s)
               Value function loss: 23.2045
                    Surrogate loss: -0.0049
             Mean action noise std: 0.98
                       Mean reward: -50.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1972800
                    Iteration time: 3.90s
                        Total time: 1066.34s
                               ETA: 6721.0s
################################################################################
                     [1m Learning iteration 274/2000 [0m                      

                       Computation: 1895 steps/s (collection: 3.126s, learning 0.671s)
               Value function loss: 23.3671
                    Surrogate loss: -0.0032
             Mean action noise std: 0.98
                       Mean reward: -49.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1980000
                    Iteration time: 3.80s
                        Total time: 1070.14s
                               ETA: 6716.6s
################################################################################
                     [1m Learning iteration 275/2000 [0m                      

                       Computation: 1875 steps/s (collection: 3.166s, learning 0.672s)
               Value function loss: 22.4145
                    Surrogate loss: 0.0005
             Mean action noise std: 0.98
                       Mean reward: -49.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1987200
                    Iteration time: 3.84s
                        Total time: 1073.97s
                               ETA: 6712.3s
################################################################################
                     [1m Learning iteration 276/2000 [0m                      

                       Computation: 1893 steps/s (collection: 3.151s, learning 0.650s)
               Value function loss: 19.7985
                    Surrogate loss: -0.0082
             Mean action noise std: 0.98
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1994400
                    Iteration time: 3.80s
                        Total time: 1077.78s
                               ETA: 6707.9s
################################################################################
                     [1m Learning iteration 277/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.123s, learning 0.660s)
               Value function loss: 20.9885
                    Surrogate loss: -0.0056
             Mean action noise std: 0.98
                       Mean reward: -48.68
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2001600
                    Iteration time: 3.78s
                        Total time: 1081.56s
                               ETA: 6703.3s
################################################################################
                     [1m Learning iteration 278/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.134s, learning 0.694s)
               Value function loss: 24.2448
                    Surrogate loss: -0.0002
             Mean action noise std: 0.98
                       Mean reward: -48.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2008800
                    Iteration time: 3.83s
                        Total time: 1085.39s
                               ETA: 6699.1s
################################################################################
                     [1m Learning iteration 279/2000 [0m                      

                       Computation: 1893 steps/s (collection: 3.129s, learning 0.674s)
               Value function loss: 21.9236
                    Surrogate loss: -0.0033
             Mean action noise std: 0.98
                       Mean reward: -48.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2016000
                    Iteration time: 3.80s
                        Total time: 1089.19s
                               ETA: 6694.6s
################################################################################
                     [1m Learning iteration 280/2000 [0m                      

                       Computation: 1837 steps/s (collection: 3.265s, learning 0.655s)
               Value function loss: 24.8706
                    Surrogate loss: -0.0074
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2023200
                    Iteration time: 3.92s
                        Total time: 1093.11s
                               ETA: 6690.9s
################################################################################
                     [1m Learning iteration 281/2000 [0m                      

                       Computation: 1905 steps/s (collection: 3.128s, learning 0.651s)
               Value function loss: 25.0024
                    Surrogate loss: 0.0022
             Mean action noise std: 0.98
                       Mean reward: -48.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2030400
                    Iteration time: 3.78s
                        Total time: 1096.89s
                               ETA: 6686.4s
################################################################################
                     [1m Learning iteration 282/2000 [0m                      

                       Computation: 1855 steps/s (collection: 3.179s, learning 0.702s)
               Value function loss: 24.9283
                    Surrogate loss: 0.0051
             Mean action noise std: 0.99
                       Mean reward: -49.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2037600
                    Iteration time: 3.88s
                        Total time: 1100.77s
                               ETA: 6682.4s
################################################################################
                     [1m Learning iteration 283/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.184s, learning 0.628s)
               Value function loss: 24.5556
                    Surrogate loss: -0.0014
             Mean action noise std: 0.99
                       Mean reward: -49.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2044800
                    Iteration time: 3.81s
                        Total time: 1104.58s
                               ETA: 6678.0s
################################################################################
                     [1m Learning iteration 284/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.164s, learning 0.629s)
               Value function loss: 24.1487
                    Surrogate loss: -0.0077
             Mean action noise std: 0.99
                       Mean reward: -49.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2052000
                    Iteration time: 3.79s
                        Total time: 1108.37s
                               ETA: 6673.6s
################################################################################
                     [1m Learning iteration 285/2000 [0m                      

                       Computation: 1866 steps/s (collection: 3.207s, learning 0.650s)
               Value function loss: 22.2641
                    Surrogate loss: -0.0062
             Mean action noise std: 0.99
                       Mean reward: -50.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2059200
                    Iteration time: 3.86s
                        Total time: 1112.23s
                               ETA: 6669.5s
################################################################################
                     [1m Learning iteration 286/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.140s, learning 0.682s)
               Value function loss: 25.7941
                    Surrogate loss: 0.0024
             Mean action noise std: 0.99
                       Mean reward: -49.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2066400
                    Iteration time: 3.82s
                        Total time: 1116.05s
                               ETA: 6665.2s
################################################################################
                     [1m Learning iteration 287/2000 [0m                      

                       Computation: 1836 steps/s (collection: 3.259s, learning 0.661s)
               Value function loss: 24.5523
                    Surrogate loss: -0.0045
             Mean action noise std: 0.99
                       Mean reward: -49.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2073600
                    Iteration time: 3.92s
                        Total time: 1119.97s
                               ETA: 6661.5s
################################################################################
                     [1m Learning iteration 288/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.143s, learning 0.673s)
               Value function loss: 26.5085
                    Surrogate loss: -0.0086
             Mean action noise std: 0.99
                       Mean reward: -49.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2080800
                    Iteration time: 3.82s
                        Total time: 1123.79s
                               ETA: 6657.2s
################################################################################
                     [1m Learning iteration 289/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.158s, learning 0.667s)
               Value function loss: 22.9385
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -48.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2088000
                    Iteration time: 3.82s
                        Total time: 1127.61s
                               ETA: 6652.9s
################################################################################
                     [1m Learning iteration 290/2000 [0m                      

                       Computation: 1839 steps/s (collection: 3.246s, learning 0.669s)
               Value function loss: 24.5835
                    Surrogate loss: -0.0027
             Mean action noise std: 0.99
                       Mean reward: -48.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2095200
                    Iteration time: 3.91s
                        Total time: 1131.53s
                               ETA: 6649.2s
################################################################################
                     [1m Learning iteration 291/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.155s, learning 0.693s)
               Value function loss: 23.8659
                    Surrogate loss: -0.0036
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2102400
                    Iteration time: 3.85s
                        Total time: 1135.38s
                               ETA: 6645.1s
################################################################################
                     [1m Learning iteration 292/2000 [0m                      

                       Computation: 1811 steps/s (collection: 3.253s, learning 0.722s)
               Value function loss: 22.8394
                    Surrogate loss: -0.0006
             Mean action noise std: 0.99
                       Mean reward: -48.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2109600
                    Iteration time: 3.98s
                        Total time: 1139.35s
                               ETA: 6641.7s
################################################################################
                     [1m Learning iteration 293/2000 [0m                      

                       Computation: 1847 steps/s (collection: 3.099s, learning 0.798s)
               Value function loss: 21.6723
                    Surrogate loss: -0.0034
             Mean action noise std: 0.98
                       Mean reward: -48.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2116800
                    Iteration time: 3.90s
                        Total time: 1143.25s
                               ETA: 6637.8s
################################################################################
                     [1m Learning iteration 294/2000 [0m                      

                       Computation: 1828 steps/s (collection: 3.154s, learning 0.785s)
               Value function loss: 24.1306
                    Surrogate loss: 0.0116
             Mean action noise std: 0.98
                       Mean reward: -48.36
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2124000
                    Iteration time: 3.94s
                        Total time: 1147.19s
                               ETA: 6634.2s
################################################################################
                     [1m Learning iteration 295/2000 [0m                      

                       Computation: 1834 steps/s (collection: 3.186s, learning 0.738s)
               Value function loss: 22.0499
                    Surrogate loss: -0.0045
             Mean action noise std: 0.98
                       Mean reward: -48.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2131200
                    Iteration time: 3.92s
                        Total time: 1151.11s
                               ETA: 6630.6s
################################################################################
                     [1m Learning iteration 296/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.142s, learning 0.729s)
               Value function loss: 22.5580
                    Surrogate loss: -0.0015
             Mean action noise std: 0.98
                       Mean reward: -47.98
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2138400
                    Iteration time: 3.87s
                        Total time: 1154.98s
                               ETA: 6626.6s
################################################################################
                     [1m Learning iteration 297/2000 [0m                      

                       Computation: 1765 steps/s (collection: 3.208s, learning 0.870s)
               Value function loss: 22.6305
                    Surrogate loss: -0.0073
             Mean action noise std: 0.98
                       Mean reward: -47.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2145600
                    Iteration time: 4.08s
                        Total time: 1159.06s
                               ETA: 6623.8s
################################################################################
                     [1m Learning iteration 298/2000 [0m                      

                       Computation: 1899 steps/s (collection: 3.121s, learning 0.669s)
               Value function loss: 23.5003
                    Surrogate loss: -0.0075
             Mean action noise std: 0.99
                       Mean reward: -47.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2152800
                    Iteration time: 3.79s
                        Total time: 1162.85s
                               ETA: 6619.3s
################################################################################
                     [1m Learning iteration 299/2000 [0m                      

                       Computation: 1784 steps/s (collection: 3.211s, learning 0.823s)
               Value function loss: 21.1185
                    Surrogate loss: -0.0080
             Mean action noise std: 0.99
                       Mean reward: -48.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2160000
                    Iteration time: 4.03s
                        Total time: 1166.89s
                               ETA: 6616.2s
################################################################################
                     [1m Learning iteration 300/2000 [0m                      

                       Computation: 1820 steps/s (collection: 3.124s, learning 0.832s)
               Value function loss: 23.4866
                    Surrogate loss: -0.0049
             Mean action noise std: 0.99
                       Mean reward: -48.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2167200
                    Iteration time: 3.96s
                        Total time: 1170.84s
                               ETA: 6612.7s
################################################################################
                     [1m Learning iteration 301/2000 [0m                      

                       Computation: 1811 steps/s (collection: 3.142s, learning 0.833s)
               Value function loss: 23.1504
                    Surrogate loss: 0.0014
             Mean action noise std: 0.98
                       Mean reward: -48.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2174400
                    Iteration time: 3.98s
                        Total time: 1174.82s
                               ETA: 6609.3s
################################################################################
                     [1m Learning iteration 302/2000 [0m                      

                       Computation: 1778 steps/s (collection: 3.170s, learning 0.877s)
               Value function loss: 24.5832
                    Surrogate loss: 0.0195
             Mean action noise std: 0.99
                       Mean reward: -48.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2181600
                    Iteration time: 4.05s
                        Total time: 1178.86s
                               ETA: 6606.3s
################################################################################
                     [1m Learning iteration 303/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.149s, learning 0.754s)
               Value function loss: 25.0824
                    Surrogate loss: -0.0050
             Mean action noise std: 0.99
                       Mean reward: -49.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2188800
                    Iteration time: 3.90s
                        Total time: 1182.77s
                               ETA: 6602.5s
################################################################################
                     [1m Learning iteration 304/2000 [0m                      

                       Computation: 1778 steps/s (collection: 3.231s, learning 0.817s)
               Value function loss: 27.1040
                    Surrogate loss: 0.0085
             Mean action noise std: 0.98
                       Mean reward: -48.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2196000
                    Iteration time: 4.05s
                        Total time: 1186.82s
                               ETA: 6599.5s
################################################################################
                     [1m Learning iteration 305/2000 [0m                      

                       Computation: 1800 steps/s (collection: 3.168s, learning 0.830s)
               Value function loss: 27.6650
                    Surrogate loss: -0.0001
             Mean action noise std: 0.98
                       Mean reward: -49.26
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2203200
                    Iteration time: 4.00s
                        Total time: 1190.81s
                               ETA: 6596.2s
################################################################################
                     [1m Learning iteration 306/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.140s, learning 0.675s)
               Value function loss: 26.0118
                    Surrogate loss: -0.0016
             Mean action noise std: 0.98
                       Mean reward: -49.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2210400
                    Iteration time: 3.82s
                        Total time: 1194.63s
                               ETA: 6591.9s
################################################################################
                     [1m Learning iteration 307/2000 [0m                      

                       Computation: 1780 steps/s (collection: 3.279s, learning 0.764s)
               Value function loss: 26.8548
                    Surrogate loss: -0.0010
             Mean action noise std: 0.99
                       Mean reward: -49.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2217600
                    Iteration time: 4.04s
                        Total time: 1198.67s
                               ETA: 6588.8s
################################################################################
                     [1m Learning iteration 308/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.138s, learning 0.734s)
               Value function loss: 24.3430
                    Surrogate loss: -0.0001
             Mean action noise std: 0.99
                       Mean reward: -49.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2224800
                    Iteration time: 3.87s
                        Total time: 1202.54s
                               ETA: 6584.8s
################################################################################
                     [1m Learning iteration 309/2000 [0m                      

                       Computation: 1794 steps/s (collection: 3.178s, learning 0.835s)
               Value function loss: 24.7785
                    Surrogate loss: -0.0061
             Mean action noise std: 0.99
                       Mean reward: -49.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2232000
                    Iteration time: 4.01s
                        Total time: 1206.56s
                               ETA: 6581.6s
################################################################################
                     [1m Learning iteration 310/2000 [0m                      

                       Computation: 1770 steps/s (collection: 3.203s, learning 0.863s)
               Value function loss: 25.6623
                    Surrogate loss: 0.0043
             Mean action noise std: 0.99
                       Mean reward: -49.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2239200
                    Iteration time: 4.07s
                        Total time: 1210.62s
                               ETA: 6578.6s
################################################################################
                     [1m Learning iteration 311/2000 [0m                      

                       Computation: 1815 steps/s (collection: 3.180s, learning 0.785s)
               Value function loss: 28.0493
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -49.12
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2246400
                    Iteration time: 3.97s
                        Total time: 1214.59s
                               ETA: 6575.1s
################################################################################
                     [1m Learning iteration 312/2000 [0m                      

                       Computation: 1735 steps/s (collection: 3.348s, learning 0.801s)
               Value function loss: 25.0996
                    Surrogate loss: -0.0076
             Mean action noise std: 0.99
                       Mean reward: -49.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2253600
                    Iteration time: 4.15s
                        Total time: 1218.74s
                               ETA: 6572.6s
################################################################################
                     [1m Learning iteration 313/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.166s, learning 0.654s)
               Value function loss: 24.5458
                    Surrogate loss: -0.0071
             Mean action noise std: 0.99
                       Mean reward: -48.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2260800
                    Iteration time: 3.82s
                        Total time: 1222.56s
                               ETA: 6568.3s
################################################################################
                     [1m Learning iteration 314/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.204s, learning 0.712s)
               Value function loss: 25.5399
                    Surrogate loss: 0.0100
             Mean action noise std: 0.99
                       Mean reward: -49.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2268000
                    Iteration time: 3.92s
                        Total time: 1226.47s
                               ETA: 6564.6s
################################################################################
                     [1m Learning iteration 315/2000 [0m                      

                       Computation: 1791 steps/s (collection: 3.239s, learning 0.780s)
               Value function loss: 26.5048
                    Surrogate loss: -0.0087
             Mean action noise std: 0.99
                       Mean reward: -48.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2275200
                    Iteration time: 4.02s
                        Total time: 1230.49s
                               ETA: 6561.3s
################################################################################
                     [1m Learning iteration 316/2000 [0m                      

                       Computation: 1856 steps/s (collection: 3.133s, learning 0.745s)
               Value function loss: 27.2158
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -49.25
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2282400
                    Iteration time: 3.88s
                        Total time: 1234.37s
                               ETA: 6557.3s
################################################################################
                     [1m Learning iteration 317/2000 [0m                      

                       Computation: 1749 steps/s (collection: 3.304s, learning 0.812s)
               Value function loss: 25.8812
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -49.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2289600
                    Iteration time: 4.12s
                        Total time: 1238.49s
                               ETA: 6554.6s
################################################################################
                     [1m Learning iteration 318/2000 [0m                      

                       Computation: 1823 steps/s (collection: 3.096s, learning 0.852s)
               Value function loss: 25.4462
                    Surrogate loss: -0.0003
             Mean action noise std: 1.00
                       Mean reward: -49.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2296800
                    Iteration time: 3.95s
                        Total time: 1242.43s
                               ETA: 6551.0s
################################################################################
                     [1m Learning iteration 319/2000 [0m                      

                       Computation: 1750 steps/s (collection: 3.211s, learning 0.903s)
               Value function loss: 26.5040
                    Surrogate loss: -0.0066
             Mean action noise std: 0.99
                       Mean reward: -49.28
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2304000
                    Iteration time: 4.11s
                        Total time: 1246.55s
                               ETA: 6548.3s
################################################################################
                     [1m Learning iteration 320/2000 [0m                      

                       Computation: 1794 steps/s (collection: 3.229s, learning 0.783s)
               Value function loss: 25.4339
                    Surrogate loss: -0.0023
             Mean action noise std: 0.99
                       Mean reward: -49.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2311200
                    Iteration time: 4.01s
                        Total time: 1250.56s
                               ETA: 6545.0s
################################################################################
                     [1m Learning iteration 321/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.142s, learning 0.773s)
               Value function loss: 23.7000
                    Surrogate loss: 0.0005
             Mean action noise std: 1.00
                       Mean reward: -49.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2318400
                    Iteration time: 3.92s
                        Total time: 1254.48s
                               ETA: 6541.2s
################################################################################
                     [1m Learning iteration 322/2000 [0m                      

                       Computation: 1788 steps/s (collection: 3.249s, learning 0.778s)
               Value function loss: 25.7746
                    Surrogate loss: -0.0022
             Mean action noise std: 1.00
                       Mean reward: -48.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2325600
                    Iteration time: 4.03s
                        Total time: 1258.50s
                               ETA: 6538.0s
################################################################################
                     [1m Learning iteration 323/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.118s, learning 0.797s)
               Value function loss: 27.4068
                    Surrogate loss: -0.0042
             Mean action noise std: 1.00
                       Mean reward: -48.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2332800
                    Iteration time: 3.92s
                        Total time: 1262.42s
                               ETA: 6534.2s
################################################################################
                     [1m Learning iteration 324/2000 [0m                      

                       Computation: 1790 steps/s (collection: 3.148s, learning 0.874s)
               Value function loss: 24.0192
                    Surrogate loss: -0.0053
             Mean action noise std: 1.00
                       Mean reward: -49.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2340000
                    Iteration time: 4.02s
                        Total time: 1266.44s
                               ETA: 6530.9s
################################################################################
                     [1m Learning iteration 325/2000 [0m                      

                       Computation: 1865 steps/s (collection: 3.206s, learning 0.653s)
               Value function loss: 26.2549
                    Surrogate loss: -0.0003
             Mean action noise std: 1.00
                       Mean reward: -48.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2347200
                    Iteration time: 3.86s
                        Total time: 1270.30s
                               ETA: 6526.8s
################################################################################
                     [1m Learning iteration 326/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.138s, learning 0.686s)
               Value function loss: 23.3614
                    Surrogate loss: -0.0049
             Mean action noise std: 1.00
                       Mean reward: -48.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2354400
                    Iteration time: 3.82s
                        Total time: 1274.12s
                               ETA: 6522.6s
################################################################################
                     [1m Learning iteration 327/2000 [0m                      

                       Computation: 1825 steps/s (collection: 3.290s, learning 0.654s)
               Value function loss: 24.3731
                    Surrogate loss: -0.0020
             Mean action noise std: 1.00
                       Mean reward: -48.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2361600
                    Iteration time: 3.94s
                        Total time: 1278.07s
                               ETA: 6518.9s
################################################################################
                     [1m Learning iteration 328/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.167s, learning 0.649s)
               Value function loss: 27.2123
                    Surrogate loss: -0.0050
             Mean action noise std: 1.00
                       Mean reward: -47.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2368800
                    Iteration time: 3.82s
                        Total time: 1281.88s
                               ETA: 6514.6s
################################################################################
                     [1m Learning iteration 329/2000 [0m                      

                       Computation: 1822 steps/s (collection: 3.271s, learning 0.679s)
               Value function loss: 24.0957
                    Surrogate loss: -0.0080
             Mean action noise std: 1.00
                       Mean reward: -47.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2376000
                    Iteration time: 3.95s
                        Total time: 1285.83s
                               ETA: 6511.0s
################################################################################
                     [1m Learning iteration 330/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.181s, learning 0.636s)
               Value function loss: 25.1048
                    Surrogate loss: -0.0095
             Mean action noise std: 1.00
                       Mean reward: -47.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2383200
                    Iteration time: 3.82s
                        Total time: 1289.65s
                               ETA: 6506.7s
################################################################################
                     [1m Learning iteration 331/2000 [0m                      

                       Computation: 1879 steps/s (collection: 3.144s, learning 0.686s)
               Value function loss: 28.0447
                    Surrogate loss: 0.0053
             Mean action noise std: 1.00
                       Mean reward: -48.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2390400
                    Iteration time: 3.83s
                        Total time: 1293.48s
                               ETA: 6502.5s
################################################################################
                     [1m Learning iteration 332/2000 [0m                      

                       Computation: 1776 steps/s (collection: 3.187s, learning 0.865s)
               Value function loss: 25.5438
                    Surrogate loss: 0.0057
             Mean action noise std: 1.00
                       Mean reward: -48.73
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2397600
                    Iteration time: 4.05s
                        Total time: 1297.53s
                               ETA: 6499.4s
################################################################################
                     [1m Learning iteration 333/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.144s, learning 0.757s)
               Value function loss: 25.3527
                    Surrogate loss: -0.0021
             Mean action noise std: 1.00
                       Mean reward: -49.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2404800
                    Iteration time: 3.90s
                        Total time: 1301.43s
                               ETA: 6495.5s
################################################################################
                     [1m Learning iteration 334/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.225s, learning 0.712s)
               Value function loss: 25.1033
                    Surrogate loss: -0.0081
             Mean action noise std: 1.00
                       Mean reward: -49.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2412000
                    Iteration time: 3.94s
                        Total time: 1305.37s
                               ETA: 6491.8s
################################################################################
                     [1m Learning iteration 335/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.136s, learning 0.659s)
               Value function loss: 27.1526
                    Surrogate loss: 0.0034
             Mean action noise std: 1.00
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2419200
                    Iteration time: 3.80s
                        Total time: 1309.17s
                               ETA: 6487.4s
################################################################################
                     [1m Learning iteration 336/2000 [0m                      

                       Computation: 1857 steps/s (collection: 3.174s, learning 0.702s)
               Value function loss: 26.5627
                    Surrogate loss: 0.0015
             Mean action noise std: 1.00
                       Mean reward: -49.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2426400
                    Iteration time: 3.88s
                        Total time: 1313.04s
                               ETA: 6483.4s
################################################################################
                     [1m Learning iteration 337/2000 [0m                      

                       Computation: 1839 steps/s (collection: 3.190s, learning 0.724s)
               Value function loss: 23.1018
                    Surrogate loss: 0.0051
             Mean action noise std: 1.00
                       Mean reward: -49.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2433600
                    Iteration time: 3.91s
                        Total time: 1316.96s
                               ETA: 6479.6s
################################################################################
                     [1m Learning iteration 338/2000 [0m                      

                       Computation: 1915 steps/s (collection: 3.106s, learning 0.654s)
               Value function loss: 24.8659
                    Surrogate loss: -0.0057
             Mean action noise std: 1.00
                       Mean reward: -48.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2440800
                    Iteration time: 3.76s
                        Total time: 1320.72s
                               ETA: 6475.0s
################################################################################
                     [1m Learning iteration 339/2000 [0m                      

                       Computation: 1827 steps/s (collection: 3.163s, learning 0.778s)
               Value function loss: 26.4998
                    Surrogate loss: -0.0044
             Mean action noise std: 1.00
                       Mean reward: -48.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2448000
                    Iteration time: 3.94s
                        Total time: 1324.66s
                               ETA: 6471.3s
################################################################################
                     [1m Learning iteration 340/2000 [0m                      

                       Computation: 1834 steps/s (collection: 3.149s, learning 0.774s)
               Value function loss: 24.0434
                    Surrogate loss: -0.0030
             Mean action noise std: 1.00
                       Mean reward: -49.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2455200
                    Iteration time: 3.92s
                        Total time: 1328.58s
                               ETA: 6467.6s
################################################################################
                     [1m Learning iteration 341/2000 [0m                      

                       Computation: 1791 steps/s (collection: 3.198s, learning 0.821s)
               Value function loss: 25.5198
                    Surrogate loss: -0.0058
             Mean action noise std: 1.00
                       Mean reward: -48.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2462400
                    Iteration time: 4.02s
                        Total time: 1332.60s
                               ETA: 6464.3s
################################################################################
                      [1m Learning iteration 0/2000 [0m                       

                       Computation: 1441 steps/s (collection: 4.369s, learning 0.628s)
               Value function loss: 87.6143
                    Surrogate loss: -0.0028
             Mean action noise std: 1.00
                       Mean reward: -55.21
               Mean episode length: 43.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7200
                    Iteration time: 5.00s
                        Total time: 5.00s
                               ETA: 9992.9s
################################################################################
                      [1m Learning iteration 1/2000 [0m                       

                       Computation: 1860 steps/s (collection: 3.227s, learning 0.643s)
               Value function loss: 60.9052
                    Surrogate loss: -0.0024
             Mean action noise std: 1.00
                       Mean reward: -55.22
               Mean episode length: 43.67
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 14400
                    Iteration time: 3.87s
                        Total time: 8.87s
                               ETA: 8862.0s
################################################################################
                      [1m Learning iteration 2/2000 [0m                       

                       Computation: 1818 steps/s (collection: 3.130s, learning 0.830s)
               Value function loss: 87.3786
                    Surrogate loss: -0.0007
             Mean action noise std: 1.00
                       Mean reward: -55.43
               Mean episode length: 44.20
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 21600
                    Iteration time: 3.96s
                        Total time: 12.83s
                               ETA: 8542.4s
################################################################################
                      [1m Learning iteration 3/2000 [0m                       

                       Computation: 1795 steps/s (collection: 3.148s, learning 0.863s)
               Value function loss: 69.4787
                    Surrogate loss: -0.0035
             Mean action noise std: 1.00
                       Mean reward: -55.55
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 28800
                    Iteration time: 4.01s
                        Total time: 16.84s
                               ETA: 8406.1s
################################################################################
                      [1m Learning iteration 4/2000 [0m                       

                       Computation: 1846 steps/s (collection: 3.180s, learning 0.719s)
               Value function loss: 76.6303
                    Surrogate loss: -0.0057
             Mean action noise std: 1.00
                       Mean reward: -55.72
               Mean episode length: 44.60
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 36000
                    Iteration time: 3.90s
                        Total time: 20.74s
                               ETA: 8278.2s
################################################################################
                      [1m Learning iteration 5/2000 [0m                       

                       Computation: 1920 steps/s (collection: 3.091s, learning 0.658s)
               Value function loss: 59.9183
                    Surrogate loss: 0.0016
             Mean action noise std: 1.00
                       Mean reward: -55.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 43200
                    Iteration time: 3.75s
                        Total time: 24.49s
                               ETA: 8141.4s
################################################################################
                      [1m Learning iteration 6/2000 [0m                       

                       Computation: 1862 steps/s (collection: 3.252s, learning 0.614s)
               Value function loss: 58.3303
                    Surrogate loss: -0.0043
             Mean action noise std: 1.00
                       Mean reward: -55.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 50400
                    Iteration time: 3.87s
                        Total time: 28.35s
                               ETA: 8076.2s
################################################################################
                      [1m Learning iteration 7/2000 [0m                       

                       Computation: 1943 steps/s (collection: 3.080s, learning 0.625s)
               Value function loss: 50.1596
                    Surrogate loss: -0.0037
             Mean action noise std: 1.00
                       Mean reward: -55.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 57600
                    Iteration time: 3.70s
                        Total time: 32.06s
                               ETA: 7986.1s
################################################################################
                      [1m Learning iteration 8/2000 [0m                       

                       Computation: 1919 steps/s (collection: 3.063s, learning 0.689s)
               Value function loss: 48.1750
                    Surrogate loss: -0.0042
             Mean action noise std: 0.99
                       Mean reward: -55.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.25
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 64800
                    Iteration time: 3.75s
                        Total time: 35.81s
                               ETA: 7925.5s
################################################################################
                      [1m Learning iteration 9/2000 [0m                       

                       Computation: 1927 steps/s (collection: 3.123s, learning 0.611s)
               Value function loss: 46.1737
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -55.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 72000
                    Iteration time: 3.73s
                        Total time: 39.54s
                               ETA: 7872.9s
################################################################################
                      [1m Learning iteration 10/2000 [0m                      

                       Computation: 1942 steps/s (collection: 3.094s, learning 0.612s)
               Value function loss: 49.5829
                    Surrogate loss: -0.0049
             Mean action noise std: 0.99
                       Mean reward: -55.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 79200
                    Iteration time: 3.71s
                        Total time: 43.25s
                               ETA: 7824.2s
################################################################################
                      [1m Learning iteration 11/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.120s, learning 0.672s)
               Value function loss: 58.2134
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -55.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 86400
                    Iteration time: 3.79s
                        Total time: 47.04s
                               ETA: 7797.0s
################################################################################
                      [1m Learning iteration 12/2000 [0m                      

                       Computation: 1925 steps/s (collection: 3.032s, learning 0.709s)
               Value function loss: 47.5025
                    Surrogate loss: 0.0007
             Mean action noise std: 0.99
                       Mean reward: -56.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.29
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 93600
                    Iteration time: 3.74s
                        Total time: 50.78s
                               ETA: 7765.6s
################################################################################
                      [1m Learning iteration 13/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.218s, learning 0.625s)
               Value function loss: 52.7263
                    Surrogate loss: -0.0032
             Mean action noise std: 0.99
                       Mean reward: -56.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 100800
                    Iteration time: 3.84s
                        Total time: 54.62s
                               ETA: 7752.8s
################################################################################
                      [1m Learning iteration 14/2000 [0m                      

                       Computation: 1919 steps/s (collection: 3.120s, learning 0.631s)
               Value function loss: 57.3124
                    Surrogate loss: -0.0038
             Mean action noise std: 0.99
                       Mean reward: -56.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 108000
                    Iteration time: 3.75s
                        Total time: 58.38s
                               ETA: 7729.0s
################################################################################
                      [1m Learning iteration 15/2000 [0m                      

                       Computation: 1929 steps/s (collection: 3.114s, learning 0.618s)
               Value function loss: 43.4845
                    Surrogate loss: -0.0045
             Mean action noise std: 0.99
                       Mean reward: -56.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 115200
                    Iteration time: 3.73s
                        Total time: 62.11s
                               ETA: 7705.3s
################################################################################
                      [1m Learning iteration 16/2000 [0m                      

                       Computation: 1936 steps/s (collection: 3.108s, learning 0.611s)
               Value function loss: 44.4359
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 122400
                    Iteration time: 3.72s
                        Total time: 65.83s
                               ETA: 7682.4s
################################################################################
                      [1m Learning iteration 17/2000 [0m                      

                       Computation: 1941 steps/s (collection: 3.093s, learning 0.615s)
               Value function loss: 42.2122
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -54.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 129600
                    Iteration time: 3.71s
                        Total time: 69.54s
                               ETA: 7660.5s
################################################################################
                      [1m Learning iteration 18/2000 [0m                      

                       Computation: 1933 steps/s (collection: 3.104s, learning 0.620s)
               Value function loss: 41.1112
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -54.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 136800
                    Iteration time: 3.72s
                        Total time: 73.26s
                               ETA: 7642.1s
################################################################################
                      [1m Learning iteration 19/2000 [0m                      

                       Computation: 1945 steps/s (collection: 3.087s, learning 0.614s)
               Value function loss: 43.5620
                    Surrogate loss: -0.0051
             Mean action noise std: 0.99
                       Mean reward: -54.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 144000
                    Iteration time: 3.70s
                        Total time: 76.96s
                               ETA: 7622.9s
################################################################################
                      [1m Learning iteration 20/2000 [0m                      

                       Computation: 1900 steps/s (collection: 3.142s, learning 0.647s)
               Value function loss: 34.2933
                    Surrogate loss: 0.0097
             Mean action noise std: 0.99
                       Mean reward: -54.33
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 151200
                    Iteration time: 3.79s
                        Total time: 80.75s
                               ETA: 7613.5s
################################################################################
                      [1m Learning iteration 21/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.117s, learning 0.611s)
               Value function loss: 46.9817
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -54.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 158400
                    Iteration time: 3.73s
                        Total time: 84.48s
                               ETA: 7599.1s
################################################################################
                      [1m Learning iteration 22/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.102s, learning 0.633s)
               Value function loss: 48.4932
                    Surrogate loss: 0.0012
             Mean action noise std: 0.99
                       Mean reward: -55.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.27
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 165600
                    Iteration time: 3.73s
                        Total time: 88.21s
                               ETA: 7586.2s
################################################################################
                      [1m Learning iteration 23/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.118s, learning 0.610s)
               Value function loss: 43.2159
                    Surrogate loss: -0.0033
             Mean action noise std: 0.99
                       Mean reward: -55.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 172800
                    Iteration time: 3.73s
                        Total time: 91.94s
                               ETA: 7573.5s
################################################################################
                      [1m Learning iteration 24/2000 [0m                      

                       Computation: 1930 steps/s (collection: 3.108s, learning 0.622s)
               Value function loss: 47.0554
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -55.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 180000
                    Iteration time: 3.73s
                        Total time: 95.67s
                               ETA: 7561.8s
################################################################################
                      [1m Learning iteration 25/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.138s, learning 0.624s)
               Value function loss: 47.8379
                    Surrogate loss: -0.0025
             Mean action noise std: 0.99
                       Mean reward: -55.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.22
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 187200
                    Iteration time: 3.76s
                        Total time: 99.43s
                               ETA: 7553.0s
################################################################################
                      [1m Learning iteration 26/2000 [0m                      

                       Computation: 1928 steps/s (collection: 3.095s, learning 0.637s)
               Value function loss: 38.4298
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -55.53
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.23
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 194400
                    Iteration time: 3.73s
                        Total time: 103.16s
                               ETA: 7542.5s
################################################################################
                      [1m Learning iteration 27/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.114s, learning 0.724s)
               Value function loss: 39.0335
                    Surrogate loss: -0.0024
             Mean action noise std: 0.99
                       Mean reward: -54.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 201600
                    Iteration time: 3.84s
                        Total time: 107.00s
                               ETA: 7539.8s
################################################################################
                      [1m Learning iteration 28/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.107s, learning 0.613s)
               Value function loss: 33.7753
                    Surrogate loss: -0.0058
             Mean action noise std: 0.99
                       Mean reward: -54.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 208800
                    Iteration time: 3.72s
                        Total time: 110.72s
                               ETA: 7529.1s
################################################################################
                      [1m Learning iteration 29/2000 [0m                      

                       Computation: 1909 steps/s (collection: 3.130s, learning 0.641s)
               Value function loss: 40.2645
                    Surrogate loss: -0.0073
             Mean action noise std: 0.99
                       Mean reward: -53.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 216000
                    Iteration time: 3.77s
                        Total time: 114.49s
                               ETA: 7522.2s
################################################################################
                      [1m Learning iteration 30/2000 [0m                      

                       Computation: 1901 steps/s (collection: 3.127s, learning 0.660s)
               Value function loss: 38.1285
                    Surrogate loss: -0.0027
             Mean action noise std: 0.99
                       Mean reward: -53.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 223200
                    Iteration time: 3.79s
                        Total time: 118.28s
                               ETA: 7516.4s
################################################################################
                      [1m Learning iteration 31/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.120s, learning 0.721s)
               Value function loss: 41.0155
                    Surrogate loss: -0.0043
             Mean action noise std: 0.99
                       Mean reward: -52.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 230400
                    Iteration time: 3.84s
                        Total time: 122.12s
                               ETA: 7514.2s
################################################################################
                      [1m Learning iteration 32/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.129s, learning 0.684s)
               Value function loss: 40.3199
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -53.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.21
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 237600
                    Iteration time: 3.81s
                        Total time: 125.93s
                               ETA: 7510.1s
################################################################################
                      [1m Learning iteration 33/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.115s, learning 0.619s)
               Value function loss: 38.3529
                    Surrogate loss: -0.0039
             Mean action noise std: 0.99
                       Mean reward: -52.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 244800
                    Iteration time: 3.73s
                        Total time: 129.67s
                               ETA: 7501.6s
################################################################################
                      [1m Learning iteration 34/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.185s, learning 0.611s)
               Value function loss: 38.4416
                    Surrogate loss: 0.0076
             Mean action noise std: 0.99
                       Mean reward: -53.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.19
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 252000
                    Iteration time: 3.80s
                        Total time: 133.46s
                               ETA: 7496.8s
################################################################################
                      [1m Learning iteration 35/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.114s, learning 0.636s)
               Value function loss: 39.5888
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -53.10
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 259200
                    Iteration time: 3.75s
                        Total time: 137.21s
                               ETA: 7489.5s
################################################################################
                      [1m Learning iteration 36/2000 [0m                      

                       Computation: 1902 steps/s (collection: 3.159s, learning 0.626s)
               Value function loss: 41.4946
                    Surrogate loss: -0.0040
             Mean action noise std: 0.99
                       Mean reward: -53.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 266400
                    Iteration time: 3.78s
                        Total time: 141.00s
                               ETA: 7484.2s
################################################################################
                      [1m Learning iteration 37/2000 [0m                      

                       Computation: 1917 steps/s (collection: 3.129s, learning 0.626s)
               Value function loss: 38.0765
                    Surrogate loss: -0.0061
             Mean action noise std: 0.99
                       Mean reward: -52.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 273600
                    Iteration time: 3.75s
                        Total time: 144.75s
                               ETA: 7477.5s
################################################################################
                      [1m Learning iteration 38/2000 [0m                      

                       Computation: 1912 steps/s (collection: 3.125s, learning 0.640s)
               Value function loss: 44.5340
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -52.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 280800
                    Iteration time: 3.76s
                        Total time: 148.52s
                               ETA: 7471.5s
################################################################################
                      [1m Learning iteration 39/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.130s, learning 0.741s)
               Value function loss: 36.2183
                    Surrogate loss: 0.0018
             Mean action noise std: 0.99
                       Mean reward: -52.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 288000
                    Iteration time: 3.87s
                        Total time: 152.39s
                               ETA: 7470.8s
################################################################################
                      [1m Learning iteration 40/2000 [0m                      

                       Computation: 1930 steps/s (collection: 3.128s, learning 0.601s)
               Value function loss: 34.4764
                    Surrogate loss: -0.0010
             Mean action noise std: 0.99
                       Mean reward: -51.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 295200
                    Iteration time: 3.73s
                        Total time: 156.12s
                               ETA: 7463.1s
################################################################################
                      [1m Learning iteration 41/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.171s, learning 0.625s)
               Value function loss: 36.5184
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -51.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 302400
                    Iteration time: 3.80s
                        Total time: 159.91s
                               ETA: 7458.7s
################################################################################
                      [1m Learning iteration 42/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.102s, learning 0.710s)
               Value function loss: 39.0004
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -51.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 309600
                    Iteration time: 3.81s
                        Total time: 163.72s
                               ETA: 7455.1s
################################################################################
                      [1m Learning iteration 43/2000 [0m                      

                       Computation: 1849 steps/s (collection: 3.153s, learning 0.739s)
               Value function loss: 42.0665
                    Surrogate loss: -0.0017
             Mean action noise std: 0.99
                       Mean reward: -52.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.20
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 316800
                    Iteration time: 3.89s
                        Total time: 167.62s
                               ETA: 7455.1s
################################################################################
                      [1m Learning iteration 44/2000 [0m                      

                       Computation: 1827 steps/s (collection: 3.024s, learning 0.916s)
               Value function loss: 41.4940
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -52.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 324000
                    Iteration time: 3.94s
                        Total time: 171.55s
                               ETA: 7456.9s
################################################################################
                      [1m Learning iteration 45/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.128s, learning 0.616s)
               Value function loss: 33.4112
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -52.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 331200
                    Iteration time: 3.74s
                        Total time: 175.30s
                               ETA: 7450.2s
################################################################################
                      [1m Learning iteration 46/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.132s, learning 0.665s)
               Value function loss: 29.0818
                    Surrogate loss: 0.0185
             Mean action noise std: 0.99
                       Mean reward: -52.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 338400
                    Iteration time: 3.80s
                        Total time: 179.09s
                               ETA: 7445.8s
################################################################################
                      [1m Learning iteration 47/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.101s, learning 0.706s)
               Value function loss: 35.3084
                    Surrogate loss: 0.0096
             Mean action noise std: 0.99
                       Mean reward: -52.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 345600
                    Iteration time: 3.81s
                        Total time: 182.90s
                               ETA: 7441.8s
################################################################################
                      [1m Learning iteration 48/2000 [0m                      

                       Computation: 1900 steps/s (collection: 3.129s, learning 0.660s)
               Value function loss: 35.7524
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -51.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 352800
                    Iteration time: 3.79s
                        Total time: 186.69s
                               ETA: 7437.1s
################################################################################
                      [1m Learning iteration 49/2000 [0m                      

                       Computation: 1928 steps/s (collection: 3.086s, learning 0.647s)
               Value function loss: 33.0440
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -51.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 360000
                    Iteration time: 3.73s
                        Total time: 190.42s
                               ETA: 7430.3s
################################################################################
                      [1m Learning iteration 50/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.177s, learning 0.706s)
               Value function loss: 34.2946
                    Surrogate loss: -0.0047
             Mean action noise std: 0.99
                       Mean reward: -51.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.18
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 367200
                    Iteration time: 3.88s
                        Total time: 194.31s
                               ETA: 7429.4s
################################################################################
                      [1m Learning iteration 51/2000 [0m                      

                       Computation: 1867 steps/s (collection: 3.105s, learning 0.750s)
               Value function loss: 33.1621
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -51.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 374400
                    Iteration time: 3.86s
                        Total time: 198.16s
                               ETA: 7427.3s
################################################################################
                      [1m Learning iteration 52/2000 [0m                      

                       Computation: 1868 steps/s (collection: 3.104s, learning 0.750s)
               Value function loss: 33.1356
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -51.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 381600
                    Iteration time: 3.85s
                        Total time: 202.02s
                               ETA: 7425.0s
################################################################################
                      [1m Learning iteration 53/2000 [0m                      

                       Computation: 1856 steps/s (collection: 3.119s, learning 0.758s)
               Value function loss: 34.3554
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -51.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 388800
                    Iteration time: 3.88s
                        Total time: 205.89s
                               ETA: 7423.6s
################################################################################
                      [1m Learning iteration 54/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.131s, learning 0.618s)
               Value function loss: 32.2024
                    Surrogate loss: -0.0022
             Mean action noise std: 0.99
                       Mean reward: -51.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 396000
                    Iteration time: 3.75s
                        Total time: 209.64s
                               ETA: 7417.5s
################################################################################
                      [1m Learning iteration 55/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.129s, learning 0.769s)
               Value function loss: 33.4714
                    Surrogate loss: 0.0039
             Mean action noise std: 0.99
                       Mean reward: -51.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 403200
                    Iteration time: 3.90s
                        Total time: 213.54s
                               ETA: 7416.7s
################################################################################
                      [1m Learning iteration 56/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.125s, learning 0.596s)
               Value function loss: 29.8262
                    Surrogate loss: -0.0002
             Mean action noise std: 0.99
                       Mean reward: -51.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 410400
                    Iteration time: 3.72s
                        Total time: 217.26s
                               ETA: 7409.8s
################################################################################
                      [1m Learning iteration 57/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.143s, learning 0.669s)
               Value function loss: 32.3009
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -50.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 417600
                    Iteration time: 3.81s
                        Total time: 221.07s
                               ETA: 7406.0s
################################################################################
                      [1m Learning iteration 58/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.140s, learning 0.618s)
               Value function loss: 29.6770
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -50.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 424800
                    Iteration time: 3.76s
                        Total time: 224.83s
                               ETA: 7400.4s
################################################################################
                      [1m Learning iteration 59/2000 [0m                      

                       Computation: 1936 steps/s (collection: 3.105s, learning 0.614s)
               Value function loss: 27.6777
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -50.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 432000
                    Iteration time: 3.72s
                        Total time: 228.55s
                               ETA: 7393.6s
################################################################################
                      [1m Learning iteration 60/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.126s, learning 0.725s)
               Value function loss: 30.1422
                    Surrogate loss: -0.0003
             Mean action noise std: 0.99
                       Mean reward: -50.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 439200
                    Iteration time: 3.85s
                        Total time: 232.40s
                               ETA: 7391.1s
################################################################################
                      [1m Learning iteration 61/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.112s, learning 0.615s)
               Value function loss: 31.8961
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -50.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 446400
                    Iteration time: 3.73s
                        Total time: 236.13s
                               ETA: 7384.7s
################################################################################
                      [1m Learning iteration 62/2000 [0m                      

                       Computation: 1833 steps/s (collection: 3.101s, learning 0.825s)
               Value function loss: 33.4506
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -50.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 453600
                    Iteration time: 3.93s
                        Total time: 240.05s
                               ETA: 7384.5s
################################################################################
                      [1m Learning iteration 63/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.146s, learning 0.664s)
               Value function loss: 30.5063
                    Surrogate loss: -0.0029
             Mean action noise std: 0.98
                       Mean reward: -49.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 460800
                    Iteration time: 3.81s
                        Total time: 243.86s
                               ETA: 7380.7s
################################################################################
                      [1m Learning iteration 64/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.168s, learning 0.612s)
               Value function loss: 33.2652
                    Surrogate loss: -0.0063
             Mean action noise std: 0.98
                       Mean reward: -49.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 468000
                    Iteration time: 3.78s
                        Total time: 247.64s
                               ETA: 7376.0s
################################################################################
                      [1m Learning iteration 65/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.143s, learning 0.614s)
               Value function loss: 31.3134
                    Surrogate loss: -0.0074
             Mean action noise std: 0.98
                       Mean reward: -50.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 475200
                    Iteration time: 3.76s
                        Total time: 251.40s
                               ETA: 7370.7s
################################################################################
                      [1m Learning iteration 66/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.185s, learning 0.607s)
               Value function loss: 35.0529
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 482400
                    Iteration time: 3.79s
                        Total time: 255.19s
                               ETA: 7366.4s
################################################################################
                      [1m Learning iteration 67/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.175s, learning 0.644s)
               Value function loss: 30.9591
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -50.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 489600
                    Iteration time: 3.82s
                        Total time: 259.01s
                               ETA: 7362.8s
################################################################################
                      [1m Learning iteration 68/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.115s, learning 0.631s)
               Value function loss: 31.7109
                    Surrogate loss: -0.0084
             Mean action noise std: 0.98
                       Mean reward: -49.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 496800
                    Iteration time: 3.75s
                        Total time: 262.76s
                               ETA: 7357.3s
################################################################################
                      [1m Learning iteration 69/2000 [0m                      

                       Computation: 1862 steps/s (collection: 3.196s, learning 0.670s)
               Value function loss: 29.9669
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 504000
                    Iteration time: 3.87s
                        Total time: 266.63s
                               ETA: 7355.1s
################################################################################
                      [1m Learning iteration 70/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.147s, learning 0.658s)
               Value function loss: 30.2034
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 511200
                    Iteration time: 3.81s
                        Total time: 270.43s
                               ETA: 7351.2s
################################################################################
                      [1m Learning iteration 71/2000 [0m                      

                       Computation: 1852 steps/s (collection: 3.107s, learning 0.781s)
               Value function loss: 32.5000
                    Surrogate loss: -0.0026
             Mean action noise std: 0.98
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 518400
                    Iteration time: 3.89s
                        Total time: 274.32s
                               ETA: 7349.5s
################################################################################
                      [1m Learning iteration 72/2000 [0m                      

                       Computation: 1820 steps/s (collection: 3.168s, learning 0.788s)
               Value function loss: 34.1269
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 525600
                    Iteration time: 3.96s
                        Total time: 278.27s
                               ETA: 7349.5s
################################################################################
                      [1m Learning iteration 73/2000 [0m                      

                       Computation: 1817 steps/s (collection: 3.087s, learning 0.874s)
               Value function loss: 31.0529
                    Surrogate loss: -0.0057
             Mean action noise std: 0.98
                       Mean reward: -50.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 532800
                    Iteration time: 3.96s
                        Total time: 282.24s
                               ETA: 7349.6s
################################################################################
                      [1m Learning iteration 74/2000 [0m                      

                       Computation: 1775 steps/s (collection: 3.129s, learning 0.927s)
               Value function loss: 28.5101
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -49.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 540000
                    Iteration time: 4.06s
                        Total time: 286.29s
                               ETA: 7352.0s
################################################################################
                      [1m Learning iteration 75/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.140s, learning 0.744s)
               Value function loss: 32.0992
                    Surrogate loss: -0.0059
             Mean action noise std: 0.98
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 547200
                    Iteration time: 3.88s
                        Total time: 290.18s
                               ETA: 7349.9s
################################################################################
                      [1m Learning iteration 76/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.153s, learning 0.781s)
               Value function loss: 31.4500
                    Surrogate loss: -0.0063
             Mean action noise std: 0.98
                       Mean reward: -49.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 554400
                    Iteration time: 3.93s
                        Total time: 294.11s
                               ETA: 7349.0s
################################################################################
                      [1m Learning iteration 77/2000 [0m                      

                       Computation: 1809 steps/s (collection: 3.095s, learning 0.884s)
               Value function loss: 30.3769
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 561600
                    Iteration time: 3.98s
                        Total time: 298.09s
                               ETA: 7349.1s
################################################################################
                      [1m Learning iteration 78/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.122s, learning 0.745s)
               Value function loss: 32.6787
                    Surrogate loss: -0.0048
             Mean action noise std: 0.98
                       Mean reward: -49.25
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 568800
                    Iteration time: 3.87s
                        Total time: 301.96s
                               ETA: 7346.3s
################################################################################
                      [1m Learning iteration 79/2000 [0m                      

                       Computation: 1827 steps/s (collection: 3.119s, learning 0.821s)
               Value function loss: 29.4594
                    Surrogate loss: -0.0066
             Mean action noise std: 0.98
                       Mean reward: -49.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 576000
                    Iteration time: 3.94s
                        Total time: 305.90s
                               ETA: 7345.3s
################################################################################
                      [1m Learning iteration 80/2000 [0m                      

                       Computation: 1894 steps/s (collection: 3.177s, learning 0.624s)
               Value function loss: 31.4366
                    Surrogate loss: -0.0033
             Mean action noise std: 0.98
                       Mean reward: -50.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 583200
                    Iteration time: 3.80s
                        Total time: 309.70s
                               ETA: 7341.0s
################################################################################
                      [1m Learning iteration 81/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.225s, learning 0.623s)
               Value function loss: 31.4435
                    Surrogate loss: 0.0025
             Mean action noise std: 0.97
                       Mean reward: -50.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 590400
                    Iteration time: 3.85s
                        Total time: 313.55s
                               ETA: 7337.7s
################################################################################
                      [1m Learning iteration 82/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.120s, learning 0.752s)
               Value function loss: 27.2720
                    Surrogate loss: -0.0026
             Mean action noise std: 0.97
                       Mean reward: -50.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 597600
                    Iteration time: 3.87s
                        Total time: 317.42s
                               ETA: 7335.0s
################################################################################
                      [1m Learning iteration 83/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.084s, learning 0.744s)
               Value function loss: 24.7333
                    Surrogate loss: 0.0035
             Mean action noise std: 0.97
                       Mean reward: -50.28
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 604800
                    Iteration time: 3.83s
                        Total time: 321.24s
                               ETA: 7331.2s
################################################################################
                      [1m Learning iteration 84/2000 [0m                      

                       Computation: 1893 steps/s (collection: 3.124s, learning 0.679s)
               Value function loss: 30.4519
                    Surrogate loss: -0.0006
             Mean action noise std: 0.97
                       Mean reward: -49.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 612000
                    Iteration time: 3.80s
                        Total time: 325.05s
                               ETA: 7326.9s
################################################################################
                      [1m Learning iteration 85/2000 [0m                      

                       Computation: 1849 steps/s (collection: 3.268s, learning 0.625s)
               Value function loss: 27.7287
                    Surrogate loss: 0.0006
             Mean action noise std: 0.97
                       Mean reward: -49.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 619200
                    Iteration time: 3.89s
                        Total time: 328.94s
                               ETA: 7324.7s
################################################################################
                      [1m Learning iteration 86/2000 [0m                      

                       Computation: 1837 steps/s (collection: 3.229s, learning 0.689s)
               Value function loss: 24.4723
                    Surrogate loss: -0.0016
             Mean action noise std: 0.97
                       Mean reward: -49.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 626400
                    Iteration time: 3.92s
                        Total time: 332.86s
                               ETA: 7322.9s
################################################################################
                      [1m Learning iteration 87/2000 [0m                      

                       Computation: 1862 steps/s (collection: 3.172s, learning 0.693s)
               Value function loss: 32.0193
                    Surrogate loss: -0.0001
             Mean action noise std: 0.97
                       Mean reward: -48.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 633600
                    Iteration time: 3.87s
                        Total time: 336.72s
                               ETA: 7319.9s
################################################################################
                      [1m Learning iteration 88/2000 [0m                      

                       Computation: 1895 steps/s (collection: 3.191s, learning 0.607s)
               Value function loss: 28.3677
                    Surrogate loss: -0.0040
             Mean action noise std: 0.97
                       Mean reward: -49.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 640800
                    Iteration time: 3.80s
                        Total time: 340.52s
                               ETA: 7315.5s
################################################################################
                      [1m Learning iteration 89/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.142s, learning 0.707s)
               Value function loss: 29.8453
                    Surrogate loss: -0.0028
             Mean action noise std: 0.97
                       Mean reward: -50.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 648000
                    Iteration time: 3.85s
                        Total time: 344.37s
                               ETA: 7312.1s
################################################################################
                      [1m Learning iteration 90/2000 [0m                      

                       Computation: 1933 steps/s (collection: 3.101s, learning 0.622s)
               Value function loss: 25.7069
                    Surrogate loss: -0.0019
             Mean action noise std: 0.97
                       Mean reward: -49.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 655200
                    Iteration time: 3.72s
                        Total time: 348.09s
                               ETA: 7306.1s
################################################################################
                      [1m Learning iteration 91/2000 [0m                      

                       Computation: 1899 steps/s (collection: 3.091s, learning 0.699s)
               Value function loss: 28.5759
                    Surrogate loss: -0.0049
             Mean action noise std: 0.97
                       Mean reward: -49.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 662400
                    Iteration time: 3.79s
                        Total time: 351.88s
                               ETA: 7301.6s
################################################################################
                      [1m Learning iteration 92/2000 [0m                      

                       Computation: 1932 steps/s (collection: 3.113s, learning 0.612s)
               Value function loss: 25.1321
                    Surrogate loss: -0.0003
             Mean action noise std: 0.97
                       Mean reward: -50.02
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 669600
                    Iteration time: 3.72s
                        Total time: 355.61s
                               ETA: 7295.7s
################################################################################
                      [1m Learning iteration 93/2000 [0m                      

                       Computation: 1863 steps/s (collection: 3.182s, learning 0.683s)
               Value function loss: 26.4642
                    Surrogate loss: -0.0053
             Mean action noise std: 0.97
                       Mean reward: -49.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 676800
                    Iteration time: 3.86s
                        Total time: 359.47s
                               ETA: 7292.7s
################################################################################
                      [1m Learning iteration 94/2000 [0m                      

                       Computation: 1928 steps/s (collection: 3.100s, learning 0.633s)
               Value function loss: 26.6313
                    Surrogate loss: -0.0059
             Mean action noise std: 0.97
                       Mean reward: -48.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 684000
                    Iteration time: 3.73s
                        Total time: 363.21s
                               ETA: 7287.1s
################################################################################
                      [1m Learning iteration 95/2000 [0m                      

                       Computation: 1840 steps/s (collection: 3.149s, learning 0.763s)
               Value function loss: 25.3491
                    Surrogate loss: 0.0016
             Mean action noise std: 0.97
                       Mean reward: -49.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 691200
                    Iteration time: 3.91s
                        Total time: 367.12s
                               ETA: 7285.0s
################################################################################
                      [1m Learning iteration 96/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.100s, learning 0.771s)
               Value function loss: 28.1155
                    Surrogate loss: 0.0093
             Mean action noise std: 0.98
                       Mean reward: -49.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 698400
                    Iteration time: 3.87s
                        Total time: 370.99s
                               ETA: 7282.1s
################################################################################
                      [1m Learning iteration 97/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.107s, learning 0.719s)
               Value function loss: 23.7082
                    Surrogate loss: -0.0052
             Mean action noise std: 0.98
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 705600
                    Iteration time: 3.83s
                        Total time: 374.82s
                               ETA: 7278.3s
################################################################################
                      [1m Learning iteration 98/2000 [0m                      

                       Computation: 1897 steps/s (collection: 3.145s, learning 0.649s)
               Value function loss: 26.0409
                    Surrogate loss: -0.0017
             Mean action noise std: 0.98
                       Mean reward: -49.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 712800
                    Iteration time: 3.79s
                        Total time: 378.61s
                               ETA: 7273.9s
################################################################################
                      [1m Learning iteration 99/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.098s, learning 0.623s)
               Value function loss: 27.1381
                    Surrogate loss: 0.0020
             Mean action noise std: 0.98
                       Mean reward: -49.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 720000
                    Iteration time: 3.72s
                        Total time: 382.33s
                               ETA: 7268.1s
################################################################################
                     [1m Learning iteration 100/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.180s, learning 0.638s)
               Value function loss: 26.2942
                    Surrogate loss: -0.0006
             Mean action noise std: 0.98
                       Mean reward: -49.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 727200
                    Iteration time: 3.82s
                        Total time: 386.15s
                               ETA: 7264.2s
################################################################################
                     [1m Learning iteration 101/2000 [0m                      

                       Computation: 1934 steps/s (collection: 3.116s, learning 0.606s)
               Value function loss: 28.5187
                    Surrogate loss: 0.0052
             Mean action noise std: 0.98
                       Mean reward: -48.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 734400
                    Iteration time: 3.72s
                        Total time: 389.87s
                               ETA: 7258.5s
################################################################################
                     [1m Learning iteration 102/2000 [0m                      

                       Computation: 1862 steps/s (collection: 3.124s, learning 0.741s)
               Value function loss: 27.8748
                    Surrogate loss: 0.0123
             Mean action noise std: 0.98
                       Mean reward: -48.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 741600
                    Iteration time: 3.87s
                        Total time: 393.74s
                               ETA: 7255.4s
################################################################################
                     [1m Learning iteration 103/2000 [0m                      

                       Computation: 1925 steps/s (collection: 3.126s, learning 0.613s)
               Value function loss: 25.6303
                    Surrogate loss: -0.0047
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 748800
                    Iteration time: 3.74s
                        Total time: 397.47s
                               ETA: 7250.1s
################################################################################
                     [1m Learning iteration 104/2000 [0m                      

                       Computation: 1901 steps/s (collection: 3.144s, learning 0.643s)
               Value function loss: 26.0222
                    Surrogate loss: -0.0057
             Mean action noise std: 0.98
                       Mean reward: -48.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 756000
                    Iteration time: 3.79s
                        Total time: 401.26s
                               ETA: 7245.6s
################################################################################
                     [1m Learning iteration 105/2000 [0m                      

                       Computation: 1842 steps/s (collection: 3.282s, learning 0.625s)
               Value function loss: 23.4744
                    Surrogate loss: -0.0027
             Mean action noise std: 0.98
                       Mean reward: -48.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 763200
                    Iteration time: 3.91s
                        Total time: 405.17s
                               ETA: 7243.3s
################################################################################
                     [1m Learning iteration 106/2000 [0m                      

                       Computation: 1897 steps/s (collection: 3.181s, learning 0.614s)
               Value function loss: 24.8079
                    Surrogate loss: 0.0012
             Mean action noise std: 0.98
                       Mean reward: -49.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 770400
                    Iteration time: 3.80s
                        Total time: 408.96s
                               ETA: 7239.0s
################################################################################
                     [1m Learning iteration 107/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.226s, learning 0.673s)
               Value function loss: 24.6536
                    Surrogate loss: -0.0047
             Mean action noise std: 0.98
                       Mean reward: -49.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 777600
                    Iteration time: 3.90s
                        Total time: 412.86s
                               ETA: 7236.6s
################################################################################
                     [1m Learning iteration 108/2000 [0m                      

                       Computation: 1909 steps/s (collection: 3.125s, learning 0.646s)
               Value function loss: 23.5256
                    Surrogate loss: -0.0065
             Mean action noise std: 0.98
                       Mean reward: -49.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 784800
                    Iteration time: 3.77s
                        Total time: 416.63s
                               ETA: 7231.8s
################################################################################
                     [1m Learning iteration 109/2000 [0m                      

                       Computation: 1868 steps/s (collection: 3.140s, learning 0.713s)
               Value function loss: 26.3820
                    Surrogate loss: -0.0037
             Mean action noise std: 0.98
                       Mean reward: -49.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 792000
                    Iteration time: 3.85s
                        Total time: 420.49s
                               ETA: 7228.5s
################################################################################
                     [1m Learning iteration 110/2000 [0m                      

                       Computation: 1897 steps/s (collection: 3.096s, learning 0.699s)
               Value function loss: 25.5668
                    Surrogate loss: -0.0080
             Mean action noise std: 0.98
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 799200
                    Iteration time: 3.80s
                        Total time: 424.28s
                               ETA: 7224.2s
################################################################################
                     [1m Learning iteration 111/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.088s, learning 0.662s)
               Value function loss: 26.6566
                    Surrogate loss: -0.0052
             Mean action noise std: 0.98
                       Mean reward: -48.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 806400
                    Iteration time: 3.75s
                        Total time: 428.03s
                               ETA: 7219.2s
################################################################################
                     [1m Learning iteration 112/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.161s, learning 0.620s)
               Value function loss: 27.0673
                    Surrogate loss: -0.0049
             Mean action noise std: 0.98
                       Mean reward: -49.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.17
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 813600
                    Iteration time: 3.78s
                        Total time: 431.81s
                               ETA: 7214.7s
################################################################################
                     [1m Learning iteration 113/2000 [0m                      

                       Computation: 1924 steps/s (collection: 3.117s, learning 0.624s)
               Value function loss: 24.0829
                    Surrogate loss: -0.0058
             Mean action noise std: 0.98
                       Mean reward: -50.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 820800
                    Iteration time: 3.74s
                        Total time: 435.55s
                               ETA: 7209.6s
################################################################################
                     [1m Learning iteration 114/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.198s, learning 0.651s)
               Value function loss: 23.7772
                    Surrogate loss: -0.0040
             Mean action noise std: 0.98
                       Mean reward: -50.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 828000
                    Iteration time: 3.85s
                        Total time: 439.40s
                               ETA: 7206.2s
################################################################################
                     [1m Learning iteration 115/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.104s, learning 0.689s)
               Value function loss: 24.7225
                    Surrogate loss: -0.0034
             Mean action noise std: 0.98
                       Mean reward: -50.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 835200
                    Iteration time: 3.79s
                        Total time: 443.20s
                               ETA: 7201.9s
################################################################################
                     [1m Learning iteration 116/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.104s, learning 0.712s)
               Value function loss: 27.2398
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -50.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 842400
                    Iteration time: 3.82s
                        Total time: 447.01s
                               ETA: 7198.0s
################################################################################
                     [1m Learning iteration 117/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.107s, learning 0.740s)
               Value function loss: 24.7676
                    Surrogate loss: -0.0052
             Mean action noise std: 0.98
                       Mean reward: -49.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 849600
                    Iteration time: 3.85s
                        Total time: 450.86s
                               ETA: 7194.6s
################################################################################
                     [1m Learning iteration 118/2000 [0m                      

                       Computation: 1917 steps/s (collection: 3.127s, learning 0.628s)
               Value function loss: 23.6692
                    Surrogate loss: -0.0036
             Mean action noise std: 0.98
                       Mean reward: -49.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 856800
                    Iteration time: 3.76s
                        Total time: 454.61s
                               ETA: 7189.8s
################################################################################
                     [1m Learning iteration 119/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.205s, learning 0.686s)
               Value function loss: 26.7770
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 864000
                    Iteration time: 3.89s
                        Total time: 458.50s
                               ETA: 7187.1s
################################################################################
                     [1m Learning iteration 120/2000 [0m                      

                       Computation: 1918 steps/s (collection: 3.124s, learning 0.628s)
               Value function loss: 25.6117
                    Surrogate loss: -0.0023
             Mean action noise std: 0.98
                       Mean reward: -49.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 871200
                    Iteration time: 3.75s
                        Total time: 462.26s
                               ETA: 7182.2s
################################################################################
                     [1m Learning iteration 121/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.137s, learning 0.696s)
               Value function loss: 24.0778
                    Surrogate loss: -0.0024
             Mean action noise std: 0.98
                       Mean reward: -49.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 878400
                    Iteration time: 3.83s
                        Total time: 466.09s
                               ETA: 7178.5s
################################################################################
                     [1m Learning iteration 122/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.157s, learning 0.648s)
               Value function loss: 26.9927
                    Surrogate loss: -0.0057
             Mean action noise std: 0.98
                       Mean reward: -49.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 885600
                    Iteration time: 3.80s
                        Total time: 469.89s
                               ETA: 7174.5s
################################################################################
                     [1m Learning iteration 123/2000 [0m                      

                       Computation: 1915 steps/s (collection: 3.108s, learning 0.652s)
               Value function loss: 26.7252
                    Surrogate loss: -0.0059
             Mean action noise std: 0.98
                       Mean reward: -49.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 892800
                    Iteration time: 3.76s
                        Total time: 473.65s
                               ETA: 7169.7s
################################################################################
                     [1m Learning iteration 124/2000 [0m                      

                       Computation: 1849 steps/s (collection: 3.154s, learning 0.738s)
               Value function loss: 27.0006
                    Surrogate loss: -0.0048
             Mean action noise std: 0.98
                       Mean reward: -49.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 900000
                    Iteration time: 3.89s
                        Total time: 477.55s
                               ETA: 7167.0s
################################################################################
                     [1m Learning iteration 125/2000 [0m                      

                       Computation: 1922 steps/s (collection: 3.123s, learning 0.621s)
               Value function loss: 27.6821
                    Surrogate loss: -0.0002
             Mean action noise std: 0.98
                       Mean reward: -49.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 907200
                    Iteration time: 3.74s
                        Total time: 481.29s
                               ETA: 7162.1s
################################################################################
                     [1m Learning iteration 126/2000 [0m                      

                       Computation: 1864 steps/s (collection: 3.224s, learning 0.639s)
               Value function loss: 25.2490
                    Surrogate loss: -0.0013
             Mean action noise std: 0.98
                       Mean reward: -49.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 914400
                    Iteration time: 3.86s
                        Total time: 485.15s
                               ETA: 7158.9s
################################################################################
                     [1m Learning iteration 127/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.095s, learning 0.654s)
               Value function loss: 23.9829
                    Surrogate loss: -0.0044
             Mean action noise std: 0.98
                       Mean reward: -50.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 921600
                    Iteration time: 3.75s
                        Total time: 488.90s
                               ETA: 7154.0s
################################################################################
                     [1m Learning iteration 128/2000 [0m                      

                       Computation: 1865 steps/s (collection: 3.184s, learning 0.677s)
               Value function loss: 26.1981
                    Surrogate loss: 0.0020
             Mean action noise std: 0.98
                       Mean reward: -49.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 928800
                    Iteration time: 3.86s
                        Total time: 492.76s
                               ETA: 7150.8s
################################################################################
                     [1m Learning iteration 129/2000 [0m                      

                       Computation: 1917 steps/s (collection: 3.148s, learning 0.607s)
               Value function loss: 24.2423
                    Surrogate loss: 0.0080
             Mean action noise std: 0.98
                       Mean reward: -49.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 936000
                    Iteration time: 3.76s
                        Total time: 496.52s
                               ETA: 7146.0s
################################################################################
                     [1m Learning iteration 130/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.121s, learning 0.625s)
               Value function loss: 24.1949
                    Surrogate loss: 0.0060
             Mean action noise std: 0.98
                       Mean reward: -50.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 943200
                    Iteration time: 3.75s
                        Total time: 500.26s
                               ETA: 7141.2s
################################################################################
                     [1m Learning iteration 131/2000 [0m                      

                       Computation: 1875 steps/s (collection: 3.152s, learning 0.687s)
               Value function loss: 25.2905
                    Surrogate loss: -0.0003
             Mean action noise std: 0.99
                       Mean reward: -49.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 950400
                    Iteration time: 3.84s
                        Total time: 504.10s
                               ETA: 7137.6s
################################################################################
                     [1m Learning iteration 132/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.117s, learning 0.703s)
               Value function loss: 26.7670
                    Surrogate loss: -0.0029
             Mean action noise std: 0.98
                       Mean reward: -49.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 957600
                    Iteration time: 3.82s
                        Total time: 507.92s
                               ETA: 7133.8s
################################################################################
                     [1m Learning iteration 133/2000 [0m                      

                       Computation: 1817 steps/s (collection: 3.279s, learning 0.681s)
               Value function loss: 28.2369
                    Surrogate loss: -0.0070
             Mean action noise std: 0.98
                       Mean reward: -50.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 964800
                    Iteration time: 3.96s
                        Total time: 511.88s
                               ETA: 7132.0s
################################################################################
                     [1m Learning iteration 134/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.072s, learning 0.671s)
               Value function loss: 24.7809
                    Surrogate loss: -0.0086
             Mean action noise std: 0.98
                       Mean reward: -50.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 972000
                    Iteration time: 3.74s
                        Total time: 515.62s
                               ETA: 7127.1s
################################################################################
                     [1m Learning iteration 135/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.137s, learning 0.660s)
               Value function loss: 26.0732
                    Surrogate loss: 0.0021
             Mean action noise std: 0.98
                       Mean reward: -49.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 979200
                    Iteration time: 3.80s
                        Total time: 519.42s
                               ETA: 7123.0s
################################################################################
                     [1m Learning iteration 136/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.144s, learning 0.637s)
               Value function loss: 25.9407
                    Surrogate loss: -0.0010
             Mean action noise std: 0.98
                       Mean reward: -49.14
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 986400
                    Iteration time: 3.78s
                        Total time: 523.20s
                               ETA: 7118.6s
################################################################################
                     [1m Learning iteration 137/2000 [0m                      

                       Computation: 1890 steps/s (collection: 3.149s, learning 0.659s)
               Value function loss: 25.3057
                    Surrogate loss: -0.0069
             Mean action noise std: 0.98
                       Mean reward: -49.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 993600
                    Iteration time: 3.81s
                        Total time: 527.01s
                               ETA: 7114.6s
################################################################################
                     [1m Learning iteration 138/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.168s, learning 0.749s)
               Value function loss: 21.5821
                    Surrogate loss: -0.0022
             Mean action noise std: 0.98
                       Mean reward: -49.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1000800
                    Iteration time: 3.92s
                        Total time: 530.93s
                               ETA: 7112.1s
################################################################################
                     [1m Learning iteration 139/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.044s, learning 0.846s)
               Value function loss: 25.2801
                    Surrogate loss: -0.0004
             Mean action noise std: 0.98
                       Mean reward: -48.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1008000
                    Iteration time: 3.89s
                        Total time: 534.82s
                               ETA: 7109.3s
################################################################################
                     [1m Learning iteration 140/2000 [0m                      

                       Computation: 1823 steps/s (collection: 3.211s, learning 0.738s)
               Value function loss: 24.5242
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -48.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1015200
                    Iteration time: 3.95s
                        Total time: 538.77s
                               ETA: 7107.1s
################################################################################
                     [1m Learning iteration 141/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.142s, learning 0.678s)
               Value function loss: 24.3534
                    Surrogate loss: -0.0042
             Mean action noise std: 0.98
                       Mean reward: -49.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1022400
                    Iteration time: 3.82s
                        Total time: 542.59s
                               ETA: 7103.3s
################################################################################
                     [1m Learning iteration 142/2000 [0m                      

                       Computation: 1843 steps/s (collection: 3.156s, learning 0.750s)
               Value function loss: 23.2714
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -49.57
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1029600
                    Iteration time: 3.91s
                        Total time: 546.49s
                               ETA: 7100.6s
################################################################################
                     [1m Learning iteration 143/2000 [0m                      

                       Computation: 1854 steps/s (collection: 3.131s, learning 0.751s)
               Value function loss: 20.0844
                    Surrogate loss: -0.0080
             Mean action noise std: 0.98
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1036800
                    Iteration time: 3.88s
                        Total time: 550.38s
                               ETA: 7097.6s
################################################################################
                     [1m Learning iteration 144/2000 [0m                      

                       Computation: 1851 steps/s (collection: 3.140s, learning 0.750s)
               Value function loss: 25.0813
                    Surrogate loss: 0.0005
             Mean action noise std: 0.98
                       Mean reward: -48.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1044000
                    Iteration time: 3.89s
                        Total time: 554.27s
                               ETA: 7094.6s
################################################################################
                     [1m Learning iteration 145/2000 [0m                      

                       Computation: 1795 steps/s (collection: 3.244s, learning 0.766s)
               Value function loss: 26.3893
                    Surrogate loss: -0.0056
             Mean action noise std: 0.98
                       Mean reward: -49.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1051200
                    Iteration time: 4.01s
                        Total time: 558.27s
                               ETA: 7093.1s
################################################################################
                     [1m Learning iteration 146/2000 [0m                      

                       Computation: 1795 steps/s (collection: 3.168s, learning 0.843s)
               Value function loss: 27.5452
                    Surrogate loss: -0.0001
             Mean action noise std: 0.98
                       Mean reward: -48.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1058400
                    Iteration time: 4.01s
                        Total time: 562.29s
                               ETA: 7091.7s
################################################################################
                     [1m Learning iteration 147/2000 [0m                      

                       Computation: 1826 steps/s (collection: 3.154s, learning 0.787s)
               Value function loss: 25.5431
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -48.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1065600
                    Iteration time: 3.94s
                        Total time: 566.23s
                               ETA: 7089.3s
################################################################################
                     [1m Learning iteration 148/2000 [0m                      

                       Computation: 1842 steps/s (collection: 3.159s, learning 0.749s)
               Value function loss: 27.0503
                    Surrogate loss: 0.0057
             Mean action noise std: 0.98
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1072800
                    Iteration time: 3.91s
                        Total time: 570.14s
                               ETA: 7086.5s
################################################################################
                     [1m Learning iteration 149/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.108s, learning 0.777s)
               Value function loss: 25.9118
                    Surrogate loss: -0.0055
             Mean action noise std: 0.98
                       Mean reward: -50.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1080000
                    Iteration time: 3.89s
                        Total time: 574.02s
                               ETA: 7083.4s
################################################################################
                     [1m Learning iteration 150/2000 [0m                      

                       Computation: 1819 steps/s (collection: 3.185s, learning 0.772s)
               Value function loss: 24.2447
                    Surrogate loss: -0.0069
             Mean action noise std: 0.98
                       Mean reward: -49.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1087200
                    Iteration time: 3.96s
                        Total time: 577.98s
                               ETA: 7081.2s
################################################################################
                     [1m Learning iteration 151/2000 [0m                      

                       Computation: 1932 steps/s (collection: 3.115s, learning 0.611s)
               Value function loss: 26.4226
                    Surrogate loss: 0.0092
             Mean action noise std: 0.98
                       Mean reward: -49.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1094400
                    Iteration time: 3.73s
                        Total time: 581.70s
                               ETA: 7076.1s
################################################################################
                     [1m Learning iteration 152/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.164s, learning 0.674s)
               Value function loss: 22.4295
                    Surrogate loss: 0.0011
             Mean action noise std: 0.98
                       Mean reward: -49.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1101600
                    Iteration time: 3.84s
                        Total time: 585.54s
                               ETA: 7072.4s
################################################################################
                     [1m Learning iteration 153/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.111s, learning 0.617s)
               Value function loss: 23.1539
                    Surrogate loss: -0.0036
             Mean action noise std: 0.98
                       Mean reward: -49.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1108800
                    Iteration time: 3.73s
                        Total time: 589.27s
                               ETA: 7067.4s
################################################################################
                     [1m Learning iteration 154/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.096s, learning 0.632s)
               Value function loss: 27.7175
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -49.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1116000
                    Iteration time: 3.73s
                        Total time: 593.00s
                               ETA: 7062.4s
################################################################################
                     [1m Learning iteration 155/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.181s, learning 0.637s)
               Value function loss: 24.1345
                    Surrogate loss: -0.0072
             Mean action noise std: 0.98
                       Mean reward: -49.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1123200
                    Iteration time: 3.82s
                        Total time: 596.82s
                               ETA: 7058.5s
################################################################################
                     [1m Learning iteration 156/2000 [0m                      

                       Computation: 1941 steps/s (collection: 3.080s, learning 0.629s)
               Value function loss: 22.0083
                    Surrogate loss: -0.0025
             Mean action noise std: 0.98
                       Mean reward: -50.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1130400
                    Iteration time: 3.71s
                        Total time: 600.52s
                               ETA: 7053.3s
################################################################################
                     [1m Learning iteration 157/2000 [0m                      

                       Computation: 1912 steps/s (collection: 3.131s, learning 0.634s)
               Value function loss: 23.9514
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -49.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1137600
                    Iteration time: 3.77s
                        Total time: 604.29s
                               ETA: 7048.8s
################################################################################
                     [1m Learning iteration 158/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.112s, learning 0.616s)
               Value function loss: 25.4504
                    Surrogate loss: 0.0003
             Mean action noise std: 0.98
                       Mean reward: -49.33
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1144800
                    Iteration time: 3.73s
                        Total time: 608.02s
                               ETA: 7043.8s
################################################################################
                     [1m Learning iteration 159/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.201s, learning 0.636s)
               Value function loss: 27.5835
                    Surrogate loss: -0.0025
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1152000
                    Iteration time: 3.84s
                        Total time: 611.85s
                               ETA: 7040.1s
################################################################################
                     [1m Learning iteration 160/2000 [0m                      

                       Computation: 1930 steps/s (collection: 3.115s, learning 0.615s)
               Value function loss: 23.5132
                    Surrogate loss: 0.0008
             Mean action noise std: 0.98
                       Mean reward: -48.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1159200
                    Iteration time: 3.73s
                        Total time: 615.58s
                               ETA: 7035.2s
################################################################################
                     [1m Learning iteration 161/2000 [0m                      

                       Computation: 1894 steps/s (collection: 3.123s, learning 0.678s)
               Value function loss: 22.6475
                    Surrogate loss: 0.0022
             Mean action noise std: 0.98
                       Mean reward: -48.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1166400
                    Iteration time: 3.80s
                        Total time: 619.39s
                               ETA: 7031.2s
################################################################################
                     [1m Learning iteration 162/2000 [0m                      

                       Computation: 1909 steps/s (collection: 3.131s, learning 0.639s)
               Value function loss: 24.6285
                    Surrogate loss: -0.0047
             Mean action noise std: 0.99
                       Mean reward: -48.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1173600
                    Iteration time: 3.77s
                        Total time: 623.16s
                               ETA: 7026.7s
################################################################################
                     [1m Learning iteration 163/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.112s, learning 0.617s)
               Value function loss: 23.4110
                    Surrogate loss: -0.0028
             Mean action noise std: 0.98
                       Mean reward: -49.06
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1180800
                    Iteration time: 3.73s
                        Total time: 626.88s
                               ETA: 7021.9s
################################################################################
                     [1m Learning iteration 164/2000 [0m                      

                       Computation: 1911 steps/s (collection: 3.148s, learning 0.618s)
               Value function loss: 23.4650
                    Surrogate loss: 0.0057
             Mean action noise std: 0.99
                       Mean reward: -49.02
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1188000
                    Iteration time: 3.77s
                        Total time: 630.65s
                               ETA: 7017.4s
################################################################################
                     [1m Learning iteration 165/2000 [0m                      

                       Computation: 1934 steps/s (collection: 3.108s, learning 0.614s)
               Value function loss: 22.0317
                    Surrogate loss: -0.0012
             Mean action noise std: 0.99
                       Mean reward: -48.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1195200
                    Iteration time: 3.72s
                        Total time: 634.37s
                               ETA: 7012.5s
################################################################################
                     [1m Learning iteration 166/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.190s, learning 0.638s)
               Value function loss: 27.3392
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -48.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1202400
                    Iteration time: 3.83s
                        Total time: 638.20s
                               ETA: 7008.7s
################################################################################
                     [1m Learning iteration 167/2000 [0m                      

                       Computation: 1932 steps/s (collection: 3.119s, learning 0.608s)
               Value function loss: 27.9535
                    Surrogate loss: -0.0048
             Mean action noise std: 0.99
                       Mean reward: -49.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1209600
                    Iteration time: 3.73s
                        Total time: 641.93s
                               ETA: 7003.9s
################################################################################
                     [1m Learning iteration 168/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.127s, learning 0.677s)
               Value function loss: 25.2779
                    Surrogate loss: -0.0063
             Mean action noise std: 0.99
                       Mean reward: -49.12
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1216800
                    Iteration time: 3.80s
                        Total time: 645.73s
                               ETA: 6999.9s
################################################################################
                     [1m Learning iteration 169/2000 [0m                      

                       Computation: 1895 steps/s (collection: 3.114s, learning 0.685s)
               Value function loss: 25.4004
                    Surrogate loss: -0.0058
             Mean action noise std: 0.99
                       Mean reward: -49.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1224000
                    Iteration time: 3.80s
                        Total time: 649.53s
                               ETA: 6995.8s
################################################################################
                     [1m Learning iteration 170/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.137s, learning 0.619s)
               Value function loss: 23.0949
                    Surrogate loss: -0.0073
             Mean action noise std: 0.99
                       Mean reward: -49.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1231200
                    Iteration time: 3.76s
                        Total time: 653.29s
                               ETA: 6991.3s
################################################################################
                     [1m Learning iteration 171/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.142s, learning 0.619s)
               Value function loss: 21.6251
                    Surrogate loss: -0.0053
             Mean action noise std: 0.99
                       Mean reward: -49.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1238400
                    Iteration time: 3.76s
                        Total time: 657.05s
                               ETA: 6986.9s
################################################################################
                     [1m Learning iteration 172/2000 [0m                      

                       Computation: 1912 steps/s (collection: 3.144s, learning 0.621s)
               Value function loss: 21.9461
                    Surrogate loss: -0.0035
             Mean action noise std: 0.99
                       Mean reward: -49.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1245600
                    Iteration time: 3.76s
                        Total time: 660.81s
                               ETA: 6982.4s
################################################################################
                     [1m Learning iteration 173/2000 [0m                      

                       Computation: 1867 steps/s (collection: 3.209s, learning 0.647s)
               Value function loss: 22.4251
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -48.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1252800
                    Iteration time: 3.86s
                        Total time: 664.67s
                               ETA: 6979.0s
################################################################################
                     [1m Learning iteration 174/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.061s, learning 0.685s)
               Value function loss: 23.9181
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -48.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1260000
                    Iteration time: 3.75s
                        Total time: 668.41s
                               ETA: 6974.4s
################################################################################
                     [1m Learning iteration 175/2000 [0m                      

                       Computation: 1856 steps/s (collection: 3.106s, learning 0.773s)
               Value function loss: 23.4596
                    Surrogate loss: -0.0062
             Mean action noise std: 0.99
                       Mean reward: -48.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1267200
                    Iteration time: 3.88s
                        Total time: 672.29s
                               ETA: 6971.2s
################################################################################
                     [1m Learning iteration 176/2000 [0m                      

                       Computation: 1778 steps/s (collection: 3.224s, learning 0.823s)
               Value function loss: 21.7822
                    Surrogate loss: -0.0063
             Mean action noise std: 0.99
                       Mean reward: -49.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1274400
                    Iteration time: 4.05s
                        Total time: 676.34s
                               ETA: 6969.7s
################################################################################
                     [1m Learning iteration 177/2000 [0m                      

                       Computation: 1907 steps/s (collection: 3.176s, learning 0.599s)
               Value function loss: 25.5504
                    Surrogate loss: -0.0018
             Mean action noise std: 0.99
                       Mean reward: -49.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1281600
                    Iteration time: 3.77s
                        Total time: 680.11s
                               ETA: 6965.4s
################################################################################
                     [1m Learning iteration 178/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.201s, learning 0.613s)
               Value function loss: 24.1356
                    Surrogate loss: -0.0032
             Mean action noise std: 0.99
                       Mean reward: -49.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1288800
                    Iteration time: 3.81s
                        Total time: 683.93s
                               ETA: 6961.5s
################################################################################
                     [1m Learning iteration 179/2000 [0m                      

                       Computation: 1908 steps/s (collection: 3.090s, learning 0.682s)
               Value function loss: 25.0832
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -49.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1296000
                    Iteration time: 3.77s
                        Total time: 687.70s
                               ETA: 6957.2s
################################################################################
                     [1m Learning iteration 180/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.173s, learning 0.634s)
               Value function loss: 24.8530
                    Surrogate loss: -0.0038
             Mean action noise std: 0.99
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1303200
                    Iteration time: 3.81s
                        Total time: 691.51s
                               ETA: 6953.3s
################################################################################
                     [1m Learning iteration 181/2000 [0m                      

                       Computation: 1864 steps/s (collection: 3.098s, learning 0.763s)
               Value function loss: 23.5585
                    Surrogate loss: 0.0131
             Mean action noise std: 0.99
                       Mean reward: -48.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1310400
                    Iteration time: 3.86s
                        Total time: 695.37s
                               ETA: 6949.8s
################################################################################
                     [1m Learning iteration 182/2000 [0m                      

                       Computation: 1842 steps/s (collection: 3.102s, learning 0.805s)
               Value function loss: 27.4653
                    Surrogate loss: -0.0031
             Mean action noise std: 0.99
                       Mean reward: -48.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1317600
                    Iteration time: 3.91s
                        Total time: 699.27s
                               ETA: 6946.9s
################################################################################
                     [1m Learning iteration 183/2000 [0m                      

                       Computation: 1843 steps/s (collection: 3.136s, learning 0.769s)
               Value function loss: 22.3123
                    Surrogate loss: -0.0042
             Mean action noise std: 0.99
                       Mean reward: -48.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1324800
                    Iteration time: 3.91s
                        Total time: 703.18s
                               ETA: 6943.9s
################################################################################
                     [1m Learning iteration 184/2000 [0m                      

                       Computation: 1860 steps/s (collection: 3.104s, learning 0.766s)
               Value function loss: 23.4091
                    Surrogate loss: -0.0063
             Mean action noise std: 0.99
                       Mean reward: -48.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1332000
                    Iteration time: 3.87s
                        Total time: 707.05s
                               ETA: 6940.5s
################################################################################
                     [1m Learning iteration 185/2000 [0m                      

                       Computation: 1825 steps/s (collection: 3.151s, learning 0.793s)
               Value function loss: 23.6082
                    Surrogate loss: -0.0072
             Mean action noise std: 1.00
                       Mean reward: -48.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1339200
                    Iteration time: 3.94s
                        Total time: 710.99s
                               ETA: 6937.9s
################################################################################
                     [1m Learning iteration 186/2000 [0m                      

                       Computation: 1875 steps/s (collection: 3.105s, learning 0.734s)
               Value function loss: 22.5121
                    Surrogate loss: -0.0058
             Mean action noise std: 1.00
                       Mean reward: -49.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1346400
                    Iteration time: 3.84s
                        Total time: 714.83s
                               ETA: 6934.3s
################################################################################
                     [1m Learning iteration 187/2000 [0m                      

                       Computation: 1849 steps/s (collection: 3.096s, learning 0.797s)
               Value function loss: 23.5580
                    Surrogate loss: -0.0047
             Mean action noise std: 1.00
                       Mean reward: -49.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1353600
                    Iteration time: 3.89s
                        Total time: 718.73s
                               ETA: 6931.1s
################################################################################
                     [1m Learning iteration 188/2000 [0m                      

                       Computation: 1847 steps/s (collection: 3.152s, learning 0.745s)
               Value function loss: 25.0229
                    Surrogate loss: -0.0059
             Mean action noise std: 1.00
                       Mean reward: -49.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1360800
                    Iteration time: 3.90s
                        Total time: 722.62s
                               ETA: 6928.0s
################################################################################
                     [1m Learning iteration 189/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.087s, learning 0.781s)
               Value function loss: 22.7439
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -49.57
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1368000
                    Iteration time: 3.87s
                        Total time: 726.49s
                               ETA: 6924.6s
################################################################################
                     [1m Learning iteration 190/2000 [0m                      

                       Computation: 1832 steps/s (collection: 3.153s, learning 0.776s)
               Value function loss: 22.4193
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -49.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1375200
                    Iteration time: 3.93s
                        Total time: 730.42s
                               ETA: 6921.8s
################################################################################
                     [1m Learning iteration 191/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.075s, learning 0.794s)
               Value function loss: 23.2602
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -49.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1382400
                    Iteration time: 3.87s
                        Total time: 734.29s
                               ETA: 6918.4s
################################################################################
                     [1m Learning iteration 192/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.136s, learning 0.714s)
               Value function loss: 22.3916
                    Surrogate loss: -0.0056
             Mean action noise std: 0.99
                       Mean reward: -49.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1389600
                    Iteration time: 3.85s
                        Total time: 738.14s
                               ETA: 6914.8s
################################################################################
                     [1m Learning iteration 193/2000 [0m                      

                       Computation: 1937 steps/s (collection: 3.102s, learning 0.615s)
               Value function loss: 24.1906
                    Surrogate loss: -0.0044
             Mean action noise std: 0.99
                       Mean reward: -50.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1396800
                    Iteration time: 3.72s
                        Total time: 741.86s
                               ETA: 6910.0s
################################################################################
                     [1m Learning iteration 194/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.107s, learning 0.612s)
               Value function loss: 23.0095
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -49.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1404000
                    Iteration time: 3.72s
                        Total time: 745.58s
                               ETA: 6905.2s
################################################################################
                     [1m Learning iteration 195/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.131s, learning 0.618s)
               Value function loss: 21.7467
                    Surrogate loss: -0.0061
             Mean action noise std: 0.99
                       Mean reward: -49.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1411200
                    Iteration time: 3.75s
                        Total time: 749.33s
                               ETA: 6900.7s
################################################################################
                     [1m Learning iteration 196/2000 [0m                      

                       Computation: 1936 steps/s (collection: 3.090s, learning 0.627s)
               Value function loss: 22.1022
                    Surrogate loss: -0.0065
             Mean action noise std: 0.99
                       Mean reward: -49.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1418400
                    Iteration time: 3.72s
                        Total time: 753.04s
                               ETA: 6895.9s
################################################################################
                     [1m Learning iteration 197/2000 [0m                      

                       Computation: 1907 steps/s (collection: 3.158s, learning 0.617s)
               Value function loss: 23.1021
                    Surrogate loss: -0.0013
             Mean action noise std: 0.99
                       Mean reward: -49.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1425600
                    Iteration time: 3.77s
                        Total time: 756.82s
                               ETA: 6891.6s
################################################################################
                     [1m Learning iteration 198/2000 [0m                      

                       Computation: 1909 steps/s (collection: 3.090s, learning 0.682s)
               Value function loss: 25.1243
                    Surrogate loss: 0.0016
             Mean action noise std: 0.99
                       Mean reward: -49.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1432800
                    Iteration time: 3.77s
                        Total time: 760.59s
                               ETA: 6887.3s
################################################################################
                     [1m Learning iteration 199/2000 [0m                      

                       Computation: 1860 steps/s (collection: 3.198s, learning 0.672s)
               Value function loss: 25.0668
                    Surrogate loss: -0.0001
             Mean action noise std: 0.99
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1440000
                    Iteration time: 3.87s
                        Total time: 764.46s
                               ETA: 6884.0s
################################################################################
                     [1m Learning iteration 200/2000 [0m                      

                       Computation: 1946 steps/s (collection: 3.059s, learning 0.640s)
               Value function loss: 21.4048
                    Surrogate loss: -0.0000
             Mean action noise std: 0.99
                       Mean reward: -49.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1447200
                    Iteration time: 3.70s
                        Total time: 768.16s
                               ETA: 6879.0s
################################################################################
                     [1m Learning iteration 201/2000 [0m                      

                       Computation: 1925 steps/s (collection: 3.038s, learning 0.700s)
               Value function loss: 21.6403
                    Surrogate loss: 0.0018
             Mean action noise std: 0.99
                       Mean reward: -49.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1454400
                    Iteration time: 3.74s
                        Total time: 771.90s
                               ETA: 6874.5s
################################################################################
                     [1m Learning iteration 202/2000 [0m                      

                       Computation: 1945 steps/s (collection: 3.078s, learning 0.622s)
               Value function loss: 22.4766
                    Surrogate loss: 0.0005
             Mean action noise std: 0.99
                       Mean reward: -50.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1461600
                    Iteration time: 3.70s
                        Total time: 775.60s
                               ETA: 6869.6s
################################################################################
                     [1m Learning iteration 203/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.103s, learning 0.635s)
               Value function loss: 25.6986
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -50.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1468800
                    Iteration time: 3.74s
                        Total time: 779.34s
                               ETA: 6865.0s
################################################################################
                     [1m Learning iteration 204/2000 [0m                      

                       Computation: 1930 steps/s (collection: 3.090s, learning 0.640s)
               Value function loss: 22.4942
                    Surrogate loss: -0.0039
             Mean action noise std: 0.99
                       Mean reward: -49.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1476000
                    Iteration time: 3.73s
                        Total time: 783.07s
                               ETA: 6860.4s
################################################################################
                     [1m Learning iteration 205/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.185s, learning 0.636s)
               Value function loss: 23.0014
                    Surrogate loss: -0.0051
             Mean action noise std: 0.99
                       Mean reward: -49.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1483200
                    Iteration time: 3.82s
                        Total time: 786.89s
                               ETA: 6856.6s
################################################################################
                     [1m Learning iteration 206/2000 [0m                      

                       Computation: 1841 steps/s (collection: 3.156s, learning 0.754s)
               Value function loss: 24.9075
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -49.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1490400
                    Iteration time: 3.91s
                        Total time: 790.80s
                               ETA: 6853.6s
################################################################################
                     [1m Learning iteration 207/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.023s, learning 0.796s)
               Value function loss: 22.3574
                    Surrogate loss: -0.0004
             Mean action noise std: 0.99
                       Mean reward: -49.78
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1497600
                    Iteration time: 3.82s
                        Total time: 794.62s
                               ETA: 6849.7s
################################################################################
                     [1m Learning iteration 208/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.037s, learning 0.836s)
               Value function loss: 21.9472
                    Surrogate loss: 0.0057
             Mean action noise std: 0.99
                       Mean reward: -49.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1504800
                    Iteration time: 3.87s
                        Total time: 798.49s
                               ETA: 6846.4s
################################################################################
                     [1m Learning iteration 209/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.085s, learning 0.756s)
               Value function loss: 22.0032
                    Surrogate loss: 0.0003
             Mean action noise std: 0.99
                       Mean reward: -49.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1512000
                    Iteration time: 3.84s
                        Total time: 802.33s
                               ETA: 6842.7s
################################################################################
                     [1m Learning iteration 210/2000 [0m                      

                       Computation: 1912 steps/s (collection: 3.104s, learning 0.662s)
               Value function loss: 23.0420
                    Surrogate loss: -0.0050
             Mean action noise std: 0.99
                       Mean reward: -49.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1519200
                    Iteration time: 3.77s
                        Total time: 806.09s
                               ETA: 6838.4s
################################################################################
                     [1m Learning iteration 211/2000 [0m                      

                       Computation: 1835 steps/s (collection: 3.138s, learning 0.785s)
               Value function loss: 21.1968
                    Surrogate loss: -0.0029
             Mean action noise std: 0.99
                       Mean reward: -49.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1526400
                    Iteration time: 3.92s
                        Total time: 810.02s
                               ETA: 6835.5s
################################################################################
                     [1m Learning iteration 212/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.040s, learning 0.787s)
               Value function loss: 22.8399
                    Surrogate loss: -0.0061
             Mean action noise std: 0.98
                       Mean reward: -48.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1533600
                    Iteration time: 3.83s
                        Total time: 813.84s
                               ETA: 6831.7s
################################################################################
                     [1m Learning iteration 213/2000 [0m                      

                       Computation: 1837 steps/s (collection: 3.120s, learning 0.798s)
               Value function loss: 21.9394
                    Surrogate loss: -0.0009
             Mean action noise std: 0.98
                       Mean reward: -48.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1540800
                    Iteration time: 3.92s
                        Total time: 817.76s
                               ETA: 6828.7s
################################################################################
                     [1m Learning iteration 214/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.084s, learning 0.766s)
               Value function loss: 22.1092
                    Surrogate loss: -0.0047
             Mean action noise std: 0.98
                       Mean reward: -48.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1548000
                    Iteration time: 3.85s
                        Total time: 821.61s
                               ETA: 6825.1s
################################################################################
                     [1m Learning iteration 215/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.092s, learning 0.752s)
               Value function loss: 22.2267
                    Surrogate loss: -0.0032
             Mean action noise std: 0.98
                       Mean reward: -49.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1555200
                    Iteration time: 3.84s
                        Total time: 825.46s
                               ETA: 6821.5s
################################################################################
                     [1m Learning iteration 216/2000 [0m                      

                       Computation: 1854 steps/s (collection: 3.171s, learning 0.712s)
               Value function loss: 21.5600
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1562400
                    Iteration time: 3.88s
                        Total time: 829.34s
                               ETA: 6818.2s
################################################################################
                     [1m Learning iteration 217/2000 [0m                      

                       Computation: 1933 steps/s (collection: 3.037s, learning 0.687s)
               Value function loss: 22.0846
                    Surrogate loss: -0.0037
             Mean action noise std: 0.98
                       Mean reward: -49.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1569600
                    Iteration time: 3.72s
                        Total time: 833.06s
                               ETA: 6813.5s
################################################################################
                     [1m Learning iteration 218/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.227s, learning 0.615s)
               Value function loss: 21.1803
                    Surrogate loss: 0.0014
             Mean action noise std: 0.98
                       Mean reward: -49.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1576800
                    Iteration time: 3.84s
                        Total time: 836.90s
                               ETA: 6809.9s
################################################################################
                     [1m Learning iteration 219/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.156s, learning 0.607s)
               Value function loss: 20.8003
                    Surrogate loss: 0.0081
             Mean action noise std: 0.98
                       Mean reward: -49.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1584000
                    Iteration time: 3.76s
                        Total time: 840.67s
                               ETA: 6805.6s
################################################################################
                     [1m Learning iteration 220/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.089s, learning 0.673s)
               Value function loss: 25.7714
                    Surrogate loss: 0.0002
             Mean action noise std: 0.98
                       Mean reward: -48.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1591200
                    Iteration time: 3.76s
                        Total time: 844.43s
                               ETA: 6801.3s
################################################################################
                     [1m Learning iteration 221/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.135s, learning 0.626s)
               Value function loss: 25.3793
                    Surrogate loss: 0.0039
             Mean action noise std: 0.98
                       Mean reward: -48.51
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1598400
                    Iteration time: 3.76s
                        Total time: 848.19s
                               ETA: 6797.0s
################################################################################
                     [1m Learning iteration 222/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.222s, learning 0.621s)
               Value function loss: 24.1853
                    Surrogate loss: -0.0039
             Mean action noise std: 0.98
                       Mean reward: -48.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1605600
                    Iteration time: 3.84s
                        Total time: 852.03s
                               ETA: 6793.3s
################################################################################
                     [1m Learning iteration 223/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.185s, learning 0.626s)
               Value function loss: 24.0120
                    Surrogate loss: -0.0037
             Mean action noise std: 0.98
                       Mean reward: -48.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1612800
                    Iteration time: 3.81s
                        Total time: 855.84s
                               ETA: 6789.4s
################################################################################
                     [1m Learning iteration 224/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.249s, learning 0.624s)
               Value function loss: 21.1353
                    Surrogate loss: -0.0016
             Mean action noise std: 0.98
                       Mean reward: -48.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1620000
                    Iteration time: 3.87s
                        Total time: 859.72s
                               ETA: 6786.0s
################################################################################
                     [1m Learning iteration 225/2000 [0m                      

                       Computation: 1820 steps/s (collection: 3.333s, learning 0.621s)
               Value function loss: 25.1484
                    Surrogate loss: 0.0006
             Mean action noise std: 0.99
                       Mean reward: -48.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1627200
                    Iteration time: 3.95s
                        Total time: 863.67s
                               ETA: 6783.3s
################################################################################
                     [1m Learning iteration 226/2000 [0m                      

                       Computation: 1872 steps/s (collection: 3.222s, learning 0.622s)
               Value function loss: 23.8658
                    Surrogate loss: 0.0010
             Mean action noise std: 0.98
                       Mean reward: -48.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1634400
                    Iteration time: 3.84s
                        Total time: 867.52s
                               ETA: 6779.6s
################################################################################
                     [1m Learning iteration 227/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.158s, learning 0.623s)
               Value function loss: 22.0531
                    Surrogate loss: -0.0021
             Mean action noise std: 0.98
                       Mean reward: -48.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1641600
                    Iteration time: 3.78s
                        Total time: 871.30s
                               ETA: 6775.5s
################################################################################
                     [1m Learning iteration 228/2000 [0m                      

                       Computation: 1915 steps/s (collection: 3.149s, learning 0.610s)
               Value function loss: 24.8021
                    Surrogate loss: -0.0072
             Mean action noise std: 0.98
                       Mean reward: -48.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1648800
                    Iteration time: 3.76s
                        Total time: 875.06s
                               ETA: 6771.2s
################################################################################
                     [1m Learning iteration 229/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.125s, learning 0.613s)
               Value function loss: 23.2220
                    Surrogate loss: -0.0049
             Mean action noise std: 0.98
                       Mean reward: -48.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1656000
                    Iteration time: 3.74s
                        Total time: 878.79s
                               ETA: 6766.7s
################################################################################
                     [1m Learning iteration 230/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.071s, learning 0.746s)
               Value function loss: 23.0715
                    Surrogate loss: 0.0006
             Mean action noise std: 0.98
                       Mean reward: -48.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1663200
                    Iteration time: 3.82s
                        Total time: 882.61s
                               ETA: 6762.9s
################################################################################
                     [1m Learning iteration 231/2000 [0m                      

                       Computation: 1930 steps/s (collection: 3.039s, learning 0.690s)
               Value function loss: 21.6452
                    Surrogate loss: 0.0006
             Mean action noise std: 0.98
                       Mean reward: -48.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1670400
                    Iteration time: 3.73s
                        Total time: 886.34s
                               ETA: 6758.3s
################################################################################
                     [1m Learning iteration 232/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.103s, learning 0.710s)
               Value function loss: 23.9235
                    Surrogate loss: 0.0005
             Mean action noise std: 0.98
                       Mean reward: -48.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1677600
                    Iteration time: 3.81s
                        Total time: 890.15s
                               ETA: 6754.5s
################################################################################
                     [1m Learning iteration 233/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.110s, learning 0.713s)
               Value function loss: 26.4303
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -48.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1684800
                    Iteration time: 3.82s
                        Total time: 893.98s
                               ETA: 6750.7s
################################################################################
                     [1m Learning iteration 234/2000 [0m                      

                       Computation: 1924 steps/s (collection: 3.101s, learning 0.640s)
               Value function loss: 26.0548
                    Surrogate loss: -0.0012
             Mean action noise std: 0.99
                       Mean reward: -48.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1692000
                    Iteration time: 3.74s
                        Total time: 897.72s
                               ETA: 6746.3s
################################################################################
                     [1m Learning iteration 235/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.136s, learning 0.626s)
               Value function loss: 25.6000
                    Surrogate loss: -0.0066
             Mean action noise std: 0.99
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1699200
                    Iteration time: 3.76s
                        Total time: 901.48s
                               ETA: 6742.0s
################################################################################
                     [1m Learning iteration 236/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.111s, learning 0.610s)
               Value function loss: 24.9361
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -48.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1706400
                    Iteration time: 3.72s
                        Total time: 905.20s
                               ETA: 6737.4s
################################################################################
                     [1m Learning iteration 237/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.163s, learning 0.629s)
               Value function loss: 26.6330
                    Surrogate loss: -0.0026
             Mean action noise std: 0.99
                       Mean reward: -48.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1713600
                    Iteration time: 3.79s
                        Total time: 908.99s
                               ETA: 6733.4s
################################################################################
                     [1m Learning iteration 238/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.081s, learning 0.743s)
               Value function loss: 25.2448
                    Surrogate loss: -0.0023
             Mean action noise std: 0.99
                       Mean reward: -49.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1720800
                    Iteration time: 3.82s
                        Total time: 912.82s
                               ETA: 6729.6s
################################################################################
                     [1m Learning iteration 239/2000 [0m                      

                       Computation: 1894 steps/s (collection: 3.189s, learning 0.610s)
               Value function loss: 24.8098
                    Surrogate loss: -0.0068
             Mean action noise std: 0.99
                       Mean reward: -49.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1728000
                    Iteration time: 3.80s
                        Total time: 916.62s
                               ETA: 6725.7s
################################################################################
                     [1m Learning iteration 240/2000 [0m                      

                       Computation: 1925 steps/s (collection: 3.119s, learning 0.620s)
               Value function loss: 26.1251
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -49.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1735200
                    Iteration time: 3.74s
                        Total time: 920.36s
                               ETA: 6721.3s
################################################################################
                     [1m Learning iteration 241/2000 [0m                      

                       Computation: 1950 steps/s (collection: 3.076s, learning 0.616s)
               Value function loss: 23.2910
                    Surrogate loss: -0.0003
             Mean action noise std: 0.99
                       Mean reward: -48.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1742400
                    Iteration time: 3.69s
                        Total time: 924.05s
                               ETA: 6716.5s
################################################################################
                     [1m Learning iteration 242/2000 [0m                      

                       Computation: 1925 steps/s (collection: 3.103s, learning 0.637s)
               Value function loss: 23.9826
                    Surrogate loss: -0.0043
             Mean action noise std: 0.99
                       Mean reward: -49.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1749600
                    Iteration time: 3.74s
                        Total time: 927.79s
                               ETA: 6712.1s
################################################################################
                     [1m Learning iteration 243/2000 [0m                      

                       Computation: 1939 steps/s (collection: 3.093s, learning 0.621s)
               Value function loss: 29.8779
                    Surrogate loss: 0.0062
             Mean action noise std: 0.99
                       Mean reward: -49.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1756800
                    Iteration time: 3.71s
                        Total time: 931.50s
                               ETA: 6707.6s
################################################################################
                     [1m Learning iteration 244/2000 [0m                      

                       Computation: 1910 steps/s (collection: 3.149s, learning 0.619s)
               Value function loss: 23.5749
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -49.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1764000
                    Iteration time: 3.77s
                        Total time: 935.27s
                               ETA: 6703.4s
################################################################################
                     [1m Learning iteration 245/2000 [0m                      

                       Computation: 1928 steps/s (collection: 3.070s, learning 0.664s)
               Value function loss: 23.8934
                    Surrogate loss: -0.0040
             Mean action noise std: 0.99
                       Mean reward: -49.25
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1771200
                    Iteration time: 3.73s
                        Total time: 939.00s
                               ETA: 6699.0s
################################################################################
                     [1m Learning iteration 246/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.156s, learning 0.672s)
               Value function loss: 23.5059
                    Surrogate loss: -0.0055
             Mean action noise std: 0.99
                       Mean reward: -49.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1778400
                    Iteration time: 3.83s
                        Total time: 942.83s
                               ETA: 6695.2s
################################################################################
                     [1m Learning iteration 247/2000 [0m                      

                       Computation: 1938 steps/s (collection: 3.099s, learning 0.616s)
               Value function loss: 21.6688
                    Surrogate loss: -0.0052
             Mean action noise std: 0.98
                       Mean reward: -49.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1785600
                    Iteration time: 3.72s
                        Total time: 946.54s
                               ETA: 6690.7s
################################################################################
                     [1m Learning iteration 248/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.128s, learning 0.652s)
               Value function loss: 24.1192
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1792800
                    Iteration time: 3.78s
                        Total time: 950.32s
                               ETA: 6686.6s
################################################################################
                     [1m Learning iteration 249/2000 [0m                      

                       Computation: 1922 steps/s (collection: 3.128s, learning 0.617s)
               Value function loss: 22.5071
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -49.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1800000
                    Iteration time: 3.75s
                        Total time: 954.07s
                               ETA: 6682.3s
################################################################################
                     [1m Learning iteration 250/2000 [0m                      

                       Computation: 1933 steps/s (collection: 3.114s, learning 0.610s)
               Value function loss: 22.8507
                    Surrogate loss: 0.0011
             Mean action noise std: 0.98
                       Mean reward: -48.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1807200
                    Iteration time: 3.72s
                        Total time: 957.79s
                               ETA: 6677.8s
################################################################################
                     [1m Learning iteration 251/2000 [0m                      

                       Computation: 1919 steps/s (collection: 3.142s, learning 0.609s)
               Value function loss: 23.1898
                    Surrogate loss: -0.0040
             Mean action noise std: 0.98
                       Mean reward: -48.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1814400
                    Iteration time: 3.75s
                        Total time: 961.55s
                               ETA: 6673.6s
################################################################################
                     [1m Learning iteration 252/2000 [0m                      

                       Computation: 1933 steps/s (collection: 3.099s, learning 0.624s)
               Value function loss: 37.5236
                    Surrogate loss: 0.0044
             Mean action noise std: 0.98
                       Mean reward: -49.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1821600
                    Iteration time: 3.72s
                        Total time: 965.27s
                               ETA: 6669.1s
################################################################################
                     [1m Learning iteration 253/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.208s, learning 0.618s)
               Value function loss: 28.5306
                    Surrogate loss: -0.0064
             Mean action noise std: 0.98
                       Mean reward: -49.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1828800
                    Iteration time: 3.83s
                        Total time: 969.09s
                               ETA: 6665.4s
################################################################################
                     [1m Learning iteration 254/2000 [0m                      

                       Computation: 1937 steps/s (collection: 3.099s, learning 0.617s)
               Value function loss: 25.6968
                    Surrogate loss: -0.0015
             Mean action noise std: 0.98
                       Mean reward: -50.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1836000
                    Iteration time: 3.72s
                        Total time: 972.81s
                               ETA: 6660.9s
################################################################################
                     [1m Learning iteration 255/2000 [0m                      

                       Computation: 1864 steps/s (collection: 3.177s, learning 0.685s)
               Value function loss: 25.1534
                    Surrogate loss: -0.0056
             Mean action noise std: 0.98
                       Mean reward: -50.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1843200
                    Iteration time: 3.86s
                        Total time: 976.67s
                               ETA: 6657.4s
################################################################################
                     [1m Learning iteration 256/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.112s, learning 0.609s)
               Value function loss: 22.6175
                    Surrogate loss: -0.0030
             Mean action noise std: 0.98
                       Mean reward: -51.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1850400
                    Iteration time: 3.72s
                        Total time: 980.39s
                               ETA: 6652.9s
################################################################################
                     [1m Learning iteration 257/2000 [0m                      

                       Computation: 1929 steps/s (collection: 3.117s, learning 0.614s)
               Value function loss: 21.6485
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -50.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1857600
                    Iteration time: 3.73s
                        Total time: 984.12s
                               ETA: 6648.6s
################################################################################
                     [1m Learning iteration 258/2000 [0m                      

                       Computation: 1925 steps/s (collection: 3.127s, learning 0.612s)
               Value function loss: 24.4532
                    Surrogate loss: -0.0035
             Mean action noise std: 0.98
                       Mean reward: -49.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1864800
                    Iteration time: 3.74s
                        Total time: 987.86s
                               ETA: 6644.2s
################################################################################
                     [1m Learning iteration 259/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.100s, learning 0.627s)
               Value function loss: 23.0100
                    Surrogate loss: -0.0013
             Mean action noise std: 0.98
                       Mean reward: -49.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1872000
                    Iteration time: 3.73s
                        Total time: 991.59s
                               ETA: 6639.8s
################################################################################
                     [1m Learning iteration 260/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.166s, learning 0.616s)
               Value function loss: 21.3587
                    Surrogate loss: 0.0107
             Mean action noise std: 0.98
                       Mean reward: -49.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1879200
                    Iteration time: 3.78s
                        Total time: 995.37s
                               ETA: 6635.8s
################################################################################
                     [1m Learning iteration 261/2000 [0m                      

                       Computation: 1944 steps/s (collection: 3.033s, learning 0.670s)
               Value function loss: 20.4422
                    Surrogate loss: 0.0072
             Mean action noise std: 0.98
                       Mean reward: -48.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1886400
                    Iteration time: 3.70s
                        Total time: 999.08s
                               ETA: 6631.3s
################################################################################
                     [1m Learning iteration 262/2000 [0m                      

                       Computation: 1848 steps/s (collection: 3.151s, learning 0.743s)
               Value function loss: 20.3537
                    Surrogate loss: 0.0003
             Mean action noise std: 0.98
                       Mean reward: -48.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1893600
                    Iteration time: 3.89s
                        Total time: 1002.97s
                               ETA: 6628.0s
################################################################################
                     [1m Learning iteration 263/2000 [0m                      

                       Computation: 1905 steps/s (collection: 3.154s, learning 0.625s)
               Value function loss: 24.2994
                    Surrogate loss: -0.0005
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1900800
                    Iteration time: 3.78s
                        Total time: 1006.75s
                               ETA: 6623.9s
################################################################################
                     [1m Learning iteration 264/2000 [0m                      

                       Computation: 1862 steps/s (collection: 3.242s, learning 0.625s)
               Value function loss: 23.5149
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -48.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1908000
                    Iteration time: 3.87s
                        Total time: 1010.61s
                               ETA: 6620.5s
################################################################################
                     [1m Learning iteration 265/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.209s, learning 0.610s)
               Value function loss: 22.3087
                    Surrogate loss: -0.0034
             Mean action noise std: 0.98
                       Mean reward: -48.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1915200
                    Iteration time: 3.82s
                        Total time: 1014.43s
                               ETA: 6616.7s
################################################################################
                     [1m Learning iteration 266/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.195s, learning 0.624s)
               Value function loss: 22.6762
                    Surrogate loss: -0.0048
             Mean action noise std: 0.98
                       Mean reward: -48.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1922400
                    Iteration time: 3.82s
                        Total time: 1018.25s
                               ETA: 6612.9s
################################################################################
                     [1m Learning iteration 267/2000 [0m                      

                       Computation: 1905 steps/s (collection: 3.149s, learning 0.629s)
               Value function loss: 23.9864
                    Surrogate loss: 0.0081
             Mean action noise std: 0.98
                       Mean reward: -48.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1929600
                    Iteration time: 3.78s
                        Total time: 1022.03s
                               ETA: 6608.9s
################################################################################
                     [1m Learning iteration 268/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.099s, learning 0.620s)
               Value function loss: 24.1072
                    Surrogate loss: 0.0037
             Mean action noise std: 0.98
                       Mean reward: -48.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1936800
                    Iteration time: 3.72s
                        Total time: 1025.75s
                               ETA: 6604.5s
################################################################################
                     [1m Learning iteration 269/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.222s, learning 0.611s)
               Value function loss: 25.2979
                    Surrogate loss: 0.0019
             Mean action noise std: 0.98
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1944000
                    Iteration time: 3.83s
                        Total time: 1029.58s
                               ETA: 6600.8s
################################################################################
                     [1m Learning iteration 270/2000 [0m                      

                       Computation: 1936 steps/s (collection: 3.100s, learning 0.619s)
               Value function loss: 26.4653
                    Surrogate loss: -0.0036
             Mean action noise std: 0.98
                       Mean reward: -50.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.16
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1951200
                    Iteration time: 3.72s
                        Total time: 1033.30s
                               ETA: 6596.4s
################################################################################
                     [1m Learning iteration 271/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.141s, learning 0.609s)
               Value function loss: 23.3921
                    Surrogate loss: -0.0044
             Mean action noise std: 0.98
                       Mean reward: -50.39
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1958400
                    Iteration time: 3.75s
                        Total time: 1037.05s
                               ETA: 6592.1s
################################################################################
                     [1m Learning iteration 272/2000 [0m                      

                       Computation: 1894 steps/s (collection: 3.181s, learning 0.619s)
               Value function loss: 24.8940
                    Surrogate loss: -0.0009
             Mean action noise std: 0.98
                       Mean reward: -50.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1965600
                    Iteration time: 3.80s
                        Total time: 1040.85s
                               ETA: 6588.2s
################################################################################
                     [1m Learning iteration 273/2000 [0m                      

                       Computation: 1943 steps/s (collection: 3.062s, learning 0.643s)
               Value function loss: 23.2045
                    Surrogate loss: -0.0049
             Mean action noise std: 0.98
                       Mean reward: -50.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1972800
                    Iteration time: 3.70s
                        Total time: 1044.56s
                               ETA: 6583.8s
################################################################################
                     [1m Learning iteration 274/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.106s, learning 0.654s)
               Value function loss: 23.3671
                    Surrogate loss: -0.0032
             Mean action noise std: 0.98
                       Mean reward: -49.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1980000
                    Iteration time: 3.76s
                        Total time: 1048.32s
                               ETA: 6579.6s
################################################################################
                     [1m Learning iteration 275/2000 [0m                      

                       Computation: 1947 steps/s (collection: 3.082s, learning 0.615s)
               Value function loss: 22.4145
                    Surrogate loss: 0.0005
             Mean action noise std: 0.98
                       Mean reward: -49.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1987200
                    Iteration time: 3.70s
                        Total time: 1052.01s
                               ETA: 6575.1s
################################################################################
                     [1m Learning iteration 276/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.153s, learning 0.640s)
               Value function loss: 19.7985
                    Surrogate loss: -0.0082
             Mean action noise std: 0.98
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 1994400
                    Iteration time: 3.79s
                        Total time: 1055.81s
                               ETA: 6571.2s
################################################################################
                     [1m Learning iteration 277/2000 [0m                      

                       Computation: 1949 steps/s (collection: 3.080s, learning 0.613s)
               Value function loss: 20.9885
                    Surrogate loss: -0.0056
             Mean action noise std: 0.98
                       Mean reward: -48.68
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2001600
                    Iteration time: 3.69s
                        Total time: 1059.50s
                               ETA: 6566.6s
################################################################################
                     [1m Learning iteration 278/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.131s, learning 0.633s)
               Value function loss: 24.2448
                    Surrogate loss: -0.0002
             Mean action noise std: 0.98
                       Mean reward: -48.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2008800
                    Iteration time: 3.76s
                        Total time: 1063.26s
                               ETA: 6562.5s
################################################################################
                     [1m Learning iteration 279/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.093s, learning 0.643s)
               Value function loss: 21.9236
                    Surrogate loss: -0.0033
             Mean action noise std: 0.98
                       Mean reward: -48.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2016000
                    Iteration time: 3.74s
                        Total time: 1067.00s
                               ETA: 6558.2s
################################################################################
                     [1m Learning iteration 280/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.098s, learning 0.640s)
               Value function loss: 24.8706
                    Surrogate loss: -0.0074
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2023200
                    Iteration time: 3.74s
                        Total time: 1070.74s
                               ETA: 6554.0s
################################################################################
                     [1m Learning iteration 281/2000 [0m                      

                       Computation: 1922 steps/s (collection: 3.082s, learning 0.662s)
               Value function loss: 25.0024
                    Surrogate loss: 0.0022
             Mean action noise std: 0.98
                       Mean reward: -48.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2030400
                    Iteration time: 3.74s
                        Total time: 1074.48s
                               ETA: 6549.8s
################################################################################
                     [1m Learning iteration 282/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.088s, learning 0.732s)
               Value function loss: 24.9283
                    Surrogate loss: 0.0051
             Mean action noise std: 0.99
                       Mean reward: -49.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2037600
                    Iteration time: 3.82s
                        Total time: 1078.30s
                               ETA: 6546.0s
################################################################################
                     [1m Learning iteration 283/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.175s, learning 0.673s)
               Value function loss: 24.5556
                    Surrogate loss: -0.0014
             Mean action noise std: 0.99
                       Mean reward: -49.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2044800
                    Iteration time: 3.85s
                        Total time: 1082.15s
                               ETA: 6542.4s
################################################################################
                     [1m Learning iteration 284/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.107s, learning 0.725s)
               Value function loss: 24.1487
                    Surrogate loss: -0.0077
             Mean action noise std: 0.99
                       Mean reward: -49.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2052000
                    Iteration time: 3.83s
                        Total time: 1085.98s
                               ETA: 6538.8s
################################################################################
                     [1m Learning iteration 285/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.126s, learning 0.700s)
               Value function loss: 22.2641
                    Surrogate loss: -0.0062
             Mean action noise std: 0.99
                       Mean reward: -50.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2059200
                    Iteration time: 3.83s
                        Total time: 1089.81s
                               ETA: 6535.0s
################################################################################
                     [1m Learning iteration 286/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.134s, learning 0.627s)
               Value function loss: 25.7941
                    Surrogate loss: 0.0024
             Mean action noise std: 0.99
                       Mean reward: -49.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2066400
                    Iteration time: 3.76s
                        Total time: 1093.57s
                               ETA: 6530.9s
################################################################################
                     [1m Learning iteration 287/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.195s, learning 0.621s)
               Value function loss: 24.5523
                    Surrogate loss: -0.0045
             Mean action noise std: 0.99
                       Mean reward: -49.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2073600
                    Iteration time: 3.82s
                        Total time: 1097.38s
                               ETA: 6527.2s
################################################################################
                     [1m Learning iteration 288/2000 [0m                      

                       Computation: 1900 steps/s (collection: 3.143s, learning 0.645s)
               Value function loss: 26.5085
                    Surrogate loss: -0.0086
             Mean action noise std: 0.99
                       Mean reward: -49.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2080800
                    Iteration time: 3.79s
                        Total time: 1101.17s
                               ETA: 6523.2s
################################################################################
                     [1m Learning iteration 289/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.110s, learning 0.672s)
               Value function loss: 22.9385
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -48.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2088000
                    Iteration time: 3.78s
                        Total time: 1104.96s
                               ETA: 6519.2s
################################################################################
                     [1m Learning iteration 290/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.217s, learning 0.688s)
               Value function loss: 24.5835
                    Surrogate loss: -0.0027
             Mean action noise std: 0.99
                       Mean reward: -48.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2095200
                    Iteration time: 3.90s
                        Total time: 1108.86s
                               ETA: 6516.0s
################################################################################
                     [1m Learning iteration 291/2000 [0m                      

                       Computation: 1915 steps/s (collection: 3.158s, learning 0.601s)
               Value function loss: 23.8659
                    Surrogate loss: -0.0036
             Mean action noise std: 0.98
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2102400
                    Iteration time: 3.76s
                        Total time: 1112.62s
                               ETA: 6511.9s
################################################################################
                     [1m Learning iteration 292/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.104s, learning 0.643s)
               Value function loss: 22.8394
                    Surrogate loss: -0.0006
             Mean action noise std: 0.99
                       Mean reward: -48.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2109600
                    Iteration time: 3.75s
                        Total time: 1116.37s
                               ETA: 6507.7s
################################################################################
                     [1m Learning iteration 293/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.146s, learning 0.612s)
               Value function loss: 21.6723
                    Surrogate loss: -0.0034
             Mean action noise std: 0.98
                       Mean reward: -48.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2116800
                    Iteration time: 3.76s
                        Total time: 1120.12s
                               ETA: 6503.6s
################################################################################
                     [1m Learning iteration 294/2000 [0m                      

                       Computation: 1932 steps/s (collection: 3.104s, learning 0.622s)
               Value function loss: 24.1306
                    Surrogate loss: 0.0116
             Mean action noise std: 0.98
                       Mean reward: -48.36
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2124000
                    Iteration time: 3.73s
                        Total time: 1123.85s
                               ETA: 6499.3s
################################################################################
                     [1m Learning iteration 295/2000 [0m                      

                       Computation: 1899 steps/s (collection: 3.122s, learning 0.669s)
               Value function loss: 22.0499
                    Surrogate loss: -0.0045
             Mean action noise std: 0.98
                       Mean reward: -48.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2131200
                    Iteration time: 3.79s
                        Total time: 1127.64s
                               ETA: 6495.4s
################################################################################
                     [1m Learning iteration 296/2000 [0m                      

                       Computation: 1917 steps/s (collection: 3.102s, learning 0.653s)
               Value function loss: 22.5580
                    Surrogate loss: -0.0015
             Mean action noise std: 0.98
                       Mean reward: -47.98
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2138400
                    Iteration time: 3.75s
                        Total time: 1131.40s
                               ETA: 6491.2s
################################################################################
                     [1m Learning iteration 297/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.139s, learning 0.701s)
               Value function loss: 22.6305
                    Surrogate loss: -0.0073
             Mean action noise std: 0.98
                       Mean reward: -47.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2145600
                    Iteration time: 3.84s
                        Total time: 1135.24s
                               ETA: 6487.6s
################################################################################
                     [1m Learning iteration 298/2000 [0m                      

                       Computation: 1930 steps/s (collection: 3.083s, learning 0.647s)
               Value function loss: 23.5003
                    Surrogate loss: -0.0075
             Mean action noise std: 0.99
                       Mean reward: -47.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2152800
                    Iteration time: 3.73s
                        Total time: 1138.97s
                               ETA: 6483.3s
################################################################################
                     [1m Learning iteration 299/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.134s, learning 0.609s)
               Value function loss: 21.1185
                    Surrogate loss: -0.0080
             Mean action noise std: 0.99
                       Mean reward: -48.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2160000
                    Iteration time: 3.74s
                        Total time: 1142.71s
                               ETA: 6479.2s
################################################################################
                     [1m Learning iteration 300/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.120s, learning 0.608s)
               Value function loss: 23.4866
                    Surrogate loss: -0.0049
             Mean action noise std: 0.99
                       Mean reward: -48.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2167200
                    Iteration time: 3.73s
                        Total time: 1146.44s
                               ETA: 6474.9s
################################################################################
                     [1m Learning iteration 301/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.097s, learning 0.775s)
               Value function loss: 23.1504
                    Surrogate loss: 0.0014
             Mean action noise std: 0.98
                       Mean reward: -48.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2174400
                    Iteration time: 3.87s
                        Total time: 1150.31s
                               ETA: 6471.4s
################################################################################
                     [1m Learning iteration 302/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.121s, learning 0.628s)
               Value function loss: 24.5832
                    Surrogate loss: 0.0195
             Mean action noise std: 0.99
                       Mean reward: -48.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2181600
                    Iteration time: 3.75s
                        Total time: 1154.06s
                               ETA: 6467.3s
################################################################################
                     [1m Learning iteration 303/2000 [0m                      

                       Computation: 1938 steps/s (collection: 3.100s, learning 0.614s)
               Value function loss: 25.0824
                    Surrogate loss: -0.0050
             Mean action noise std: 0.99
                       Mean reward: -49.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2188800
                    Iteration time: 3.71s
                        Total time: 1157.77s
                               ETA: 6463.0s
################################################################################
                     [1m Learning iteration 304/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.195s, learning 0.708s)
               Value function loss: 27.1040
                    Surrogate loss: 0.0085
             Mean action noise std: 0.98
                       Mean reward: -48.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2196000
                    Iteration time: 3.90s
                        Total time: 1161.68s
                               ETA: 6459.7s
################################################################################
                     [1m Learning iteration 305/2000 [0m                      

                       Computation: 1893 steps/s (collection: 3.113s, learning 0.690s)
               Value function loss: 27.6650
                    Surrogate loss: -0.0001
             Mean action noise std: 0.98
                       Mean reward: -49.26
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2203200
                    Iteration time: 3.80s
                        Total time: 1165.48s
                               ETA: 6455.8s
################################################################################
                     [1m Learning iteration 306/2000 [0m                      

                       Computation: 1902 steps/s (collection: 3.123s, learning 0.662s)
               Value function loss: 26.0118
                    Surrogate loss: -0.0016
             Mean action noise std: 0.98
                       Mean reward: -49.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2210400
                    Iteration time: 3.79s
                        Total time: 1169.26s
                               ETA: 6451.9s
################################################################################
                     [1m Learning iteration 307/2000 [0m                      

                       Computation: 1872 steps/s (collection: 3.117s, learning 0.729s)
               Value function loss: 26.8548
                    Surrogate loss: -0.0010
             Mean action noise std: 0.99
                       Mean reward: -49.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2217600
                    Iteration time: 3.85s
                        Total time: 1173.11s
                               ETA: 6448.3s
################################################################################
                     [1m Learning iteration 308/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.098s, learning 0.639s)
               Value function loss: 24.3430
                    Surrogate loss: -0.0001
             Mean action noise std: 0.99
                       Mean reward: -49.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2224800
                    Iteration time: 3.74s
                        Total time: 1176.85s
                               ETA: 6444.1s
################################################################################
                     [1m Learning iteration 309/2000 [0m                      

                       Computation: 1905 steps/s (collection: 3.150s, learning 0.629s)
               Value function loss: 24.7785
                    Surrogate loss: -0.0061
             Mean action noise std: 0.99
                       Mean reward: -49.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2232000
                    Iteration time: 3.78s
                        Total time: 1180.62s
                               ETA: 6440.1s
################################################################################
                     [1m Learning iteration 310/2000 [0m                      

                       Computation: 1865 steps/s (collection: 3.226s, learning 0.634s)
               Value function loss: 25.6623
                    Surrogate loss: 0.0043
             Mean action noise std: 0.99
                       Mean reward: -49.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2239200
                    Iteration time: 3.86s
                        Total time: 1184.48s
                               ETA: 6436.6s
################################################################################
                     [1m Learning iteration 311/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.279s, learning 0.607s)
               Value function loss: 28.0493
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -49.12
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2246400
                    Iteration time: 3.89s
                        Total time: 1188.37s
                               ETA: 6433.2s
################################################################################
                     [1m Learning iteration 312/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.155s, learning 0.627s)
               Value function loss: 25.0996
                    Surrogate loss: -0.0076
             Mean action noise std: 0.99
                       Mean reward: -49.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2253600
                    Iteration time: 3.78s
                        Total time: 1192.15s
                               ETA: 6429.2s
################################################################################
                     [1m Learning iteration 313/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.175s, learning 0.677s)
               Value function loss: 24.5458
                    Surrogate loss: -0.0071
             Mean action noise std: 0.99
                       Mean reward: -48.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2260800
                    Iteration time: 3.85s
                        Total time: 1196.00s
                               ETA: 6425.7s
################################################################################
                     [1m Learning iteration 314/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.189s, learning 0.625s)
               Value function loss: 25.5399
                    Surrogate loss: 0.0100
             Mean action noise std: 0.99
                       Mean reward: -49.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2268000
                    Iteration time: 3.81s
                        Total time: 1199.82s
                               ETA: 6421.9s
################################################################################
                     [1m Learning iteration 315/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.149s, learning 0.611s)
               Value function loss: 26.5048
                    Surrogate loss: -0.0087
             Mean action noise std: 0.99
                       Mean reward: -48.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2275200
                    Iteration time: 3.76s
                        Total time: 1203.58s
                               ETA: 6417.8s
################################################################################
                     [1m Learning iteration 316/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.191s, learning 0.623s)
               Value function loss: 27.2158
                    Surrogate loss: -0.0034
             Mean action noise std: 0.99
                       Mean reward: -49.25
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2282400
                    Iteration time: 3.81s
                        Total time: 1207.39s
                               ETA: 6414.0s
################################################################################
                     [1m Learning iteration 317/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.123s, learning 0.624s)
               Value function loss: 25.8812
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -49.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2289600
                    Iteration time: 3.75s
                        Total time: 1211.14s
                               ETA: 6409.9s
################################################################################
                     [1m Learning iteration 318/2000 [0m                      

                       Computation: 1858 steps/s (collection: 3.267s, learning 0.607s)
               Value function loss: 25.4462
                    Surrogate loss: -0.0003
             Mean action noise std: 1.00
                       Mean reward: -49.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2296800
                    Iteration time: 3.87s
                        Total time: 1215.01s
                               ETA: 6406.4s
################################################################################
                     [1m Learning iteration 319/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.121s, learning 0.707s)
               Value function loss: 26.5040
                    Surrogate loss: -0.0066
             Mean action noise std: 0.99
                       Mean reward: -49.28
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2304000
                    Iteration time: 3.83s
                        Total time: 1218.84s
                               ETA: 6402.7s
################################################################################
                     [1m Learning iteration 320/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.165s, learning 0.616s)
               Value function loss: 25.4339
                    Surrogate loss: -0.0023
             Mean action noise std: 0.99
                       Mean reward: -49.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2311200
                    Iteration time: 3.78s
                        Total time: 1222.62s
                               ETA: 6398.8s
################################################################################
                     [1m Learning iteration 321/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.110s, learning 0.637s)
               Value function loss: 23.7000
                    Surrogate loss: 0.0005
             Mean action noise std: 1.00
                       Mean reward: -49.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2318400
                    Iteration time: 3.75s
                        Total time: 1226.37s
                               ETA: 6394.6s
################################################################################
                     [1m Learning iteration 322/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.090s, learning 0.649s)
               Value function loss: 25.7746
                    Surrogate loss: -0.0022
             Mean action noise std: 1.00
                       Mean reward: -48.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2325600
                    Iteration time: 3.74s
                        Total time: 1230.11s
                               ETA: 6390.5s
################################################################################
                     [1m Learning iteration 323/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.168s, learning 0.612s)
               Value function loss: 27.4068
                    Surrogate loss: -0.0042
             Mean action noise std: 1.00
                       Mean reward: -48.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2332800
                    Iteration time: 3.78s
                        Total time: 1233.89s
                               ETA: 6386.5s
################################################################################
                     [1m Learning iteration 324/2000 [0m                      

                       Computation: 1944 steps/s (collection: 3.084s, learning 0.618s)
               Value function loss: 24.0192
                    Surrogate loss: -0.0053
             Mean action noise std: 1.00
                       Mean reward: -49.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2340000
                    Iteration time: 3.70s
                        Total time: 1237.59s
                               ETA: 6382.1s
################################################################################
                     [1m Learning iteration 325/2000 [0m                      

                       Computation: 1895 steps/s (collection: 3.133s, learning 0.666s)
               Value function loss: 26.2549
                    Surrogate loss: -0.0003
             Mean action noise std: 1.00
                       Mean reward: -48.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2347200
                    Iteration time: 3.80s
                        Total time: 1241.39s
                               ETA: 6378.3s
################################################################################
                     [1m Learning iteration 326/2000 [0m                      

                       Computation: 1925 steps/s (collection: 3.118s, learning 0.622s)
               Value function loss: 23.3614
                    Surrogate loss: -0.0049
             Mean action noise std: 1.00
                       Mean reward: -48.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2354400
                    Iteration time: 3.74s
                        Total time: 1245.13s
                               ETA: 6374.1s
################################################################################
                     [1m Learning iteration 327/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.174s, learning 0.618s)
               Value function loss: 24.3731
                    Surrogate loss: -0.0020
             Mean action noise std: 1.00
                       Mean reward: -48.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2361600
                    Iteration time: 3.79s
                        Total time: 1248.92s
                               ETA: 6370.2s
################################################################################
                     [1m Learning iteration 328/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.078s, learning 0.658s)
               Value function loss: 27.2123
                    Surrogate loss: -0.0050
             Mean action noise std: 1.00
                       Mean reward: -47.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2368800
                    Iteration time: 3.74s
                        Total time: 1252.65s
                               ETA: 6366.1s
################################################################################
                     [1m Learning iteration 329/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.124s, learning 0.636s)
               Value function loss: 24.0957
                    Surrogate loss: -0.0080
             Mean action noise std: 1.00
                       Mean reward: -47.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2376000
                    Iteration time: 3.76s
                        Total time: 1256.41s
                               ETA: 6362.0s
################################################################################
                     [1m Learning iteration 330/2000 [0m                      

                       Computation: 1907 steps/s (collection: 3.147s, learning 0.627s)
               Value function loss: 25.1048
                    Surrogate loss: -0.0095
             Mean action noise std: 1.00
                       Mean reward: -47.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2383200
                    Iteration time: 3.77s
                        Total time: 1260.19s
                               ETA: 6358.1s
################################################################################
                     [1m Learning iteration 331/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.131s, learning 0.618s)
               Value function loss: 28.0447
                    Surrogate loss: 0.0053
             Mean action noise std: 1.00
                       Mean reward: -48.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2390400
                    Iteration time: 3.75s
                        Total time: 1263.94s
                               ETA: 6354.0s
################################################################################
                     [1m Learning iteration 332/2000 [0m                      

                       Computation: 1866 steps/s (collection: 3.207s, learning 0.649s)
               Value function loss: 25.5438
                    Surrogate loss: 0.0057
             Mean action noise std: 1.00
                       Mean reward: -48.73
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2397600
                    Iteration time: 3.86s
                        Total time: 1267.80s
                               ETA: 6350.4s
################################################################################
                     [1m Learning iteration 333/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.112s, learning 0.615s)
               Value function loss: 25.3527
                    Surrogate loss: -0.0021
             Mean action noise std: 1.00
                       Mean reward: -49.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2404800
                    Iteration time: 3.73s
                        Total time: 1271.52s
                               ETA: 6346.2s
################################################################################
                     [1m Learning iteration 334/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.163s, learning 0.674s)
               Value function loss: 25.1033
                    Surrogate loss: -0.0081
             Mean action noise std: 1.00
                       Mean reward: -49.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2412000
                    Iteration time: 3.84s
                        Total time: 1275.36s
                               ETA: 6342.5s
################################################################################
                     [1m Learning iteration 335/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.139s, learning 0.623s)
               Value function loss: 27.1526
                    Surrogate loss: 0.0034
             Mean action noise std: 1.00
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2419200
                    Iteration time: 3.76s
                        Total time: 1279.12s
                               ETA: 6338.5s
################################################################################
                     [1m Learning iteration 336/2000 [0m                      

                       Computation: 1937 steps/s (collection: 3.101s, learning 0.615s)
               Value function loss: 26.5627
                    Surrogate loss: 0.0015
             Mean action noise std: 1.00
                       Mean reward: -49.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2426400
                    Iteration time: 3.72s
                        Total time: 1282.84s
                               ETA: 6334.3s
################################################################################
                     [1m Learning iteration 337/2000 [0m                      

                       Computation: 1912 steps/s (collection: 3.130s, learning 0.635s)
               Value function loss: 23.1018
                    Surrogate loss: 0.0051
             Mean action noise std: 1.00
                       Mean reward: -49.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2433600
                    Iteration time: 3.77s
                        Total time: 1286.60s
                               ETA: 6330.2s
################################################################################
                     [1m Learning iteration 338/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.084s, learning 0.674s)
               Value function loss: 24.8659
                    Surrogate loss: -0.0057
             Mean action noise std: 1.00
                       Mean reward: -48.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2440800
                    Iteration time: 3.76s
                        Total time: 1290.36s
                               ETA: 6326.2s
################################################################################
                     [1m Learning iteration 339/2000 [0m                      

                       Computation: 1877 steps/s (collection: 3.213s, learning 0.621s)
               Value function loss: 26.4998
                    Surrogate loss: -0.0044
             Mean action noise std: 1.00
                       Mean reward: -48.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2448000
                    Iteration time: 3.83s
                        Total time: 1294.19s
                               ETA: 6322.5s
################################################################################
                     [1m Learning iteration 340/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.052s, learning 0.669s)
               Value function loss: 24.0434
                    Surrogate loss: -0.0030
             Mean action noise std: 1.00
                       Mean reward: -49.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2455200
                    Iteration time: 3.72s
                        Total time: 1297.92s
                               ETA: 6318.3s
################################################################################
                     [1m Learning iteration 341/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.113s, learning 0.703s)
               Value function loss: 25.5198
                    Surrogate loss: -0.0058
             Mean action noise std: 1.00
                       Mean reward: -48.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2462400
                    Iteration time: 3.82s
                        Total time: 1301.73s
                               ETA: 6314.5s
################################################################################
                     [1m Learning iteration 342/2000 [0m                      

                       Computation: 1929 steps/s (collection: 3.104s, learning 0.628s)
               Value function loss: 23.4905
                    Surrogate loss: -0.0065
             Mean action noise std: 1.00
                       Mean reward: -48.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2469600
                    Iteration time: 3.73s
                        Total time: 1305.46s
                               ETA: 6310.4s
################################################################################
                     [1m Learning iteration 343/2000 [0m                      

                       Computation: 1950 steps/s (collection: 3.081s, learning 0.610s)
               Value function loss: 22.0977
                    Surrogate loss: -0.0014
             Mean action noise std: 1.00
                       Mean reward: -49.10
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2476800
                    Iteration time: 3.69s
                        Total time: 1309.15s
                               ETA: 6306.0s
################################################################################
                     [1m Learning iteration 344/2000 [0m                      

                       Computation: 1924 steps/s (collection: 3.105s, learning 0.636s)
               Value function loss: 23.3705
                    Surrogate loss: -0.0011
             Mean action noise std: 1.00
                       Mean reward: -48.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2484000
                    Iteration time: 3.74s
                        Total time: 1312.90s
                               ETA: 6301.9s
################################################################################
                     [1m Learning iteration 345/2000 [0m                      

                       Computation: 1928 steps/s (collection: 3.087s, learning 0.646s)
               Value function loss: 24.9944
                    Surrogate loss: -0.0076
             Mean action noise std: 1.00
                       Mean reward: -48.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2491200
                    Iteration time: 3.73s
                        Total time: 1316.63s
                               ETA: 6297.7s
################################################################################
                     [1m Learning iteration 346/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.162s, learning 0.651s)
               Value function loss: 25.3040
                    Surrogate loss: 0.0012
             Mean action noise std: 1.00
                       Mean reward: -48.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2498400
                    Iteration time: 3.81s
                        Total time: 1320.44s
                               ETA: 6294.0s
################################################################################
                     [1m Learning iteration 347/2000 [0m                      

                       Computation: 1938 steps/s (collection: 3.091s, learning 0.624s)
               Value function loss: 25.9971
                    Surrogate loss: -0.0008
             Mean action noise std: 1.00
                       Mean reward: -48.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2505600
                    Iteration time: 3.72s
                        Total time: 1324.16s
                               ETA: 6289.7s
################################################################################
                     [1m Learning iteration 348/2000 [0m                      

                       Computation: 1907 steps/s (collection: 3.146s, learning 0.629s)
               Value function loss: 25.9575
                    Surrogate loss: -0.0062
             Mean action noise std: 1.00
                       Mean reward: -48.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2512800
                    Iteration time: 3.78s
                        Total time: 1327.93s
                               ETA: 6285.8s
################################################################################
                     [1m Learning iteration 349/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.059s, learning 0.759s)
               Value function loss: 23.4884
                    Surrogate loss: -0.0055
             Mean action noise std: 1.00
                       Mean reward: -49.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2520000
                    Iteration time: 3.82s
                        Total time: 1331.75s
                               ETA: 6282.0s
################################################################################
                     [1m Learning iteration 350/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.068s, learning 0.670s)
               Value function loss: 23.4292
                    Surrogate loss: -0.0028
             Mean action noise std: 1.00
                       Mean reward: -49.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2527200
                    Iteration time: 3.74s
                        Total time: 1335.49s
                               ETA: 6277.9s
################################################################################
                     [1m Learning iteration 351/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.133s, learning 0.617s)
               Value function loss: 22.8344
                    Surrogate loss: -0.0031
             Mean action noise std: 1.00
                       Mean reward: -48.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2534400
                    Iteration time: 3.75s
                        Total time: 1339.24s
                               ETA: 6273.9s
################################################################################
                     [1m Learning iteration 352/2000 [0m                      

                       Computation: 1929 steps/s (collection: 3.089s, learning 0.643s)
               Value function loss: 24.0456
                    Surrogate loss: -0.0048
             Mean action noise std: 1.00
                       Mean reward: -49.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2541600
                    Iteration time: 3.73s
                        Total time: 1342.97s
                               ETA: 6269.7s
################################################################################
                     [1m Learning iteration 353/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.157s, learning 0.662s)
               Value function loss: 24.7567
                    Surrogate loss: -0.0038
             Mean action noise std: 1.00
                       Mean reward: -48.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2548800
                    Iteration time: 3.82s
                        Total time: 1346.79s
                               ETA: 6266.0s
################################################################################
                     [1m Learning iteration 354/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.107s, learning 0.639s)
               Value function loss: 24.7725
                    Surrogate loss: -0.0064
             Mean action noise std: 1.00
                       Mean reward: -48.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2556000
                    Iteration time: 3.75s
                        Total time: 1350.53s
                               ETA: 6261.9s
################################################################################
                     [1m Learning iteration 355/2000 [0m                      

                       Computation: 1875 steps/s (collection: 3.222s, learning 0.617s)
               Value function loss: 25.3731
                    Surrogate loss: 0.0070
             Mean action noise std: 1.00
                       Mean reward: -48.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2563200
                    Iteration time: 3.84s
                        Total time: 1354.37s
                               ETA: 6258.3s
################################################################################
                     [1m Learning iteration 356/2000 [0m                      

                       Computation: 1937 steps/s (collection: 3.082s, learning 0.634s)
               Value function loss: 26.5635
                    Surrogate loss: 0.0006
             Mean action noise std: 1.00
                       Mean reward: -48.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2570400
                    Iteration time: 3.72s
                        Total time: 1358.09s
                               ETA: 6254.1s
################################################################################
                     [1m Learning iteration 357/2000 [0m                      

                       Computation: 1908 steps/s (collection: 3.138s, learning 0.634s)
               Value function loss: 24.8121
                    Surrogate loss: -0.0029
             Mean action noise std: 1.00
                       Mean reward: -49.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2577600
                    Iteration time: 3.77s
                        Total time: 1361.86s
                               ETA: 6250.1s
################################################################################
                     [1m Learning iteration 358/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.123s, learning 0.614s)
               Value function loss: 23.6093
                    Surrogate loss: -0.0056
             Mean action noise std: 1.00
                       Mean reward: -49.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2584800
                    Iteration time: 3.74s
                        Total time: 1365.60s
                               ETA: 6246.0s
################################################################################
                     [1m Learning iteration 359/2000 [0m                      

                       Computation: 1938 steps/s (collection: 3.100s, learning 0.615s)
               Value function loss: 25.6103
                    Surrogate loss: -0.0022
             Mean action noise std: 0.99
                       Mean reward: -49.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2592000
                    Iteration time: 3.71s
                        Total time: 1369.31s
                               ETA: 6241.8s
################################################################################
                     [1m Learning iteration 360/2000 [0m                      

                       Computation: 1917 steps/s (collection: 3.145s, learning 0.610s)
               Value function loss: 21.3104
                    Surrogate loss: -0.0046
             Mean action noise std: 0.99
                       Mean reward: -49.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2599200
                    Iteration time: 3.75s
                        Total time: 1373.07s
                               ETA: 6237.8s
################################################################################
                     [1m Learning iteration 361/2000 [0m                      

                       Computation: 1941 steps/s (collection: 3.077s, learning 0.632s)
               Value function loss: 25.2629
                    Surrogate loss: -0.0012
             Mean action noise std: 0.99
                       Mean reward: -48.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2606400
                    Iteration time: 3.71s
                        Total time: 1376.78s
                               ETA: 6233.5s
################################################################################
                     [1m Learning iteration 362/2000 [0m                      

                       Computation: 1899 steps/s (collection: 3.176s, learning 0.615s)
               Value function loss: 25.3912
                    Surrogate loss: -0.0087
             Mean action noise std: 0.99
                       Mean reward: -48.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2613600
                    Iteration time: 3.79s
                        Total time: 1380.57s
                               ETA: 6229.7s
################################################################################
                     [1m Learning iteration 363/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.116s, learning 0.620s)
               Value function loss: 23.0861
                    Surrogate loss: -0.0010
             Mean action noise std: 0.99
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2620800
                    Iteration time: 3.74s
                        Total time: 1384.30s
                               ETA: 6225.6s
################################################################################
                     [1m Learning iteration 364/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.188s, learning 0.627s)
               Value function loss: 22.1692
                    Surrogate loss: 0.0020
             Mean action noise std: 0.99
                       Mean reward: -48.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2628000
                    Iteration time: 3.81s
                        Total time: 1388.12s
                               ETA: 6221.8s
################################################################################
                     [1m Learning iteration 365/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.098s, learning 0.638s)
               Value function loss: 22.3598
                    Surrogate loss: -0.0060
             Mean action noise std: 0.99
                       Mean reward: -47.73
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2635200
                    Iteration time: 3.74s
                        Total time: 1391.85s
                               ETA: 6217.7s
################################################################################
                     [1m Learning iteration 366/2000 [0m                      

                       Computation: 1912 steps/s (collection: 3.126s, learning 0.639s)
               Value function loss: 22.8870
                    Surrogate loss: -0.0051
             Mean action noise std: 0.99
                       Mean reward: -47.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2642400
                    Iteration time: 3.76s
                        Total time: 1395.62s
                               ETA: 6213.7s
################################################################################
                     [1m Learning iteration 367/2000 [0m                      

                       Computation: 1907 steps/s (collection: 2.953s, learning 0.820s)
               Value function loss: 28.2158
                    Surrogate loss: -0.0045
             Mean action noise std: 0.99
                       Mean reward: -47.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2649600
                    Iteration time: 3.77s
                        Total time: 1399.39s
                               ETA: 6209.8s
################################################################################
                     [1m Learning iteration 368/2000 [0m                      

                       Computation: 1933 steps/s (collection: 3.062s, learning 0.661s)
               Value function loss: 24.1120
                    Surrogate loss: 0.0002
             Mean action noise std: 0.99
                       Mean reward: -47.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2656800
                    Iteration time: 3.72s
                        Total time: 1403.12s
                               ETA: 6205.6s
################################################################################
                     [1m Learning iteration 369/2000 [0m                      

                       Computation: 1890 steps/s (collection: 3.121s, learning 0.687s)
               Value function loss: 24.7467
                    Surrogate loss: -0.0022
             Mean action noise std: 0.99
                       Mean reward: -48.02
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2664000
                    Iteration time: 3.81s
                        Total time: 1406.92s
                               ETA: 6201.9s
################################################################################
                     [1m Learning iteration 370/2000 [0m                      

                       Computation: 1856 steps/s (collection: 3.001s, learning 0.878s)
               Value function loss: 22.3638
                    Surrogate loss: -0.0014
             Mean action noise std: 0.99
                       Mean reward: -48.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2671200
                    Iteration time: 3.88s
                        Total time: 1410.80s
                               ETA: 6198.4s
################################################################################
                     [1m Learning iteration 371/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.141s, learning 0.685s)
               Value function loss: 24.0573
                    Surrogate loss: -0.0027
             Mean action noise std: 0.98
                       Mean reward: -48.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2678400
                    Iteration time: 3.83s
                        Total time: 1414.63s
                               ETA: 6194.7s
################################################################################
                     [1m Learning iteration 372/2000 [0m                      

                       Computation: 1939 steps/s (collection: 3.091s, learning 0.621s)
               Value function loss: 24.1759
                    Surrogate loss: -0.0000
             Mean action noise std: 0.98
                       Mean reward: -48.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2685600
                    Iteration time: 3.71s
                        Total time: 1418.34s
                               ETA: 6190.5s
################################################################################
                     [1m Learning iteration 373/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.106s, learning 0.637s)
               Value function loss: 22.5762
                    Surrogate loss: -0.0071
             Mean action noise std: 0.99
                       Mean reward: -48.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2692800
                    Iteration time: 3.74s
                        Total time: 1422.08s
                               ETA: 6186.4s
################################################################################
                     [1m Learning iteration 374/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.121s, learning 0.615s)
               Value function loss: 22.7255
                    Surrogate loss: -0.0043
             Mean action noise std: 0.98
                       Mean reward: -48.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2700000
                    Iteration time: 3.74s
                        Total time: 1425.82s
                               ETA: 6182.4s
################################################################################
                     [1m Learning iteration 375/2000 [0m                      

                       Computation: 1940 steps/s (collection: 3.095s, learning 0.615s)
               Value function loss: 23.4692
                    Surrogate loss: -0.0043
             Mean action noise std: 0.99
                       Mean reward: -48.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2707200
                    Iteration time: 3.71s
                        Total time: 1429.53s
                               ETA: 6178.2s
################################################################################
                     [1m Learning iteration 376/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.122s, learning 0.720s)
               Value function loss: 22.8025
                    Surrogate loss: -0.0048
             Mean action noise std: 0.98
                       Mean reward: -49.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2714400
                    Iteration time: 3.84s
                        Total time: 1433.37s
                               ETA: 6174.5s
################################################################################
                     [1m Learning iteration 377/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.100s, learning 0.720s)
               Value function loss: 22.5077
                    Surrogate loss: -0.0035
             Mean action noise std: 0.99
                       Mean reward: -49.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2721600
                    Iteration time: 3.82s
                        Total time: 1437.19s
                               ETA: 6170.8s
################################################################################
                     [1m Learning iteration 378/2000 [0m                      

                       Computation: 1823 steps/s (collection: 3.111s, learning 0.839s)
               Value function loss: 24.4256
                    Surrogate loss: 0.0018
             Mean action noise std: 0.98
                       Mean reward: -48.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2728800
                    Iteration time: 3.95s
                        Total time: 1441.14s
                               ETA: 6167.6s
################################################################################
                     [1m Learning iteration 379/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.100s, learning 0.750s)
               Value function loss: 27.0310
                    Surrogate loss: -0.0061
             Mean action noise std: 0.98
                       Mean reward: -48.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2736000
                    Iteration time: 3.85s
                        Total time: 1444.99s
                               ETA: 6164.0s
################################################################################
                     [1m Learning iteration 380/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.042s, learning 0.702s)
               Value function loss: 26.0557
                    Surrogate loss: -0.0040
             Mean action noise std: 0.98
                       Mean reward: -48.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2743200
                    Iteration time: 3.74s
                        Total time: 1448.73s
                               ETA: 6160.0s
################################################################################
                     [1m Learning iteration 381/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.103s, learning 0.644s)
               Value function loss: 26.4775
                    Surrogate loss: 0.0032
             Mean action noise std: 0.99
                       Mean reward: -48.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2750400
                    Iteration time: 3.75s
                        Total time: 1452.48s
                               ETA: 6155.9s
################################################################################
                     [1m Learning iteration 382/2000 [0m                      

                       Computation: 1941 steps/s (collection: 3.089s, learning 0.618s)
               Value function loss: 23.8898
                    Surrogate loss: -0.0012
             Mean action noise std: 0.99
                       Mean reward: -48.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2757600
                    Iteration time: 3.71s
                        Total time: 1456.19s
                               ETA: 6151.7s
################################################################################
                     [1m Learning iteration 383/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.135s, learning 0.669s)
               Value function loss: 22.8559
                    Surrogate loss: -0.0020
             Mean action noise std: 0.99
                       Mean reward: -48.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2764800
                    Iteration time: 3.80s
                        Total time: 1459.99s
                               ETA: 6147.9s
################################################################################
                     [1m Learning iteration 384/2000 [0m                      

                       Computation: 1938 steps/s (collection: 3.102s, learning 0.611s)
               Value function loss: 24.1499
                    Surrogate loss: -0.0059
             Mean action noise std: 0.99
                       Mean reward: -48.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2772000
                    Iteration time: 3.71s
                        Total time: 1463.71s
                               ETA: 6143.8s
################################################################################
                     [1m Learning iteration 385/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.175s, learning 0.635s)
               Value function loss: 23.6426
                    Surrogate loss: 0.0053
             Mean action noise std: 0.99
                       Mean reward: -48.73
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2779200
                    Iteration time: 3.81s
                        Total time: 1467.52s
                               ETA: 6140.0s
################################################################################
                     [1m Learning iteration 386/2000 [0m                      

                       Computation: 1945 steps/s (collection: 3.095s, learning 0.606s)
               Value function loss: 23.9069
                    Surrogate loss: 0.0116
             Mean action noise std: 0.99
                       Mean reward: -48.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2786400
                    Iteration time: 3.70s
                        Total time: 1471.22s
                               ETA: 6135.8s
################################################################################
                     [1m Learning iteration 387/2000 [0m                      

                       Computation: 1944 steps/s (collection: 3.087s, learning 0.617s)
               Value function loss: 24.2790
                    Surrogate loss: 0.0052
             Mean action noise std: 0.99
                       Mean reward: -48.68
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2793600
                    Iteration time: 3.70s
                        Total time: 1474.92s
                               ETA: 6131.6s
################################################################################
                     [1m Learning iteration 388/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.135s, learning 0.613s)
               Value function loss: 24.2543
                    Surrogate loss: -0.0056
             Mean action noise std: 0.99
                       Mean reward: -48.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2800800
                    Iteration time: 3.75s
                        Total time: 1478.67s
                               ETA: 6127.5s
################################################################################
                     [1m Learning iteration 389/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.024s, learning 0.737s)
               Value function loss: 24.7946
                    Surrogate loss: 0.0001
             Mean action noise std: 0.99
                       Mean reward: -48.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2808000
                    Iteration time: 3.76s
                        Total time: 1482.43s
                               ETA: 6123.6s
################################################################################
                     [1m Learning iteration 390/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.129s, learning 0.687s)
               Value function loss: 24.9535
                    Surrogate loss: -0.0053
             Mean action noise std: 0.99
                       Mean reward: -49.02
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2815200
                    Iteration time: 3.82s
                        Total time: 1486.25s
                               ETA: 6119.8s
################################################################################
                     [1m Learning iteration 391/2000 [0m                      

                       Computation: 1934 steps/s (collection: 3.110s, learning 0.613s)
               Value function loss: 25.1567
                    Surrogate loss: -0.0078
             Mean action noise std: 0.99
                       Mean reward: -48.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2822400
                    Iteration time: 3.72s
                        Total time: 1489.97s
                               ETA: 6115.7s
################################################################################
                     [1m Learning iteration 392/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.180s, learning 0.633s)
               Value function loss: 23.9979
                    Surrogate loss: -0.0036
             Mean action noise std: 0.99
                       Mean reward: -48.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2829600
                    Iteration time: 3.81s
                        Total time: 1493.78s
                               ETA: 6112.0s
################################################################################
                     [1m Learning iteration 393/2000 [0m                      

                       Computation: 1942 steps/s (collection: 3.087s, learning 0.621s)
               Value function loss: 24.4505
                    Surrogate loss: -0.0011
             Mean action noise std: 0.99
                       Mean reward: -48.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2836800
                    Iteration time: 3.71s
                        Total time: 1497.49s
                               ETA: 6107.8s
################################################################################
                     [1m Learning iteration 394/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.143s, learning 0.620s)
               Value function loss: 24.3175
                    Surrogate loss: -0.0026
             Mean action noise std: 0.99
                       Mean reward: -48.68
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2844000
                    Iteration time: 3.76s
                        Total time: 1501.25s
                               ETA: 6103.8s
################################################################################
                     [1m Learning iteration 395/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.088s, learning 0.655s)
               Value function loss: 26.1281
                    Surrogate loss: 0.0021
             Mean action noise std: 0.99
                       Mean reward: -48.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2851200
                    Iteration time: 3.74s
                        Total time: 1505.00s
                               ETA: 6099.8s
################################################################################
                     [1m Learning iteration 396/2000 [0m                      

                       Computation: 1933 steps/s (collection: 3.103s, learning 0.621s)
               Value function loss: 24.9521
                    Surrogate loss: -0.0016
             Mean action noise std: 0.99
                       Mean reward: -48.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2858400
                    Iteration time: 3.72s
                        Total time: 1508.72s
                               ETA: 6095.7s
################################################################################
                     [1m Learning iteration 397/2000 [0m                      

                       Computation: 1917 steps/s (collection: 3.139s, learning 0.615s)
               Value function loss: 25.8021
                    Surrogate loss: 0.0246
             Mean action noise std: 1.00
                       Mean reward: -48.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2865600
                    Iteration time: 3.75s
                        Total time: 1512.48s
                               ETA: 6091.7s
################################################################################
                     [1m Learning iteration 398/2000 [0m                      

                       Computation: 1919 steps/s (collection: 3.127s, learning 0.624s)
               Value function loss: 26.5418
                    Surrogate loss: 0.0159
             Mean action noise std: 1.00
                       Mean reward: -48.98
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2872800
                    Iteration time: 3.75s
                        Total time: 1516.23s
                               ETA: 6087.7s
################################################################################
                     [1m Learning iteration 399/2000 [0m                      

                       Computation: 1868 steps/s (collection: 3.146s, learning 0.707s)
               Value function loss: 24.1633
                    Surrogate loss: -0.0052
             Mean action noise std: 0.99
                       Mean reward: -49.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2880000
                    Iteration time: 3.85s
                        Total time: 1520.08s
                               ETA: 6084.1s
################################################################################
                     [1m Learning iteration 400/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.120s, learning 0.701s)
               Value function loss: 24.4407
                    Surrogate loss: -0.0031
             Mean action noise std: 0.99
                       Mean reward: -48.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2887200
                    Iteration time: 3.82s
                        Total time: 1523.90s
                               ETA: 6080.4s
################################################################################
                     [1m Learning iteration 401/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.096s, learning 0.809s)
               Value function loss: 26.6392
                    Surrogate loss: -0.0067
             Mean action noise std: 0.99
                       Mean reward: -48.51
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2894400
                    Iteration time: 3.90s
                        Total time: 1527.81s
                               ETA: 6077.0s
################################################################################
                     [1m Learning iteration 402/2000 [0m                      

                       Computation: 1858 steps/s (collection: 3.100s, learning 0.773s)
               Value function loss: 26.7117
                    Surrogate loss: -0.0036
             Mean action noise std: 1.00
                       Mean reward: -48.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2901600
                    Iteration time: 3.87s
                        Total time: 1531.68s
                               ETA: 6073.5s
################################################################################
                     [1m Learning iteration 403/2000 [0m                      

                       Computation: 1911 steps/s (collection: 3.091s, learning 0.677s)
               Value function loss: 24.6989
                    Surrogate loss: 0.0007
             Mean action noise std: 0.99
                       Mean reward: -47.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2908800
                    Iteration time: 3.77s
                        Total time: 1535.45s
                               ETA: 6069.6s
################################################################################
                     [1m Learning iteration 404/2000 [0m                      

                       Computation: 1833 steps/s (collection: 3.135s, learning 0.792s)
               Value function loss: 26.0997
                    Surrogate loss: 0.0052
             Mean action noise std: 1.00
                       Mean reward: -48.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2916000
                    Iteration time: 3.93s
                        Total time: 1539.37s
                               ETA: 6066.3s
################################################################################
                     [1m Learning iteration 405/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.121s, learning 0.614s)
               Value function loss: 26.1355
                    Surrogate loss: -0.0036
             Mean action noise std: 1.00
                       Mean reward: -48.98
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2923200
                    Iteration time: 3.73s
                        Total time: 1543.11s
                               ETA: 6062.2s
################################################################################
                     [1m Learning iteration 406/2000 [0m                      

                       Computation: 1815 steps/s (collection: 3.244s, learning 0.723s)
               Value function loss: 25.4537
                    Surrogate loss: -0.0084
             Mean action noise std: 1.00
                       Mean reward: -49.36
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2930400
                    Iteration time: 3.97s
                        Total time: 1547.08s
                               ETA: 6059.1s
################################################################################
                     [1m Learning iteration 407/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.116s, learning 0.641s)
               Value function loss: 23.5452
                    Surrogate loss: -0.0047
             Mean action noise std: 1.00
                       Mean reward: -49.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2937600
                    Iteration time: 3.76s
                        Total time: 1550.83s
                               ETA: 6055.1s
################################################################################
                     [1m Learning iteration 408/2000 [0m                      

                       Computation: 1875 steps/s (collection: 3.171s, learning 0.668s)
               Value function loss: 25.5752
                    Surrogate loss: -0.0062
             Mean action noise std: 1.00
                       Mean reward: -49.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2944800
                    Iteration time: 3.84s
                        Total time: 1554.67s
                               ETA: 6051.4s
################################################################################
                     [1m Learning iteration 409/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.130s, learning 0.674s)
               Value function loss: 22.8156
                    Surrogate loss: 0.0078
             Mean action noise std: 1.00
                       Mean reward: -48.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2952000
                    Iteration time: 3.80s
                        Total time: 1558.48s
                               ETA: 6047.6s
################################################################################
                     [1m Learning iteration 410/2000 [0m                      

                       Computation: 1922 steps/s (collection: 3.122s, learning 0.623s)
               Value function loss: 26.9963
                    Surrogate loss: 0.0061
             Mean action noise std: 1.00
                       Mean reward: -48.10
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2959200
                    Iteration time: 3.75s
                        Total time: 1562.22s
                               ETA: 6043.6s
################################################################################
                     [1m Learning iteration 411/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.085s, learning 0.658s)
               Value function loss: 24.9575
                    Surrogate loss: 0.0008
             Mean action noise std: 1.00
                       Mean reward: -48.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2966400
                    Iteration time: 3.74s
                        Total time: 1565.96s
                               ETA: 6039.6s
################################################################################
                     [1m Learning iteration 412/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.114s, learning 0.632s)
               Value function loss: 23.2498
                    Surrogate loss: -0.0021
             Mean action noise std: 1.00
                       Mean reward: -48.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2973600
                    Iteration time: 3.75s
                        Total time: 1569.71s
                               ETA: 6035.6s
################################################################################
                     [1m Learning iteration 413/2000 [0m                      

                       Computation: 1841 steps/s (collection: 3.178s, learning 0.732s)
               Value function loss: 26.7221
                    Surrogate loss: -0.0070
             Mean action noise std: 1.00
                       Mean reward: -48.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2980800
                    Iteration time: 3.91s
                        Total time: 1573.62s
                               ETA: 6032.2s
################################################################################
                     [1m Learning iteration 414/2000 [0m                      

                       Computation: 1929 steps/s (collection: 3.104s, learning 0.627s)
               Value function loss: 26.8464
                    Surrogate loss: -0.0040
             Mean action noise std: 1.00
                       Mean reward: -49.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2988000
                    Iteration time: 3.73s
                        Total time: 1577.35s
                               ETA: 6028.1s
################################################################################
                     [1m Learning iteration 415/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.173s, learning 0.761s)
               Value function loss: 26.6923
                    Surrogate loss: -0.0045
             Mean action noise std: 1.00
                       Mean reward: -49.68
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 2995200
                    Iteration time: 3.93s
                        Total time: 1581.29s
                               ETA: 6024.8s
################################################################################
                     [1m Learning iteration 416/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.094s, learning 0.724s)
               Value function loss: 25.7979
                    Surrogate loss: -0.0041
             Mean action noise std: 1.00
                       Mean reward: -49.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3002400
                    Iteration time: 3.82s
                        Total time: 1585.10s
                               ETA: 6021.1s
################################################################################
                     [1m Learning iteration 417/2000 [0m                      

                       Computation: 1929 steps/s (collection: 3.093s, learning 0.638s)
               Value function loss: 25.5273
                    Surrogate loss: 0.0044
             Mean action noise std: 1.00
                       Mean reward: -49.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3009600
                    Iteration time: 3.73s
                        Total time: 1588.83s
                               ETA: 6017.0s
################################################################################
                     [1m Learning iteration 418/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.097s, learning 0.641s)
               Value function loss: 25.7022
                    Surrogate loss: 0.0050
             Mean action noise std: 1.00
                       Mean reward: -49.98
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3016800
                    Iteration time: 3.74s
                        Total time: 1592.57s
                               ETA: 6013.0s
################################################################################
                     [1m Learning iteration 419/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.110s, learning 0.712s)
               Value function loss: 23.9544
                    Surrogate loss: -0.0074
             Mean action noise std: 1.00
                       Mean reward: -50.36
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3024000
                    Iteration time: 3.82s
                        Total time: 1596.39s
                               ETA: 6009.3s
################################################################################
                     [1m Learning iteration 420/2000 [0m                      

                       Computation: 1802 steps/s (collection: 3.191s, learning 0.803s)
               Value function loss: 23.3615
                    Surrogate loss: -0.0058
             Mean action noise std: 1.00
                       Mean reward: -49.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3031200
                    Iteration time: 3.99s
                        Total time: 1600.39s
                               ETA: 6006.2s
################################################################################
                     [1m Learning iteration 421/2000 [0m                      

                       Computation: 1906 steps/s (collection: 3.077s, learning 0.699s)
               Value function loss: 25.9622
                    Surrogate loss: -0.0026
             Mean action noise std: 1.00
                       Mean reward: -49.78
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3038400
                    Iteration time: 3.78s
                        Total time: 1604.17s
                               ETA: 6002.3s
################################################################################
                     [1m Learning iteration 422/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.109s, learning 0.725s)
               Value function loss: 25.0420
                    Surrogate loss: -0.0019
             Mean action noise std: 1.00
                       Mean reward: -49.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3045600
                    Iteration time: 3.83s
                        Total time: 1608.00s
                               ETA: 5998.6s
################################################################################
                     [1m Learning iteration 423/2000 [0m                      

                       Computation: 1893 steps/s (collection: 3.063s, learning 0.741s)
               Value function loss: 22.7741
                    Surrogate loss: -0.0069
             Mean action noise std: 1.00
                       Mean reward: -49.33
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3052800
                    Iteration time: 3.80s
                        Total time: 1611.80s
                               ETA: 5994.8s
################################################################################
                     [1m Learning iteration 424/2000 [0m                      

                       Computation: 1929 steps/s (collection: 3.109s, learning 0.623s)
               Value function loss: 24.4113
                    Surrogate loss: -0.0031
             Mean action noise std: 1.00
                       Mean reward: -48.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3060000
                    Iteration time: 3.73s
                        Total time: 1615.53s
                               ETA: 5990.8s
################################################################################
                     [1m Learning iteration 425/2000 [0m                      

                       Computation: 1907 steps/s (collection: 3.154s, learning 0.621s)
               Value function loss: 24.3203
                    Surrogate loss: 0.0067
             Mean action noise std: 1.00
                       Mean reward: -48.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3067200
                    Iteration time: 3.78s
                        Total time: 1619.31s
                               ETA: 5986.9s
################################################################################
                     [1m Learning iteration 426/2000 [0m                      

                       Computation: 1929 steps/s (collection: 3.104s, learning 0.627s)
               Value function loss: 23.7378
                    Surrogate loss: -0.0022
             Mean action noise std: 1.00
                       Mean reward: -48.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3074400
                    Iteration time: 3.73s
                        Total time: 1623.04s
                               ETA: 5982.8s
################################################################################
                     [1m Learning iteration 427/2000 [0m                      

                       Computation: 1864 steps/s (collection: 3.236s, learning 0.625s)
               Value function loss: 23.6941
                    Surrogate loss: -0.0079
             Mean action noise std: 1.00
                       Mean reward: -48.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3081600
                    Iteration time: 3.86s
                        Total time: 1626.90s
                               ETA: 5979.2s
################################################################################
                     [1m Learning iteration 428/2000 [0m                      

                       Computation: 1897 steps/s (collection: 3.109s, learning 0.685s)
               Value function loss: 26.4119
                    Surrogate loss: -0.0052
             Mean action noise std: 1.00
                       Mean reward: -47.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3088800
                    Iteration time: 3.79s
                        Total time: 1630.70s
                               ETA: 5975.4s
################################################################################
                     [1m Learning iteration 429/2000 [0m                      

                       Computation: 1863 steps/s (collection: 3.133s, learning 0.731s)
               Value function loss: 25.3289
                    Surrogate loss: -0.0031
             Mean action noise std: 1.00
                       Mean reward: -48.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3096000
                    Iteration time: 3.86s
                        Total time: 1634.56s
                               ETA: 5971.8s
################################################################################
                     [1m Learning iteration 430/2000 [0m                      

                       Computation: 1924 steps/s (collection: 3.125s, learning 0.617s)
               Value function loss: 23.5605
                    Surrogate loss: -0.0004
             Mean action noise std: 1.00
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3103200
                    Iteration time: 3.74s
                        Total time: 1638.30s
                               ETA: 5967.8s
################################################################################
                     [1m Learning iteration 431/2000 [0m                      

                       Computation: 1933 steps/s (collection: 3.110s, learning 0.614s)
               Value function loss: 26.9155
                    Surrogate loss: 0.0069
             Mean action noise std: 1.00
                       Mean reward: -48.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3110400
                    Iteration time: 3.72s
                        Total time: 1642.03s
                               ETA: 5963.7s
################################################################################
                     [1m Learning iteration 432/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.159s, learning 0.624s)
               Value function loss: 25.3559
                    Surrogate loss: -0.0002
             Mean action noise std: 0.99
                       Mean reward: -49.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3117600
                    Iteration time: 3.78s
                        Total time: 1645.81s
                               ETA: 5959.9s
################################################################################
                     [1m Learning iteration 433/2000 [0m                      

                       Computation: 1879 steps/s (collection: 3.107s, learning 0.723s)
               Value function loss: 24.2309
                    Surrogate loss: -0.0079
             Mean action noise std: 0.99
                       Mean reward: -49.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3124800
                    Iteration time: 3.83s
                        Total time: 1649.64s
                               ETA: 5956.2s
################################################################################
                     [1m Learning iteration 434/2000 [0m                      

                       Computation: 1858 steps/s (collection: 3.194s, learning 0.680s)
               Value function loss: 24.2236
                    Surrogate loss: -0.0013
             Mean action noise std: 1.00
                       Mean reward: -50.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3132000
                    Iteration time: 3.87s
                        Total time: 1653.51s
                               ETA: 5952.6s
################################################################################
                     [1m Learning iteration 435/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.112s, learning 0.691s)
               Value function loss: 23.7700
                    Surrogate loss: -0.0037
             Mean action noise std: 1.00
                       Mean reward: -49.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3139200
                    Iteration time: 3.80s
                        Total time: 1657.32s
                               ETA: 5948.9s
################################################################################
                     [1m Learning iteration 436/2000 [0m                      

                       Computation: 1909 steps/s (collection: 3.121s, learning 0.649s)
               Value function loss: 24.4002
                    Surrogate loss: -0.0010
             Mean action noise std: 1.00
                       Mean reward: -49.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3146400
                    Iteration time: 3.77s
                        Total time: 1661.09s
                               ETA: 5944.9s
################################################################################
                     [1m Learning iteration 437/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.044s, learning 0.705s)
               Value function loss: 24.2530
                    Surrogate loss: -0.0009
             Mean action noise std: 1.00
                       Mean reward: -49.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3153600
                    Iteration time: 3.75s
                        Total time: 1664.84s
                               ETA: 5941.0s
################################################################################
                     [1m Learning iteration 438/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.085s, learning 0.634s)
               Value function loss: 22.9255
                    Surrogate loss: 0.0022
             Mean action noise std: 1.00
                       Mean reward: -49.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3160800
                    Iteration time: 3.72s
                        Total time: 1668.55s
                               ETA: 5936.9s
################################################################################
                     [1m Learning iteration 439/2000 [0m                      

                       Computation: 1906 steps/s (collection: 3.139s, learning 0.638s)
               Value function loss: 25.3726
                    Surrogate loss: -0.0041
             Mean action noise std: 1.00
                       Mean reward: -48.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3168000
                    Iteration time: 3.78s
                        Total time: 1672.33s
                               ETA: 5933.0s
################################################################################
                     [1m Learning iteration 440/2000 [0m                      

                       Computation: 1906 steps/s (collection: 3.105s, learning 0.671s)
               Value function loss: 23.3869
                    Surrogate loss: -0.0004
             Mean action noise std: 1.00
                       Mean reward: -48.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3175200
                    Iteration time: 3.78s
                        Total time: 1676.11s
                               ETA: 5929.1s
################################################################################
                     [1m Learning iteration 441/2000 [0m                      

                       Computation: 1813 steps/s (collection: 3.194s, learning 0.777s)
               Value function loss: 22.5861
                    Surrogate loss: -0.0043
             Mean action noise std: 1.00
                       Mean reward: -48.73
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3182400
                    Iteration time: 3.97s
                        Total time: 1680.08s
                               ETA: 5925.9s
################################################################################
                     [1m Learning iteration 442/2000 [0m                      

                       Computation: 1934 steps/s (collection: 3.086s, learning 0.637s)
               Value function loss: 25.6486
                    Surrogate loss: -0.0059
             Mean action noise std: 1.00
                       Mean reward: -48.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3189600
                    Iteration time: 3.72s
                        Total time: 1683.80s
                               ETA: 5921.8s
################################################################################
                     [1m Learning iteration 443/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.110s, learning 0.628s)
               Value function loss: 24.8511
                    Surrogate loss: -0.0076
             Mean action noise std: 1.00
                       Mean reward: -48.57
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3196800
                    Iteration time: 3.74s
                        Total time: 1687.54s
                               ETA: 5917.8s
################################################################################
                     [1m Learning iteration 444/2000 [0m                      

                       Computation: 1894 steps/s (collection: 3.132s, learning 0.668s)
               Value function loss: 22.7728
                    Surrogate loss: -0.0030
             Mean action noise std: 1.00
                       Mean reward: -48.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3204000
                    Iteration time: 3.80s
                        Total time: 1691.34s
                               ETA: 5914.0s
################################################################################
                     [1m Learning iteration 445/2000 [0m                      

                       Computation: 1909 steps/s (collection: 3.078s, learning 0.693s)
               Value function loss: 21.7537
                    Surrogate loss: 0.0011
             Mean action noise std: 1.00
                       Mean reward: -48.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3211200
                    Iteration time: 3.77s
                        Total time: 1695.11s
                               ETA: 5910.1s
################################################################################
                     [1m Learning iteration 446/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.161s, learning 0.668s)
               Value function loss: 22.8619
                    Surrogate loss: -0.0038
             Mean action noise std: 1.00
                       Mean reward: -48.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3218400
                    Iteration time: 3.83s
                        Total time: 1698.94s
                               ETA: 5906.4s
################################################################################
                     [1m Learning iteration 447/2000 [0m                      

                       Computation: 1922 steps/s (collection: 3.111s, learning 0.634s)
               Value function loss: 23.7790
                    Surrogate loss: -0.0038
             Mean action noise std: 1.00
                       Mean reward: -49.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3225600
                    Iteration time: 3.74s
                        Total time: 1702.68s
                               ETA: 5902.4s
################################################################################
                     [1m Learning iteration 448/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.196s, learning 0.651s)
               Value function loss: 24.3668
                    Surrogate loss: -0.0034
             Mean action noise std: 1.00
                       Mean reward: -48.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3232800
                    Iteration time: 3.85s
                        Total time: 1706.53s
                               ETA: 5898.7s
################################################################################
                     [1m Learning iteration 449/2000 [0m                      

                       Computation: 1937 steps/s (collection: 3.098s, learning 0.618s)
               Value function loss: 21.6879
                    Surrogate loss: -0.0007
             Mean action noise std: 1.01
                       Mean reward: -48.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3240000
                    Iteration time: 3.72s
                        Total time: 1710.25s
                               ETA: 5894.6s
################################################################################
                     [1m Learning iteration 450/2000 [0m                      

                       Computation: 1900 steps/s (collection: 3.122s, learning 0.667s)
               Value function loss: 23.0568
                    Surrogate loss: -0.0070
             Mean action noise std: 1.01
                       Mean reward: -48.59
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3247200
                    Iteration time: 3.79s
                        Total time: 1714.04s
                               ETA: 5890.8s
################################################################################
                     [1m Learning iteration 451/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.130s, learning 0.607s)
               Value function loss: 22.3302
                    Surrogate loss: -0.0019
             Mean action noise std: 1.01
                       Mean reward: -48.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3254400
                    Iteration time: 3.74s
                        Total time: 1717.77s
                               ETA: 5886.8s
################################################################################
                     [1m Learning iteration 452/2000 [0m                      

                       Computation: 1934 steps/s (collection: 3.103s, learning 0.618s)
               Value function loss: 23.8261
                    Surrogate loss: -0.0029
             Mean action noise std: 1.01
                       Mean reward: -48.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3261600
                    Iteration time: 3.72s
                        Total time: 1721.49s
                               ETA: 5882.7s
################################################################################
                     [1m Learning iteration 453/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.114s, learning 0.633s)
               Value function loss: 23.3471
                    Surrogate loss: -0.0045
             Mean action noise std: 1.01
                       Mean reward: -48.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3268800
                    Iteration time: 3.75s
                        Total time: 1725.24s
                               ETA: 5878.7s
################################################################################
                     [1m Learning iteration 454/2000 [0m                      

                       Computation: 1922 steps/s (collection: 3.125s, learning 0.620s)
               Value function loss: 22.3986
                    Surrogate loss: -0.0004
             Mean action noise std: 1.01
                       Mean reward: -48.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3276000
                    Iteration time: 3.74s
                        Total time: 1728.98s
                               ETA: 5874.7s
################################################################################
                     [1m Learning iteration 455/2000 [0m                      

                       Computation: 1907 steps/s (collection: 3.159s, learning 0.616s)
               Value function loss: 24.8533
                    Surrogate loss: -0.0003
             Mean action noise std: 1.01
                       Mean reward: -48.59
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3283200
                    Iteration time: 3.77s
                        Total time: 1732.76s
                               ETA: 5870.9s
################################################################################
                     [1m Learning iteration 456/2000 [0m                      

                       Computation: 1940 steps/s (collection: 3.079s, learning 0.631s)
               Value function loss: 25.0342
                    Surrogate loss: 0.0014
             Mean action noise std: 1.01
                       Mean reward: -49.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3290400
                    Iteration time: 3.71s
                        Total time: 1736.47s
                               ETA: 5866.8s
################################################################################
                     [1m Learning iteration 457/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.156s, learning 0.685s)
               Value function loss: 21.9704
                    Surrogate loss: -0.0024
             Mean action noise std: 1.01
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3297600
                    Iteration time: 3.84s
                        Total time: 1740.31s
                               ETA: 5863.1s
################################################################################
                     [1m Learning iteration 458/2000 [0m                      

                       Computation: 1942 steps/s (collection: 3.087s, learning 0.620s)
               Value function loss: 23.2846
                    Surrogate loss: -0.0034
             Mean action noise std: 1.01
                       Mean reward: -49.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3304800
                    Iteration time: 3.71s
                        Total time: 1744.02s
                               ETA: 5859.0s
################################################################################
                     [1m Learning iteration 459/2000 [0m                      

                       Computation: 1929 steps/s (collection: 3.080s, learning 0.653s)
               Value function loss: 22.1231
                    Surrogate loss: -0.0019
             Mean action noise std: 1.01
                       Mean reward: -49.06
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3312000
                    Iteration time: 3.73s
                        Total time: 1747.75s
                               ETA: 5855.0s
################################################################################
                     [1m Learning iteration 460/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.103s, learning 0.647s)
               Value function loss: 21.3512
                    Surrogate loss: -0.0019
             Mean action noise std: 1.01
                       Mean reward: -49.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3319200
                    Iteration time: 3.75s
                        Total time: 1751.50s
                               ETA: 5851.0s
################################################################################
                     [1m Learning iteration 461/2000 [0m                      

                       Computation: 1952 steps/s (collection: 3.080s, learning 0.607s)
               Value function loss: 21.9459
                    Surrogate loss: -0.0085
             Mean action noise std: 1.01
                       Mean reward: -48.57
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3326400
                    Iteration time: 3.69s
                        Total time: 1755.19s
                               ETA: 5846.8s
################################################################################
                     [1m Learning iteration 462/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.117s, learning 0.618s)
               Value function loss: 23.1733
                    Surrogate loss: 0.0017
             Mean action noise std: 1.01
                       Mean reward: -48.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3333600
                    Iteration time: 3.74s
                        Total time: 1758.92s
                               ETA: 5842.8s
################################################################################
                     [1m Learning iteration 463/2000 [0m                      

                       Computation: 1951 steps/s (collection: 3.075s, learning 0.615s)
               Value function loss: 20.9465
                    Surrogate loss: 0.0051
             Mean action noise std: 1.01
                       Mean reward: -48.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3340800
                    Iteration time: 3.69s
                        Total time: 1762.61s
                               ETA: 5838.6s
################################################################################
                     [1m Learning iteration 464/2000 [0m                      

                       Computation: 1868 steps/s (collection: 3.117s, learning 0.737s)
               Value function loss: 24.7145
                    Surrogate loss: -0.0037
             Mean action noise std: 1.01
                       Mean reward: -48.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3348000
                    Iteration time: 3.85s
                        Total time: 1766.46s
                               ETA: 5835.0s
################################################################################
                     [1m Learning iteration 465/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.073s, learning 0.754s)
               Value function loss: 22.1702
                    Surrogate loss: -0.0051
             Mean action noise std: 1.01
                       Mean reward: -48.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3355200
                    Iteration time: 3.83s
                        Total time: 1770.29s
                               ETA: 5831.3s
################################################################################
                     [1m Learning iteration 466/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.049s, learning 0.780s)
               Value function loss: 22.6762
                    Surrogate loss: -0.0040
             Mean action noise std: 1.01
                       Mean reward: -48.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3362400
                    Iteration time: 3.83s
                        Total time: 1774.12s
                               ETA: 5827.6s
################################################################################
                     [1m Learning iteration 467/2000 [0m                      

                       Computation: 1937 steps/s (collection: 3.075s, learning 0.641s)
               Value function loss: 22.0938
                    Surrogate loss: -0.0075
             Mean action noise std: 1.01
                       Mean reward: -49.10
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3369600
                    Iteration time: 3.72s
                        Total time: 1777.83s
                               ETA: 5823.5s
################################################################################
                     [1m Learning iteration 468/2000 [0m                      

                       Computation: 1949 steps/s (collection: 3.048s, learning 0.646s)
               Value function loss: 21.2791
                    Surrogate loss: -0.0044
             Mean action noise std: 1.01
                       Mean reward: -49.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3376800
                    Iteration time: 3.69s
                        Total time: 1781.53s
                               ETA: 5819.4s
################################################################################
                     [1m Learning iteration 469/2000 [0m                      

                       Computation: 1843 steps/s (collection: 3.108s, learning 0.797s)
               Value function loss: 22.3316
                    Surrogate loss: 0.0012
             Mean action noise std: 1.01
                       Mean reward: -49.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3384000
                    Iteration time: 3.90s
                        Total time: 1785.43s
                               ETA: 5816.0s
################################################################################
                     [1m Learning iteration 470/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.057s, learning 0.764s)
               Value function loss: 23.3540
                    Surrogate loss: -0.0018
             Mean action noise std: 1.01
                       Mean reward: -49.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3391200
                    Iteration time: 3.82s
                        Total time: 1789.26s
                               ETA: 5812.2s
################################################################################
                     [1m Learning iteration 471/2000 [0m                      

                       Computation: 1834 steps/s (collection: 3.138s, learning 0.787s)
               Value function loss: 24.5818
                    Surrogate loss: -0.0055
             Mean action noise std: 1.01
                       Mean reward: -49.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3398400
                    Iteration time: 3.92s
                        Total time: 1793.18s
                               ETA: 5808.8s
################################################################################
                     [1m Learning iteration 472/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.046s, learning 0.783s)
               Value function loss: 21.1353
                    Surrogate loss: -0.0031
             Mean action noise std: 1.01
                       Mean reward: -49.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3405600
                    Iteration time: 3.83s
                        Total time: 1797.01s
                               ETA: 5805.1s
################################################################################
                     [1m Learning iteration 473/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.054s, learning 0.796s)
               Value function loss: 18.8999
                    Surrogate loss: 0.0013
             Mean action noise std: 1.01
                       Mean reward: -49.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3412800
                    Iteration time: 3.85s
                        Total time: 1800.86s
                               ETA: 5801.5s
################################################################################
                     [1m Learning iteration 474/2000 [0m                      

                       Computation: 1865 steps/s (collection: 3.077s, learning 0.782s)
               Value function loss: 21.5776
                    Surrogate loss: -0.0064
             Mean action noise std: 1.01
                       Mean reward: -49.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3420000
                    Iteration time: 3.86s
                        Total time: 1804.72s
                               ETA: 5797.9s
################################################################################
                     [1m Learning iteration 475/2000 [0m                      

                       Computation: 1894 steps/s (collection: 3.052s, learning 0.748s)
               Value function loss: 23.3068
                    Surrogate loss: 0.0004
             Mean action noise std: 1.01
                       Mean reward: -49.02
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3427200
                    Iteration time: 3.80s
                        Total time: 1808.52s
                               ETA: 5794.1s
################################################################################
                     [1m Learning iteration 476/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.166s, learning 0.751s)
               Value function loss: 23.1952
                    Surrogate loss: -0.0034
             Mean action noise std: 1.01
                       Mean reward: -48.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3434400
                    Iteration time: 3.92s
                        Total time: 1812.43s
                               ETA: 5790.7s
################################################################################
                     [1m Learning iteration 477/2000 [0m                      

                       Computation: 1961 steps/s (collection: 3.045s, learning 0.626s)
               Value function loss: 21.9761
                    Surrogate loss: -0.0033
             Mean action noise std: 1.01
                       Mean reward: -49.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3441600
                    Iteration time: 3.67s
                        Total time: 1816.11s
                               ETA: 5786.5s
################################################################################
                     [1m Learning iteration 478/2000 [0m                      

                       Computation: 1939 steps/s (collection: 3.095s, learning 0.617s)
               Value function loss: 22.3273
                    Surrogate loss: 0.0024
             Mean action noise std: 1.01
                       Mean reward: -49.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3448800
                    Iteration time: 3.71s
                        Total time: 1819.82s
                               ETA: 5782.4s
################################################################################
                     [1m Learning iteration 479/2000 [0m                      

                       Computation: 1958 steps/s (collection: 3.054s, learning 0.623s)
               Value function loss: 21.3729
                    Surrogate loss: -0.0032
             Mean action noise std: 1.01
                       Mean reward: -50.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3456000
                    Iteration time: 3.68s
                        Total time: 1823.50s
                               ETA: 5778.2s
################################################################################
                     [1m Learning iteration 480/2000 [0m                      

                       Computation: 1966 steps/s (collection: 3.042s, learning 0.620s)
               Value function loss: 22.6827
                    Surrogate loss: -0.0034
             Mean action noise std: 1.02
                       Mean reward: -50.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3463200
                    Iteration time: 3.66s
                        Total time: 1827.16s
                               ETA: 5774.0s
################################################################################
                     [1m Learning iteration 481/2000 [0m                      

                       Computation: 1911 steps/s (collection: 3.087s, learning 0.680s)
               Value function loss: 22.5279
                    Surrogate loss: 0.0193
             Mean action noise std: 1.02
                       Mean reward: -50.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3470400
                    Iteration time: 3.77s
                        Total time: 1830.92s
                               ETA: 5770.1s
################################################################################
                     [1m Learning iteration 482/2000 [0m                      

                       Computation: 1966 steps/s (collection: 3.043s, learning 0.618s)
               Value function loss: 20.0892
                    Surrogate loss: 0.0322
             Mean action noise std: 1.02
                       Mean reward: -49.98
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3477600
                    Iteration time: 3.66s
                        Total time: 1834.58s
                               ETA: 5765.8s
################################################################################
                     [1m Learning iteration 483/2000 [0m                      

                       Computation: 1940 steps/s (collection: 3.093s, learning 0.617s)
               Value function loss: 25.6564
                    Surrogate loss: -0.0032
             Mean action noise std: 1.02
                       Mean reward: -49.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3484800
                    Iteration time: 3.71s
                        Total time: 1838.29s
                               ETA: 5761.8s
################################################################################
                     [1m Learning iteration 484/2000 [0m                      

                       Computation: 1968 steps/s (collection: 3.044s, learning 0.613s)
               Value function loss: 20.8209
                    Surrogate loss: -0.0001
             Mean action noise std: 1.02
                       Mean reward: -49.51
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3492000
                    Iteration time: 3.66s
                        Total time: 1841.95s
                               ETA: 5757.5s
################################################################################
                     [1m Learning iteration 485/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.094s, learning 0.686s)
               Value function loss: 20.8411
                    Surrogate loss: 0.0036
             Mean action noise std: 1.02
                       Mean reward: -49.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3499200
                    Iteration time: 3.78s
                        Total time: 1845.73s
                               ETA: 5753.7s
################################################################################
                     [1m Learning iteration 486/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.034s, learning 0.712s)
               Value function loss: 20.4820
                    Surrogate loss: -0.0003
             Mean action noise std: 1.02
                       Mean reward: -49.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3506400
                    Iteration time: 3.75s
                        Total time: 1849.48s
                               ETA: 5749.7s
################################################################################
                     [1m Learning iteration 487/2000 [0m                      

                       Computation: 1958 steps/s (collection: 3.049s, learning 0.627s)
               Value function loss: 21.4569
                    Surrogate loss: 0.0006
             Mean action noise std: 1.02
                       Mean reward: -48.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3513600
                    Iteration time: 3.68s
                        Total time: 1853.15s
                               ETA: 5745.5s
################################################################################
                     [1m Learning iteration 488/2000 [0m                      

                       Computation: 1949 steps/s (collection: 3.064s, learning 0.629s)
               Value function loss: 20.4797
                    Surrogate loss: -0.0065
             Mean action noise std: 1.02
                       Mean reward: -48.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3520800
                    Iteration time: 3.69s
                        Total time: 1856.85s
                               ETA: 5741.4s
################################################################################
                     [1m Learning iteration 489/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.028s, learning 0.797s)
               Value function loss: 19.2091
                    Surrogate loss: -0.0016
             Mean action noise std: 1.02
                       Mean reward: -49.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3528000
                    Iteration time: 3.83s
                        Total time: 1860.67s
                               ETA: 5737.7s
################################################################################
                     [1m Learning iteration 490/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.070s, learning 0.779s)
               Value function loss: 17.3036
                    Surrogate loss: -0.0060
             Mean action noise std: 1.02
                       Mean reward: -49.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3535200
                    Iteration time: 3.85s
                        Total time: 1864.52s
                               ETA: 5734.1s
################################################################################
                     [1m Learning iteration 491/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.004s, learning 0.722s)
               Value function loss: 19.1755
                    Surrogate loss: 0.0198
             Mean action noise std: 1.02
                       Mean reward: -49.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3542400
                    Iteration time: 3.73s
                        Total time: 1868.25s
                               ETA: 5730.1s
################################################################################
                     [1m Learning iteration 492/2000 [0m                      

                       Computation: 1789 steps/s (collection: 3.089s, learning 0.935s)
               Value function loss: 19.8092
                    Surrogate loss: -0.0038
             Mean action noise std: 1.02
                       Mean reward: -50.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3549600
                    Iteration time: 4.02s
                        Total time: 1872.27s
                               ETA: 5727.0s
################################################################################
                     [1m Learning iteration 493/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.029s, learning 0.804s)
               Value function loss: 17.7930
                    Surrogate loss: -0.0026
             Mean action noise std: 1.02
                       Mean reward: -50.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3556800
                    Iteration time: 3.83s
                        Total time: 1876.11s
                               ETA: 5723.3s
################################################################################
                     [1m Learning iteration 494/2000 [0m                      

                       Computation: 1890 steps/s (collection: 3.057s, learning 0.750s)
               Value function loss: 18.1709
                    Surrogate loss: 0.0026
             Mean action noise std: 1.02
                       Mean reward: -49.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3564000
                    Iteration time: 3.81s
                        Total time: 1879.91s
                               ETA: 5719.5s
################################################################################
                     [1m Learning iteration 495/2000 [0m                      

                       Computation: 1875 steps/s (collection: 3.076s, learning 0.764s)
               Value function loss: 15.7132
                    Surrogate loss: -0.0066
             Mean action noise std: 1.02
                       Mean reward: -49.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3571200
                    Iteration time: 3.84s
                        Total time: 1883.75s
                               ETA: 5715.8s
################################################################################
                     [1m Learning iteration 496/2000 [0m                      

                       Computation: 1897 steps/s (collection: 3.016s, learning 0.778s)
               Value function loss: 15.7726
                    Surrogate loss: -0.0060
             Mean action noise std: 1.02
                       Mean reward: -49.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3578400
                    Iteration time: 3.79s
                        Total time: 1887.55s
                               ETA: 5712.0s
################################################################################
                     [1m Learning iteration 497/2000 [0m                      

                       Computation: 1934 steps/s (collection: 3.082s, learning 0.640s)
               Value function loss: 15.5340
                    Surrogate loss: -0.0017
             Mean action noise std: 1.02
                       Mean reward: -49.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3585600
                    Iteration time: 3.72s
                        Total time: 1891.27s
                               ETA: 5708.0s
################################################################################
                     [1m Learning iteration 498/2000 [0m                      

                       Computation: 1980 steps/s (collection: 3.016s, learning 0.620s)
               Value function loss: 17.6601
                    Surrogate loss: -0.0008
             Mean action noise std: 1.02
                       Mean reward: -49.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3592800
                    Iteration time: 3.64s
                        Total time: 1894.91s
                               ETA: 5703.7s
################################################################################
                     [1m Learning iteration 499/2000 [0m                      

                       Computation: 1909 steps/s (collection: 3.122s, learning 0.648s)
               Value function loss: 18.3097
                    Surrogate loss: 0.0079
             Mean action noise std: 1.02
                       Mean reward: -49.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3600000
                    Iteration time: 3.77s
                        Total time: 1898.68s
                               ETA: 5699.8s
################################################################################
                     [1m Learning iteration 500/2000 [0m                      

                       Computation: 1981 steps/s (collection: 3.013s, learning 0.620s)
               Value function loss: 18.5448
                    Surrogate loss: -0.0043
             Mean action noise std: 1.02
                       Mean reward: -50.12
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3607200
                    Iteration time: 3.63s
                        Total time: 1902.31s
                               ETA: 5695.5s
################################################################################
                     [1m Learning iteration 501/2000 [0m                      

                       Computation: 1932 steps/s (collection: 3.093s, learning 0.633s)
               Value function loss: 15.1839
                    Surrogate loss: 0.0018
             Mean action noise std: 1.02
                       Mean reward: -49.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3614400
                    Iteration time: 3.73s
                        Total time: 1906.04s
                               ETA: 5691.5s
################################################################################
                     [1m Learning iteration 502/2000 [0m                      

                       Computation: 1952 steps/s (collection: 3.057s, learning 0.630s)
               Value function loss: 17.5800
                    Surrogate loss: -0.0064
             Mean action noise std: 1.02
                       Mean reward: -49.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3621600
                    Iteration time: 3.69s
                        Total time: 1909.72s
                               ETA: 5687.4s
################################################################################
                     [1m Learning iteration 503/2000 [0m                      

                       Computation: 1978 steps/s (collection: 3.034s, learning 0.604s)
               Value function loss: 17.2594
                    Surrogate loss: 0.0002
             Mean action noise std: 1.02
                       Mean reward: -49.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3628800
                    Iteration time: 3.64s
                        Total time: 1913.36s
                               ETA: 5683.1s
################################################################################
                     [1m Learning iteration 504/2000 [0m                      

                       Computation: 1937 steps/s (collection: 3.103s, learning 0.614s)
               Value function loss: 15.0051
                    Surrogate loss: -0.0039
             Mean action noise std: 1.02
                       Mean reward: -49.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3636000
                    Iteration time: 3.72s
                        Total time: 1917.08s
                               ETA: 5679.1s
################################################################################
                     [1m Learning iteration 505/2000 [0m                      

                       Computation: 1968 steps/s (collection: 3.023s, learning 0.635s)
               Value function loss: 14.6015
                    Surrogate loss: -0.0030
             Mean action noise std: 1.02
                       Mean reward: -49.14
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3643200
                    Iteration time: 3.66s
                        Total time: 1920.74s
                               ETA: 5674.9s
################################################################################
                     [1m Learning iteration 506/2000 [0m                      

                       Computation: 1937 steps/s (collection: 3.079s, learning 0.638s)
               Value function loss: 13.6496
                    Surrogate loss: -0.0003
             Mean action noise std: 1.02
                       Mean reward: -48.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3650400
                    Iteration time: 3.72s
                        Total time: 1924.45s
                               ETA: 5670.9s
################################################################################
                     [1m Learning iteration 507/2000 [0m                      

                       Computation: 1971 steps/s (collection: 3.038s, learning 0.613s)
               Value function loss: 16.2050
                    Surrogate loss: 0.0114
             Mean action noise std: 1.02
                       Mean reward: -49.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3657600
                    Iteration time: 3.65s
                        Total time: 1928.10s
                               ETA: 5666.7s
################################################################################
                     [1m Learning iteration 508/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.119s, learning 0.618s)
               Value function loss: 16.5220
                    Surrogate loss: -0.0046
             Mean action noise std: 1.02
                       Mean reward: -49.06
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3664800
                    Iteration time: 3.74s
                        Total time: 1931.84s
                               ETA: 5662.7s
################################################################################
                     [1m Learning iteration 509/2000 [0m                      

                       Computation: 1974 steps/s (collection: 3.018s, learning 0.628s)
               Value function loss: 14.6244
                    Surrogate loss: -0.0007
             Mean action noise std: 1.02
                       Mean reward: -49.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3672000
                    Iteration time: 3.65s
                        Total time: 1935.49s
                               ETA: 5658.5s
################################################################################
                     [1m Learning iteration 510/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.062s, learning 0.743s)
               Value function loss: 12.5656
                    Surrogate loss: -0.0047
             Mean action noise std: 1.02
                       Mean reward: -49.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3679200
                    Iteration time: 3.80s
                        Total time: 1939.29s
                               ETA: 5654.7s
################################################################################
                     [1m Learning iteration 511/2000 [0m                      

                       Computation: 1932 steps/s (collection: 3.040s, learning 0.686s)
               Value function loss: 16.2998
                    Surrogate loss: -0.0070
             Mean action noise std: 1.02
                       Mean reward: -48.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3686400
                    Iteration time: 3.73s
                        Total time: 1943.02s
                               ETA: 5650.7s
################################################################################
                     [1m Learning iteration 512/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.033s, learning 0.729s)
               Value function loss: 19.3428
                    Surrogate loss: -0.0038
             Mean action noise std: 1.02
                       Mean reward: -49.02
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3693600
                    Iteration time: 3.76s
                        Total time: 1946.78s
                               ETA: 5646.8s
################################################################################
                     [1m Learning iteration 513/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.106s, learning 0.713s)
               Value function loss: 20.9096
                    Surrogate loss: -0.0046
             Mean action noise std: 1.02
                       Mean reward: -49.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3700800
                    Iteration time: 3.82s
                        Total time: 1950.60s
                               ETA: 5643.1s
################################################################################
                     [1m Learning iteration 514/2000 [0m                      

                       Computation: 1917 steps/s (collection: 3.035s, learning 0.720s)
               Value function loss: 18.6666
                    Surrogate loss: -0.0007
             Mean action noise std: 1.02
                       Mean reward: -48.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3708000
                    Iteration time: 3.76s
                        Total time: 1954.36s
                               ETA: 5639.2s
################################################################################
                     [1m Learning iteration 515/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.091s, learning 0.666s)
               Value function loss: 16.6613
                    Surrogate loss: -0.0030
             Mean action noise std: 1.02
                       Mean reward: -49.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3715200
                    Iteration time: 3.76s
                        Total time: 1958.11s
                               ETA: 5635.3s
################################################################################
                     [1m Learning iteration 516/2000 [0m                      

                       Computation: 1959 steps/s (collection: 3.025s, learning 0.650s)
               Value function loss: 15.9149
                    Surrogate loss: -0.0053
             Mean action noise std: 1.02
                       Mean reward: -49.12
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3722400
                    Iteration time: 3.67s
                        Total time: 1961.79s
                               ETA: 5631.1s
################################################################################
                     [1m Learning iteration 517/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.105s, learning 0.657s)
               Value function loss: 14.5926
                    Surrogate loss: -0.0064
             Mean action noise std: 1.02
                       Mean reward: -49.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3729600
                    Iteration time: 3.76s
                        Total time: 1965.55s
                               ETA: 5627.2s
################################################################################
                     [1m Learning iteration 518/2000 [0m                      

                       Computation: 1945 steps/s (collection: 3.039s, learning 0.662s)
               Value function loss: 16.3380
                    Surrogate loss: -0.0050
             Mean action noise std: 1.02
                       Mean reward: -49.59
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3736800
                    Iteration time: 3.70s
                        Total time: 1969.25s
                               ETA: 5623.2s
################################################################################
                     [1m Learning iteration 519/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.021s, learning 0.811s)
               Value function loss: 14.8895
                    Surrogate loss: 0.0137
             Mean action noise std: 1.02
                       Mean reward: -49.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3744000
                    Iteration time: 3.83s
                        Total time: 1973.08s
                               ETA: 5619.5s
################################################################################
                     [1m Learning iteration 520/2000 [0m                      

                       Computation: 1936 steps/s (collection: 3.092s, learning 0.627s)
               Value function loss: 14.7484
                    Surrogate loss: -0.0014
             Mean action noise std: 1.02
                       Mean reward: -49.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3751200
                    Iteration time: 3.72s
                        Total time: 1976.80s
                               ETA: 5615.5s
################################################################################
                     [1m Learning iteration 521/2000 [0m                      

                       Computation: 1977 steps/s (collection: 3.032s, learning 0.608s)
               Value function loss: 16.6164
                    Surrogate loss: -0.0052
             Mean action noise std: 1.02
                       Mean reward: -50.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3758400
                    Iteration time: 3.64s
                        Total time: 1980.44s
                               ETA: 5611.2s
################################################################################
                     [1m Learning iteration 522/2000 [0m                      

                       Computation: 1817 steps/s (collection: 3.106s, learning 0.855s)
               Value function loss: 19.0408
                    Surrogate loss: -0.0034
             Mean action noise std: 1.02
                       Mean reward: -50.39
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3765600
                    Iteration time: 3.96s
                        Total time: 1984.40s
                               ETA: 5607.9s
################################################################################
                     [1m Learning iteration 523/2000 [0m                      

                       Computation: 1893 steps/s (collection: 3.022s, learning 0.780s)
               Value function loss: 13.9923
                    Surrogate loss: 0.0016
             Mean action noise std: 1.02
                       Mean reward: -50.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3772800
                    Iteration time: 3.80s
                        Total time: 1988.21s
                               ETA: 5604.2s
################################################################################
                     [1m Learning iteration 524/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.144s, learning 0.649s)
               Value function loss: 15.1302
                    Surrogate loss: -0.0035
             Mean action noise std: 1.02
                       Mean reward: -50.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.14
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3780000
                    Iteration time: 3.79s
                        Total time: 1992.00s
                               ETA: 5600.4s
################################################################################
                     [1m Learning iteration 525/2000 [0m                      

                       Computation: 1960 steps/s (collection: 3.065s, learning 0.608s)
               Value function loss: 15.3655
                    Surrogate loss: -0.0056
             Mean action noise std: 1.02
                       Mean reward: -50.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3787200
                    Iteration time: 3.67s
                        Total time: 1995.67s
                               ETA: 5596.2s
################################################################################
                     [1m Learning iteration 526/2000 [0m                      

                       Computation: 1905 steps/s (collection: 3.136s, learning 0.642s)
               Value function loss: 13.9886
                    Surrogate loss: -0.0051
             Mean action noise std: 1.02
                       Mean reward: -50.02
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3794400
                    Iteration time: 3.78s
                        Total time: 1999.45s
                               ETA: 5592.4s
################################################################################
                     [1m Learning iteration 527/2000 [0m                      

                       Computation: 1922 steps/s (collection: 3.083s, learning 0.662s)
               Value function loss: 12.7639
                    Surrogate loss: 0.0105
             Mean action noise std: 1.02
                       Mean reward: -49.65
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3801600
                    Iteration time: 3.74s
                        Total time: 2003.19s
                               ETA: 5588.5s
################################################################################
                     [1m Learning iteration 528/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.037s, learning 0.745s)
               Value function loss: 16.6035
                    Surrogate loss: -0.0020
             Mean action noise std: 1.02
                       Mean reward: -49.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3808800
                    Iteration time: 3.78s
                        Total time: 2006.98s
                               ETA: 5584.6s
################################################################################
                     [1m Learning iteration 529/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.093s, learning 0.797s)
               Value function loss: 15.4747
                    Surrogate loss: -0.0044
             Mean action noise std: 1.02
                       Mean reward: -48.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3816000
                    Iteration time: 3.89s
                        Total time: 2010.87s
                               ETA: 5581.1s
################################################################################
                     [1m Learning iteration 530/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.026s, learning 0.754s)
               Value function loss: 13.6864
                    Surrogate loss: -0.0018
             Mean action noise std: 1.02
                       Mean reward: -49.33
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.15
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3823200
                    Iteration time: 3.78s
                        Total time: 2014.65s
                               ETA: 5577.3s
################################################################################
                     [1m Learning iteration 531/2000 [0m                      

                       Computation: 1866 steps/s (collection: 3.096s, learning 0.761s)
               Value function loss: 12.1891
                    Surrogate loss: 0.0014
             Mean action noise std: 1.02
                       Mean reward: -49.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3830400
                    Iteration time: 3.86s
                        Total time: 2018.50s
                               ETA: 5573.6s
################################################################################
                     [1m Learning iteration 532/2000 [0m                      

                       Computation: 1968 steps/s (collection: 3.018s, learning 0.641s)
               Value function loss: 15.5444
                    Surrogate loss: -0.0007
             Mean action noise std: 1.02
                       Mean reward: -49.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3837600
                    Iteration time: 3.66s
                        Total time: 2022.16s
                               ETA: 5569.5s
################################################################################
                     [1m Learning iteration 533/2000 [0m                      

                       Computation: 1954 steps/s (collection: 3.052s, learning 0.632s)
               Value function loss: 13.9505
                    Surrogate loss: -0.0020
             Mean action noise std: 1.02
                       Mean reward: -49.78
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3844800
                    Iteration time: 3.68s
                        Total time: 2025.84s
                               ETA: 5565.4s
################################################################################
                     [1m Learning iteration 534/2000 [0m                      

                       Computation: 1934 steps/s (collection: 3.093s, learning 0.629s)
               Value function loss: 15.1418
                    Surrogate loss: 0.0017
             Mean action noise std: 1.02
                       Mean reward: -49.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3852000
                    Iteration time: 3.72s
                        Total time: 2029.57s
                               ETA: 5561.4s
################################################################################
                     [1m Learning iteration 535/2000 [0m                      

                       Computation: 1951 steps/s (collection: 3.033s, learning 0.655s)
               Value function loss: 13.4221
                    Surrogate loss: -0.0030
             Mean action noise std: 1.02
                       Mean reward: -49.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3859200
                    Iteration time: 3.69s
                        Total time: 2033.26s
                               ETA: 5557.3s
################################################################################
                     [1m Learning iteration 536/2000 [0m                      

                       Computation: 1943 steps/s (collection: 3.068s, learning 0.637s)
               Value function loss: 10.8070
                    Surrogate loss: -0.0019
             Mean action noise std: 1.02
                       Mean reward: -49.26
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3866400
                    Iteration time: 3.71s
                        Total time: 2036.96s
                               ETA: 5553.3s
################################################################################
                     [1m Learning iteration 537/2000 [0m                      

                       Computation: 1978 steps/s (collection: 3.028s, learning 0.612s)
               Value function loss: 12.2114
                    Surrogate loss: -0.0030
             Mean action noise std: 1.02
                       Mean reward: -49.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3873600
                    Iteration time: 3.64s
                        Total time: 2040.60s
                               ETA: 5549.1s
################################################################################
                     [1m Learning iteration 538/2000 [0m                      

                       Computation: 1925 steps/s (collection: 3.077s, learning 0.662s)
               Value function loss: 13.7195
                    Surrogate loss: -0.0043
             Mean action noise std: 1.02
                       Mean reward: -49.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3880800
                    Iteration time: 3.74s
                        Total time: 2044.34s
                               ETA: 5545.1s
################################################################################
                     [1m Learning iteration 539/2000 [0m                      

                       Computation: 1959 steps/s (collection: 3.052s, learning 0.623s)
               Value function loss: 13.4831
                    Surrogate loss: -0.0035
             Mean action noise std: 1.02
                       Mean reward: -49.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3888000
                    Iteration time: 3.67s
                        Total time: 2048.01s
                               ETA: 5541.0s
################################################################################
                     [1m Learning iteration 540/2000 [0m                      

                       Computation: 1932 steps/s (collection: 3.079s, learning 0.647s)
               Value function loss: 23.9854
                    Surrogate loss: 0.0043
             Mean action noise std: 1.01
                       Mean reward: -49.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3895200
                    Iteration time: 3.73s
                        Total time: 2051.74s
                               ETA: 5537.0s
################################################################################
                     [1m Learning iteration 541/2000 [0m                      

                       Computation: 1960 steps/s (collection: 3.018s, learning 0.654s)
               Value function loss: 14.3050
                    Surrogate loss: 0.0005
             Mean action noise std: 1.01
                       Mean reward: -49.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3902400
                    Iteration time: 3.67s
                        Total time: 2055.41s
                               ETA: 5532.9s
################################################################################
                     [1m Learning iteration 542/2000 [0m                      

                       Computation: 1969 steps/s (collection: 2.965s, learning 0.692s)
               Value function loss: 14.4215
                    Surrogate loss: -0.0031
             Mean action noise std: 1.01
                       Mean reward: -49.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3909600
                    Iteration time: 3.66s
                        Total time: 2059.07s
                               ETA: 5528.8s
################################################################################
                     [1m Learning iteration 543/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.236s, learning 0.633s)
               Value function loss: 13.0128
                    Surrogate loss: -0.0040
             Mean action noise std: 1.01
                       Mean reward: -48.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3916800
                    Iteration time: 3.87s
                        Total time: 2062.94s
                               ETA: 5525.2s
################################################################################
                     [1m Learning iteration 544/2000 [0m                      

                       Computation: 1903 steps/s (collection: 3.033s, learning 0.749s)
               Value function loss: 13.3639
                    Surrogate loss: 0.0006
             Mean action noise std: 1.01
                       Mean reward: -49.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3924000
                    Iteration time: 3.78s
                        Total time: 2066.72s
                               ETA: 5521.4s
################################################################################
                     [1m Learning iteration 545/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.104s, learning 0.788s)
               Value function loss: 14.4550
                    Surrogate loss: 0.0087
             Mean action noise std: 1.01
                       Mean reward: -49.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3931200
                    Iteration time: 3.89s
                        Total time: 2070.61s
                               ETA: 5517.8s
################################################################################
                     [1m Learning iteration 546/2000 [0m                      

                       Computation: 1897 steps/s (collection: 3.030s, learning 0.765s)
               Value function loss: 13.6805
                    Surrogate loss: -0.0039
             Mean action noise std: 1.01
                       Mean reward: -49.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3938400
                    Iteration time: 3.79s
                        Total time: 2074.40s
                               ETA: 5514.0s
################################################################################
                     [1m Learning iteration 547/2000 [0m                      

                       Computation: 1866 steps/s (collection: 3.088s, learning 0.770s)
               Value function loss: 13.0871
                    Surrogate loss: -0.0070
             Mean action noise std: 1.01
                       Mean reward: -49.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3945600
                    Iteration time: 3.86s
                        Total time: 2078.26s
                               ETA: 5510.4s
################################################################################
                     [1m Learning iteration 548/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.066s, learning 0.782s)
               Value function loss: 14.7914
                    Surrogate loss: 0.0066
             Mean action noise std: 1.01
                       Mean reward: -49.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3952800
                    Iteration time: 3.85s
                        Total time: 2082.11s
                               ETA: 5506.8s
################################################################################
                     [1m Learning iteration 549/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.030s, learning 0.787s)
               Value function loss: 13.9335
                    Surrogate loss: 0.0025
             Mean action noise std: 1.01
                       Mean reward: -48.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3960000
                    Iteration time: 3.82s
                        Total time: 2085.93s
                               ETA: 5503.1s
################################################################################
                     [1m Learning iteration 550/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.106s, learning 0.741s)
               Value function loss: 11.9388
                    Surrogate loss: -0.0035
             Mean action noise std: 1.01
                       Mean reward: -48.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3967200
                    Iteration time: 3.85s
                        Total time: 2089.78s
                               ETA: 5499.4s
################################################################################
                     [1m Learning iteration 551/2000 [0m                      

                       Computation: 1938 steps/s (collection: 3.029s, learning 0.685s)
               Value function loss: 13.9290
                    Surrogate loss: -0.0039
             Mean action noise std: 1.01
                       Mean reward: -49.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3974400
                    Iteration time: 3.71s
                        Total time: 2093.49s
                               ETA: 5495.4s
################################################################################
                     [1m Learning iteration 552/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.117s, learning 0.620s)
               Value function loss: 13.9794
                    Surrogate loss: 0.0044
             Mean action noise std: 1.01
                       Mean reward: -49.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3981600
                    Iteration time: 3.74s
                        Total time: 2097.23s
                               ETA: 5491.5s
################################################################################
                     [1m Learning iteration 553/2000 [0m                      

                       Computation: 1974 steps/s (collection: 3.014s, learning 0.632s)
               Value function loss: 11.3726
                    Surrogate loss: 0.0072
             Mean action noise std: 1.01
                       Mean reward: -49.28
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3988800
                    Iteration time: 3.65s
                        Total time: 2100.87s
                               ETA: 5487.3s
################################################################################
                     [1m Learning iteration 554/2000 [0m                      

                       Computation: 1922 steps/s (collection: 3.080s, learning 0.665s)
               Value function loss: 9.5256
                    Surrogate loss: -0.0020
             Mean action noise std: 1.01
                       Mean reward: -49.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 3996000
                    Iteration time: 3.75s
                        Total time: 2104.62s
                               ETA: 5483.4s
################################################################################
                     [1m Learning iteration 555/2000 [0m                      

                       Computation: 1977 steps/s (collection: 3.008s, learning 0.633s)
               Value function loss: 10.2851
                    Surrogate loss: 0.0056
             Mean action noise std: 1.01
                       Mean reward: -49.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4003200
                    Iteration time: 3.64s
                        Total time: 2108.26s
                               ETA: 5479.2s
################################################################################
                     [1m Learning iteration 556/2000 [0m                      

                       Computation: 1970 steps/s (collection: 3.036s, learning 0.617s)
               Value function loss: 10.5424
                    Surrogate loss: -0.0011
             Mean action noise std: 1.01
                       Mean reward: -48.68
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4010400
                    Iteration time: 3.65s
                        Total time: 2111.91s
                               ETA: 5475.0s
################################################################################
                     [1m Learning iteration 557/2000 [0m                      

                       Computation: 1907 steps/s (collection: 3.153s, learning 0.622s)
               Value function loss: 8.2767
                    Surrogate loss: -0.0045
             Mean action noise std: 1.01
                       Mean reward: -48.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4017600
                    Iteration time: 3.77s
                        Total time: 2115.69s
                               ETA: 5471.2s
################################################################################
                     [1m Learning iteration 558/2000 [0m                      

                       Computation: 1938 steps/s (collection: 3.102s, learning 0.612s)
               Value function loss: 10.7760
                    Surrogate loss: -0.0057
             Mean action noise std: 1.01
                       Mean reward: -48.78
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4024800
                    Iteration time: 3.71s
                        Total time: 2119.40s
                               ETA: 5467.2s
################################################################################
                     [1m Learning iteration 559/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.180s, learning 0.635s)
               Value function loss: 11.6567
                    Surrogate loss: 0.0002
             Mean action noise std: 1.01
                       Mean reward: -49.06
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4032000
                    Iteration time: 3.82s
                        Total time: 2123.21s
                               ETA: 5463.5s
################################################################################
                     [1m Learning iteration 560/2000 [0m                      

                       Computation: 1975 steps/s (collection: 3.030s, learning 0.615s)
               Value function loss: 10.2582
                    Surrogate loss: -0.0014
             Mean action noise std: 1.01
                       Mean reward: -48.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4039200
                    Iteration time: 3.65s
                        Total time: 2126.86s
                               ETA: 5459.3s
################################################################################
                     [1m Learning iteration 561/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.150s, learning 0.671s)
               Value function loss: 13.6231
                    Surrogate loss: -0.0033
             Mean action noise std: 1.01
                       Mean reward: -49.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4046400
                    Iteration time: 3.82s
                        Total time: 2130.68s
                               ETA: 5455.6s
################################################################################
                     [1m Learning iteration 562/2000 [0m                      

                       Computation: 1963 steps/s (collection: 3.055s, learning 0.612s)
               Value function loss: 10.0756
                    Surrogate loss: -0.0002
             Mean action noise std: 1.01
                       Mean reward: -49.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4053600
                    Iteration time: 3.67s
                        Total time: 2134.35s
                               ETA: 5451.5s
################################################################################
                     [1m Learning iteration 563/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.151s, learning 0.641s)
               Value function loss: 10.2314
                    Surrogate loss: 0.0015
             Mean action noise std: 1.01
                       Mean reward: -48.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4060800
                    Iteration time: 3.79s
                        Total time: 2138.14s
                               ETA: 5447.7s
################################################################################
                     [1m Learning iteration 564/2000 [0m                      

                       Computation: 1973 steps/s (collection: 3.035s, learning 0.614s)
               Value function loss: 9.4922
                    Surrogate loss: -0.0022
             Mean action noise std: 1.01
                       Mean reward: -48.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4068000
                    Iteration time: 3.65s
                        Total time: 2141.79s
                               ETA: 5443.6s
################################################################################
                     [1m Learning iteration 565/2000 [0m                      

                       Computation: 1960 steps/s (collection: 3.064s, learning 0.609s)
               Value function loss: 239.6393
                    Surrogate loss: -0.0039
             Mean action noise std: 1.01
                       Mean reward: -50.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.40
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4075200
                    Iteration time: 3.67s
                        Total time: 2145.46s
                               ETA: 5439.5s
################################################################################
                     [1m Learning iteration 566/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.089s, learning 0.632s)
               Value function loss: 9.8537
                    Surrogate loss: -0.0051
             Mean action noise std: 1.00
                       Mean reward: -50.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4082400
                    Iteration time: 3.72s
                        Total time: 2149.18s
                               ETA: 5435.5s
################################################################################
                     [1m Learning iteration 567/2000 [0m                      

                       Computation: 1953 steps/s (collection: 3.081s, learning 0.605s)
               Value function loss: 11.6660
                    Surrogate loss: 0.0016
             Mean action noise std: 1.00
                       Mean reward: -50.36
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4089600
                    Iteration time: 3.69s
                        Total time: 2152.87s
                               ETA: 5431.4s
################################################################################
                     [1m Learning iteration 568/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.076s, learning 0.673s)
               Value function loss: 14.4917
                    Surrogate loss: -0.0042
             Mean action noise std: 1.00
                       Mean reward: -50.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4096800
                    Iteration time: 3.75s
                        Total time: 2156.62s
                               ETA: 5427.6s
################################################################################
                     [1m Learning iteration 569/2000 [0m                      

                       Computation: 1945 steps/s (collection: 3.083s, learning 0.617s)
               Value function loss: 14.8905
                    Surrogate loss: 0.0033
             Mean action noise std: 1.01
                       Mean reward: -51.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4104000
                    Iteration time: 3.70s
                        Total time: 2160.32s
                               ETA: 5423.5s
################################################################################
                     [1m Learning iteration 570/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.146s, learning 0.612s)
               Value function loss: 11.4103
                    Surrogate loss: -0.0054
             Mean action noise std: 1.00
                       Mean reward: -48.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4111200
                    Iteration time: 3.76s
                        Total time: 2164.08s
                               ETA: 5419.7s
################################################################################
                     [1m Learning iteration 571/2000 [0m                      

                       Computation: 1947 steps/s (collection: 3.064s, learning 0.634s)
               Value function loss: 15.0727
                    Surrogate loss: -0.0010
             Mean action noise std: 1.00
                       Mean reward: -48.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4118400
                    Iteration time: 3.70s
                        Total time: 2167.77s
                               ETA: 5415.6s
################################################################################
                     [1m Learning iteration 572/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.155s, learning 0.650s)
               Value function loss: 12.0693
                    Surrogate loss: -0.0037
             Mean action noise std: 1.00
                       Mean reward: -49.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4125600
                    Iteration time: 3.81s
                        Total time: 2171.58s
                               ETA: 5411.9s
################################################################################
                     [1m Learning iteration 573/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.113s, learning 0.684s)
               Value function loss: 18.1572
                    Surrogate loss: -0.0008
             Mean action noise std: 1.00
                       Mean reward: -49.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4132800
                    Iteration time: 3.80s
                        Total time: 2175.38s
                               ETA: 5408.1s
################################################################################
                     [1m Learning iteration 574/2000 [0m                      

                       Computation: 1899 steps/s (collection: 3.053s, learning 0.738s)
               Value function loss: 11.1399
                    Surrogate loss: -0.0057
             Mean action noise std: 1.00
                       Mean reward: -49.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4140000
                    Iteration time: 3.79s
                        Total time: 2179.17s
                               ETA: 5404.3s
################################################################################
                     [1m Learning iteration 575/2000 [0m                      

                       Computation: 1925 steps/s (collection: 3.126s, learning 0.613s)
               Value function loss: 11.3423
                    Surrogate loss: 0.0131
             Mean action noise std: 1.00
                       Mean reward: -48.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4147200
                    Iteration time: 3.74s
                        Total time: 2182.91s
                               ETA: 5400.4s
################################################################################
                     [1m Learning iteration 576/2000 [0m                      

                       Computation: 1897 steps/s (collection: 3.071s, learning 0.724s)
               Value function loss: 9.1085
                    Surrogate loss: -0.0043
             Mean action noise std: 1.00
                       Mean reward: -48.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4154400
                    Iteration time: 3.80s
                        Total time: 2186.70s
                               ETA: 5396.6s
################################################################################
                     [1m Learning iteration 577/2000 [0m                      

                       Computation: 1828 steps/s (collection: 3.135s, learning 0.804s)
               Value function loss: 10.7942
                    Surrogate loss: -0.0025
             Mean action noise std: 1.00
                       Mean reward: -48.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4161600
                    Iteration time: 3.94s
                        Total time: 2190.64s
                               ETA: 5393.2s
################################################################################
                     [1m Learning iteration 578/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.048s, learning 0.776s)
               Value function loss: 14.8541
                    Surrogate loss: 0.0043
             Mean action noise std: 1.00
                       Mean reward: -48.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4168800
                    Iteration time: 3.82s
                        Total time: 2194.46s
                               ETA: 5389.5s
################################################################################
                     [1m Learning iteration 579/2000 [0m                      

                       Computation: 1867 steps/s (collection: 3.046s, learning 0.809s)
               Value function loss: 9.3349
                    Surrogate loss: -0.0049
             Mean action noise std: 1.00
                       Mean reward: -48.73
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4176000
                    Iteration time: 3.85s
                        Total time: 2198.32s
                               ETA: 5385.9s
################################################################################
                     [1m Learning iteration 580/2000 [0m                      

                       Computation: 1944 steps/s (collection: 3.084s, learning 0.619s)
               Value function loss: 13.0256
                    Surrogate loss: 0.0029
             Mean action noise std: 1.00
                       Mean reward: -48.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4183200
                    Iteration time: 3.70s
                        Total time: 2202.02s
                               ETA: 5381.9s
################################################################################
                     [1m Learning iteration 581/2000 [0m                      

                       Computation: 1962 steps/s (collection: 3.055s, learning 0.614s)
               Value function loss: 11.4011
                    Surrogate loss: -0.0001
             Mean action noise std: 1.00
                       Mean reward: -49.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4190400
                    Iteration time: 3.67s
                        Total time: 2205.69s
                               ETA: 5377.8s
################################################################################
                     [1m Learning iteration 582/2000 [0m                      

                       Computation: 1912 steps/s (collection: 3.144s, learning 0.621s)
               Value function loss: 13.7657
                    Surrogate loss: -0.0035
             Mean action noise std: 1.00
                       Mean reward: -49.57
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4197600
                    Iteration time: 3.77s
                        Total time: 2209.46s
                               ETA: 5373.9s
################################################################################
                     [1m Learning iteration 583/2000 [0m                      

                       Computation: 1917 steps/s (collection: 3.085s, learning 0.670s)
               Value function loss: 13.7715
                    Surrogate loss: -0.0046
             Mean action noise std: 1.00
                       Mean reward: -49.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4204800
                    Iteration time: 3.75s
                        Total time: 2213.21s
                               ETA: 5370.1s
################################################################################
                     [1m Learning iteration 584/2000 [0m                      

                       Computation: 1840 steps/s (collection: 3.177s, learning 0.736s)
               Value function loss: 11.2214
                    Surrogate loss: -0.0017
             Mean action noise std: 1.00
                       Mean reward: -49.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4212000
                    Iteration time: 3.91s
                        Total time: 2217.12s
                               ETA: 5366.6s
################################################################################
                     [1m Learning iteration 585/2000 [0m                      

                       Computation: 1915 steps/s (collection: 3.124s, learning 0.635s)
               Value function loss: 14.4790
                    Surrogate loss: -0.0064
             Mean action noise std: 1.00
                       Mean reward: -49.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4219200
                    Iteration time: 3.76s
                        Total time: 2220.88s
                               ETA: 5362.7s
################################################################################
                     [1m Learning iteration 586/2000 [0m                      

                       Computation: 1902 steps/s (collection: 3.140s, learning 0.644s)
               Value function loss: 13.3768
                    Surrogate loss: -0.0034
             Mean action noise std: 1.00
                       Mean reward: -49.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4226400
                    Iteration time: 3.78s
                        Total time: 2224.67s
                               ETA: 5358.9s
################################################################################
                     [1m Learning iteration 587/2000 [0m                      

                       Computation: 1932 steps/s (collection: 3.099s, learning 0.627s)
               Value function loss: 10.0069
                    Surrogate loss: -0.0075
             Mean action noise std: 1.00
                       Mean reward: -49.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4233600
                    Iteration time: 3.73s
                        Total time: 2228.39s
                               ETA: 5355.0s
################################################################################
                     [1m Learning iteration 588/2000 [0m                      

                       Computation: 1940 steps/s (collection: 3.082s, learning 0.629s)
               Value function loss: 12.1555
                    Surrogate loss: -0.0043
             Mean action noise std: 0.99
                       Mean reward: -49.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4240800
                    Iteration time: 3.71s
                        Total time: 2232.10s
                               ETA: 5351.0s
################################################################################
                     [1m Learning iteration 589/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.106s, learning 0.629s)
               Value function loss: 10.8017
                    Surrogate loss: -0.0016
             Mean action noise std: 1.00
                       Mean reward: -49.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4248000
                    Iteration time: 3.74s
                        Total time: 2235.84s
                               ETA: 5347.1s
################################################################################
                     [1m Learning iteration 590/2000 [0m                      

                       Computation: 1939 steps/s (collection: 3.093s, learning 0.620s)
               Value function loss: 11.6110
                    Surrogate loss: -0.0054
             Mean action noise std: 1.00
                       Mean reward: -49.06
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4255200
                    Iteration time: 3.71s
                        Total time: 2239.55s
                               ETA: 5343.1s
################################################################################
                     [1m Learning iteration 591/2000 [0m                      

                       Computation: 1907 steps/s (collection: 3.161s, learning 0.614s)
               Value function loss: 9.6530
                    Surrogate loss: -0.0051
             Mean action noise std: 0.99
                       Mean reward: -48.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4262400
                    Iteration time: 3.78s
                        Total time: 2243.33s
                               ETA: 5339.3s
################################################################################
                     [1m Learning iteration 592/2000 [0m                      

                       Computation: 1941 steps/s (collection: 3.094s, learning 0.614s)
               Value function loss: 13.0591
                    Surrogate loss: -0.0011
             Mean action noise std: 1.00
                       Mean reward: -48.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4269600
                    Iteration time: 3.71s
                        Total time: 2247.03s
                               ETA: 5335.3s
################################################################################
                     [1m Learning iteration 593/2000 [0m                      

                       Computation: 1899 steps/s (collection: 3.098s, learning 0.693s)
               Value function loss: 9.0972
                    Surrogate loss: -0.0027
             Mean action noise std: 1.00
                       Mean reward: -48.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4276800
                    Iteration time: 3.79s
                        Total time: 2250.83s
                               ETA: 5331.5s
################################################################################
                     [1m Learning iteration 594/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.149s, learning 0.607s)
               Value function loss: 10.7038
                    Surrogate loss: -0.0064
             Mean action noise std: 0.99
                       Mean reward: -48.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4284000
                    Iteration time: 3.76s
                        Total time: 2254.58s
                               ETA: 5327.6s
################################################################################
                     [1m Learning iteration 595/2000 [0m                      

                       Computation: 1937 steps/s (collection: 3.076s, learning 0.640s)
               Value function loss: 12.2271
                    Surrogate loss: -0.0041
             Mean action noise std: 0.99
                       Mean reward: -48.28
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4291200
                    Iteration time: 3.72s
                        Total time: 2258.30s
                               ETA: 5323.7s
################################################################################
                     [1m Learning iteration 596/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.105s, learning 0.638s)
               Value function loss: 13.3908
                    Surrogate loss: 0.0028
             Mean action noise std: 0.99
                       Mean reward: -48.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4298400
                    Iteration time: 3.74s
                        Total time: 2262.04s
                               ETA: 5319.8s
################################################################################
                     [1m Learning iteration 597/2000 [0m                      

                       Computation: 1937 steps/s (collection: 3.080s, learning 0.636s)
               Value function loss: 10.6141
                    Surrogate loss: -0.0006
             Mean action noise std: 0.99
                       Mean reward: -48.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4305600
                    Iteration time: 3.72s
                        Total time: 2265.76s
                               ETA: 5315.8s
################################################################################
                     [1m Learning iteration 598/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.161s, learning 0.646s)
               Value function loss: 9.9463
                    Surrogate loss: -0.0044
             Mean action noise std: 0.99
                       Mean reward: -49.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4312800
                    Iteration time: 3.81s
                        Total time: 2269.56s
                               ETA: 5312.1s
################################################################################
                     [1m Learning iteration 599/2000 [0m                      

                       Computation: 1908 steps/s (collection: 3.066s, learning 0.708s)
               Value function loss: 12.9515
                    Surrogate loss: -0.0050
             Mean action noise std: 0.99
                       Mean reward: -49.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4320000
                    Iteration time: 3.77s
                        Total time: 2273.34s
                               ETA: 5308.2s
################################################################################
                     [1m Learning iteration 600/2000 [0m                      

                       Computation: 1826 steps/s (collection: 3.135s, learning 0.807s)
               Value function loss: 11.5097
                    Surrogate loss: -0.0067
             Mean action noise std: 0.99
                       Mean reward: -49.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4327200
                    Iteration time: 3.94s
                        Total time: 2277.28s
                               ETA: 5304.8s
################################################################################
                     [1m Learning iteration 601/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.058s, learning 0.833s)
               Value function loss: 10.1352
                    Surrogate loss: -0.0057
             Mean action noise std: 0.99
                       Mean reward: -49.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4334400
                    Iteration time: 3.89s
                        Total time: 2281.17s
                               ETA: 5301.3s
################################################################################
                     [1m Learning iteration 602/2000 [0m                      

                       Computation: 1936 steps/s (collection: 3.017s, learning 0.701s)
               Value function loss: 13.8743
                    Surrogate loss: -0.0057
             Mean action noise std: 0.99
                       Mean reward: -48.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4341600
                    Iteration time: 3.72s
                        Total time: 2284.89s
                               ETA: 5297.3s
################################################################################
                     [1m Learning iteration 603/2000 [0m                      

                       Computation: 1797 steps/s (collection: 3.098s, learning 0.907s)
               Value function loss: 11.0699
                    Surrogate loss: -0.0022
             Mean action noise std: 0.99
                       Mean reward: -48.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4348800
                    Iteration time: 4.00s
                        Total time: 2288.89s
                               ETA: 5294.0s
################################################################################
                     [1m Learning iteration 604/2000 [0m                      

                       Computation: 1848 steps/s (collection: 3.081s, learning 0.814s)
               Value function loss: 23.9265
                    Surrogate loss: -0.0049
             Mean action noise std: 0.99
                       Mean reward: -48.78
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4356000
                    Iteration time: 3.90s
                        Total time: 2292.79s
                               ETA: 5290.5s
################################################################################
                     [1m Learning iteration 605/2000 [0m                      

                       Computation: 1858 steps/s (collection: 3.159s, learning 0.714s)
               Value function loss: 15.4637
                    Surrogate loss: 0.0133
             Mean action noise std: 0.99
                       Mean reward: -48.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4363200
                    Iteration time: 3.87s
                        Total time: 2296.66s
                               ETA: 5286.9s
################################################################################
                     [1m Learning iteration 606/2000 [0m                      

                       Computation: 1915 steps/s (collection: 3.053s, learning 0.705s)
               Value function loss: 16.4473
                    Surrogate loss: -0.0040
             Mean action noise std: 0.99
                       Mean reward: -49.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4370400
                    Iteration time: 3.76s
                        Total time: 2300.42s
                               ETA: 5283.0s
################################################################################
                     [1m Learning iteration 607/2000 [0m                      

                       Computation: 1900 steps/s (collection: 3.136s, learning 0.652s)
               Value function loss: 14.9676
                    Surrogate loss: -0.0013
             Mean action noise std: 0.98
                       Mean reward: -49.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4377600
                    Iteration time: 3.79s
                        Total time: 2304.21s
                               ETA: 5279.2s
################################################################################
                     [1m Learning iteration 608/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.120s, learning 0.816s)
               Value function loss: 14.8604
                    Surrogate loss: -0.0015
             Mean action noise std: 0.98
                       Mean reward: -48.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4384800
                    Iteration time: 3.94s
                        Total time: 2308.14s
                               ETA: 5275.8s
################################################################################
                     [1m Learning iteration 609/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.038s, learning 0.705s)
               Value function loss: 11.9740
                    Surrogate loss: 0.0014
             Mean action noise std: 0.98
                       Mean reward: -48.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4392000
                    Iteration time: 3.74s
                        Total time: 2311.88s
                               ETA: 5271.9s
################################################################################
                     [1m Learning iteration 610/2000 [0m                      

                       Computation: 1795 steps/s (collection: 3.138s, learning 0.873s)
               Value function loss: 12.7891
                    Surrogate loss: 0.0005
             Mean action noise std: 0.98
                       Mean reward: -48.53
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4399200
                    Iteration time: 4.01s
                        Total time: 2315.90s
                               ETA: 5268.6s
################################################################################
                     [1m Learning iteration 611/2000 [0m                      

                       Computation: 1962 steps/s (collection: 3.075s, learning 0.595s)
               Value function loss: 13.7326
                    Surrogate loss: -0.0033
             Mean action noise std: 0.98
                       Mean reward: -48.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4406400
                    Iteration time: 3.67s
                        Total time: 2319.57s
                               ETA: 5264.5s
################################################################################
                     [1m Learning iteration 612/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.160s, learning 0.656s)
               Value function loss: 14.5343
                    Surrogate loss: -0.0014
             Mean action noise std: 0.98
                       Mean reward: -48.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4413600
                    Iteration time: 3.82s
                        Total time: 2323.38s
                               ETA: 5260.8s
################################################################################
                     [1m Learning iteration 613/2000 [0m                      

                       Computation: 1947 steps/s (collection: 3.089s, learning 0.609s)
               Value function loss: 13.7873
                    Surrogate loss: -0.0081
             Mean action noise std: 0.98
                       Mean reward: -49.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4420800
                    Iteration time: 3.70s
                        Total time: 2327.08s
                               ETA: 5256.8s
################################################################################
                     [1m Learning iteration 614/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.116s, learning 0.690s)
               Value function loss: 13.2460
                    Surrogate loss: -0.0027
             Mean action noise std: 0.98
                       Mean reward: -48.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4428000
                    Iteration time: 3.81s
                        Total time: 2330.89s
                               ETA: 5253.0s
################################################################################
                     [1m Learning iteration 615/2000 [0m                      

                       Computation: 1932 steps/s (collection: 3.116s, learning 0.610s)
               Value function loss: 10.2517
                    Surrogate loss: -0.0040
             Mean action noise std: 0.98
                       Mean reward: -49.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4435200
                    Iteration time: 3.73s
                        Total time: 2334.61s
                               ETA: 5249.1s
################################################################################
                     [1m Learning iteration 616/2000 [0m                      

                       Computation: 1958 steps/s (collection: 3.062s, learning 0.615s)
               Value function loss: 12.5257
                    Surrogate loss: -0.0055
             Mean action noise std: 0.98
                       Mean reward: -49.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4442400
                    Iteration time: 3.68s
                        Total time: 2338.29s
                               ETA: 5245.0s
################################################################################
                     [1m Learning iteration 617/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.111s, learning 0.616s)
               Value function loss: 8.5708
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -48.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4449600
                    Iteration time: 3.73s
                        Total time: 2342.02s
                               ETA: 5241.1s
################################################################################
                     [1m Learning iteration 618/2000 [0m                      

                       Computation: 1961 steps/s (collection: 3.048s, learning 0.622s)
               Value function loss: 9.0706
                    Surrogate loss: -0.0039
             Mean action noise std: 0.98
                       Mean reward: -48.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4456800
                    Iteration time: 3.67s
                        Total time: 2345.69s
                               ETA: 5237.1s
################################################################################
                     [1m Learning iteration 619/2000 [0m                      

                       Computation: 1922 steps/s (collection: 3.080s, learning 0.664s)
               Value function loss: 10.2247
                    Surrogate loss: -0.0027
             Mean action noise std: 0.98
                       Mean reward: -47.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4464000
                    Iteration time: 3.74s
                        Total time: 2349.43s
                               ETA: 5233.2s
################################################################################
                     [1m Learning iteration 620/2000 [0m                      

                       Computation: 1948 steps/s (collection: 3.069s, learning 0.627s)
               Value function loss: 10.9884
                    Surrogate loss: -0.0031
             Mean action noise std: 0.98
                       Mean reward: -47.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4471200
                    Iteration time: 3.70s
                        Total time: 2353.13s
                               ETA: 5229.2s
################################################################################
                     [1m Learning iteration 621/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.177s, learning 0.649s)
               Value function loss: 12.8460
                    Surrogate loss: -0.0031
             Mean action noise std: 0.98
                       Mean reward: -47.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4478400
                    Iteration time: 3.83s
                        Total time: 2356.95s
                               ETA: 5225.5s
################################################################################
                     [1m Learning iteration 622/2000 [0m                      

                       Computation: 1951 steps/s (collection: 3.056s, learning 0.634s)
               Value function loss: 10.2569
                    Surrogate loss: -0.0066
             Mean action noise std: 0.98
                       Mean reward: -47.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4485600
                    Iteration time: 3.69s
                        Total time: 2360.64s
                               ETA: 5221.5s
################################################################################
                     [1m Learning iteration 623/2000 [0m                      

                       Computation: 1912 steps/s (collection: 3.111s, learning 0.653s)
               Value function loss: 10.8121
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -47.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4492800
                    Iteration time: 3.76s
                        Total time: 2364.41s
                               ETA: 5217.6s
################################################################################
                     [1m Learning iteration 624/2000 [0m                      

                       Computation: 1932 steps/s (collection: 3.117s, learning 0.609s)
               Value function loss: 15.3375
                    Surrogate loss: -0.0053
             Mean action noise std: 0.98
                       Mean reward: -48.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4500000
                    Iteration time: 3.73s
                        Total time: 2368.13s
                               ETA: 5213.7s
################################################################################
                     [1m Learning iteration 625/2000 [0m                      

                       Computation: 1941 steps/s (collection: 3.069s, learning 0.639s)
               Value function loss: 14.1002
                    Surrogate loss: -0.0059
             Mean action noise std: 0.97
                       Mean reward: -48.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4507200
                    Iteration time: 3.71s
                        Total time: 2371.84s
                               ETA: 5209.7s
################################################################################
                     [1m Learning iteration 626/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.126s, learning 0.630s)
               Value function loss: 10.5730
                    Surrogate loss: -0.0022
             Mean action noise std: 0.98
                       Mean reward: -48.98
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4514400
                    Iteration time: 3.76s
                        Total time: 2375.60s
                               ETA: 5205.9s
################################################################################
                     [1m Learning iteration 627/2000 [0m                      

                       Computation: 1972 steps/s (collection: 3.049s, learning 0.601s)
               Value function loss: 11.9607
                    Surrogate loss: -0.0060
             Mean action noise std: 0.98
                       Mean reward: -49.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4521600
                    Iteration time: 3.65s
                        Total time: 2379.25s
                               ETA: 5201.8s
################################################################################
                     [1m Learning iteration 628/2000 [0m                      

                       Computation: 1912 steps/s (collection: 3.155s, learning 0.610s)
               Value function loss: 11.0452
                    Surrogate loss: -0.0050
             Mean action noise std: 0.97
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4528800
                    Iteration time: 3.76s
                        Total time: 2383.01s
                               ETA: 5197.9s
################################################################################
                     [1m Learning iteration 629/2000 [0m                      

                       Computation: 1915 steps/s (collection: 3.121s, learning 0.638s)
               Value function loss: 11.4262
                    Surrogate loss: -0.0026
             Mean action noise std: 0.97
                       Mean reward: -49.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4536000
                    Iteration time: 3.76s
                        Total time: 2386.77s
                               ETA: 5194.1s
################################################################################
                     [1m Learning iteration 630/2000 [0m                      

                       Computation: 1915 steps/s (collection: 3.099s, learning 0.660s)
               Value function loss: 12.6905
                    Surrogate loss: -0.0012
             Mean action noise std: 0.97
                       Mean reward: -49.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4543200
                    Iteration time: 3.76s
                        Total time: 2390.53s
                               ETA: 5190.2s
################################################################################
                     [1m Learning iteration 631/2000 [0m                      

                       Computation: 1939 steps/s (collection: 3.099s, learning 0.613s)
               Value function loss: 10.0412
                    Surrogate loss: -0.0069
             Mean action noise std: 0.97
                       Mean reward: -49.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4550400
                    Iteration time: 3.71s
                        Total time: 2394.24s
                               ETA: 5186.3s
################################################################################
                     [1m Learning iteration 632/2000 [0m                      

                       Computation: 1944 steps/s (collection: 3.077s, learning 0.626s)
               Value function loss: 12.1546
                    Surrogate loss: -0.0004
             Mean action noise std: 0.97
                       Mean reward: -49.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4557600
                    Iteration time: 3.70s
                        Total time: 2397.95s
                               ETA: 5182.3s
################################################################################
                     [1m Learning iteration 633/2000 [0m                      

                       Computation: 1905 steps/s (collection: 3.131s, learning 0.647s)
               Value function loss: 7.5031
                    Surrogate loss: -0.0048
             Mean action noise std: 0.97
                       Mean reward: -48.98
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4564800
                    Iteration time: 3.78s
                        Total time: 2401.72s
                               ETA: 5178.5s
################################################################################
                     [1m Learning iteration 634/2000 [0m                      

                       Computation: 1950 steps/s (collection: 3.037s, learning 0.654s)
               Value function loss: 9.5341
                    Surrogate loss: -0.0049
             Mean action noise std: 0.97
                       Mean reward: -48.53
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4572000
                    Iteration time: 3.69s
                        Total time: 2405.41s
                               ETA: 5174.5s
################################################################################
                     [1m Learning iteration 635/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.112s, learning 0.649s)
               Value function loss: 9.4598
                    Surrogate loss: -0.0015
             Mean action noise std: 0.97
                       Mean reward: -48.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4579200
                    Iteration time: 3.76s
                        Total time: 2409.18s
                               ETA: 5170.6s
################################################################################
                     [1m Learning iteration 636/2000 [0m                      

                       Computation: 1946 steps/s (collection: 3.080s, learning 0.619s)
               Value function loss: 12.1041
                    Surrogate loss: -0.0037
             Mean action noise std: 0.97
                       Mean reward: -48.53
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4586400
                    Iteration time: 3.70s
                        Total time: 2412.88s
                               ETA: 5166.7s
################################################################################
                     [1m Learning iteration 637/2000 [0m                      

                       Computation: 1879 steps/s (collection: 3.157s, learning 0.673s)
               Value function loss: 10.5582
                    Surrogate loss: -0.0015
             Mean action noise std: 0.97
                       Mean reward: -48.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4593600
                    Iteration time: 3.83s
                        Total time: 2416.71s
                               ETA: 5163.0s
################################################################################
                     [1m Learning iteration 638/2000 [0m                      

                       Computation: 1940 steps/s (collection: 3.076s, learning 0.634s)
               Value function loss: 12.0457
                    Surrogate loss: -0.0036
             Mean action noise std: 0.97
                       Mean reward: -48.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4600800
                    Iteration time: 3.71s
                        Total time: 2420.42s
                               ETA: 5159.0s
################################################################################
                     [1m Learning iteration 639/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.084s, learning 0.637s)
               Value function loss: 11.4617
                    Surrogate loss: -0.0032
             Mean action noise std: 0.97
                       Mean reward: -49.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4608000
                    Iteration time: 3.72s
                        Total time: 2424.14s
                               ETA: 5155.1s
################################################################################
                     [1m Learning iteration 640/2000 [0m                      

                       Computation: 1900 steps/s (collection: 3.119s, learning 0.671s)
               Value function loss: 9.2711
                    Surrogate loss: -0.0039
             Mean action noise std: 0.97
                       Mean reward: -48.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4615200
                    Iteration time: 3.79s
                        Total time: 2427.93s
                               ETA: 5151.3s
################################################################################
                     [1m Learning iteration 641/2000 [0m                      

                       Computation: 1864 steps/s (collection: 3.073s, learning 0.789s)
               Value function loss: 8.8712
                    Surrogate loss: -0.0010
             Mean action noise std: 0.97
                       Mean reward: -49.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4622400
                    Iteration time: 3.86s
                        Total time: 2431.79s
                               ETA: 5147.7s
################################################################################
                     [1m Learning iteration 642/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.139s, learning 0.702s)
               Value function loss: 8.2206
                    Surrogate loss: -0.0036
             Mean action noise std: 0.97
                       Mean reward: -48.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4629600
                    Iteration time: 3.84s
                        Total time: 2435.63s
                               ETA: 5144.0s
################################################################################
                     [1m Learning iteration 643/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.085s, learning 0.663s)
               Value function loss: 14.5714
                    Surrogate loss: -0.0055
             Mean action noise std: 0.97
                       Mean reward: -48.65
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4636800
                    Iteration time: 3.75s
                        Total time: 2439.38s
                               ETA: 5140.1s
################################################################################
                     [1m Learning iteration 644/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.130s, learning 0.721s)
               Value function loss: 10.6635
                    Surrogate loss: 0.0054
             Mean action noise std: 0.97
                       Mean reward: -48.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4644000
                    Iteration time: 3.85s
                        Total time: 2443.23s
                               ETA: 5136.5s
################################################################################
                     [1m Learning iteration 645/2000 [0m                      

                       Computation: 1929 steps/s (collection: 3.051s, learning 0.681s)
               Value function loss: 10.1320
                    Surrogate loss: 0.0015
             Mean action noise std: 0.97
                       Mean reward: -49.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4651200
                    Iteration time: 3.73s
                        Total time: 2446.96s
                               ETA: 5132.6s
################################################################################
                     [1m Learning iteration 646/2000 [0m                      

                       Computation: 1929 steps/s (collection: 3.051s, learning 0.681s)
               Value function loss: 11.9359
                    Surrogate loss: -0.0031
             Mean action noise std: 0.97
                       Mean reward: -48.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4658400
                    Iteration time: 3.73s
                        Total time: 2450.69s
                               ETA: 5128.7s
################################################################################
                     [1m Learning iteration 647/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.129s, learning 0.692s)
               Value function loss: 12.2330
                    Surrogate loss: 0.0047
             Mean action noise std: 0.96
                       Mean reward: -48.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4665600
                    Iteration time: 3.82s
                        Total time: 2454.51s
                               ETA: 5124.9s
################################################################################
                     [1m Learning iteration 648/2000 [0m                      

                       Computation: 1897 steps/s (collection: 3.080s, learning 0.713s)
               Value function loss: 13.0209
                    Surrogate loss: -0.0025
             Mean action noise std: 0.96
                       Mean reward: -49.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4672800
                    Iteration time: 3.79s
                        Total time: 2458.31s
                               ETA: 5121.2s
################################################################################
                     [1m Learning iteration 649/2000 [0m                      

                       Computation: 1852 steps/s (collection: 3.148s, learning 0.739s)
               Value function loss: 12.6830
                    Surrogate loss: -0.0057
             Mean action noise std: 0.97
                       Mean reward: -48.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4680000
                    Iteration time: 3.89s
                        Total time: 2462.19s
                               ETA: 5117.6s
################################################################################
                     [1m Learning iteration 650/2000 [0m                      

                       Computation: 1875 steps/s (collection: 3.085s, learning 0.753s)
               Value function loss: 11.3091
                    Surrogate loss: -0.0053
             Mean action noise std: 0.96
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4687200
                    Iteration time: 3.84s
                        Total time: 2466.03s
                               ETA: 5113.9s
################################################################################
                     [1m Learning iteration 651/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.163s, learning 0.685s)
               Value function loss: 11.0568
                    Surrogate loss: -0.0024
             Mean action noise std: 0.96
                       Mean reward: -49.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4694400
                    Iteration time: 3.85s
                        Total time: 2469.88s
                               ETA: 5110.2s
################################################################################
                     [1m Learning iteration 652/2000 [0m                      

                       Computation: 1930 steps/s (collection: 3.105s, learning 0.625s)
               Value function loss: 9.9137
                    Surrogate loss: -0.0000
             Mean action noise std: 0.96
                       Mean reward: -48.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4701600
                    Iteration time: 3.73s
                        Total time: 2473.61s
                               ETA: 5106.3s
################################################################################
                     [1m Learning iteration 653/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.099s, learning 0.744s)
               Value function loss: 10.1911
                    Surrogate loss: 0.0051
             Mean action noise std: 0.97
                       Mean reward: -48.57
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4708800
                    Iteration time: 3.84s
                        Total time: 2477.45s
                               ETA: 5102.6s
################################################################################
                     [1m Learning iteration 654/2000 [0m                      

                       Computation: 1878 steps/s (collection: 2.951s, learning 0.883s)
               Value function loss: 13.9281
                    Surrogate loss: 0.0036
             Mean action noise std: 0.97
                       Mean reward: -49.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4716000
                    Iteration time: 3.83s
                        Total time: 2481.29s
                               ETA: 5099.0s
################################################################################
                     [1m Learning iteration 655/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.075s, learning 0.722s)
               Value function loss: 13.0643
                    Surrogate loss: -0.0054
             Mean action noise std: 0.97
                       Mean reward: -49.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4723200
                    Iteration time: 3.80s
                        Total time: 2485.09s
                               ETA: 5095.2s
################################################################################
                     [1m Learning iteration 656/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.124s, learning 0.704s)
               Value function loss: 11.6696
                    Surrogate loss: -0.0042
             Mean action noise std: 0.97
                       Mean reward: -48.78
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4730400
                    Iteration time: 3.83s
                        Total time: 2488.91s
                               ETA: 5091.5s
################################################################################
                     [1m Learning iteration 657/2000 [0m                      

                       Computation: 1928 steps/s (collection: 3.057s, learning 0.677s)
               Value function loss: 24.1536
                    Surrogate loss: -0.0085
             Mean action noise std: 0.97
                       Mean reward: -49.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4737600
                    Iteration time: 3.73s
                        Total time: 2492.65s
                               ETA: 5087.6s
################################################################################
                     [1m Learning iteration 658/2000 [0m                      

                       Computation: 1808 steps/s (collection: 3.114s, learning 0.867s)
               Value function loss: 13.5232
                    Surrogate loss: -0.0059
             Mean action noise std: 0.97
                       Mean reward: -49.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4744800
                    Iteration time: 3.98s
                        Total time: 2496.63s
                               ETA: 5084.2s
################################################################################
                     [1m Learning iteration 659/2000 [0m                      

                       Computation: 1872 steps/s (collection: 3.082s, learning 0.763s)
               Value function loss: 13.9263
                    Surrogate loss: -0.0049
             Mean action noise std: 0.97
                       Mean reward: -48.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4752000
                    Iteration time: 3.85s
                        Total time: 2500.47s
                               ETA: 5080.5s
################################################################################
                     [1m Learning iteration 660/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.067s, learning 0.729s)
               Value function loss: 11.9857
                    Surrogate loss: -0.0048
             Mean action noise std: 0.97
                       Mean reward: -48.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4759200
                    Iteration time: 3.80s
                        Total time: 2504.27s
                               ETA: 5076.7s
################################################################################
                     [1m Learning iteration 661/2000 [0m                      

                       Computation: 1906 steps/s (collection: 3.089s, learning 0.688s)
               Value function loss: 12.9285
                    Surrogate loss: 0.0049
             Mean action noise std: 0.97
                       Mean reward: -48.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4766400
                    Iteration time: 3.78s
                        Total time: 2508.05s
                               ETA: 5072.9s
################################################################################
                     [1m Learning iteration 662/2000 [0m                      

                       Computation: 1937 steps/s (collection: 3.103s, learning 0.612s)
               Value function loss: 18.5241
                    Surrogate loss: -0.0053
             Mean action noise std: 0.97
                       Mean reward: -48.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4773600
                    Iteration time: 3.72s
                        Total time: 2511.76s
                               ETA: 5069.0s
################################################################################
                     [1m Learning iteration 663/2000 [0m                      

                       Computation: 1919 steps/s (collection: 3.082s, learning 0.669s)
               Value function loss: 15.7702
                    Surrogate loss: 0.0005
             Mean action noise std: 0.97
                       Mean reward: -48.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4780800
                    Iteration time: 3.75s
                        Total time: 2515.51s
                               ETA: 5065.1s
################################################################################
                     [1m Learning iteration 664/2000 [0m                      

                       Computation: 1964 steps/s (collection: 3.065s, learning 0.600s)
               Value function loss: 14.8675
                    Surrogate loss: 0.0047
             Mean action noise std: 0.97
                       Mean reward: -48.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4788000
                    Iteration time: 3.66s
                        Total time: 2519.18s
                               ETA: 5061.1s
################################################################################
                     [1m Learning iteration 665/2000 [0m                      

                       Computation: 1867 steps/s (collection: 3.124s, learning 0.732s)
               Value function loss: 15.6912
                    Surrogate loss: -0.0020
             Mean action noise std: 0.97
                       Mean reward: -48.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4795200
                    Iteration time: 3.86s
                        Total time: 2523.03s
                               ETA: 5057.4s
################################################################################
                     [1m Learning iteration 666/2000 [0m                      

                       Computation: 1978 steps/s (collection: 3.013s, learning 0.626s)
               Value function loss: 16.3665
                    Surrogate loss: -0.0034
             Mean action noise std: 0.97
                       Mean reward: -48.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4802400
                    Iteration time: 3.64s
                        Total time: 2526.67s
                               ETA: 5053.3s
################################################################################
                     [1m Learning iteration 667/2000 [0m                      

                       Computation: 1940 steps/s (collection: 3.082s, learning 0.628s)
               Value function loss: 17.0549
                    Surrogate loss: -0.0062
             Mean action noise std: 0.97
                       Mean reward: -48.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4809600
                    Iteration time: 3.71s
                        Total time: 2530.38s
                               ETA: 5049.4s
################################################################################
                     [1m Learning iteration 668/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.116s, learning 0.680s)
               Value function loss: 16.8266
                    Surrogate loss: -0.0000
             Mean action noise std: 0.97
                       Mean reward: -47.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4816800
                    Iteration time: 3.80s
                        Total time: 2534.18s
                               ETA: 5045.6s
################################################################################
                     [1m Learning iteration 669/2000 [0m                      

                       Computation: 1958 steps/s (collection: 3.061s, learning 0.616s)
               Value function loss: 12.6366
                    Surrogate loss: -0.0013
             Mean action noise std: 0.97
                       Mean reward: -48.25
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4824000
                    Iteration time: 3.68s
                        Total time: 2537.86s
                               ETA: 5041.6s
################################################################################
                     [1m Learning iteration 670/2000 [0m                      

                       Computation: 1924 steps/s (collection: 3.124s, learning 0.617s)
               Value function loss: 13.6244
                    Surrogate loss: -0.0066
             Mean action noise std: 0.97
                       Mean reward: -48.14
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4831200
                    Iteration time: 3.74s
                        Total time: 2541.60s
                               ETA: 5037.7s
################################################################################
                     [1m Learning iteration 671/2000 [0m                      

                       Computation: 1940 steps/s (collection: 3.068s, learning 0.641s)
               Value function loss: 18.4945
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -47.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4838400
                    Iteration time: 3.71s
                        Total time: 2545.31s
                               ETA: 5033.8s
################################################################################
                     [1m Learning iteration 672/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.135s, learning 0.697s)
               Value function loss: 15.9890
                    Surrogate loss: -0.0016
             Mean action noise std: 0.98
                       Mean reward: -47.98
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4845600
                    Iteration time: 3.83s
                        Total time: 2549.14s
                               ETA: 5030.1s
################################################################################
                     [1m Learning iteration 673/2000 [0m                      

                       Computation: 1947 steps/s (collection: 3.045s, learning 0.652s)
               Value function loss: 18.3529
                    Surrogate loss: -0.0037
             Mean action noise std: 0.98
                       Mean reward: -48.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4852800
                    Iteration time: 3.70s
                        Total time: 2552.84s
                               ETA: 5026.1s
################################################################################
                     [1m Learning iteration 674/2000 [0m                      

                       Computation: 1875 steps/s (collection: 3.141s, learning 0.697s)
               Value function loss: 16.1602
                    Surrogate loss: -0.0032
             Mean action noise std: 0.98
                       Mean reward: -48.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4860000
                    Iteration time: 3.84s
                        Total time: 2556.67s
                               ETA: 5022.4s
################################################################################
                     [1m Learning iteration 675/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.068s, learning 0.754s)
               Value function loss: 17.0392
                    Surrogate loss: -0.0016
             Mean action noise std: 0.98
                       Mean reward: -48.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4867200
                    Iteration time: 3.82s
                        Total time: 2560.50s
                               ETA: 5018.7s
################################################################################
                     [1m Learning iteration 676/2000 [0m                      

                       Computation: 1951 steps/s (collection: 3.057s, learning 0.632s)
               Value function loss: 13.7155
                    Surrogate loss: -0.0019
             Mean action noise std: 0.98
                       Mean reward: -48.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4874400
                    Iteration time: 3.69s
                        Total time: 2564.19s
                               ETA: 5014.7s
################################################################################
                     [1m Learning iteration 677/2000 [0m                      

                       Computation: 1922 steps/s (collection: 3.133s, learning 0.613s)
               Value function loss: 14.8894
                    Surrogate loss: -0.0063
             Mean action noise std: 0.98
                       Mean reward: -47.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4881600
                    Iteration time: 3.75s
                        Total time: 2567.93s
                               ETA: 5010.9s
################################################################################
                     [1m Learning iteration 678/2000 [0m                      

                       Computation: 1945 steps/s (collection: 3.092s, learning 0.610s)
               Value function loss: 12.8551
                    Surrogate loss: -0.0091
             Mean action noise std: 0.98
                       Mean reward: -48.53
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4888800
                    Iteration time: 3.70s
                        Total time: 2571.63s
                               ETA: 5006.9s
################################################################################
                     [1m Learning iteration 679/2000 [0m                      

                       Computation: 1929 steps/s (collection: 3.116s, learning 0.616s)
               Value function loss: 15.1259
                    Surrogate loss: -0.0018
             Mean action noise std: 0.98
                       Mean reward: -48.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4896000
                    Iteration time: 3.73s
                        Total time: 2575.36s
                               ETA: 5003.0s
################################################################################
                     [1m Learning iteration 680/2000 [0m                      

                       Computation: 1934 steps/s (collection: 3.055s, learning 0.668s)
               Value function loss: 14.3835
                    Surrogate loss: -0.0043
             Mean action noise std: 0.98
                       Mean reward: -48.59
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4903200
                    Iteration time: 3.72s
                        Total time: 2579.09s
                               ETA: 4999.1s
################################################################################
                     [1m Learning iteration 681/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.128s, learning 0.633s)
               Value function loss: 16.7674
                    Surrogate loss: -0.0052
             Mean action noise std: 0.98
                       Mean reward: -48.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4910400
                    Iteration time: 3.76s
                        Total time: 2582.85s
                               ETA: 4995.3s
################################################################################
                     [1m Learning iteration 682/2000 [0m                      

                       Computation: 1940 steps/s (collection: 3.088s, learning 0.623s)
               Value function loss: 16.0982
                    Surrogate loss: -0.0028
             Mean action noise std: 0.98
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4917600
                    Iteration time: 3.71s
                        Total time: 2586.56s
                               ETA: 4991.3s
################################################################################
                     [1m Learning iteration 683/2000 [0m                      

                       Computation: 1943 steps/s (collection: 3.073s, learning 0.630s)
               Value function loss: 13.6523
                    Surrogate loss: -0.0011
             Mean action noise std: 0.98
                       Mean reward: -48.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4924800
                    Iteration time: 3.70s
                        Total time: 2590.26s
                               ETA: 4987.4s
################################################################################
                     [1m Learning iteration 684/2000 [0m                      

                       Computation: 1925 steps/s (collection: 3.124s, learning 0.615s)
               Value function loss: 11.9550
                    Surrogate loss: -0.0009
             Mean action noise std: 0.98
                       Mean reward: -48.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4932000
                    Iteration time: 3.74s
                        Total time: 2594.00s
                               ETA: 4983.5s
################################################################################
                     [1m Learning iteration 685/2000 [0m                      

                       Computation: 1957 steps/s (collection: 3.053s, learning 0.625s)
               Value function loss: 14.9584
                    Surrogate loss: -0.0065
             Mean action noise std: 0.98
                       Mean reward: -47.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4939200
                    Iteration time: 3.68s
                        Total time: 2597.68s
                               ETA: 4979.5s
################################################################################
                     [1m Learning iteration 686/2000 [0m                      

                       Computation: 1918 steps/s (collection: 3.143s, learning 0.610s)
               Value function loss: 16.8794
                    Surrogate loss: -0.0007
             Mean action noise std: 0.98
                       Mean reward: -47.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4946400
                    Iteration time: 3.75s
                        Total time: 2601.43s
                               ETA: 4975.7s
################################################################################
                     [1m Learning iteration 687/2000 [0m                      

                       Computation: 1943 steps/s (collection: 3.084s, learning 0.621s)
               Value function loss: 16.0954
                    Surrogate loss: -0.0050
             Mean action noise std: 0.98
                       Mean reward: -47.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4953600
                    Iteration time: 3.70s
                        Total time: 2605.14s
                               ETA: 4971.7s
################################################################################
                     [1m Learning iteration 688/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.204s, learning 0.614s)
               Value function loss: 15.8458
                    Surrogate loss: -0.0030
             Mean action noise std: 0.98
                       Mean reward: -48.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4960800
                    Iteration time: 3.82s
                        Total time: 2608.95s
                               ETA: 4968.0s
################################################################################
                     [1m Learning iteration 689/2000 [0m                      

                       Computation: 1942 steps/s (collection: 3.046s, learning 0.660s)
               Value function loss: 16.3427
                    Surrogate loss: -0.0055
             Mean action noise std: 0.98
                       Mean reward: -48.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4968000
                    Iteration time: 3.71s
                        Total time: 2612.66s
                               ETA: 4964.1s
################################################################################
                     [1m Learning iteration 690/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.099s, learning 0.638s)
               Value function loss: 15.2788
                    Surrogate loss: -0.0048
             Mean action noise std: 0.98
                       Mean reward: -48.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4975200
                    Iteration time: 3.74s
                        Total time: 2616.40s
                               ETA: 4960.2s
################################################################################
                     [1m Learning iteration 691/2000 [0m                      

                       Computation: 1934 steps/s (collection: 3.092s, learning 0.630s)
               Value function loss: 16.2068
                    Surrogate loss: -0.0070
             Mean action noise std: 0.98
                       Mean reward: -47.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4982400
                    Iteration time: 3.72s
                        Total time: 2620.12s
                               ETA: 4956.3s
################################################################################
                     [1m Learning iteration 692/2000 [0m                      

                       Computation: 1949 steps/s (collection: 3.079s, learning 0.615s)
               Value function loss: 12.4731
                    Surrogate loss: -0.0046
             Mean action noise std: 0.98
                       Mean reward: -47.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4989600
                    Iteration time: 3.69s
                        Total time: 2623.81s
                               ETA: 4952.3s
################################################################################
                     [1m Learning iteration 693/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.119s, learning 0.609s)
               Value function loss: 14.9426
                    Surrogate loss: -0.0073
             Mean action noise std: 0.98
                       Mean reward: -47.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 4996800
                    Iteration time: 3.73s
                        Total time: 2627.54s
                               ETA: 4948.4s
################################################################################
                     [1m Learning iteration 694/2000 [0m                      

                       Computation: 1957 steps/s (collection: 3.034s, learning 0.644s)
               Value function loss: 15.0243
                    Surrogate loss: -0.0052
             Mean action noise std: 0.98
                       Mean reward: -47.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5004000
                    Iteration time: 3.68s
                        Total time: 2631.22s
                               ETA: 4944.4s
################################################################################
                     [1m Learning iteration 695/2000 [0m                      

                       Computation: 1867 steps/s (collection: 3.136s, learning 0.720s)
               Value function loss: 15.4964
                    Surrogate loss: -0.0054
             Mean action noise std: 0.98
                       Mean reward: -47.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5011200
                    Iteration time: 3.86s
                        Total time: 2635.08s
                               ETA: 4940.8s
################################################################################
                     [1m Learning iteration 696/2000 [0m                      

                       Computation: 1944 steps/s (collection: 3.077s, learning 0.625s)
               Value function loss: 16.7286
                    Surrogate loss: -0.0028
             Mean action noise std: 0.98
                       Mean reward: -47.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5018400
                    Iteration time: 3.70s
                        Total time: 2638.78s
                               ETA: 4936.8s
################################################################################
                     [1m Learning iteration 697/2000 [0m                      

                       Computation: 1912 steps/s (collection: 3.143s, learning 0.621s)
               Value function loss: 14.7651
                    Surrogate loss: -0.0006
             Mean action noise std: 0.98
                       Mean reward: -47.59
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5025600
                    Iteration time: 3.76s
                        Total time: 2642.54s
                               ETA: 4933.0s
################################################################################
                     [1m Learning iteration 698/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.093s, learning 0.667s)
               Value function loss: 13.2969
                    Surrogate loss: -0.0006
             Mean action noise std: 0.98
                       Mean reward: -47.68
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5032800
                    Iteration time: 3.76s
                        Total time: 2646.30s
                               ETA: 4929.2s
################################################################################
                     [1m Learning iteration 699/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.105s, learning 0.657s)
               Value function loss: 15.7779
                    Surrogate loss: -0.0050
             Mean action noise std: 0.98
                       Mean reward: -47.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5040000
                    Iteration time: 3.76s
                        Total time: 2650.07s
                               ETA: 4925.3s
################################################################################
                     [1m Learning iteration 700/2000 [0m                      

                       Computation: 1837 steps/s (collection: 3.172s, learning 0.746s)
               Value function loss: 15.6989
                    Surrogate loss: -0.0039
             Mean action noise std: 0.98
                       Mean reward: -47.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5047200
                    Iteration time: 3.92s
                        Total time: 2653.98s
                               ETA: 4921.8s
################################################################################
                     [1m Learning iteration 701/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.086s, learning 0.755s)
               Value function loss: 15.1232
                    Surrogate loss: -0.0062
             Mean action noise std: 0.97
                       Mean reward: -47.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5054400
                    Iteration time: 3.84s
                        Total time: 2657.82s
                               ETA: 4918.1s
################################################################################
                     [1m Learning iteration 702/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.166s, learning 0.682s)
               Value function loss: 16.4982
                    Surrogate loss: 0.0061
             Mean action noise std: 0.97
                       Mean reward: -48.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5061600
                    Iteration time: 3.85s
                        Total time: 2661.67s
                               ETA: 4914.4s
################################################################################
                     [1m Learning iteration 703/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.067s, learning 0.784s)
               Value function loss: 16.8117
                    Surrogate loss: -0.0069
             Mean action noise std: 0.97
                       Mean reward: -48.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5068800
                    Iteration time: 3.85s
                        Total time: 2665.52s
                               ETA: 4910.8s
################################################################################
                     [1m Learning iteration 704/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.139s, learning 0.763s)
               Value function loss: 16.0727
                    Surrogate loss: -0.0019
             Mean action noise std: 0.97
                       Mean reward: -49.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5076000
                    Iteration time: 3.90s
                        Total time: 2669.42s
                               ETA: 4907.2s
################################################################################
                     [1m Learning iteration 705/2000 [0m                      

                       Computation: 1811 steps/s (collection: 3.107s, learning 0.868s)
               Value function loss: 15.0968
                    Surrogate loss: 0.0008
             Mean action noise std: 0.97
                       Mean reward: -49.06
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5083200
                    Iteration time: 3.98s
                        Total time: 2673.40s
                               ETA: 4903.8s
################################################################################
                     [1m Learning iteration 706/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.070s, learning 0.756s)
               Value function loss: 16.5670
                    Surrogate loss: -0.0009
             Mean action noise std: 0.97
                       Mean reward: -49.26
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5090400
                    Iteration time: 3.83s
                        Total time: 2677.23s
                               ETA: 4900.0s
################################################################################
                     [1m Learning iteration 707/2000 [0m                      

                       Computation: 1867 steps/s (collection: 3.158s, learning 0.698s)
               Value function loss: 16.4178
                    Surrogate loss: -0.0024
             Mean action noise std: 0.97
                       Mean reward: -49.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5097600
                    Iteration time: 3.86s
                        Total time: 2681.08s
                               ETA: 4896.4s
################################################################################
                     [1m Learning iteration 708/2000 [0m                      

                       Computation: 1932 steps/s (collection: 3.115s, learning 0.611s)
               Value function loss: 12.1563
                    Surrogate loss: 0.0031
             Mean action noise std: 0.97
                       Mean reward: -49.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5104800
                    Iteration time: 3.73s
                        Total time: 2684.81s
                               ETA: 4892.5s
################################################################################
                     [1m Learning iteration 709/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.209s, learning 0.616s)
               Value function loss: 14.3970
                    Surrogate loss: -0.0041
             Mean action noise std: 0.98
                       Mean reward: -49.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5112000
                    Iteration time: 3.82s
                        Total time: 2688.63s
                               ETA: 4888.8s
################################################################################
                     [1m Learning iteration 710/2000 [0m                      

                       Computation: 1934 steps/s (collection: 3.099s, learning 0.623s)
               Value function loss: 14.4589
                    Surrogate loss: -0.0083
             Mean action noise std: 0.97
                       Mean reward: -49.12
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5119200
                    Iteration time: 3.72s
                        Total time: 2692.35s
                               ETA: 4884.9s
################################################################################
                     [1m Learning iteration 711/2000 [0m                      

                       Computation: 1913 steps/s (collection: 3.106s, learning 0.657s)
               Value function loss: 12.6840
                    Surrogate loss: 0.0037
             Mean action noise std: 0.98
                       Mean reward: -48.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5126400
                    Iteration time: 3.76s
                        Total time: 2696.12s
                               ETA: 4881.0s
################################################################################
                     [1m Learning iteration 712/2000 [0m                      

                       Computation: 1905 steps/s (collection: 3.123s, learning 0.656s)
               Value function loss: 12.6777
                    Surrogate loss: -0.0051
             Mean action noise std: 0.97
                       Mean reward: -47.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5133600
                    Iteration time: 3.78s
                        Total time: 2699.90s
                               ETA: 4877.2s
################################################################################
                     [1m Learning iteration 713/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.077s, learning 0.770s)
               Value function loss: 12.9034
                    Surrogate loss: 0.0026
             Mean action noise std: 0.97
                       Mean reward: -47.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5140800
                    Iteration time: 3.85s
                        Total time: 2703.74s
                               ETA: 4873.6s
################################################################################
                     [1m Learning iteration 714/2000 [0m                      

                       Computation: 1852 steps/s (collection: 3.102s, learning 0.784s)
               Value function loss: 14.8836
                    Surrogate loss: -0.0046
             Mean action noise std: 0.97
                       Mean reward: -47.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5148000
                    Iteration time: 3.89s
                        Total time: 2707.63s
                               ETA: 4869.9s
################################################################################
                     [1m Learning iteration 715/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.078s, learning 0.765s)
               Value function loss: 14.2361
                    Surrogate loss: -0.0024
             Mean action noise std: 0.97
                       Mean reward: -48.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5155200
                    Iteration time: 3.84s
                        Total time: 2711.47s
                               ETA: 4866.3s
################################################################################
                     [1m Learning iteration 716/2000 [0m                      

                       Computation: 1818 steps/s (collection: 3.175s, learning 0.785s)
               Value function loss: 14.7109
                    Surrogate loss: -0.0037
             Mean action noise std: 0.97
                       Mean reward: -48.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5162400
                    Iteration time: 3.96s
                        Total time: 2715.43s
                               ETA: 4862.8s
################################################################################
                     [1m Learning iteration 717/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.119s, learning 0.752s)
               Value function loss: 16.7949
                    Surrogate loss: -0.0082
             Mean action noise std: 0.97
                       Mean reward: -48.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5169600
                    Iteration time: 3.87s
                        Total time: 2719.30s
                               ETA: 4859.1s
################################################################################
                     [1m Learning iteration 718/2000 [0m                      

                       Computation: 1857 steps/s (collection: 3.143s, learning 0.733s)
               Value function loss: 17.3517
                    Surrogate loss: -0.0040
             Mean action noise std: 0.97
                       Mean reward: -48.59
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5176800
                    Iteration time: 3.88s
                        Total time: 2723.18s
                               ETA: 4855.5s
################################################################################
                     [1m Learning iteration 719/2000 [0m                      

                       Computation: 1840 steps/s (collection: 3.123s, learning 0.790s)
               Value function loss: 17.8832
                    Surrogate loss: -0.0020
             Mean action noise std: 0.97
                       Mean reward: -48.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5184000
                    Iteration time: 3.91s
                        Total time: 2727.09s
                               ETA: 4851.9s
################################################################################
                     [1m Learning iteration 720/2000 [0m                      

                       Computation: 1820 steps/s (collection: 3.122s, learning 0.833s)
               Value function loss: 15.9444
                    Surrogate loss: -0.0044
             Mean action noise std: 0.97
                       Mean reward: -48.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5191200
                    Iteration time: 3.95s
                        Total time: 2731.05s
                               ETA: 4848.5s
################################################################################
                     [1m Learning iteration 721/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.185s, learning 0.630s)
               Value function loss: 17.8374
                    Surrogate loss: 0.0011
             Mean action noise std: 0.97
                       Mean reward: -48.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5198400
                    Iteration time: 3.82s
                        Total time: 2734.86s
                               ETA: 4844.7s
################################################################################
                     [1m Learning iteration 722/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.067s, learning 0.771s)
               Value function loss: 14.2092
                    Surrogate loss: -0.0070
             Mean action noise std: 0.97
                       Mean reward: -49.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5205600
                    Iteration time: 3.84s
                        Total time: 2738.70s
                               ETA: 4841.0s
################################################################################
                     [1m Learning iteration 723/2000 [0m                      

                       Computation: 1857 steps/s (collection: 3.149s, learning 0.728s)
               Value function loss: 14.3342
                    Surrogate loss: 0.0035
             Mean action noise std: 0.96
                       Mean reward: -49.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5212800
                    Iteration time: 3.88s
                        Total time: 2742.58s
                               ETA: 4837.4s
################################################################################
                     [1m Learning iteration 724/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.104s, learning 0.769s)
               Value function loss: 14.1314
                    Surrogate loss: -0.0052
             Mean action noise std: 0.96
                       Mean reward: -48.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5220000
                    Iteration time: 3.87s
                        Total time: 2746.45s
                               ETA: 4833.7s
################################################################################
                     [1m Learning iteration 725/2000 [0m                      

                       Computation: 1863 steps/s (collection: 3.097s, learning 0.766s)
               Value function loss: 11.7000
                    Surrogate loss: -0.0055
             Mean action noise std: 0.96
                       Mean reward: -48.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5227200
                    Iteration time: 3.86s
                        Total time: 2750.31s
                               ETA: 4830.1s
################################################################################
                     [1m Learning iteration 726/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.129s, learning 0.770s)
               Value function loss: 15.0473
                    Surrogate loss: -0.0018
             Mean action noise std: 0.96
                       Mean reward: -48.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5234400
                    Iteration time: 3.90s
                        Total time: 2754.21s
                               ETA: 4826.5s
################################################################################
                     [1m Learning iteration 727/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.124s, learning 0.744s)
               Value function loss: 12.1154
                    Surrogate loss: -0.0043
             Mean action noise std: 0.96
                       Mean reward: -47.68
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5241600
                    Iteration time: 3.87s
                        Total time: 2758.08s
                               ETA: 4822.8s
################################################################################
                     [1m Learning iteration 728/2000 [0m                      

                       Computation: 1818 steps/s (collection: 3.190s, learning 0.770s)
               Value function loss: 14.5863
                    Surrogate loss: -0.0016
             Mean action noise std: 0.97
                       Mean reward: -47.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5248800
                    Iteration time: 3.96s
                        Total time: 2762.04s
                               ETA: 4819.4s
################################################################################
                     [1m Learning iteration 729/2000 [0m                      

                       Computation: 1865 steps/s (collection: 3.081s, learning 0.779s)
               Value function loss: 14.3826
                    Surrogate loss: -0.0074
             Mean action noise std: 0.97
                       Mean reward: -47.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5256000
                    Iteration time: 3.86s
                        Total time: 2765.90s
                               ETA: 4815.7s
################################################################################
                     [1m Learning iteration 730/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.087s, learning 0.803s)
               Value function loss: 13.4580
                    Surrogate loss: 0.0021
             Mean action noise std: 0.97
                       Mean reward: -48.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5263200
                    Iteration time: 3.89s
                        Total time: 2769.79s
                               ETA: 4812.1s
################################################################################
                     [1m Learning iteration 731/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.124s, learning 0.761s)
               Value function loss: 12.2351
                    Surrogate loss: -0.0050
             Mean action noise std: 0.97
                       Mean reward: -47.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5270400
                    Iteration time: 3.88s
                        Total time: 2773.67s
                               ETA: 4808.5s
################################################################################
                     [1m Learning iteration 732/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.075s, learning 0.775s)
               Value function loss: 13.0482
                    Surrogate loss: -0.0049
             Mean action noise std: 0.96
                       Mean reward: -47.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5277600
                    Iteration time: 3.85s
                        Total time: 2777.52s
                               ETA: 4804.8s
################################################################################
                     [1m Learning iteration 733/2000 [0m                      

                       Computation: 1860 steps/s (collection: 3.196s, learning 0.675s)
               Value function loss: 13.2998
                    Surrogate loss: 0.0026
             Mean action noise std: 0.96
                       Mean reward: -48.02
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5284800
                    Iteration time: 3.87s
                        Total time: 2781.39s
                               ETA: 4801.1s
################################################################################
                     [1m Learning iteration 734/2000 [0m                      

                       Computation: 1879 steps/s (collection: 3.082s, learning 0.749s)
               Value function loss: 11.6667
                    Surrogate loss: -0.0040
             Mean action noise std: 0.96
                       Mean reward: -47.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5292000
                    Iteration time: 3.83s
                        Total time: 2785.22s
                               ETA: 4797.4s
################################################################################
                     [1m Learning iteration 735/2000 [0m                      

                       Computation: 1809 steps/s (collection: 3.094s, learning 0.884s)
               Value function loss: 12.1987
                    Surrogate loss: -0.0005
             Mean action noise std: 0.96
                       Mean reward: -47.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5299200
                    Iteration time: 3.98s
                        Total time: 2789.20s
                               ETA: 4793.9s
################################################################################
                     [1m Learning iteration 736/2000 [0m                      

                       Computation: 1898 steps/s (collection: 3.092s, learning 0.701s)
               Value function loss: 14.4704
                    Surrogate loss: -0.0045
             Mean action noise std: 0.96
                       Mean reward: -48.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5306400
                    Iteration time: 3.79s
                        Total time: 2793.00s
                               ETA: 4790.2s
################################################################################
                     [1m Learning iteration 737/2000 [0m                      

                       Computation: 1918 steps/s (collection: 3.075s, learning 0.678s)
               Value function loss: 12.7520
                    Surrogate loss: 0.0008
             Mean action noise std: 0.96
                       Mean reward: -48.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5313600
                    Iteration time: 3.75s
                        Total time: 2796.75s
                               ETA: 4786.3s
################################################################################
                     [1m Learning iteration 738/2000 [0m                      

                       Computation: 1799 steps/s (collection: 3.279s, learning 0.723s)
               Value function loss: 11.3809
                    Surrogate loss: -0.0038
             Mean action noise std: 0.96
                       Mean reward: -48.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5320800
                    Iteration time: 4.00s
                        Total time: 2800.75s
                               ETA: 4782.9s
################################################################################
                     [1m Learning iteration 739/2000 [0m                      

                       Computation: 1952 steps/s (collection: 3.052s, learning 0.636s)
               Value function loss: 13.9389
                    Surrogate loss: 0.0022
             Mean action noise std: 0.96
                       Mean reward: -48.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5328000
                    Iteration time: 3.69s
                        Total time: 2804.44s
                               ETA: 4778.9s
################################################################################
                     [1m Learning iteration 740/2000 [0m                      

                       Computation: 1801 steps/s (collection: 3.148s, learning 0.848s)
               Value function loss: 10.8943
                    Surrogate loss: -0.0035
             Mean action noise std: 0.96
                       Mean reward: -48.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5335200
                    Iteration time: 4.00s
                        Total time: 2808.43s
                               ETA: 4775.5s
################################################################################
                     [1m Learning iteration 741/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.074s, learning 0.750s)
               Value function loss: 15.0162
                    Surrogate loss: -0.0020
             Mean action noise std: 0.96
                       Mean reward: -49.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5342400
                    Iteration time: 3.82s
                        Total time: 2812.26s
                               ETA: 4771.7s
################################################################################
                     [1m Learning iteration 742/2000 [0m                      

                       Computation: 1866 steps/s (collection: 3.024s, learning 0.834s)
               Value function loss: 11.1213
                    Surrogate loss: -0.0065
             Mean action noise std: 0.96
                       Mean reward: -48.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5349600
                    Iteration time: 3.86s
                        Total time: 2816.12s
                               ETA: 4768.1s
################################################################################
                     [1m Learning iteration 743/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.136s, learning 0.755s)
               Value function loss: 11.8966
                    Surrogate loss: -0.0035
             Mean action noise std: 0.96
                       Mean reward: -48.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5356800
                    Iteration time: 3.89s
                        Total time: 2820.01s
                               ETA: 4764.4s
################################################################################
                     [1m Learning iteration 744/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.071s, learning 0.739s)
               Value function loss: 12.2194
                    Surrogate loss: -0.0056
             Mean action noise std: 0.96
                       Mean reward: -48.25
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5364000
                    Iteration time: 3.81s
                        Total time: 2823.82s
                               ETA: 4760.7s
################################################################################
                     [1m Learning iteration 745/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.177s, learning 0.725s)
               Value function loss: 12.9251
                    Surrogate loss: -0.0021
             Mean action noise std: 0.96
                       Mean reward: -48.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5371200
                    Iteration time: 3.90s
                        Total time: 2827.72s
                               ETA: 4757.1s
################################################################################
                     [1m Learning iteration 746/2000 [0m                      

                       Computation: 1934 steps/s (collection: 3.096s, learning 0.626s)
               Value function loss: 13.7235
                    Surrogate loss: 0.0008
             Mean action noise std: 0.95
                       Mean reward: -47.65
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5378400
                    Iteration time: 3.72s
                        Total time: 2831.44s
                               ETA: 4753.2s
################################################################################
                     [1m Learning iteration 747/2000 [0m                      

                       Computation: 1860 steps/s (collection: 3.116s, learning 0.753s)
               Value function loss: 11.2932
                    Surrogate loss: -0.0039
             Mean action noise std: 0.95
                       Mean reward: -47.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5385600
                    Iteration time: 3.87s
                        Total time: 2835.31s
                               ETA: 4749.5s
################################################################################
                     [1m Learning iteration 748/2000 [0m                      

                       Computation: 1900 steps/s (collection: 3.116s, learning 0.672s)
               Value function loss: 10.2621
                    Surrogate loss: 0.0000
             Mean action noise std: 0.95
                       Mean reward: -48.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5392800
                    Iteration time: 3.79s
                        Total time: 2839.10s
                               ETA: 4745.7s
################################################################################
                     [1m Learning iteration 749/2000 [0m                      

                       Computation: 1861 steps/s (collection: 3.099s, learning 0.768s)
               Value function loss: 10.5704
                    Surrogate loss: -0.0064
             Mean action noise std: 0.95
                       Mean reward: -48.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5400000
                    Iteration time: 3.87s
                        Total time: 2842.97s
                               ETA: 4742.1s
################################################################################
                     [1m Learning iteration 750/2000 [0m                      

                       Computation: 1901 steps/s (collection: 3.141s, learning 0.645s)
               Value function loss: 9.4857
                    Surrogate loss: -0.0058
             Mean action noise std: 0.95
                       Mean reward: -48.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5407200
                    Iteration time: 3.79s
                        Total time: 2846.75s
                               ETA: 4738.3s
################################################################################
                     [1m Learning iteration 751/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.077s, learning 0.740s)
               Value function loss: 12.3016
                    Surrogate loss: -0.0004
             Mean action noise std: 0.95
                       Mean reward: -48.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5414400
                    Iteration time: 3.82s
                        Total time: 2850.57s
                               ETA: 4734.5s
################################################################################
                     [1m Learning iteration 752/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.163s, learning 0.738s)
               Value function loss: 12.0613
                    Surrogate loss: -0.0018
             Mean action noise std: 0.95
                       Mean reward: -48.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5421600
                    Iteration time: 3.90s
                        Total time: 2854.47s
                               ETA: 4730.9s
################################################################################
                     [1m Learning iteration 753/2000 [0m                      

                       Computation: 1925 steps/s (collection: 3.091s, learning 0.649s)
               Value function loss: 10.3375
                    Surrogate loss: -0.0028
             Mean action noise std: 0.95
                       Mean reward: -48.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5428800
                    Iteration time: 3.74s
                        Total time: 2858.21s
                               ETA: 4727.0s
################################################################################
                     [1m Learning iteration 754/2000 [0m                      

                       Computation: 1814 steps/s (collection: 3.167s, learning 0.800s)
               Value function loss: 10.6094
                    Surrogate loss: -0.0039
             Mean action noise std: 0.95
                       Mean reward: -48.51
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5436000
                    Iteration time: 3.97s
                        Total time: 2862.18s
                               ETA: 4723.5s
################################################################################
                     [1m Learning iteration 755/2000 [0m                      

                       Computation: 1856 steps/s (collection: 3.088s, learning 0.791s)
               Value function loss: 10.9675
                    Surrogate loss: -0.0073
             Mean action noise std: 0.96
                       Mean reward: -48.39
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5443200
                    Iteration time: 3.88s
                        Total time: 2866.06s
                               ETA: 4719.9s
################################################################################
                     [1m Learning iteration 756/2000 [0m                      

                       Computation: 1909 steps/s (collection: 3.084s, learning 0.688s)
               Value function loss: 13.3747
                    Surrogate loss: -0.0070
             Mean action noise std: 0.95
                       Mean reward: -48.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5450400
                    Iteration time: 3.77s
                        Total time: 2869.83s
                               ETA: 4716.1s
################################################################################
                     [1m Learning iteration 757/2000 [0m                      

                       Computation: 1899 steps/s (collection: 3.130s, learning 0.660s)
               Value function loss: 11.4307
                    Surrogate loss: -0.0041
             Mean action noise std: 0.96
                       Mean reward: -47.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5457600
                    Iteration time: 3.79s
                        Total time: 2873.62s
                               ETA: 4712.3s
################################################################################
                     [1m Learning iteration 758/2000 [0m                      

                       Computation: 1897 steps/s (collection: 3.111s, learning 0.683s)
               Value function loss: 13.5510
                    Surrogate loss: -0.0054
             Mean action noise std: 0.96
                       Mean reward: -47.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5464800
                    Iteration time: 3.79s
                        Total time: 2877.41s
                               ETA: 4708.5s
################################################################################
                     [1m Learning iteration 759/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.195s, learning 0.648s)
               Value function loss: 15.5348
                    Surrogate loss: -0.0042
             Mean action noise std: 0.95
                       Mean reward: -47.68
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5472000
                    Iteration time: 3.84s
                        Total time: 2881.26s
                               ETA: 4704.8s
################################################################################
                     [1m Learning iteration 760/2000 [0m                      

                       Computation: 1936 steps/s (collection: 3.093s, learning 0.625s)
               Value function loss: 12.9962
                    Surrogate loss: -0.0024
             Mean action noise std: 0.96
                       Mean reward: -47.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5479200
                    Iteration time: 3.72s
                        Total time: 2884.98s
                               ETA: 4700.9s
################################################################################
                     [1m Learning iteration 761/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.129s, learning 0.692s)
               Value function loss: 12.2157
                    Surrogate loss: 0.0044
             Mean action noise std: 0.96
                       Mean reward: -48.02
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5486400
                    Iteration time: 3.82s
                        Total time: 2888.80s
                               ETA: 4697.1s
################################################################################
                     [1m Learning iteration 762/2000 [0m                      

                       Computation: 1922 steps/s (collection: 3.136s, learning 0.609s)
               Value function loss: 11.6857
                    Surrogate loss: -0.0012
             Mean action noise std: 0.96
                       Mean reward: -47.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5493600
                    Iteration time: 3.74s
                        Total time: 2892.54s
                               ETA: 4693.3s
################################################################################
                     [1m Learning iteration 763/2000 [0m                      

                       Computation: 1919 steps/s (collection: 3.116s, learning 0.635s)
               Value function loss: 15.1416
                    Surrogate loss: -0.0047
             Mean action noise std: 0.96
                       Mean reward: -47.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5500800
                    Iteration time: 3.75s
                        Total time: 2896.29s
                               ETA: 4689.4s
################################################################################
                     [1m Learning iteration 764/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.143s, learning 0.700s)
               Value function loss: 16.0687
                    Surrogate loss: -0.0076
             Mean action noise std: 0.97
                       Mean reward: -47.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5508000
                    Iteration time: 3.84s
                        Total time: 2900.14s
                               ETA: 4685.7s
################################################################################
                     [1m Learning iteration 765/2000 [0m                      

                       Computation: 1904 steps/s (collection: 3.088s, learning 0.693s)
               Value function loss: 13.4323
                    Surrogate loss: -0.0046
             Mean action noise std: 0.96
                       Mean reward: -47.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5515200
                    Iteration time: 3.78s
                        Total time: 2903.92s
                               ETA: 4681.9s
################################################################################
                     [1m Learning iteration 766/2000 [0m                      

                       Computation: 1879 steps/s (collection: 3.172s, learning 0.658s)
               Value function loss: 13.3977
                    Surrogate loss: -0.0049
             Mean action noise std: 0.96
                       Mean reward: -47.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5522400
                    Iteration time: 3.83s
                        Total time: 2907.75s
                               ETA: 4678.2s
################################################################################
                     [1m Learning iteration 767/2000 [0m                      

                       Computation: 1919 steps/s (collection: 3.088s, learning 0.663s)
               Value function loss: 11.6401
                    Surrogate loss: -0.0052
             Mean action noise std: 0.96
                       Mean reward: -47.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5529600
                    Iteration time: 3.75s
                        Total time: 2911.50s
                               ETA: 4674.3s
################################################################################
                     [1m Learning iteration 768/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.147s, learning 0.667s)
               Value function loss: 13.3865
                    Surrogate loss: -0.0035
             Mean action noise std: 0.96
                       Mean reward: -47.65
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5536800
                    Iteration time: 3.81s
                        Total time: 2915.31s
                               ETA: 4670.6s
################################################################################
                     [1m Learning iteration 769/2000 [0m                      

                       Computation: 1936 steps/s (collection: 3.106s, learning 0.612s)
               Value function loss: 12.7407
                    Surrogate loss: -0.0006
             Mean action noise std: 0.96
                       Mean reward: -47.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5544000
                    Iteration time: 3.72s
                        Total time: 2919.03s
                               ETA: 4666.7s
################################################################################
                     [1m Learning iteration 770/2000 [0m                      

                       Computation: 1939 steps/s (collection: 3.098s, learning 0.615s)
               Value function loss: 11.5236
                    Surrogate loss: 0.0041
             Mean action noise std: 0.96
                       Mean reward: -47.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5551200
                    Iteration time: 3.71s
                        Total time: 2922.74s
                               ETA: 4662.7s
################################################################################
                     [1m Learning iteration 771/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.123s, learning 0.638s)
               Value function loss: 11.6213
                    Surrogate loss: -0.0071
             Mean action noise std: 0.96
                       Mean reward: -47.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5558400
                    Iteration time: 3.76s
                        Total time: 2926.51s
                               ETA: 4658.9s
################################################################################
                     [1m Learning iteration 772/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.202s, learning 0.636s)
               Value function loss: 12.5989
                    Surrogate loss: -0.0011
             Mean action noise std: 0.96
                       Mean reward: -46.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5565600
                    Iteration time: 3.84s
                        Total time: 2930.34s
                               ETA: 4655.2s
################################################################################
                     [1m Learning iteration 773/2000 [0m                      

                       Computation: 1837 steps/s (collection: 3.297s, learning 0.622s)
               Value function loss: 14.3568
                    Surrogate loss: -0.0018
             Mean action noise std: 0.96
                       Mean reward: -47.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5572800
                    Iteration time: 3.92s
                        Total time: 2934.26s
                               ETA: 4651.6s
################################################################################
                     [1m Learning iteration 774/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.220s, learning 0.621s)
               Value function loss: 11.1716
                    Surrogate loss: -0.0014
             Mean action noise std: 0.96
                       Mean reward: -47.68
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5580000
                    Iteration time: 3.84s
                        Total time: 2938.10s
                               ETA: 4647.9s
################################################################################
                     [1m Learning iteration 775/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.236s, learning 0.596s)
               Value function loss: 13.0502
                    Surrogate loss: -0.0072
             Mean action noise std: 0.96
                       Mean reward: -47.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5587200
                    Iteration time: 3.83s
                        Total time: 2941.94s
                               ETA: 4644.2s
################################################################################
                     [1m Learning iteration 776/2000 [0m                      

                       Computation: 1940 steps/s (collection: 3.096s, learning 0.614s)
               Value function loss: 11.8929
                    Surrogate loss: -0.0072
             Mean action noise std: 0.96
                       Mean reward: -48.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5594400
                    Iteration time: 3.71s
                        Total time: 2945.65s
                               ETA: 4640.2s
################################################################################
                     [1m Learning iteration 777/2000 [0m                      

                       Computation: 1949 steps/s (collection: 3.081s, learning 0.612s)
               Value function loss: 13.5239
                    Surrogate loss: 0.0006
             Mean action noise std: 0.96
                       Mean reward: -48.14
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5601600
                    Iteration time: 3.69s
                        Total time: 2949.34s
                               ETA: 4636.3s
################################################################################
                     [1m Learning iteration 778/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.179s, learning 0.627s)
               Value function loss: 15.9681
                    Surrogate loss: -0.0053
             Mean action noise std: 0.96
                       Mean reward: -48.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5608800
                    Iteration time: 3.81s
                        Total time: 2953.15s
                               ETA: 4632.5s
################################################################################
                     [1m Learning iteration 779/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.116s, learning 0.612s)
               Value function loss: 13.5405
                    Surrogate loss: -0.0023
             Mean action noise std: 0.96
                       Mean reward: -48.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5616000
                    Iteration time: 3.73s
                        Total time: 2956.87s
                               ETA: 4628.6s
################################################################################
                     [1m Learning iteration 780/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.246s, learning 0.601s)
               Value function loss: 10.9114
                    Surrogate loss: -0.0031
             Mean action noise std: 0.95
                       Mean reward: -48.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5623200
                    Iteration time: 3.85s
                        Total time: 2960.72s
                               ETA: 4624.9s
################################################################################
                     [1m Learning iteration 781/2000 [0m                      

                       Computation: 1820 steps/s (collection: 3.258s, learning 0.698s)
               Value function loss: 12.6908
                    Surrogate loss: 0.0015
             Mean action noise std: 0.95
                       Mean reward: -48.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5630400
                    Iteration time: 3.96s
                        Total time: 2964.68s
                               ETA: 4621.4s
################################################################################
                     [1m Learning iteration 782/2000 [0m                      

                       Computation: 1832 steps/s (collection: 3.297s, learning 0.632s)
               Value function loss: 11.2774
                    Surrogate loss: -0.0048
             Mean action noise std: 0.95
                       Mean reward: -48.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5637600
                    Iteration time: 3.93s
                        Total time: 2968.60s
                               ETA: 4617.8s
################################################################################
                     [1m Learning iteration 783/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.204s, learning 0.618s)
               Value function loss: 13.9369
                    Surrogate loss: 0.0045
             Mean action noise std: 0.95
                       Mean reward: -47.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5644800
                    Iteration time: 3.82s
                        Total time: 2972.43s
                               ETA: 4614.1s
################################################################################
                     [1m Learning iteration 784/2000 [0m                      

                       Computation: 1948 steps/s (collection: 3.086s, learning 0.610s)
               Value function loss: 12.5507
                    Surrogate loss: -0.0063
             Mean action noise std: 0.95
                       Mean reward: -46.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5652000
                    Iteration time: 3.70s
                        Total time: 2976.12s
                               ETA: 4610.1s
################################################################################
                     [1m Learning iteration 785/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.105s, learning 0.631s)
               Value function loss: 12.5170
                    Surrogate loss: -0.0047
             Mean action noise std: 0.95
                       Mean reward: -47.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5659200
                    Iteration time: 3.74s
                        Total time: 2979.86s
                               ETA: 4606.3s
################################################################################
                     [1m Learning iteration 786/2000 [0m                      

                       Computation: 1934 steps/s (collection: 3.096s, learning 0.625s)
               Value function loss: 13.2980
                    Surrogate loss: -0.0054
             Mean action noise std: 0.95
                       Mean reward: -47.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5666400
                    Iteration time: 3.72s
                        Total time: 2983.58s
                               ETA: 4602.4s
################################################################################
                     [1m Learning iteration 787/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.195s, learning 0.619s)
               Value function loss: 13.2340
                    Surrogate loss: -0.0011
             Mean action noise std: 0.95
                       Mean reward: -47.26
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5673600
                    Iteration time: 3.81s
                        Total time: 2987.39s
                               ETA: 4598.6s
################################################################################
                     [1m Learning iteration 788/2000 [0m                      

                       Computation: 1939 steps/s (collection: 3.091s, learning 0.620s)
               Value function loss: 14.6366
                    Surrogate loss: -0.0011
             Mean action noise std: 0.95
                       Mean reward: -47.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5680800
                    Iteration time: 3.71s
                        Total time: 2991.10s
                               ETA: 4594.7s
################################################################################
                     [1m Learning iteration 789/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.120s, learning 0.780s)
               Value function loss: 13.3450
                    Surrogate loss: 0.0062
             Mean action noise std: 0.95
                       Mean reward: -47.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5688000
                    Iteration time: 3.90s
                        Total time: 2995.00s
                               ETA: 4591.1s
################################################################################
                     [1m Learning iteration 790/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.110s, learning 0.686s)
               Value function loss: 14.8026
                    Surrogate loss: -0.0067
             Mean action noise std: 0.95
                       Mean reward: -47.57
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5695200
                    Iteration time: 3.80s
                        Total time: 2998.80s
                               ETA: 4587.3s
################################################################################
                     [1m Learning iteration 791/2000 [0m                      

                       Computation: 1934 steps/s (collection: 3.080s, learning 0.641s)
               Value function loss: 13.0722
                    Surrogate loss: -0.0058
             Mean action noise std: 0.95
                       Mean reward: -47.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5702400
                    Iteration time: 3.72s
                        Total time: 3002.52s
                               ETA: 4583.4s
################################################################################
                     [1m Learning iteration 792/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.057s, learning 0.895s)
               Value function loss: 17.4320
                    Surrogate loss: -0.0063
             Mean action noise std: 0.95
                       Mean reward: -47.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5709600
                    Iteration time: 3.95s
                        Total time: 3006.47s
                               ETA: 4579.8s
################################################################################
                     [1m Learning iteration 793/2000 [0m                      

                       Computation: 1902 steps/s (collection: 3.079s, learning 0.705s)
               Value function loss: 14.0579
                    Surrogate loss: 0.0045
             Mean action noise std: 0.95
                       Mean reward: -48.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5716800
                    Iteration time: 3.78s
                        Total time: 3010.26s
                               ETA: 4576.0s
################################################################################
                     [1m Learning iteration 794/2000 [0m                      

                       Computation: 1807 steps/s (collection: 3.169s, learning 0.814s)
               Value function loss: 16.5306
                    Surrogate loss: -0.0018
             Mean action noise std: 0.95
                       Mean reward: -48.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5724000
                    Iteration time: 3.98s
                        Total time: 3014.24s
                               ETA: 4572.5s
################################################################################
                     [1m Learning iteration 795/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.104s, learning 0.616s)
               Value function loss: 13.0132
                    Surrogate loss: -0.0059
             Mean action noise std: 0.95
                       Mean reward: -48.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5731200
                    Iteration time: 3.72s
                        Total time: 3017.96s
                               ETA: 4568.6s
################################################################################
                     [1m Learning iteration 796/2000 [0m                      

                       Computation: 1947 steps/s (collection: 3.100s, learning 0.596s)
               Value function loss: 14.8450
                    Surrogate loss: -0.0048
             Mean action noise std: 0.95
                       Mean reward: -48.65
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5738400
                    Iteration time: 3.70s
                        Total time: 3021.66s
                               ETA: 4564.7s
################################################################################
                     [1m Learning iteration 797/2000 [0m                      

                       Computation: 1915 steps/s (collection: 3.131s, learning 0.628s)
               Value function loss: 17.1351
                    Surrogate loss: -0.0045
             Mean action noise std: 0.95
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5745600
                    Iteration time: 3.76s
                        Total time: 3025.42s
                               ETA: 4560.9s
################################################################################
                     [1m Learning iteration 798/2000 [0m                      

                       Computation: 1947 steps/s (collection: 3.078s, learning 0.618s)
               Value function loss: 17.3987
                    Surrogate loss: -0.0027
             Mean action noise std: 0.95
                       Mean reward: -48.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5752800
                    Iteration time: 3.70s
                        Total time: 3029.11s
                               ETA: 4556.9s
################################################################################
                     [1m Learning iteration 799/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.190s, learning 0.614s)
               Value function loss: 13.8819
                    Surrogate loss: 0.0000
             Mean action noise std: 0.95
                       Mean reward: -48.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5760000
                    Iteration time: 3.80s
                        Total time: 3032.92s
                               ETA: 4553.2s
################################################################################
                     [1m Learning iteration 800/2000 [0m                      

                       Computation: 1931 steps/s (collection: 3.113s, learning 0.615s)
               Value function loss: 14.9911
                    Surrogate loss: -0.0047
             Mean action noise std: 0.95
                       Mean reward: -48.06
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5767200
                    Iteration time: 3.73s
                        Total time: 3036.64s
                               ETA: 4549.3s
################################################################################
                     [1m Learning iteration 801/2000 [0m                      

                       Computation: 1882 steps/s (collection: 3.186s, learning 0.640s)
               Value function loss: 12.5666
                    Surrogate loss: 0.0048
             Mean action noise std: 0.95
                       Mean reward: -48.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5774400
                    Iteration time: 3.83s
                        Total time: 3040.47s
                               ETA: 4545.5s
################################################################################
                     [1m Learning iteration 802/2000 [0m                      

                       Computation: 1908 steps/s (collection: 3.101s, learning 0.672s)
               Value function loss: 19.7969
                    Surrogate loss: -0.0050
             Mean action noise std: 0.95
                       Mean reward: -48.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5781600
                    Iteration time: 3.77s
                        Total time: 3044.24s
                               ETA: 4541.7s
################################################################################
                     [1m Learning iteration 803/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.141s, learning 0.670s)
               Value function loss: 14.7444
                    Surrogate loss: -0.0045
             Mean action noise std: 0.95
                       Mean reward: -48.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5788800
                    Iteration time: 3.81s
                        Total time: 3048.05s
                               ETA: 4538.0s
################################################################################
                     [1m Learning iteration 804/2000 [0m                      

                       Computation: 1856 steps/s (collection: 3.123s, learning 0.755s)
               Value function loss: 13.2521
                    Surrogate loss: -0.0034
             Mean action noise std: 0.95
                       Mean reward: -48.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5796000
                    Iteration time: 3.88s
                        Total time: 3051.93s
                               ETA: 4534.3s
################################################################################
                     [1m Learning iteration 805/2000 [0m                      

                       Computation: 1940 steps/s (collection: 3.097s, learning 0.614s)
               Value function loss: 15.1380
                    Surrogate loss: -0.0056
             Mean action noise std: 0.95
                       Mean reward: -47.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5803200
                    Iteration time: 3.71s
                        Total time: 3055.64s
                               ETA: 4530.4s
################################################################################
                     [1m Learning iteration 806/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.107s, learning 0.629s)
               Value function loss: 13.7401
                    Surrogate loss: -0.0088
             Mean action noise std: 0.95
                       Mean reward: -47.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5810400
                    Iteration time: 3.74s
                        Total time: 3059.38s
                               ETA: 4526.5s
################################################################################
                     [1m Learning iteration 807/2000 [0m                      

                       Computation: 1911 steps/s (collection: 3.106s, learning 0.661s)
               Value function loss: 13.4595
                    Surrogate loss: -0.0058
             Mean action noise std: 0.95
                       Mean reward: -47.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5817600
                    Iteration time: 3.77s
                        Total time: 3063.15s
                               ETA: 4522.7s
################################################################################
                     [1m Learning iteration 808/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.216s, learning 0.596s)
               Value function loss: 18.8124
                    Surrogate loss: -0.0057
             Mean action noise std: 0.95
                       Mean reward: -46.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5824800
                    Iteration time: 3.81s
                        Total time: 3066.96s
                               ETA: 4518.9s
################################################################################
                     [1m Learning iteration 809/2000 [0m                      

                       Computation: 1938 steps/s (collection: 3.087s, learning 0.627s)
               Value function loss: 16.0082
                    Surrogate loss: -0.0034
             Mean action noise std: 0.95
                       Mean reward: -47.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5832000
                    Iteration time: 3.71s
                        Total time: 3070.67s
                               ETA: 4515.0s
################################################################################
                     [1m Learning iteration 810/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.181s, learning 0.635s)
               Value function loss: 17.2999
                    Surrogate loss: -0.0032
             Mean action noise std: 0.95
                       Mean reward: -48.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5839200
                    Iteration time: 3.82s
                        Total time: 3074.49s
                               ETA: 4511.3s
################################################################################
                     [1m Learning iteration 811/2000 [0m                      

                       Computation: 1918 steps/s (collection: 3.127s, learning 0.625s)
               Value function loss: 14.5912
                    Surrogate loss: -0.0040
             Mean action noise std: 0.95
                       Mean reward: -48.59
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5846400
                    Iteration time: 3.75s
                        Total time: 3078.24s
                               ETA: 4507.4s
################################################################################
                     [1m Learning iteration 812/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.111s, learning 0.623s)
               Value function loss: 14.0522
                    Surrogate loss: 0.0052
             Mean action noise std: 0.95
                       Mean reward: -48.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5853600
                    Iteration time: 3.73s
                        Total time: 3081.98s
                               ETA: 4503.6s
################################################################################
                     [1m Learning iteration 813/2000 [0m                      

                       Computation: 1900 steps/s (collection: 3.160s, learning 0.629s)
               Value function loss: 13.1707
                    Surrogate loss: -0.0051
             Mean action noise std: 0.94
                       Mean reward: -48.78
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5860800
                    Iteration time: 3.79s
                        Total time: 3085.77s
                               ETA: 4499.8s
################################################################################
                     [1m Learning iteration 814/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.093s, learning 0.650s)
               Value function loss: 15.7546
                    Surrogate loss: -0.0056
             Mean action noise std: 0.94
                       Mean reward: -48.12
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5868000
                    Iteration time: 3.74s
                        Total time: 3089.51s
                               ETA: 4495.9s
################################################################################
                     [1m Learning iteration 815/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.193s, learning 0.648s)
               Value function loss: 14.9495
                    Surrogate loss: -0.0015
             Mean action noise std: 0.94
                       Mean reward: -47.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5875200
                    Iteration time: 3.84s
                        Total time: 3093.35s
                               ETA: 4492.2s
################################################################################
                     [1m Learning iteration 816/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.104s, learning 0.644s)
               Value function loss: 14.8017
                    Surrogate loss: -0.0061
             Mean action noise std: 0.94
                       Mean reward: -47.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5882400
                    Iteration time: 3.75s
                        Total time: 3097.10s
                               ETA: 4488.3s
################################################################################
                     [1m Learning iteration 817/2000 [0m                      

                       Computation: 1831 steps/s (collection: 3.149s, learning 0.782s)
               Value function loss: 13.5179
                    Surrogate loss: -0.0070
             Mean action noise std: 0.94
                       Mean reward: -47.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5889600
                    Iteration time: 3.93s
                        Total time: 3101.03s
                               ETA: 4484.7s
################################################################################
                     [1m Learning iteration 818/2000 [0m                      

                       Computation: 1834 steps/s (collection: 3.123s, learning 0.802s)
               Value function loss: 11.9409
                    Surrogate loss: -0.0010
             Mean action noise std: 0.94
                       Mean reward: -47.60
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5896800
                    Iteration time: 3.93s
                        Total time: 3104.95s
                               ETA: 4481.1s
################################################################################
                     [1m Learning iteration 819/2000 [0m                      

                       Computation: 1854 steps/s (collection: 3.103s, learning 0.779s)
               Value function loss: 15.0146
                    Surrogate loss: -0.0052
             Mean action noise std: 0.95
                       Mean reward: -47.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5904000
                    Iteration time: 3.88s
                        Total time: 3108.84s
                               ETA: 4477.5s
################################################################################
                     [1m Learning iteration 820/2000 [0m                      

                       Computation: 1875 steps/s (collection: 3.132s, learning 0.708s)
               Value function loss: 14.6476
                    Surrogate loss: -0.0060
             Mean action noise std: 0.95
                       Mean reward: -47.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5911200
                    Iteration time: 3.84s
                        Total time: 3112.67s
                               ETA: 4473.8s
################################################################################
                     [1m Learning iteration 821/2000 [0m                      

                       Computation: 1832 steps/s (collection: 3.106s, learning 0.822s)
               Value function loss: 14.2709
                    Surrogate loss: -0.0019
             Mean action noise std: 0.95
                       Mean reward: -47.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5918400
                    Iteration time: 3.93s
                        Total time: 3116.60s
                               ETA: 4470.2s
################################################################################
                     [1m Learning iteration 822/2000 [0m                      

                       Computation: 1793 steps/s (collection: 3.255s, learning 0.761s)
               Value function loss: 15.1381
                    Surrogate loss: -0.0023
             Mean action noise std: 0.95
                       Mean reward: -47.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5925600
                    Iteration time: 4.02s
                        Total time: 3120.62s
                               ETA: 4466.7s
################################################################################
                     [1m Learning iteration 823/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.091s, learning 0.738s)
               Value function loss: 15.1320
                    Surrogate loss: 0.0001
             Mean action noise std: 0.95
                       Mean reward: -47.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5932800
                    Iteration time: 3.83s
                        Total time: 3124.45s
                               ETA: 4463.0s
################################################################################
                     [1m Learning iteration 824/2000 [0m                      

                       Computation: 1858 steps/s (collection: 3.121s, learning 0.754s)
               Value function loss: 17.8006
                    Surrogate loss: -0.0001
             Mean action noise std: 0.95
                       Mean reward: -47.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5940000
                    Iteration time: 3.87s
                        Total time: 3128.32s
                               ETA: 4459.3s
################################################################################
                     [1m Learning iteration 825/2000 [0m                      

                       Computation: 1836 steps/s (collection: 3.149s, learning 0.772s)
               Value function loss: 17.3138
                    Surrogate loss: -0.0053
             Mean action noise std: 0.95
                       Mean reward: -47.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5947200
                    Iteration time: 3.92s
                        Total time: 3132.24s
                               ETA: 4455.7s
################################################################################
                     [1m Learning iteration 826/2000 [0m                      

                       Computation: 1870 steps/s (collection: 3.120s, learning 0.730s)
               Value function loss: 15.5654
                    Surrogate loss: -0.0061
             Mean action noise std: 0.94
                       Mean reward: -47.28
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5954400
                    Iteration time: 3.85s
                        Total time: 3136.09s
                               ETA: 4452.0s
################################################################################
                     [1m Learning iteration 827/2000 [0m                      

                       Computation: 1794 steps/s (collection: 3.208s, learning 0.804s)
               Value function loss: 14.3900
                    Surrogate loss: -0.0043
             Mean action noise std: 0.95
                       Mean reward: -47.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5961600
                    Iteration time: 4.01s
                        Total time: 3140.11s
                               ETA: 4448.5s
################################################################################
                     [1m Learning iteration 828/2000 [0m                      

                       Computation: 1842 steps/s (collection: 3.134s, learning 0.773s)
               Value function loss: 13.6273
                    Surrogate loss: -0.0004
             Mean action noise std: 0.94
                       Mean reward: -47.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5968800
                    Iteration time: 3.91s
                        Total time: 3144.01s
                               ETA: 4444.9s
################################################################################
                     [1m Learning iteration 829/2000 [0m                      

                       Computation: 1812 steps/s (collection: 3.186s, learning 0.786s)
               Value function loss: 14.2470
                    Surrogate loss: 0.0059
             Mean action noise std: 0.94
                       Mean reward: -47.26
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5976000
                    Iteration time: 3.97s
                        Total time: 3147.98s
                               ETA: 4441.3s
################################################################################
                     [1m Learning iteration 830/2000 [0m                      

                       Computation: 1847 steps/s (collection: 3.154s, learning 0.742s)
               Value function loss: 18.7487
                    Surrogate loss: 0.0176
             Mean action noise std: 0.95
                       Mean reward: -46.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5983200
                    Iteration time: 3.90s
                        Total time: 3151.88s
                               ETA: 4437.7s
################################################################################
                     [1m Learning iteration 831/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.138s, learning 0.764s)
               Value function loss: 17.3998
                    Surrogate loss: 0.0093
             Mean action noise std: 0.95
                       Mean reward: -47.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5990400
                    Iteration time: 3.90s
                        Total time: 3155.78s
                               ETA: 4434.0s
################################################################################
                     [1m Learning iteration 832/2000 [0m                      

                       Computation: 1795 steps/s (collection: 3.199s, learning 0.812s)
               Value function loss: 18.5298
                    Surrogate loss: -0.0022
             Mean action noise std: 0.95
                       Mean reward: -48.03
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 5997600
                    Iteration time: 4.01s
                        Total time: 3159.79s
                               ETA: 4430.5s
################################################################################
                     [1m Learning iteration 833/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.121s, learning 0.832s)
               Value function loss: 14.9691
                    Surrogate loss: -0.0053
             Mean action noise std: 0.95
                       Mean reward: -48.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6004800
                    Iteration time: 3.95s
                        Total time: 3163.75s
                               ETA: 4427.0s
################################################################################
                     [1m Learning iteration 834/2000 [0m                      

                       Computation: 1857 steps/s (collection: 3.151s, learning 0.725s)
               Value function loss: 18.0218
                    Surrogate loss: -0.0073
             Mean action noise std: 0.95
                       Mean reward: -48.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6012000
                    Iteration time: 3.88s
                        Total time: 3167.62s
                               ETA: 4423.3s
################################################################################
                     [1m Learning iteration 835/2000 [0m                      

                       Computation: 1915 steps/s (collection: 3.167s, learning 0.592s)
               Value function loss: 18.3087
                    Surrogate loss: -0.0069
             Mean action noise std: 0.95
                       Mean reward: -48.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6019200
                    Iteration time: 3.76s
                        Total time: 3171.38s
                               ETA: 4419.4s
################################################################################
                     [1m Learning iteration 836/2000 [0m                      

                       Computation: 1918 steps/s (collection: 3.136s, learning 0.616s)
               Value function loss: 19.1567
                    Surrogate loss: 0.0028
             Mean action noise std: 0.95
                       Mean reward: -48.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6026400
                    Iteration time: 3.75s
                        Total time: 3175.13s
                               ETA: 4415.6s
################################################################################
                     [1m Learning iteration 837/2000 [0m                      

                       Computation: 1860 steps/s (collection: 3.180s, learning 0.690s)
               Value function loss: 21.0094
                    Surrogate loss: -0.0052
             Mean action noise std: 0.95
                       Mean reward: -48.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6033600
                    Iteration time: 3.87s
                        Total time: 3179.00s
                               ETA: 4411.9s
################################################################################
                     [1m Learning iteration 838/2000 [0m                      

                       Computation: 1865 steps/s (collection: 3.134s, learning 0.726s)
               Value function loss: 16.8096
                    Surrogate loss: -0.0076
             Mean action noise std: 0.95
                       Mean reward: -48.28
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6040800
                    Iteration time: 3.86s
                        Total time: 3182.86s
                               ETA: 4408.2s
################################################################################
                     [1m Learning iteration 839/2000 [0m                      

                       Computation: 1860 steps/s (collection: 3.247s, learning 0.622s)
               Value function loss: 18.0178
                    Surrogate loss: -0.0043
             Mean action noise std: 0.95
                       Mean reward: -48.39
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6048000
                    Iteration time: 3.87s
                        Total time: 3186.73s
                               ETA: 4404.5s
################################################################################
                     [1m Learning iteration 840/2000 [0m                      

                       Computation: 1915 steps/s (collection: 3.144s, learning 0.614s)
               Value function loss: 19.3951
                    Surrogate loss: -0.0009
             Mean action noise std: 0.95
                       Mean reward: -48.65
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6055200
                    Iteration time: 3.76s
                        Total time: 3190.49s
                               ETA: 4400.7s
################################################################################
                     [1m Learning iteration 841/2000 [0m                      

                       Computation: 1909 steps/s (collection: 3.151s, learning 0.619s)
               Value function loss: 20.4666
                    Surrogate loss: -0.0024
             Mean action noise std: 0.95
                       Mean reward: -48.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6062400
                    Iteration time: 3.77s
                        Total time: 3194.26s
                               ETA: 4396.9s
################################################################################
                     [1m Learning iteration 842/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.146s, learning 0.672s)
               Value function loss: 17.4103
                    Surrogate loss: -0.0007
             Mean action noise std: 0.95
                       Mean reward: -49.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.13
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6069600
                    Iteration time: 3.82s
                        Total time: 3198.08s
                               ETA: 4393.1s
################################################################################
                     [1m Learning iteration 843/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.131s, learning 0.626s)
               Value function loss: 18.6587
                    Surrogate loss: -0.0057
             Mean action noise std: 0.95
                       Mean reward: -48.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6076800
                    Iteration time: 3.76s
                        Total time: 3201.83s
                               ETA: 4389.2s
################################################################################
                     [1m Learning iteration 844/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.207s, learning 0.636s)
               Value function loss: 19.2527
                    Surrogate loss: -0.0057
             Mean action noise std: 0.95
                       Mean reward: -49.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6084000
                    Iteration time: 3.84s
                        Total time: 3205.68s
                               ETA: 4385.5s
################################################################################
                     [1m Learning iteration 845/2000 [0m                      

                       Computation: 1927 steps/s (collection: 3.121s, learning 0.614s)
               Value function loss: 18.6399
                    Surrogate loss: -0.0064
             Mean action noise std: 0.95
                       Mean reward: -48.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6091200
                    Iteration time: 3.74s
                        Total time: 3209.41s
                               ETA: 4381.6s
################################################################################
                     [1m Learning iteration 846/2000 [0m                      

                       Computation: 1890 steps/s (collection: 3.197s, learning 0.612s)
               Value function loss: 19.8214
                    Surrogate loss: -0.0067
             Mean action noise std: 0.95
                       Mean reward: -48.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6098400
                    Iteration time: 3.81s
                        Total time: 3213.22s
                               ETA: 4377.9s
################################################################################
                     [1m Learning iteration 847/2000 [0m                      

                       Computation: 1916 steps/s (collection: 3.148s, learning 0.609s)
               Value function loss: 17.2701
                    Surrogate loss: -0.0055
             Mean action noise std: 0.95
                       Mean reward: -48.10
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6105600
                    Iteration time: 3.76s
                        Total time: 3216.98s
                               ETA: 4374.0s
################################################################################
                     [1m Learning iteration 848/2000 [0m                      

                       Computation: 1907 steps/s (collection: 3.161s, learning 0.613s)
               Value function loss: 19.0875
                    Surrogate loss: 0.0029
             Mean action noise std: 0.95
                       Mean reward: -47.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6112800
                    Iteration time: 3.77s
                        Total time: 3220.75s
                               ETA: 4370.2s
################################################################################
                     [1m Learning iteration 849/2000 [0m                      

                       Computation: 1911 steps/s (collection: 3.162s, learning 0.604s)
               Value function loss: 15.7763
                    Surrogate loss: -0.0037
             Mean action noise std: 0.95
                       Mean reward: -47.72
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6120000
                    Iteration time: 3.77s
                        Total time: 3224.52s
                               ETA: 4366.4s
################################################################################
                     [1m Learning iteration 850/2000 [0m                      

                       Computation: 1935 steps/s (collection: 3.105s, learning 0.615s)
               Value function loss: 14.4788
                    Surrogate loss: -0.0009
             Mean action noise std: 0.95
                       Mean reward: -48.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6127200
                    Iteration time: 3.72s
                        Total time: 3228.24s
                               ETA: 4362.5s
################################################################################
                     [1m Learning iteration 851/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.204s, learning 0.630s)
               Value function loss: 16.2678
                    Surrogate loss: 0.0052
             Mean action noise std: 0.95
                       Mean reward: -48.39
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6134400
                    Iteration time: 3.83s
                        Total time: 3232.07s
                               ETA: 4358.7s
################################################################################
                     [1m Learning iteration 852/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.204s, learning 0.625s)
               Value function loss: 14.6671
                    Surrogate loss: -0.0048
             Mean action noise std: 0.95
                       Mean reward: -47.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6141600
                    Iteration time: 3.83s
                        Total time: 3235.90s
                               ETA: 4355.0s
################################################################################
                     [1m Learning iteration 853/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.221s, learning 0.620s)
               Value function loss: 14.5795
                    Surrogate loss: -0.0075
             Mean action noise std: 0.95
                       Mean reward: -47.65
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6148800
                    Iteration time: 3.84s
                        Total time: 3239.74s
                               ETA: 4351.3s
################################################################################
                     [1m Learning iteration 854/2000 [0m                      

                       Computation: 1939 steps/s (collection: 3.118s, learning 0.595s)
               Value function loss: 17.3529
                    Surrogate loss: -0.0020
             Mean action noise std: 0.95
                       Mean reward: -47.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6156000
                    Iteration time: 3.71s
                        Total time: 3243.46s
                               ETA: 4347.4s
################################################################################
                     [1m Learning iteration 855/2000 [0m                      

                       Computation: 1919 steps/s (collection: 3.132s, learning 0.618s)
               Value function loss: 16.2003
                    Surrogate loss: -0.0073
             Mean action noise std: 0.95
                       Mean reward: -46.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6163200
                    Iteration time: 3.75s
                        Total time: 3247.21s
                               ETA: 4343.5s
################################################################################
                     [1m Learning iteration 856/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.130s, learning 0.614s)
               Value function loss: 16.8668
                    Surrogate loss: -0.0035
             Mean action noise std: 0.95
                       Mean reward: -46.65
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6170400
                    Iteration time: 3.74s
                        Total time: 3250.95s
                               ETA: 4339.7s
################################################################################
                     [1m Learning iteration 857/2000 [0m                      

                       Computation: 1934 steps/s (collection: 3.066s, learning 0.656s)
               Value function loss: 16.8370
                    Surrogate loss: -0.0016
             Mean action noise std: 0.95
                       Mean reward: -47.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6177600
                    Iteration time: 3.72s
                        Total time: 3254.67s
                               ETA: 4335.8s
################################################################################
                     [1m Learning iteration 858/2000 [0m                      

                       Computation: 1921 steps/s (collection: 3.135s, learning 0.612s)
               Value function loss: 13.0762
                    Surrogate loss: -0.0052
             Mean action noise std: 0.94
                       Mean reward: -47.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6184800
                    Iteration time: 3.75s
                        Total time: 3258.42s
                               ETA: 4331.9s
################################################################################
                     [1m Learning iteration 859/2000 [0m                      

                       Computation: 1939 steps/s (collection: 3.110s, learning 0.602s)
               Value function loss: 16.1205
                    Surrogate loss: -0.0058
             Mean action noise std: 0.95
                       Mean reward: -47.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6192000
                    Iteration time: 3.71s
                        Total time: 3262.13s
                               ETA: 4328.0s
################################################################################
                     [1m Learning iteration 860/2000 [0m                      

                       Computation: 1888 steps/s (collection: 3.105s, learning 0.708s)
               Value function loss: 16.3801
                    Surrogate loss: -0.0004
             Mean action noise std: 0.95
                       Mean reward: -47.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6199200
                    Iteration time: 3.81s
                        Total time: 3265.95s
                               ETA: 4324.2s
################################################################################
                     [1m Learning iteration 861/2000 [0m                      

                       Computation: 1914 steps/s (collection: 3.144s, learning 0.617s)
               Value function loss: 15.7814
                    Surrogate loss: -0.0012
             Mean action noise std: 0.94
                       Mean reward: -47.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6206400
                    Iteration time: 3.76s
                        Total time: 3269.71s
                               ETA: 4320.4s
################################################################################
                     [1m Learning iteration 862/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.206s, learning 0.608s)
               Value function loss: 17.3616
                    Surrogate loss: -0.0046
             Mean action noise std: 0.94
                       Mean reward: -47.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6213600
                    Iteration time: 3.81s
                        Total time: 3273.52s
                               ETA: 4316.6s
################################################################################
                     [1m Learning iteration 863/2000 [0m                      

                       Computation: 1926 steps/s (collection: 3.122s, learning 0.615s)
               Value function loss: 13.2284
                    Surrogate loss: -0.0009
             Mean action noise std: 0.94
                       Mean reward: -47.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6220800
                    Iteration time: 3.74s
                        Total time: 3277.26s
                               ETA: 4312.8s
################################################################################
                     [1m Learning iteration 864/2000 [0m                      

                       Computation: 1920 steps/s (collection: 3.143s, learning 0.606s)
               Value function loss: 15.3538
                    Surrogate loss: -0.0063
             Mean action noise std: 0.94
                       Mean reward: -46.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6228000
                    Iteration time: 3.75s
                        Total time: 3281.01s
                               ETA: 4308.9s
################################################################################
                     [1m Learning iteration 865/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.145s, learning 0.677s)
               Value function loss: 13.5760
                    Surrogate loss: 0.0051
             Mean action noise std: 0.94
                       Mean reward: -47.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6235200
                    Iteration time: 3.82s
                        Total time: 3284.83s
                               ETA: 4305.2s
################################################################################
                     [1m Learning iteration 866/2000 [0m                      

                       Computation: 1923 steps/s (collection: 3.103s, learning 0.640s)
               Value function loss: 15.3220
                    Surrogate loss: 0.0032
             Mean action noise std: 0.95
                       Mean reward: -47.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6242400
                    Iteration time: 3.74s
                        Total time: 3288.57s
                               ETA: 4301.3s
################################################################################
                     [1m Learning iteration 867/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.211s, learning 0.619s)
               Value function loss: 16.2282
                    Surrogate loss: -0.0061
             Mean action noise std: 0.95
                       Mean reward: -47.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6249600
                    Iteration time: 3.83s
                        Total time: 3292.40s
                               ETA: 4297.6s
################################################################################
                     [1m Learning iteration 868/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.134s, learning 0.714s)
               Value function loss: 15.4924
                    Surrogate loss: -0.0052
             Mean action noise std: 0.95
                       Mean reward: -47.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6256800
                    Iteration time: 3.85s
                        Total time: 3296.25s
                               ETA: 4293.8s
################################################################################
                     [1m Learning iteration 869/2000 [0m                      

                       Computation: 1865 steps/s (collection: 3.226s, learning 0.633s)
               Value function loss: 14.5981
                    Surrogate loss: -0.0041
             Mean action noise std: 0.94
                       Mean reward: -47.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6264000
                    Iteration time: 3.86s
                        Total time: 3300.11s
                               ETA: 4290.1s
################################################################################
                     [1m Learning iteration 870/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.137s, learning 0.701s)
               Value function loss: 14.8471
                    Surrogate loss: 0.0073
             Mean action noise std: 0.94
                       Mean reward: -47.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6271200
                    Iteration time: 3.84s
                        Total time: 3303.95s
                               ETA: 4286.4s
################################################################################
                     [1m Learning iteration 871/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.146s, learning 0.673s)
               Value function loss: 15.7110
                    Surrogate loss: -0.0057
             Mean action noise std: 0.94
                       Mean reward: -47.39
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6278400
                    Iteration time: 3.82s
                        Total time: 3307.76s
                               ETA: 4282.6s
################################################################################
                     [1m Learning iteration 872/2000 [0m                      

                       Computation: 1769 steps/s (collection: 3.131s, learning 0.938s)
               Value function loss: 14.0580
                    Surrogate loss: -0.0065
             Mean action noise std: 0.94
                       Mean reward: -47.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6285600
                    Iteration time: 4.07s
                        Total time: 3311.83s
                               ETA: 4279.2s
################################################################################
                     [1m Learning iteration 873/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.152s, learning 0.659s)
               Value function loss: 16.0788
                    Surrogate loss: -0.0021
             Mean action noise std: 0.95
                       Mean reward: -47.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6292800
                    Iteration time: 3.81s
                        Total time: 3315.64s
                               ETA: 4275.4s
################################################################################
                     [1m Learning iteration 874/2000 [0m                      

                       Computation: 1764 steps/s (collection: 3.314s, learning 0.767s)
               Value function loss: 20.3846
                    Surrogate loss: -0.0055
             Mean action noise std: 0.94
                       Mean reward: -47.05
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6300000
                    Iteration time: 4.08s
                        Total time: 3319.73s
                               ETA: 4272.0s
################################################################################
                     [1m Learning iteration 875/2000 [0m                      

                       Computation: 1844 steps/s (collection: 3.160s, learning 0.744s)
               Value function loss: 17.9849
                    Surrogate loss: -0.0043
             Mean action noise std: 0.95
                       Mean reward: -47.59
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.12
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6307200
                    Iteration time: 3.90s
                        Total time: 3323.63s
                               ETA: 4268.4s
################################################################################
                     [1m Learning iteration 876/2000 [0m                      

                       Computation: 1836 steps/s (collection: 3.107s, learning 0.813s)
               Value function loss: 14.4951
                    Surrogate loss: -0.0072
             Mean action noise std: 0.95
                       Mean reward: -48.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6314400
                    Iteration time: 3.92s
                        Total time: 3327.55s
                               ETA: 4264.7s
################################################################################
                     [1m Learning iteration 877/2000 [0m                      

                       Computation: 1840 steps/s (collection: 3.166s, learning 0.747s)
               Value function loss: 15.4707
                    Surrogate loss: -0.0055
             Mean action noise std: 0.95
                       Mean reward: -48.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6321600
                    Iteration time: 3.91s
                        Total time: 3331.46s
                               ETA: 4261.1s
################################################################################
                     [1m Learning iteration 878/2000 [0m                      

                       Computation: 1833 steps/s (collection: 3.135s, learning 0.793s)
               Value function loss: 16.3620
                    Surrogate loss: -0.0026
             Mean action noise std: 0.95
                       Mean reward: -48.59
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6328800
                    Iteration time: 3.93s
                        Total time: 3335.39s
                               ETA: 4257.5s
################################################################################
                     [1m Learning iteration 879/2000 [0m                      

                       Computation: 1794 steps/s (collection: 3.250s, learning 0.763s)
               Value function loss: 13.5322
                    Surrogate loss: -0.0000
             Mean action noise std: 0.95
                       Mean reward: -49.06
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6336000
                    Iteration time: 4.01s
                        Total time: 3339.40s
                               ETA: 4253.9s
################################################################################
                     [1m Learning iteration 880/2000 [0m                      

                       Computation: 1842 steps/s (collection: 3.112s, learning 0.796s)
               Value function loss: 14.3066
                    Surrogate loss: -0.0074
             Mean action noise std: 0.94
                       Mean reward: -48.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6343200
                    Iteration time: 3.91s
                        Total time: 3343.31s
                               ETA: 4250.3s
################################################################################
                     [1m Learning iteration 881/2000 [0m                      

                       Computation: 1855 steps/s (collection: 3.095s, learning 0.785s)
               Value function loss: 14.9530
                    Surrogate loss: -0.0034
             Mean action noise std: 0.94
                       Mean reward: -48.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6350400
                    Iteration time: 3.88s
                        Total time: 3347.19s
                               ETA: 4246.6s
################################################################################
                     [1m Learning iteration 882/2000 [0m                      

                       Computation: 1801 steps/s (collection: 3.167s, learning 0.831s)
               Value function loss: 17.9347
                    Surrogate loss: -0.0072
             Mean action noise std: 0.94
                       Mean reward: -48.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6357600
                    Iteration time: 4.00s
                        Total time: 3351.19s
                               ETA: 4243.1s
################################################################################
                     [1m Learning iteration 883/2000 [0m                      

                       Computation: 1860 steps/s (collection: 3.125s, learning 0.745s)
               Value function loss: 17.0565
                    Surrogate loss: -0.0043
             Mean action noise std: 0.94
                       Mean reward: -47.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6364800
                    Iteration time: 3.87s
                        Total time: 3355.06s
                               ETA: 4239.4s
################################################################################
                     [1m Learning iteration 884/2000 [0m                      

                       Computation: 1807 steps/s (collection: 3.193s, learning 0.792s)
               Value function loss: 19.9508
                    Surrogate loss: -0.0035
             Mean action noise std: 0.95
                       Mean reward: -47.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6372000
                    Iteration time: 3.98s
                        Total time: 3359.04s
                               ETA: 4235.8s
################################################################################
                     [1m Learning iteration 885/2000 [0m                      

                       Computation: 1843 steps/s (collection: 3.140s, learning 0.766s)
               Value function loss: 17.3491
                    Surrogate loss: -0.0025
             Mean action noise std: 0.94
                       Mean reward: -47.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6379200
                    Iteration time: 3.91s
                        Total time: 3362.95s
                               ETA: 4232.2s
################################################################################
                     [1m Learning iteration 886/2000 [0m                      

                       Computation: 1821 steps/s (collection: 3.187s, learning 0.766s)
               Value function loss: 17.6655
                    Surrogate loss: -0.0059
             Mean action noise std: 0.94
                       Mean reward: -48.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6386400
                    Iteration time: 3.95s
                        Total time: 3366.90s
                               ETA: 4228.6s
################################################################################
                     [1m Learning iteration 887/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.148s, learning 0.788s)
               Value function loss: 17.3575
                    Surrogate loss: -0.0047
             Mean action noise std: 0.94
                       Mean reward: -48.02
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6393600
                    Iteration time: 3.94s
                        Total time: 3370.84s
                               ETA: 4224.9s
################################################################################
                     [1m Learning iteration 888/2000 [0m                      

                       Computation: 1842 steps/s (collection: 3.123s, learning 0.785s)
               Value function loss: 17.4438
                    Surrogate loss: 0.0006
             Mean action noise std: 0.94
                       Mean reward: -48.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6400800
                    Iteration time: 3.91s
                        Total time: 3374.75s
                               ETA: 4221.3s
################################################################################
                     [1m Learning iteration 889/2000 [0m                      

                       Computation: 1833 steps/s (collection: 3.170s, learning 0.757s)
               Value function loss: 17.4471
                    Surrogate loss: -0.0043
             Mean action noise std: 0.94
                       Mean reward: -48.33
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6408000
                    Iteration time: 3.93s
                        Total time: 3378.67s
                               ETA: 4217.6s
################################################################################
                     [1m Learning iteration 890/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.143s, learning 0.742s)
               Value function loss: 15.1351
                    Surrogate loss: -0.0057
             Mean action noise std: 0.94
                       Mean reward: -48.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6415200
                    Iteration time: 3.89s
                        Total time: 3382.56s
                               ETA: 4214.0s
################################################################################
                     [1m Learning iteration 891/2000 [0m                      

                       Computation: 1855 steps/s (collection: 3.193s, learning 0.687s)
               Value function loss: 16.6111
                    Surrogate loss: -0.0061
             Mean action noise std: 0.94
                       Mean reward: -47.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6422400
                    Iteration time: 3.88s
                        Total time: 3386.44s
                               ETA: 4210.3s
################################################################################
                     [1m Learning iteration 892/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.183s, learning 0.636s)
               Value function loss: 16.4185
                    Surrogate loss: -0.0028
             Mean action noise std: 0.94
                       Mean reward: -47.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6429600
                    Iteration time: 3.82s
                        Total time: 3390.26s
                               ETA: 4206.5s
################################################################################
                     [1m Learning iteration 893/2000 [0m                      

                       Computation: 1895 steps/s (collection: 3.155s, learning 0.644s)
               Value function loss: 20.5484
                    Surrogate loss: -0.0055
             Mean action noise std: 0.94
                       Mean reward: -47.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6436800
                    Iteration time: 3.80s
                        Total time: 3394.06s
                               ETA: 4202.7s
################################################################################
                     [1m Learning iteration 894/2000 [0m                      

                       Computation: 1792 steps/s (collection: 3.160s, learning 0.855s)
               Value function loss: 17.2637
                    Surrogate loss: 0.0007
             Mean action noise std: 0.94
                       Mean reward: -47.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6444000
                    Iteration time: 4.02s
                        Total time: 3398.07s
                               ETA: 4199.2s
################################################################################
                     [1m Learning iteration 895/2000 [0m                      

                       Computation: 1842 steps/s (collection: 3.164s, learning 0.743s)
               Value function loss: 20.2957
                    Surrogate loss: -0.0079
             Mean action noise std: 0.94
                       Mean reward: -47.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6451200
                    Iteration time: 3.91s
                        Total time: 3401.98s
                               ETA: 4195.5s
################################################################################
                     [1m Learning iteration 896/2000 [0m                      

                       Computation: 1813 steps/s (collection: 3.257s, learning 0.713s)
               Value function loss: 17.5459
                    Surrogate loss: -0.0046
             Mean action noise std: 0.95
                       Mean reward: -47.57
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6458400
                    Iteration time: 3.97s
                        Total time: 3405.95s
                               ETA: 4191.9s
################################################################################
                     [1m Learning iteration 897/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.179s, learning 0.625s)
               Value function loss: 19.9581
                    Surrogate loss: 0.0006
             Mean action noise std: 0.95
                       Mean reward: -47.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6465600
                    Iteration time: 3.80s
                        Total time: 3409.75s
                               ETA: 4188.1s
################################################################################
                     [1m Learning iteration 898/2000 [0m                      

                       Computation: 1900 steps/s (collection: 3.186s, learning 0.603s)
               Value function loss: 20.9503
                    Surrogate loss: 0.0013
             Mean action noise std: 0.94
                       Mean reward: -47.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6472800
                    Iteration time: 3.79s
                        Total time: 3413.54s
                               ETA: 4184.3s
################################################################################
                     [1m Learning iteration 899/2000 [0m                      

                       Computation: 1850 steps/s (collection: 3.234s, learning 0.657s)
               Value function loss: 19.0060
                    Surrogate loss: -0.0057
             Mean action noise std: 0.94
                       Mean reward: -47.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6480000
                    Iteration time: 3.89s
                        Total time: 3417.43s
                               ETA: 4180.7s
################################################################################
                     [1m Learning iteration 900/2000 [0m                      

                       Computation: 1879 steps/s (collection: 3.225s, learning 0.606s)
               Value function loss: 19.4525
                    Surrogate loss: 0.0007
             Mean action noise std: 0.94
                       Mean reward: -47.36
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6487200
                    Iteration time: 3.83s
                        Total time: 3421.26s
                               ETA: 4176.9s
################################################################################
                     [1m Learning iteration 901/2000 [0m                      

                       Computation: 1840 steps/s (collection: 3.305s, learning 0.607s)
               Value function loss: 18.9695
                    Surrogate loss: -0.0042
             Mean action noise std: 0.94
                       Mean reward: -47.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6494400
                    Iteration time: 3.91s
                        Total time: 3425.18s
                               ETA: 4173.2s
################################################################################
                     [1m Learning iteration 902/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.200s, learning 0.630s)
               Value function loss: 19.7964
                    Surrogate loss: -0.0079
             Mean action noise std: 0.94
                       Mean reward: -48.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6501600
                    Iteration time: 3.83s
                        Total time: 3429.01s
                               ETA: 4169.5s
################################################################################
                     [1m Learning iteration 903/2000 [0m                      

                       Computation: 1853 steps/s (collection: 3.225s, learning 0.658s)
               Value function loss: 17.8173
                    Surrogate loss: -0.0004
             Mean action noise std: 0.94
                       Mean reward: -48.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6508800
                    Iteration time: 3.88s
                        Total time: 3432.89s
                               ETA: 4165.8s
################################################################################
                     [1m Learning iteration 904/2000 [0m                      

                       Computation: 1841 steps/s (collection: 3.207s, learning 0.702s)
               Value function loss: 18.2237
                    Surrogate loss: -0.0078
             Mean action noise std: 0.94
                       Mean reward: -47.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6516000
                    Iteration time: 3.91s
                        Total time: 3436.80s
                               ETA: 4162.1s
################################################################################
                     [1m Learning iteration 905/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.213s, learning 0.628s)
               Value function loss: 20.2544
                    Surrogate loss: -0.0052
             Mean action noise std: 0.94
                       Mean reward: -47.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6523200
                    Iteration time: 3.84s
                        Total time: 3440.64s
                               ETA: 4158.4s
################################################################################
                     [1m Learning iteration 906/2000 [0m                      

                       Computation: 1825 steps/s (collection: 3.309s, learning 0.634s)
               Value function loss: 20.1917
                    Surrogate loss: -0.0025
             Mean action noise std: 0.94
                       Mean reward: -48.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6530400
                    Iteration time: 3.94s
                        Total time: 3444.58s
                               ETA: 4154.8s
################################################################################
                     [1m Learning iteration 907/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.163s, learning 0.649s)
               Value function loss: 20.7470
                    Surrogate loss: -0.0081
             Mean action noise std: 0.94
                       Mean reward: -48.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6537600
                    Iteration time: 3.81s
                        Total time: 3448.39s
                               ETA: 4151.0s
################################################################################
                     [1m Learning iteration 908/2000 [0m                      

                       Computation: 1830 steps/s (collection: 3.268s, learning 0.666s)
               Value function loss: 17.3467
                    Surrogate loss: -0.0085
             Mean action noise std: 0.94
                       Mean reward: -47.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6544800
                    Iteration time: 3.93s
                        Total time: 3452.33s
                               ETA: 4147.4s
################################################################################
                     [1m Learning iteration 909/2000 [0m                      

                       Computation: 1889 steps/s (collection: 3.196s, learning 0.614s)
               Value function loss: 21.9778
                    Surrogate loss: -0.0072
             Mean action noise std: 0.94
                       Mean reward: -47.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6552000
                    Iteration time: 3.81s
                        Total time: 3456.14s
                               ETA: 4143.6s
################################################################################
                     [1m Learning iteration 910/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.159s, learning 0.663s)
               Value function loss: 22.4093
                    Surrogate loss: -0.0052
             Mean action noise std: 0.94
                       Mean reward: -48.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6559200
                    Iteration time: 3.82s
                        Total time: 3459.96s
                               ETA: 4139.8s
################################################################################
                     [1m Learning iteration 911/2000 [0m                      

                       Computation: 1827 steps/s (collection: 3.319s, learning 0.620s)
               Value function loss: 21.2978
                    Surrogate loss: -0.0061
             Mean action noise std: 0.94
                       Mean reward: -48.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6566400
                    Iteration time: 3.94s
                        Total time: 3463.90s
                               ETA: 4136.2s
################################################################################
                     [1m Learning iteration 912/2000 [0m                      

                       Computation: 1896 steps/s (collection: 3.179s, learning 0.618s)
               Value function loss: 20.6407
                    Surrogate loss: -0.0080
             Mean action noise std: 0.94
                       Mean reward: -47.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6573600
                    Iteration time: 3.80s
                        Total time: 3467.70s
                               ETA: 4132.4s
################################################################################
                     [1m Learning iteration 913/2000 [0m                      

                       Computation: 1806 steps/s (collection: 3.366s, learning 0.620s)
               Value function loss: 20.1017
                    Surrogate loss: -0.0016
             Mean action noise std: 0.94
                       Mean reward: -47.80
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6580800
                    Iteration time: 3.99s
                        Total time: 3471.68s
                               ETA: 4128.8s
################################################################################
                     [1m Learning iteration 914/2000 [0m                      

                       Computation: 1880 steps/s (collection: 3.179s, learning 0.649s)
               Value function loss: 19.7915
                    Surrogate loss: -0.0043
             Mean action noise std: 0.94
                       Mean reward: -47.89
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6588000
                    Iteration time: 3.83s
                        Total time: 3475.51s
                               ETA: 4125.0s
################################################################################
                     [1m Learning iteration 915/2000 [0m                      

                       Computation: 1836 steps/s (collection: 3.274s, learning 0.647s)
               Value function loss: 19.3891
                    Surrogate loss: -0.0024
             Mean action noise std: 0.94
                       Mean reward: -47.46
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6595200
                    Iteration time: 3.92s
                        Total time: 3479.43s
                               ETA: 4121.4s
################################################################################
                     [1m Learning iteration 916/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.141s, learning 0.701s)
               Value function loss: 20.4478
                    Surrogate loss: -0.0052
             Mean action noise std: 0.94
                       Mean reward: -47.28
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6602400
                    Iteration time: 3.84s
                        Total time: 3483.27s
                               ETA: 4117.6s
################################################################################
                     [1m Learning iteration 917/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.231s, learning 0.613s)
               Value function loss: 21.1101
                    Surrogate loss: -0.0008
             Mean action noise std: 0.94
                       Mean reward: -47.17
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6609600
                    Iteration time: 3.84s
                        Total time: 3487.12s
                               ETA: 4113.9s
################################################################################
                     [1m Learning iteration 918/2000 [0m                      

                       Computation: 1801 steps/s (collection: 3.377s, learning 0.620s)
               Value function loss: 20.7018
                    Surrogate loss: -0.0018
             Mean action noise std: 0.94
                       Mean reward: -47.46
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6616800
                    Iteration time: 4.00s
                        Total time: 3491.11s
                               ETA: 4110.3s
################################################################################
                     [1m Learning iteration 919/2000 [0m                      

                       Computation: 1894 steps/s (collection: 3.186s, learning 0.614s)
               Value function loss: 19.5034
                    Surrogate loss: -0.0083
             Mean action noise std: 0.94
                       Mean reward: -47.68
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6624000
                    Iteration time: 3.80s
                        Total time: 3494.91s
                               ETA: 4106.5s
################################################################################
                     [1m Learning iteration 920/2000 [0m                      

                       Computation: 1802 steps/s (collection: 3.359s, learning 0.635s)
               Value function loss: 20.9911
                    Surrogate loss: -0.0023
             Mean action noise std: 0.94
                       Mean reward: -47.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6631200
                    Iteration time: 3.99s
                        Total time: 3498.91s
                               ETA: 4103.0s
################################################################################
                     [1m Learning iteration 921/2000 [0m                      

                       Computation: 1894 steps/s (collection: 3.171s, learning 0.630s)
               Value function loss: 19.7213
                    Surrogate loss: -0.0065
             Mean action noise std: 0.94
                       Mean reward: -47.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6638400
                    Iteration time: 3.80s
                        Total time: 3502.71s
                               ETA: 4099.2s
################################################################################
                     [1m Learning iteration 922/2000 [0m                      

                       Computation: 1833 steps/s (collection: 3.186s, learning 0.741s)
               Value function loss: 17.0575
                    Surrogate loss: -0.0054
             Mean action noise std: 0.94
                       Mean reward: -48.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6645600
                    Iteration time: 3.93s
                        Total time: 3506.64s
                               ETA: 4095.5s
################################################################################
                     [1m Learning iteration 923/2000 [0m                      

                       Computation: 1802 steps/s (collection: 3.285s, learning 0.710s)
               Value function loss: 20.2047
                    Surrogate loss: -0.0071
             Mean action noise std: 0.94
                       Mean reward: -47.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6652800
                    Iteration time: 4.00s
                        Total time: 3510.63s
                               ETA: 4091.9s
################################################################################
                     [1m Learning iteration 924/2000 [0m                      

                       Computation: 1873 steps/s (collection: 3.217s, learning 0.627s)
               Value function loss: 19.6427
                    Surrogate loss: -0.0054
             Mean action noise std: 0.94
                       Mean reward: -47.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6660000
                    Iteration time: 3.84s
                        Total time: 3514.48s
                               ETA: 4088.2s
################################################################################
                     [1m Learning iteration 925/2000 [0m                      

                       Computation: 1787 steps/s (collection: 3.246s, learning 0.782s)
               Value function loss: 19.3171
                    Surrogate loss: -0.0048
             Mean action noise std: 0.94
                       Mean reward: -47.36
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6667200
                    Iteration time: 4.03s
                        Total time: 3518.50s
                               ETA: 4084.7s
################################################################################
                     [1m Learning iteration 926/2000 [0m                      

                       Computation: 1881 steps/s (collection: 3.168s, learning 0.660s)
               Value function loss: 15.7265
                    Surrogate loss: -0.0021
             Mean action noise std: 0.94
                       Mean reward: -47.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6674400
                    Iteration time: 3.83s
                        Total time: 3522.33s
                               ETA: 4080.9s
################################################################################
                     [1m Learning iteration 927/2000 [0m                      

                       Computation: 1846 steps/s (collection: 3.237s, learning 0.663s)
               Value function loss: 21.0791
                    Surrogate loss: 0.0018
             Mean action noise std: 0.94
                       Mean reward: -46.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6681600
                    Iteration time: 3.90s
                        Total time: 3526.23s
                               ETA: 4077.2s
################################################################################
                     [1m Learning iteration 928/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.143s, learning 0.664s)
               Value function loss: 17.0780
                    Surrogate loss: 0.0061
             Mean action noise std: 0.94
                       Mean reward: -46.98
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6688800
                    Iteration time: 3.81s
                        Total time: 3530.04s
                               ETA: 4073.4s
################################################################################
                     [1m Learning iteration 929/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.188s, learning 0.629s)
               Value function loss: 20.0244
                    Surrogate loss: -0.0060
             Mean action noise std: 0.94
                       Mean reward: -46.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6696000
                    Iteration time: 3.82s
                        Total time: 3533.86s
                               ETA: 4069.6s
################################################################################
                     [1m Learning iteration 930/2000 [0m                      

                       Computation: 1830 steps/s (collection: 3.262s, learning 0.672s)
               Value function loss: 18.3624
                    Surrogate loss: 0.0018
             Mean action noise std: 0.94
                       Mean reward: -46.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6703200
                    Iteration time: 3.93s
                        Total time: 3537.79s
                               ETA: 4066.0s
################################################################################
                     [1m Learning iteration 931/2000 [0m                      

                       Computation: 1885 steps/s (collection: 3.166s, learning 0.652s)
               Value function loss: 18.4292
                    Surrogate loss: 0.0067
             Mean action noise std: 0.94
                       Mean reward: -46.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6710400
                    Iteration time: 3.82s
                        Total time: 3541.61s
                               ETA: 4062.2s
################################################################################
                     [1m Learning iteration 932/2000 [0m                      

                       Computation: 1832 steps/s (collection: 3.297s, learning 0.632s)
               Value function loss: 20.5242
                    Surrogate loss: -0.0040
             Mean action noise std: 0.94
                       Mean reward: -47.06
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6717600
                    Iteration time: 3.93s
                        Total time: 3545.54s
                               ETA: 4058.6s
################################################################################
                     [1m Learning iteration 933/2000 [0m                      

                       Computation: 1871 steps/s (collection: 3.200s, learning 0.647s)
               Value function loss: 18.5443
                    Surrogate loss: -0.0064
             Mean action noise std: 0.94
                       Mean reward: -47.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6724800
                    Iteration time: 3.85s
                        Total time: 3549.38s
                               ETA: 4054.8s
################################################################################
                     [1m Learning iteration 934/2000 [0m                      

                       Computation: 1886 steps/s (collection: 3.193s, learning 0.622s)
               Value function loss: 20.0047
                    Surrogate loss: -0.0066
             Mean action noise std: 0.93
                       Mean reward: -47.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6732000
                    Iteration time: 3.82s
                        Total time: 3553.20s
                               ETA: 4051.0s
################################################################################
                     [1m Learning iteration 935/2000 [0m                      

                       Computation: 1750 steps/s (collection: 3.318s, learning 0.794s)
               Value function loss: 18.6432
                    Surrogate loss: -0.0098
             Mean action noise std: 0.93
                       Mean reward: -47.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6739200
                    Iteration time: 4.11s
                        Total time: 3557.31s
                               ETA: 4047.6s
################################################################################
                     [1m Learning iteration 936/2000 [0m                      

                       Computation: 1876 steps/s (collection: 3.224s, learning 0.613s)
               Value function loss: 20.2350
                    Surrogate loss: -0.0056
             Mean action noise std: 0.93
                       Mean reward: -47.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6746400
                    Iteration time: 3.84s
                        Total time: 3561.15s
                               ETA: 4043.8s
################################################################################
                     [1m Learning iteration 937/2000 [0m                      

                       Computation: 1779 steps/s (collection: 3.300s, learning 0.745s)
               Value function loss: 18.7142
                    Surrogate loss: -0.0075
             Mean action noise std: 0.93
                       Mean reward: -48.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.11
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6753600
                    Iteration time: 4.05s
                        Total time: 3565.19s
                               ETA: 4040.3s
################################################################################
                     [1m Learning iteration 938/2000 [0m                      

                       Computation: 1826 steps/s (collection: 3.183s, learning 0.758s)
               Value function loss: 19.2285
                    Surrogate loss: -0.0030
             Mean action noise std: 0.93
                       Mean reward: -47.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6760800
                    Iteration time: 3.94s
                        Total time: 3569.14s
                               ETA: 4036.7s
################################################################################
                     [1m Learning iteration 939/2000 [0m                      

                       Computation: 1848 steps/s (collection: 3.222s, learning 0.674s)
               Value function loss: 18.6078
                    Surrogate loss: 0.0253
             Mean action noise std: 0.93
                       Mean reward: -47.26
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6768000
                    Iteration time: 3.90s
                        Total time: 3573.03s
                               ETA: 4033.0s
################################################################################
                     [1m Learning iteration 940/2000 [0m                      

                       Computation: 1845 steps/s (collection: 3.285s, learning 0.617s)
               Value function loss: 20.8853
                    Surrogate loss: 0.0026
             Mean action noise std: 0.93
                       Mean reward: -47.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6775200
                    Iteration time: 3.90s
                        Total time: 3576.93s
                               ETA: 4029.3s
################################################################################
                     [1m Learning iteration 941/2000 [0m                      

                       Computation: 1887 steps/s (collection: 3.138s, learning 0.677s)
               Value function loss: 15.8097
                    Surrogate loss: -0.0005
             Mean action noise std: 0.93
                       Mean reward: -47.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.10
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6782400
                    Iteration time: 3.82s
                        Total time: 3580.75s
                               ETA: 4025.5s
################################################################################
                     [1m Learning iteration 942/2000 [0m                      

                       Computation: 1834 steps/s (collection: 3.310s, learning 0.614s)
               Value function loss: 17.8528
                    Surrogate loss: -0.0070
             Mean action noise std: 0.93
                       Mean reward: -46.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6789600
                    Iteration time: 3.92s
                        Total time: 3584.67s
                               ETA: 4021.8s
################################################################################
                     [1m Learning iteration 943/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.214s, learning 0.608s)
               Value function loss: 20.7860
                    Surrogate loss: 0.0001
             Mean action noise std: 0.93
                       Mean reward: -47.17
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6796800
                    Iteration time: 3.82s
                        Total time: 3588.50s
                               ETA: 4018.1s
################################################################################
                     [1m Learning iteration 944/2000 [0m                      

                       Computation: 1847 steps/s (collection: 3.228s, learning 0.669s)
               Value function loss: 19.2683
                    Surrogate loss: -0.0083
             Mean action noise std: 0.93
                       Mean reward: -47.65
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6804000
                    Iteration time: 3.90s
                        Total time: 3592.39s
                               ETA: 4014.4s
################################################################################
                     [1m Learning iteration 945/2000 [0m                      

                       Computation: 1892 steps/s (collection: 3.175s, learning 0.629s)
               Value function loss: 17.6080
                    Surrogate loss: -0.0004
             Mean action noise std: 0.93
                       Mean reward: -47.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6811200
                    Iteration time: 3.80s
                        Total time: 3596.20s
                               ETA: 4010.6s
################################################################################
                     [1m Learning iteration 946/2000 [0m                      

                       Computation: 1894 steps/s (collection: 3.186s, learning 0.615s)
               Value function loss: 17.7518
                    Surrogate loss: -0.0046
             Mean action noise std: 0.93
                       Mean reward: -47.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6818400
                    Iteration time: 3.80s
                        Total time: 3600.00s
                               ETA: 4006.8s
################################################################################
                     [1m Learning iteration 947/2000 [0m                      

                       Computation: 1817 steps/s (collection: 3.336s, learning 0.625s)
               Value function loss: 20.6637
                    Surrogate loss: -0.0049
             Mean action noise std: 0.93
                       Mean reward: -46.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6825600
                    Iteration time: 3.96s
                        Total time: 3603.96s
                               ETA: 4003.1s
################################################################################
                     [1m Learning iteration 948/2000 [0m                      

                       Computation: 1825 steps/s (collection: 3.187s, learning 0.758s)
               Value function loss: 21.4144
                    Surrogate loss: -0.0042
             Mean action noise std: 0.93
                       Mean reward: -46.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6832800
                    Iteration time: 3.94s
                        Total time: 3607.90s
                               ETA: 3999.5s
################################################################################
                     [1m Learning iteration 949/2000 [0m                      

                       Computation: 1751 steps/s (collection: 3.310s, learning 0.800s)
               Value function loss: 19.4197
                    Surrogate loss: -0.0056
             Mean action noise std: 0.93
                       Mean reward: -46.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6840000
                    Iteration time: 4.11s
                        Total time: 3612.01s
                               ETA: 3996.0s
################################################################################
                     [1m Learning iteration 950/2000 [0m                      

                       Computation: 1818 steps/s (collection: 3.203s, learning 0.756s)
               Value function loss: 21.4092
                    Surrogate loss: -0.0077
             Mean action noise std: 0.93
                       Mean reward: -46.12
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6847200
                    Iteration time: 3.96s
                        Total time: 3615.97s
                               ETA: 3992.4s
################################################################################
                     [1m Learning iteration 951/2000 [0m                      

                       Computation: 1834 steps/s (collection: 3.192s, learning 0.734s)
               Value function loss: 21.2215
                    Surrogate loss: -0.0032
             Mean action noise std: 0.93
                       Mean reward: -46.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6854400
                    Iteration time: 3.93s
                        Total time: 3619.90s
                               ETA: 3988.7s
################################################################################
                     [1m Learning iteration 952/2000 [0m                      

                       Computation: 1815 steps/s (collection: 3.350s, learning 0.616s)
               Value function loss: 21.2031
                    Surrogate loss: 0.0007
             Mean action noise std: 0.93
                       Mean reward: -46.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6861600
                    Iteration time: 3.97s
                        Total time: 3623.86s
                               ETA: 3985.1s
################################################################################
                     [1m Learning iteration 953/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.209s, learning 0.613s)
               Value function loss: 21.4039
                    Surrogate loss: -0.0018
             Mean action noise std: 0.93
                       Mean reward: -47.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.09
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6868800
                    Iteration time: 3.82s
                        Total time: 3627.69s
                               ETA: 3981.3s
################################################################################
                     [1m Learning iteration 954/2000 [0m                      

                       Computation: 1730 steps/s (collection: 3.461s, learning 0.700s)
               Value function loss: 21.7363
                    Surrogate loss: -0.0078
             Mean action noise std: 0.93
                       Mean reward: -46.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6876000
                    Iteration time: 4.16s
                        Total time: 3631.85s
                               ETA: 3977.9s
################################################################################
                     [1m Learning iteration 955/2000 [0m                      

                       Computation: 1863 steps/s (collection: 3.241s, learning 0.623s)
               Value function loss: 19.3746
                    Surrogate loss: -0.0041
             Mean action noise std: 0.93
                       Mean reward: -46.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6883200
                    Iteration time: 3.86s
                        Total time: 3635.71s
                               ETA: 3974.2s
################################################################################
                     [1m Learning iteration 956/2000 [0m                      

                       Computation: 1835 steps/s (collection: 3.296s, learning 0.627s)
               Value function loss: 20.0778
                    Surrogate loss: -0.0010
             Mean action noise std: 0.93
                       Mean reward: -46.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6890400
                    Iteration time: 3.92s
                        Total time: 3639.63s
                               ETA: 3970.5s
################################################################################
                     [1m Learning iteration 957/2000 [0m                      

                       Computation: 1831 steps/s (collection: 3.306s, learning 0.626s)
               Value function loss: 20.9678
                    Surrogate loss: -0.0030
             Mean action noise std: 0.93
                       Mean reward: -46.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6897600
                    Iteration time: 3.93s
                        Total time: 3643.57s
                               ETA: 3966.8s
################################################################################
                     [1m Learning iteration 958/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.188s, learning 0.644s)
               Value function loss: 20.1988
                    Surrogate loss: -0.0015
             Mean action noise std: 0.93
                       Mean reward: -45.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6904800
                    Iteration time: 3.83s
                        Total time: 3647.40s
                               ETA: 3963.1s
################################################################################
                     [1m Learning iteration 959/2000 [0m                      

                       Computation: 1813 steps/s (collection: 3.326s, learning 0.644s)
               Value function loss: 22.2931
                    Surrogate loss: -0.0022
             Mean action noise std: 0.93
                       Mean reward: -45.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6912000
                    Iteration time: 3.97s
                        Total time: 3651.37s
                               ETA: 3959.5s
################################################################################
                     [1m Learning iteration 960/2000 [0m                      

                       Computation: 1891 steps/s (collection: 3.182s, learning 0.624s)
               Value function loss: 22.2614
                    Surrogate loss: -0.0050
             Mean action noise std: 0.93
                       Mean reward: -45.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6919200
                    Iteration time: 3.81s
                        Total time: 3655.17s
                               ETA: 3955.7s
################################################################################
                     [1m Learning iteration 961/2000 [0m                      

                       Computation: 1857 steps/s (collection: 3.266s, learning 0.611s)
               Value function loss: 22.7710
                    Surrogate loss: -0.0099
             Mean action noise std: 0.93
                       Mean reward: -46.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6926400
                    Iteration time: 3.88s
                        Total time: 3659.05s
                               ETA: 3951.9s
################################################################################
                     [1m Learning iteration 962/2000 [0m                      

                       Computation: 1843 steps/s (collection: 3.191s, learning 0.714s)
               Value function loss: 21.0452
                    Surrogate loss: -0.0020
             Mean action noise std: 0.93
                       Mean reward: -46.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6933600
                    Iteration time: 3.90s
                        Total time: 3662.96s
                               ETA: 3948.2s
################################################################################
                     [1m Learning iteration 963/2000 [0m                      

                       Computation: 1832 steps/s (collection: 3.212s, learning 0.717s)
               Value function loss: 22.6271
                    Surrogate loss: -0.0009
             Mean action noise std: 0.93
                       Mean reward: -46.68
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6940800
                    Iteration time: 3.93s
                        Total time: 3666.89s
                               ETA: 3944.6s
################################################################################
                     [1m Learning iteration 964/2000 [0m                      

                       Computation: 1765 steps/s (collection: 3.342s, learning 0.735s)
               Value function loss: 22.4162
                    Surrogate loss: -0.0101
             Mean action noise std: 0.93
                       Mean reward: -46.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6948000
                    Iteration time: 4.08s
                        Total time: 3670.96s
                               ETA: 3941.1s
################################################################################
                     [1m Learning iteration 965/2000 [0m                      

                       Computation: 1811 steps/s (collection: 3.219s, learning 0.756s)
               Value function loss: 19.7071
                    Surrogate loss: 0.0013
             Mean action noise std: 0.93
                       Mean reward: -46.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6955200
                    Iteration time: 3.97s
                        Total time: 3674.94s
                               ETA: 3937.4s
################################################################################
                     [1m Learning iteration 966/2000 [0m                      

                       Computation: 1816 steps/s (collection: 3.357s, learning 0.606s)
               Value function loss: 20.6571
                    Surrogate loss: -0.0064
             Mean action noise std: 0.93
                       Mean reward: -46.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6962400
                    Iteration time: 3.96s
                        Total time: 3678.90s
                               ETA: 3933.8s
################################################################################
                     [1m Learning iteration 967/2000 [0m                      

                       Computation: 1842 steps/s (collection: 3.293s, learning 0.615s)
               Value function loss: 21.2005
                    Surrogate loss: -0.0064
             Mean action noise std: 0.93
                       Mean reward: -46.36
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6969600
                    Iteration time: 3.91s
                        Total time: 3682.81s
                               ETA: 3930.1s
################################################################################
                     [1m Learning iteration 968/2000 [0m                      

                       Computation: 1866 steps/s (collection: 3.247s, learning 0.611s)
               Value function loss: 22.4303
                    Surrogate loss: -0.0095
             Mean action noise std: 0.93
                       Mean reward: -46.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6976800
                    Iteration time: 3.86s
                        Total time: 3686.67s
                               ETA: 3926.4s
################################################################################
                     [1m Learning iteration 969/2000 [0m                      

                       Computation: 1817 steps/s (collection: 3.318s, learning 0.643s)
               Value function loss: 19.7669
                    Surrogate loss: 0.0001
             Mean action noise std: 0.93
                       Mean reward: -46.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6984000
                    Iteration time: 3.96s
                        Total time: 3690.63s
                               ETA: 3922.7s
################################################################################
                     [1m Learning iteration 970/2000 [0m                      

                       Computation: 1884 steps/s (collection: 3.202s, learning 0.620s)
               Value function loss: 23.0449
                    Surrogate loss: -0.0022
             Mean action noise std: 0.93
                       Mean reward: -46.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6991200
                    Iteration time: 3.82s
                        Total time: 3694.45s
                               ETA: 3918.9s
################################################################################
                     [1m Learning iteration 971/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.319s, learning 0.616s)
               Value function loss: 19.7942
                    Surrogate loss: 0.0031
             Mean action noise std: 0.93
                       Mean reward: -46.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 6998400
                    Iteration time: 3.94s
                        Total time: 3698.38s
                               ETA: 3915.3s
################################################################################
                     [1m Learning iteration 972/2000 [0m                      

                       Computation: 1874 steps/s (collection: 3.223s, learning 0.619s)
               Value function loss: 19.9095
                    Surrogate loss: -0.0009
             Mean action noise std: 0.93
                       Mean reward: -45.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7005600
                    Iteration time: 3.84s
                        Total time: 3702.22s
                               ETA: 3911.5s
################################################################################
                     [1m Learning iteration 973/2000 [0m                      

                       Computation: 1817 steps/s (collection: 3.342s, learning 0.618s)
               Value function loss: 21.3127
                    Surrogate loss: -0.0034
             Mean action noise std: 0.93
                       Mean reward: -45.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7012800
                    Iteration time: 3.96s
                        Total time: 3706.19s
                               ETA: 3907.9s
################################################################################
                     [1m Learning iteration 974/2000 [0m                      

                       Computation: 1793 steps/s (collection: 3.402s, learning 0.613s)
               Value function loss: 24.1763
                    Surrogate loss: -0.0058
             Mean action noise std: 0.93
                       Mean reward: -45.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7020000
                    Iteration time: 4.01s
                        Total time: 3710.20s
                               ETA: 3904.3s
################################################################################
                     [1m Learning iteration 975/2000 [0m                      

                       Computation: 1878 steps/s (collection: 3.220s, learning 0.613s)
               Value function loss: 22.8572
                    Surrogate loss: -0.0028
             Mean action noise std: 0.92
                       Mean reward: -46.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.08
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7027200
                    Iteration time: 3.83s
                        Total time: 3714.03s
                               ETA: 3900.5s
################################################################################
                     [1m Learning iteration 976/2000 [0m                      

                       Computation: 1804 steps/s (collection: 3.363s, learning 0.626s)
               Value function loss: 21.5950
                    Surrogate loss: -0.0070
             Mean action noise std: 0.92
                       Mean reward: -46.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7034400
                    Iteration time: 3.99s
                        Total time: 3718.02s
                               ETA: 3896.9s
################################################################################
                     [1m Learning iteration 977/2000 [0m                      

                       Computation: 1883 steps/s (collection: 3.215s, learning 0.608s)
               Value function loss: 23.1563
                    Surrogate loss: -0.0092
             Mean action noise std: 0.92
                       Mean reward: -46.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7041600
                    Iteration time: 3.82s
                        Total time: 3721.84s
                               ETA: 3893.1s
################################################################################
                     [1m Learning iteration 978/2000 [0m                      

                       Computation: 1840 steps/s (collection: 3.292s, learning 0.621s)
               Value function loss: 21.6270
                    Surrogate loss: -0.0049
             Mean action noise std: 0.92
                       Mean reward: -47.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7048800
                    Iteration time: 3.91s
                        Total time: 3725.76s
                               ETA: 3889.4s
################################################################################
                     [1m Learning iteration 979/2000 [0m                      

                       Computation: 1829 steps/s (collection: 3.323s, learning 0.612s)
               Value function loss: 21.9096
                    Surrogate loss: 0.0040
             Mean action noise std: 0.92
                       Mean reward: -47.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7056000
                    Iteration time: 3.94s
                        Total time: 3729.69s
                               ETA: 3885.7s
################################################################################
                     [1m Learning iteration 980/2000 [0m                      

                       Computation: 1835 steps/s (collection: 3.174s, learning 0.749s)
               Value function loss: 24.2137
                    Surrogate loss: -0.0010
             Mean action noise std: 0.92
                       Mean reward: -46.59
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7063200
                    Iteration time: 3.92s
                        Total time: 3733.62s
                               ETA: 3882.0s
################################################################################
                     [1m Learning iteration 981/2000 [0m                      

                       Computation: 1790 steps/s (collection: 3.311s, learning 0.711s)
               Value function loss: 24.7498
                    Surrogate loss: -0.0069
             Mean action noise std: 0.93
                       Mean reward: -46.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7070400
                    Iteration time: 4.02s
                        Total time: 3737.64s
                               ETA: 3878.5s
################################################################################
                     [1m Learning iteration 982/2000 [0m                      

                       Computation: 1869 steps/s (collection: 3.242s, learning 0.610s)
               Value function loss: 23.3430
                    Surrogate loss: -0.0025
             Mean action noise std: 0.92
                       Mean reward: -46.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7077600
                    Iteration time: 3.85s
                        Total time: 3741.49s
                               ETA: 3874.7s
################################################################################
                     [1m Learning iteration 983/2000 [0m                      

                       Computation: 1826 steps/s (collection: 3.265s, learning 0.676s)
               Value function loss: 18.5599
                    Surrogate loss: -0.0077
             Mean action noise std: 0.92
                       Mean reward: -46.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7084800
                    Iteration time: 3.94s
                        Total time: 3745.43s
                               ETA: 3871.0s
################################################################################
                     [1m Learning iteration 984/2000 [0m                      

                       Computation: 1824 steps/s (collection: 3.331s, learning 0.616s)
               Value function loss: 18.7201
                    Surrogate loss: -0.0068
             Mean action noise std: 0.93
                       Mean reward: -46.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7092000
                    Iteration time: 3.95s
                        Total time: 3749.38s
                               ETA: 3867.4s
################################################################################
                     [1m Learning iteration 985/2000 [0m                      

                       Computation: 1859 steps/s (collection: 3.234s, learning 0.638s)
               Value function loss: 23.2665
                    Surrogate loss: -0.0029
             Mean action noise std: 0.92
                       Mean reward: -46.26
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7099200
                    Iteration time: 3.87s
                        Total time: 3753.25s
                               ETA: 3863.6s
################################################################################
                     [1m Learning iteration 986/2000 [0m                      

                       Computation: 1822 steps/s (collection: 3.333s, learning 0.618s)
               Value function loss: 22.6092
                    Surrogate loss: -0.0029
             Mean action noise std: 0.92
                       Mean reward: -46.28
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7106400
                    Iteration time: 3.95s
                        Total time: 3757.20s
                               ETA: 3860.0s
################################################################################
                     [1m Learning iteration 987/2000 [0m                      

                       Computation: 1839 steps/s (collection: 3.298s, learning 0.616s)
               Value function loss: 21.2362
                    Surrogate loss: -0.0014
             Mean action noise std: 0.92
                       Mean reward: -45.90
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7113600
                    Iteration time: 3.91s
                        Total time: 3761.11s
                               ETA: 3856.3s
################################################################################
                     [1m Learning iteration 988/2000 [0m                      

                       Computation: 1803 steps/s (collection: 3.314s, learning 0.679s)
               Value function loss: 24.2719
                    Surrogate loss: -0.0063
             Mean action noise std: 0.92
                       Mean reward: -45.67
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7120800
                    Iteration time: 3.99s
                        Total time: 3765.11s
                               ETA: 3852.7s
################################################################################
                     [1m Learning iteration 989/2000 [0m                      

                       Computation: 1832 steps/s (collection: 3.319s, learning 0.611s)
               Value function loss: 20.9429
                    Surrogate loss: -0.0018
             Mean action noise std: 0.92
                       Mean reward: -46.07
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7128000
                    Iteration time: 3.93s
                        Total time: 3769.04s
                               ETA: 3849.0s
################################################################################
                     [1m Learning iteration 990/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.293s, learning 0.624s)
               Value function loss: 21.9488
                    Surrogate loss: -0.0028
             Mean action noise std: 0.92
                       Mean reward: -46.11
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7135200
                    Iteration time: 3.92s
                        Total time: 3772.95s
                               ETA: 3845.3s
################################################################################
                     [1m Learning iteration 991/2000 [0m                      

                       Computation: 1818 steps/s (collection: 3.346s, learning 0.613s)
               Value function loss: 22.3537
                    Surrogate loss: -0.0057
             Mean action noise std: 0.92
                       Mean reward: -45.89
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7142400
                    Iteration time: 3.96s
                        Total time: 3776.91s
                               ETA: 3841.6s
################################################################################
                     [1m Learning iteration 992/2000 [0m                      

                       Computation: 1857 steps/s (collection: 3.259s, learning 0.617s)
               Value function loss: 24.4365
                    Surrogate loss: -0.0042
             Mean action noise std: 0.92
                       Mean reward: -45.83
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7149600
                    Iteration time: 3.88s
                        Total time: 3780.79s
                               ETA: 3837.9s
################################################################################
                     [1m Learning iteration 993/2000 [0m                      

                       Computation: 1825 steps/s (collection: 3.323s, learning 0.622s)
               Value function loss: 21.2615
                    Surrogate loss: -0.0057
             Mean action noise std: 0.92
                       Mean reward: -45.92
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7156800
                    Iteration time: 3.94s
                        Total time: 3784.73s
                               ETA: 3834.2s
################################################################################
                     [1m Learning iteration 994/2000 [0m                      

                       Computation: 1838 steps/s (collection: 3.267s, learning 0.648s)
               Value function loss: 20.5961
                    Surrogate loss: -0.0013
             Mean action noise std: 0.92
                       Mean reward: -45.92
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7164000
                    Iteration time: 3.92s
                        Total time: 3788.65s
                               ETA: 3830.5s
################################################################################
                     [1m Learning iteration 995/2000 [0m                      

                       Computation: 1803 steps/s (collection: 3.203s, learning 0.790s)
               Value function loss: 22.5704
                    Surrogate loss: -0.0072
             Mean action noise std: 0.92
                       Mean reward: -45.71
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7171200
                    Iteration time: 3.99s
                        Total time: 3792.64s
                               ETA: 3826.9s
################################################################################
                     [1m Learning iteration 996/2000 [0m                      

                       Computation: 1762 steps/s (collection: 3.333s, learning 0.753s)
               Value function loss: 21.7399
                    Surrogate loss: -0.0062
             Mean action noise std: 0.92
                       Mean reward: -45.14
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7178400
                    Iteration time: 4.09s
                        Total time: 3796.73s
                               ETA: 3823.4s
################################################################################
                     [1m Learning iteration 997/2000 [0m                      

                       Computation: 1809 steps/s (collection: 3.221s, learning 0.757s)
               Value function loss: 22.6763
                    Surrogate loss: -0.0099
             Mean action noise std: 0.92
                       Mean reward: -45.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7185600
                    Iteration time: 3.98s
                        Total time: 3800.70s
                               ETA: 3819.7s
################################################################################
                     [1m Learning iteration 998/2000 [0m                      

                       Computation: 1766 steps/s (collection: 3.302s, learning 0.774s)
               Value function loss: 22.2289
                    Surrogate loss: -0.0042
             Mean action noise std: 0.92
                       Mean reward: -44.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7192800
                    Iteration time: 4.08s
                        Total time: 3804.78s
                               ETA: 3816.2s
################################################################################
                     [1m Learning iteration 999/2000 [0m                      

                       Computation: 1791 steps/s (collection: 3.270s, learning 0.750s)
               Value function loss: 21.1980
                    Surrogate loss: -0.0008
             Mean action noise std: 0.92
                       Mean reward: -44.80
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7200000
                    Iteration time: 4.02s
                        Total time: 3808.80s
                               ETA: 3812.6s
################################################################################
                     [1m Learning iteration 1000/2000 [0m                     

                       Computation: 1796 steps/s (collection: 3.093s, learning 0.916s)
               Value function loss: 23.0436
                    Surrogate loss: -0.0042
             Mean action noise std: 0.92
                       Mean reward: -45.13
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7207200
                    Iteration time: 4.01s
                        Total time: 3812.81s
                               ETA: 3809.0s
################################################################################
                     [1m Learning iteration 1001/2000 [0m                     

                       Computation: 1749 steps/s (collection: 3.326s, learning 0.789s)
               Value function loss: 22.5291
                    Surrogate loss: -0.0041
             Mean action noise std: 0.92
                       Mean reward: -46.10
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7214400
                    Iteration time: 4.11s
                        Total time: 3816.92s
                               ETA: 3805.5s
################################################################################
                     [1m Learning iteration 1002/2000 [0m                     

                       Computation: 1811 steps/s (collection: 3.205s, learning 0.769s)
               Value function loss: 19.8009
                    Surrogate loss: -0.0032
             Mean action noise std: 0.92
                       Mean reward: -46.87
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7221600
                    Iteration time: 3.97s
                        Total time: 3820.90s
                               ETA: 3801.9s
################################################################################
                     [1m Learning iteration 1003/2000 [0m                     

                       Computation: 1780 steps/s (collection: 3.255s, learning 0.788s)
               Value function loss: 20.9014
                    Surrogate loss: -0.0084
             Mean action noise std: 0.92
                       Mean reward: -46.48
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7228800
                    Iteration time: 4.04s
                        Total time: 3824.94s
                               ETA: 3798.3s
################################################################################
                     [1m Learning iteration 1004/2000 [0m                     

                       Computation: 1828 steps/s (collection: 3.321s, learning 0.617s)
               Value function loss: 21.4902
                    Surrogate loss: -0.0021
             Mean action noise std: 0.93
                       Mean reward: -46.25
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7236000
                    Iteration time: 3.94s
                        Total time: 3828.88s
                               ETA: 3794.6s
################################################################################
                     [1m Learning iteration 1005/2000 [0m                     

                       Computation: 1862 steps/s (collection: 3.242s, learning 0.623s)
               Value function loss: 22.9901
                    Surrogate loss: -0.0066
             Mean action noise std: 0.93
                       Mean reward: -46.09
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7243200
                    Iteration time: 3.87s
                        Total time: 3832.74s
                               ETA: 3790.8s
################################################################################
                     [1m Learning iteration 1006/2000 [0m                     

                       Computation: 1757 steps/s (collection: 3.351s, learning 0.745s)
               Value function loss: 21.0078
                    Surrogate loss: -0.0023
             Mean action noise std: 0.93
                       Mean reward: -45.28
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7250400
                    Iteration time: 4.10s
                        Total time: 3836.84s
                               ETA: 3787.3s
################################################################################
                     [1m Learning iteration 1007/2000 [0m                     

                       Computation: 1805 steps/s (collection: 3.243s, learning 0.745s)
               Value function loss: 22.3861
                    Surrogate loss: -0.0007
             Mean action noise std: 0.92
                       Mean reward: -44.45
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7257600
                    Iteration time: 3.99s
                        Total time: 3840.83s
                               ETA: 3783.7s
################################################################################
                     [1m Learning iteration 1008/2000 [0m                     

                       Computation: 1821 steps/s (collection: 3.278s, learning 0.675s)
               Value function loss: 21.6939
                    Surrogate loss: -0.0047
             Mean action noise std: 0.92
                       Mean reward: -44.58
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7264800
                    Iteration time: 3.95s
                        Total time: 3844.78s
                               ETA: 3780.0s
################################################################################
                     [1m Learning iteration 1009/2000 [0m                     

                       Computation: 1810 steps/s (collection: 3.303s, learning 0.673s)
               Value function loss: 23.4063
                    Surrogate loss: -0.0050
             Mean action noise std: 0.92
                       Mean reward: -44.72
               Mean episode length: 45.00
                 Mean success rate: 1.50
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7272000
                    Iteration time: 3.98s
                        Total time: 3848.76s
                               ETA: 3776.4s
################################################################################
                     [1m Learning iteration 1010/2000 [0m                     

                       Computation: 1849 steps/s (collection: 3.255s, learning 0.637s)
               Value function loss: 24.3196
                    Surrogate loss: -0.0036
             Mean action noise std: 0.92
                       Mean reward: -44.66
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7279200
                    Iteration time: 3.89s
                        Total time: 3852.65s
                               ETA: 3772.6s
################################################################################
                     [1m Learning iteration 1011/2000 [0m                     

                       Computation: 1732 steps/s (collection: 3.454s, learning 0.702s)
               Value function loss: 23.5522
                    Surrogate loss: -0.0038
             Mean action noise std: 0.92
                       Mean reward: -45.39
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7286400
                    Iteration time: 4.16s
                        Total time: 3856.81s
                               ETA: 3769.2s
################################################################################
                     [1m Learning iteration 1012/2000 [0m                     

                       Computation: 1880 steps/s (collection: 3.184s, learning 0.645s)
               Value function loss: 26.8619
                    Surrogate loss: -0.0030
             Mean action noise std: 0.92
                       Mean reward: -46.01
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7293600
                    Iteration time: 3.83s
                        Total time: 3860.63s
                               ETA: 3765.4s
################################################################################
                     [1m Learning iteration 1013/2000 [0m                     

                       Computation: 1843 steps/s (collection: 3.225s, learning 0.681s)
               Value function loss: 20.0113
                    Surrogate loss: -0.0063
             Mean action noise std: 0.92
                       Mean reward: -46.42
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7300800
                    Iteration time: 3.91s
                        Total time: 3864.54s
                               ETA: 3761.6s
################################################################################
                     [1m Learning iteration 1014/2000 [0m                     

                       Computation: 1789 steps/s (collection: 3.260s, learning 0.764s)
               Value function loss: 21.7615
                    Surrogate loss: -0.0037
             Mean action noise std: 0.92
                       Mean reward: -46.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7308000
                    Iteration time: 4.02s
                        Total time: 3868.56s
                               ETA: 3758.0s
################################################################################
                     [1m Learning iteration 1015/2000 [0m                     

                       Computation: 1797 steps/s (collection: 3.223s, learning 0.782s)
               Value function loss: 21.4957
                    Surrogate loss: -0.0020
             Mean action noise std: 0.92
                       Mean reward: -46.65
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7315200
                    Iteration time: 4.01s
                        Total time: 3872.57s
                               ETA: 3754.4s
################################################################################
                     [1m Learning iteration 1016/2000 [0m                     

                       Computation: 1797 steps/s (collection: 3.319s, learning 0.687s)
               Value function loss: 20.1538
                    Surrogate loss: -0.0031
             Mean action noise std: 0.92
                       Mean reward: -46.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7322400
                    Iteration time: 4.01s
                        Total time: 3876.57s
                               ETA: 3750.8s
################################################################################
                     [1m Learning iteration 1017/2000 [0m                     

                       Computation: 1876 steps/s (collection: 3.205s, learning 0.632s)
               Value function loss: 19.1710
                    Surrogate loss: -0.0014
             Mean action noise std: 0.92
                       Mean reward: -45.80
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7329600
                    Iteration time: 3.84s
                        Total time: 3880.41s
                               ETA: 3747.0s
################################################################################
                     [1m Learning iteration 1018/2000 [0m                     

                       Computation: 1812 steps/s (collection: 3.341s, learning 0.631s)
               Value function loss: 20.9264
                    Surrogate loss: -0.0053
             Mean action noise std: 0.92
                       Mean reward: -45.18
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7336800
                    Iteration time: 3.97s
                        Total time: 3884.38s
                               ETA: 3743.3s
################################################################################
                     [1m Learning iteration 1019/2000 [0m                     

                       Computation: 1858 steps/s (collection: 3.261s, learning 0.614s)
               Value function loss: 22.0366
                    Surrogate loss: -0.0074
             Mean action noise std: 0.92
                       Mean reward: -45.07
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7344000
                    Iteration time: 3.88s
                        Total time: 3888.26s
                               ETA: 3739.6s
################################################################################
                     [1m Learning iteration 1020/2000 [0m                     

                       Computation: 1844 steps/s (collection: 3.249s, learning 0.655s)
               Value function loss: 20.0851
                    Surrogate loss: -0.0063
             Mean action noise std: 0.92
                       Mean reward: -44.98
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7351200
                    Iteration time: 3.90s
                        Total time: 3892.16s
                               ETA: 3735.9s
################################################################################
                     [1m Learning iteration 1021/2000 [0m                     

                       Computation: 1799 steps/s (collection: 3.324s, learning 0.678s)
               Value function loss: 18.6379
                    Surrogate loss: -0.0092
             Mean action noise std: 0.92
                       Mean reward: -44.92
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7358400
                    Iteration time: 4.00s
                        Total time: 3896.17s
                               ETA: 3732.2s
################################################################################
                     [1m Learning iteration 1022/2000 [0m                     

                       Computation: 1843 steps/s (collection: 3.232s, learning 0.674s)
               Value function loss: 23.4818
                    Surrogate loss: 0.0032
             Mean action noise std: 0.92
                       Mean reward: -44.52
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7365600
                    Iteration time: 3.91s
                        Total time: 3900.07s
                               ETA: 3728.5s
################################################################################
                     [1m Learning iteration 1023/2000 [0m                     

                       Computation: 1820 steps/s (collection: 3.333s, learning 0.622s)
               Value function loss: 21.8332
                    Surrogate loss: -0.0067
             Mean action noise std: 0.91
                       Mean reward: -44.62
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 3.95s
                        Total time: 3904.03s
                               ETA: 3724.8s
################################################################################
                     [1m Learning iteration 1024/2000 [0m                     

                       Computation: 1876 steps/s (collection: 3.221s, learning 0.616s)
               Value function loss: 21.0829
                    Surrogate loss: -0.0009
             Mean action noise std: 0.92
                       Mean reward: -45.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7380000
                    Iteration time: 3.84s
                        Total time: 3907.86s
                               ETA: 3721.0s
################################################################################
                     [1m Learning iteration 1025/2000 [0m                     

                       Computation: 1845 steps/s (collection: 3.224s, learning 0.677s)
               Value function loss: 19.1246
                    Surrogate loss: -0.0098
             Mean action noise std: 0.92
                       Mean reward: -45.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7387200
                    Iteration time: 3.90s
                        Total time: 3911.76s
                               ETA: 3717.3s
################################################################################
                     [1m Learning iteration 1026/2000 [0m                     

                       Computation: 1828 steps/s (collection: 3.276s, learning 0.662s)
               Value function loss: 21.9054
                    Surrogate loss: -0.0018
             Mean action noise std: 0.92
                       Mean reward: -45.13
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7394400
                    Iteration time: 3.94s
                        Total time: 3915.70s
                               ETA: 3713.6s
################################################################################
                     [1m Learning iteration 1027/2000 [0m                     

                       Computation: 1864 steps/s (collection: 3.240s, learning 0.621s)
               Value function loss: 19.3244
                    Surrogate loss: -0.0030
             Mean action noise std: 0.92
                       Mean reward: -45.51
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7401600
                    Iteration time: 3.86s
                        Total time: 3919.56s
                               ETA: 3709.9s
################################################################################
                     [1m Learning iteration 1028/2000 [0m                     

                       Computation: 1814 steps/s (collection: 3.356s, learning 0.612s)
               Value function loss: 21.5926
                    Surrogate loss: -0.0038
             Mean action noise std: 0.92
                       Mean reward: -45.83
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7408800
                    Iteration time: 3.97s
                        Total time: 3923.53s
                               ETA: 3706.2s
################################################################################
                     [1m Learning iteration 1029/2000 [0m                     

                       Computation: 1861 steps/s (collection: 3.254s, learning 0.613s)
               Value function loss: 20.0588
                    Surrogate loss: -0.0044
             Mean action noise std: 0.92
                       Mean reward: -45.53
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7416000
                    Iteration time: 3.87s
                        Total time: 3927.40s
                               ETA: 3702.4s
################################################################################
                     [1m Learning iteration 1030/2000 [0m                     

                       Computation: 1829 steps/s (collection: 3.322s, learning 0.614s)
               Value function loss: 20.6696
                    Surrogate loss: -0.0007
             Mean action noise std: 0.92
                       Mean reward: -45.22
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7423200
                    Iteration time: 3.94s
                        Total time: 3931.33s
                               ETA: 3698.7s
################################################################################
                     [1m Learning iteration 1031/2000 [0m                     

                       Computation: 1835 steps/s (collection: 3.314s, learning 0.609s)
               Value function loss: 22.1434
                    Surrogate loss: -0.0023
             Mean action noise std: 0.92
                       Mean reward: -45.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7430400
                    Iteration time: 3.92s
                        Total time: 3935.26s
                               ETA: 3695.0s
################################################################################
                     [1m Learning iteration 1032/2000 [0m                     

                       Computation: 1861 steps/s (collection: 3.259s, learning 0.609s)
               Value function loss: 22.0712
                    Surrogate loss: -0.0051
             Mean action noise std: 0.92
                       Mean reward: -45.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7437600
                    Iteration time: 3.87s
                        Total time: 3939.13s
                               ETA: 3691.3s
################################################################################
                     [1m Learning iteration 1033/2000 [0m                     

                       Computation: 1808 steps/s (collection: 3.376s, learning 0.604s)
               Value function loss: 22.4062
                    Surrogate loss: -0.0054
             Mean action noise std: 0.92
                       Mean reward: -45.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7444800
                    Iteration time: 3.98s
                        Total time: 3943.11s
                               ETA: 3687.6s
################################################################################
                     [1m Learning iteration 1034/2000 [0m                     

                       Computation: 1851 steps/s (collection: 3.265s, learning 0.623s)
               Value function loss: 21.1213
                    Surrogate loss: -0.0043
             Mean action noise std: 0.92
                       Mean reward: -45.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.04
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7452000
                    Iteration time: 3.89s
                        Total time: 3946.99s
                               ETA: 3683.9s
################################################################################
                     [1m Learning iteration 1035/2000 [0m                     

                       Computation: 1825 steps/s (collection: 3.326s, learning 0.618s)
               Value function loss: 19.0206
                    Surrogate loss: -0.0028
             Mean action noise std: 0.92
                       Mean reward: -45.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7459200
                    Iteration time: 3.94s
                        Total time: 3950.94s
                               ETA: 3680.2s
################################################################################
                     [1m Learning iteration 1036/2000 [0m                     

                       Computation: 1836 steps/s (collection: 3.281s, learning 0.641s)
               Value function loss: 22.3412
                    Surrogate loss: -0.0011
             Mean action noise std: 0.91
                       Mean reward: -45.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7466400
                    Iteration time: 3.92s
                        Total time: 3954.86s
                               ETA: 3676.5s
################################################################################
                     [1m Learning iteration 1037/2000 [0m                     

                       Computation: 1858 steps/s (collection: 3.254s, learning 0.621s)
               Value function loss: 21.7459
                    Surrogate loss: -0.0095
             Mean action noise std: 0.92
                       Mean reward: -45.23
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7473600
                    Iteration time: 3.88s
                        Total time: 3958.73s
                               ETA: 3672.7s
################################################################################
                     [1m Learning iteration 1038/2000 [0m                     

                       Computation: 1811 steps/s (collection: 3.343s, learning 0.631s)
               Value function loss: 21.4692
                    Surrogate loss: -0.0003
             Mean action noise std: 0.92
                       Mean reward: -45.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7480800
                    Iteration time: 3.97s
                        Total time: 3962.71s
                               ETA: 3669.0s
################################################################################
                     [1m Learning iteration 1039/2000 [0m                     

                       Computation: 1858 steps/s (collection: 3.256s, learning 0.618s)
               Value function loss: 24.4327
                    Surrogate loss: -0.0039
             Mean action noise std: 0.92
                       Mean reward: -44.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7488000
                    Iteration time: 3.87s
                        Total time: 3966.58s
                               ETA: 3665.3s
################################################################################
                     [1m Learning iteration 1040/2000 [0m                     

                       Computation: 1790 steps/s (collection: 3.373s, learning 0.649s)
               Value function loss: 23.3648
                    Surrogate loss: -0.0061
             Mean action noise std: 0.92
                       Mean reward: -45.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7495200
                    Iteration time: 4.02s
                        Total time: 3970.60s
                               ETA: 3661.7s
################################################################################
                     [1m Learning iteration 1041/2000 [0m                     

                       Computation: 1776 steps/s (collection: 3.331s, learning 0.723s)
               Value function loss: 23.5801
                    Surrogate loss: -0.0086
             Mean action noise std: 0.92
                       Mean reward: -45.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7502400
                    Iteration time: 4.05s
                        Total time: 3974.66s
                               ETA: 3658.1s
################################################################################
                     [1m Learning iteration 1042/2000 [0m                     

                       Computation: 1854 steps/s (collection: 3.265s, learning 0.616s)
               Value function loss: 25.6768
                    Surrogate loss: 0.0012
             Mean action noise std: 0.92
                       Mean reward: -45.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.06
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7509600
                    Iteration time: 3.88s
                        Total time: 3978.54s
                               ETA: 3654.3s
################################################################################
                     [1m Learning iteration 1043/2000 [0m                     

                       Computation: 1799 steps/s (collection: 3.383s, learning 0.617s)
               Value function loss: 21.3190
                    Surrogate loss: -0.0077
             Mean action noise std: 0.91
                       Mean reward: -45.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7516800
                    Iteration time: 4.00s
                        Total time: 3982.54s
                               ETA: 3650.7s
################################################################################
                     [1m Learning iteration 1044/2000 [0m                     

                       Computation: 1849 steps/s (collection: 3.261s, learning 0.633s)
               Value function loss: 23.6458
                    Surrogate loss: -0.0034
             Mean action noise std: 0.91
                       Mean reward: -45.51
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7524000
                    Iteration time: 3.89s
                        Total time: 3986.43s
                               ETA: 3646.9s
################################################################################
                     [1m Learning iteration 1045/2000 [0m                     

                       Computation: 1811 steps/s (collection: 3.361s, learning 0.614s)
               Value function loss: 23.8387
                    Surrogate loss: -0.0053
             Mean action noise std: 0.91
                       Mean reward: -45.34
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7531200
                    Iteration time: 3.98s
                        Total time: 3990.41s
                               ETA: 3643.2s
################################################################################
                     [1m Learning iteration 1046/2000 [0m                     

                       Computation: 1845 steps/s (collection: 3.265s, learning 0.636s)
               Value function loss: 23.3564
                    Surrogate loss: 0.0003
             Mean action noise std: 0.91
                       Mean reward: -45.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7538400
                    Iteration time: 3.90s
                        Total time: 3994.31s
                               ETA: 3639.5s
################################################################################
                     [1m Learning iteration 1047/2000 [0m                     

                       Computation: 1826 steps/s (collection: 3.228s, learning 0.715s)
               Value function loss: 21.6740
                    Surrogate loss: -0.0093
             Mean action noise std: 0.91
                       Mean reward: -45.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7545600
                    Iteration time: 3.94s
                        Total time: 3998.25s
                               ETA: 3635.8s
################################################################################
                     [1m Learning iteration 1048/2000 [0m                     

                       Computation: 1823 steps/s (collection: 3.325s, learning 0.624s)
               Value function loss: 20.3185
                    Surrogate loss: -0.0089
             Mean action noise std: 0.91
                       Mean reward: -45.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7552800
                    Iteration time: 3.95s
                        Total time: 4002.20s
                               ETA: 3632.1s
################################################################################
                     [1m Learning iteration 1049/2000 [0m                     

                       Computation: 1870 steps/s (collection: 3.230s, learning 0.619s)
               Value function loss: 22.2027
                    Surrogate loss: -0.0055
             Mean action noise std: 0.91
                       Mean reward: -45.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7560000
                    Iteration time: 3.85s
                        Total time: 4006.05s
                               ETA: 3628.3s
################################################################################
                     [1m Learning iteration 1050/2000 [0m                     

                       Computation: 1804 steps/s (collection: 3.324s, learning 0.666s)
               Value function loss: 22.2187
                    Surrogate loss: 0.0042
             Mean action noise std: 0.91
                       Mean reward: -45.10
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7567200
                    Iteration time: 3.99s
                        Total time: 4010.04s
                               ETA: 3624.7s
################################################################################
                     [1m Learning iteration 1051/2000 [0m                     

                       Computation: 1881 steps/s (collection: 3.187s, learning 0.640s)
               Value function loss: 22.6229
                    Surrogate loss: -0.0077
             Mean action noise std: 0.91
                       Mean reward: -44.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7574400
                    Iteration time: 3.83s
                        Total time: 4013.87s
                               ETA: 3620.9s
################################################################################
                     [1m Learning iteration 1052/2000 [0m                     

                       Computation: 1848 steps/s (collection: 3.198s, learning 0.697s)
               Value function loss: 21.1130
                    Surrogate loss: -0.0096
             Mean action noise std: 0.91
                       Mean reward: -45.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.07
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7581600
                    Iteration time: 3.89s
                        Total time: 4017.76s
                               ETA: 3617.1s
################################################################################
                     [1m Learning iteration 1053/2000 [0m                     

                       Computation: 1820 steps/s (collection: 3.328s, learning 0.627s)
               Value function loss: 22.8639
                    Surrogate loss: -0.0054
             Mean action noise std: 0.91
                       Mean reward: -45.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7588800
                    Iteration time: 3.96s
                        Total time: 4021.72s
                               ETA: 3613.4s
################################################################################
                     [1m Learning iteration 1054/2000 [0m                     

                       Computation: 1851 steps/s (collection: 3.224s, learning 0.665s)
               Value function loss: 21.4155
                    Surrogate loss: -0.0054
             Mean action noise std: 0.91
                       Mean reward: -45.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7596000
                    Iteration time: 3.89s
                        Total time: 4025.60s
                               ETA: 3609.7s
################################################################################
                     [1m Learning iteration 1055/2000 [0m                     

                       Computation: 1810 steps/s (collection: 3.364s, learning 0.614s)
               Value function loss: 23.4829
                    Surrogate loss: -0.0002
             Mean action noise std: 0.91
                       Mean reward: -46.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7603200
                    Iteration time: 3.98s
                        Total time: 4029.58s
                               ETA: 3606.0s
################################################################################
                     [1m Learning iteration 1056/2000 [0m                     

                       Computation: 1852 steps/s (collection: 3.274s, learning 0.613s)
               Value function loss: 22.6769
                    Surrogate loss: -0.0055
             Mean action noise std: 0.91
                       Mean reward: -46.39
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.05
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7610400
                    Iteration time: 3.89s
                        Total time: 4033.47s
                               ETA: 3602.3s
################################################################################
                     [1m Learning iteration 1057/2000 [0m                     

                       Computation: 1828 steps/s (collection: 3.318s, learning 0.620s)
               Value function loss: 22.2670
                    Surrogate loss: -0.0049
             Mean action noise std: 0.91
                       Mean reward: -45.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7617600
                    Iteration time: 3.94s
                        Total time: 4037.41s
                               ETA: 3598.6s
################################################################################
                     [1m Learning iteration 1058/2000 [0m                     

                       Computation: 1839 steps/s (collection: 3.302s, learning 0.613s)
               Value function loss: 21.5721
                    Surrogate loss: -0.0048
             Mean action noise std: 0.91
                       Mean reward: -45.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7624800
                    Iteration time: 3.91s
                        Total time: 4041.32s
                               ETA: 3594.8s
################################################################################
                     [1m Learning iteration 1059/2000 [0m                     

                       Computation: 1842 steps/s (collection: 3.241s, learning 0.666s)
               Value function loss: 23.1847
                    Surrogate loss: -0.0049
             Mean action noise std: 0.91
                       Mean reward: -45.36
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7632000
                    Iteration time: 3.91s
                        Total time: 4045.23s
                               ETA: 3591.1s
################################################################################
                     [1m Learning iteration 1060/2000 [0m                     

                       Computation: 1819 steps/s (collection: 3.329s, learning 0.629s)
               Value function loss: 21.0157
                    Surrogate loss: -0.0025
             Mean action noise std: 0.91
                       Mean reward: -45.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7639200
                    Iteration time: 3.96s
                        Total time: 4049.19s
                               ETA: 3587.4s
################################################################################
                     [1m Learning iteration 1061/2000 [0m                     

                       Computation: 1854 steps/s (collection: 3.269s, learning 0.613s)
               Value function loss: 21.5880
                    Surrogate loss: -0.0080
             Mean action noise std: 0.91
                       Mean reward: -45.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7646400
                    Iteration time: 3.88s
                        Total time: 4053.07s
                               ETA: 3583.6s
################################################################################
                     [1m Learning iteration 1062/2000 [0m                     

                       Computation: 1802 steps/s (collection: 3.345s, learning 0.649s)
               Value function loss: 22.7722
                    Surrogate loss: -0.0033
             Mean action noise std: 0.91
                       Mean reward: -45.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7653600
                    Iteration time: 3.99s
                        Total time: 4057.06s
                               ETA: 3580.0s
################################################################################
                     [1m Learning iteration 1063/2000 [0m                     

                       Computation: 1854 steps/s (collection: 3.227s, learning 0.655s)
               Value function loss: 20.8911
                    Surrogate loss: -0.0062
             Mean action noise std: 0.91
                       Mean reward: -45.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7660800
                    Iteration time: 3.88s
                        Total time: 4060.95s
                               ETA: 3576.2s
################################################################################
                     [1m Learning iteration 1064/2000 [0m                     

                       Computation: 1839 steps/s (collection: 3.310s, learning 0.603s)
               Value function loss: 20.4955
                    Surrogate loss: -0.0028
             Mean action noise std: 0.91
                       Mean reward: -45.51
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7668000
                    Iteration time: 3.91s
                        Total time: 4064.86s
                               ETA: 3572.5s
################################################################################
                     [1m Learning iteration 1065/2000 [0m                     

                       Computation: 1788 steps/s (collection: 3.298s, learning 0.729s)
               Value function loss: 20.6433
                    Surrogate loss: -0.0074
             Mean action noise std: 0.91
                       Mean reward: -45.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7675200
                    Iteration time: 4.03s
                        Total time: 4068.89s
                               ETA: 3568.9s
################################################################################
                     [1m Learning iteration 1066/2000 [0m                     

                       Computation: 1859 steps/s (collection: 3.256s, learning 0.615s)
               Value function loss: 21.6125
                    Surrogate loss: -0.0047
             Mean action noise std: 0.91
                       Mean reward: -44.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7682400
                    Iteration time: 3.87s
                        Total time: 4072.76s
                               ETA: 3565.1s
################################################################################
                     [1m Learning iteration 1067/2000 [0m                     

                       Computation: 1795 steps/s (collection: 3.387s, learning 0.623s)
               Value function loss: 23.4954
                    Surrogate loss: -0.0061
             Mean action noise std: 0.91
                       Mean reward: -44.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7689600
                    Iteration time: 4.01s
                        Total time: 4076.77s
                               ETA: 3561.4s
################################################################################
                     [1m Learning iteration 1068/2000 [0m                     

                       Computation: 1828 steps/s (collection: 3.275s, learning 0.662s)
               Value function loss: 19.3491
                    Surrogate loss: -0.0058
             Mean action noise std: 0.91
                       Mean reward: -44.72
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7696800
                    Iteration time: 3.94s
                        Total time: 4080.70s
                               ETA: 3557.7s
################################################################################
                     [1m Learning iteration 1069/2000 [0m                     

                       Computation: 1790 steps/s (collection: 3.270s, learning 0.752s)
               Value function loss: 21.6737
                    Surrogate loss: -0.0081
             Mean action noise std: 0.91
                       Mean reward: -44.26
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7704000
                    Iteration time: 4.02s
                        Total time: 4084.73s
                               ETA: 3554.1s
################################################################################
                     [1m Learning iteration 1070/2000 [0m                     

                       Computation: 1749 steps/s (collection: 3.351s, learning 0.765s)
               Value function loss: 23.1978
                    Surrogate loss: -0.0029
             Mean action noise std: 0.91
                       Mean reward: -44.19
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7711200
                    Iteration time: 4.12s
                        Total time: 4088.84s
                               ETA: 3550.5s
################################################################################
                     [1m Learning iteration 1071/2000 [0m                     

                       Computation: 1810 steps/s (collection: 3.214s, learning 0.763s)
               Value function loss: 20.2861
                    Surrogate loss: -0.0078
             Mean action noise std: 0.91
                       Mean reward: -44.28
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7718400
                    Iteration time: 3.98s
                        Total time: 4092.82s
                               ETA: 3546.9s
################################################################################
                     [1m Learning iteration 1072/2000 [0m                     

                       Computation: 1759 steps/s (collection: 3.303s, learning 0.789s)
               Value function loss: 20.5997
                    Surrogate loss: -0.0098
             Mean action noise std: 0.91
                       Mean reward: -43.88
               Mean episode length: 45.00
                 Mean success rate: 1.50
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7725600
                    Iteration time: 4.09s
                        Total time: 4096.91s
                               ETA: 3543.3s
################################################################################
                     [1m Learning iteration 1073/2000 [0m                     

                       Computation: 1795 steps/s (collection: 3.270s, learning 0.740s)
               Value function loss: 22.2915
                    Surrogate loss: -0.0072
             Mean action noise std: 0.91
                       Mean reward: -43.36
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7732800
                    Iteration time: 4.01s
                        Total time: 4100.92s
                               ETA: 3539.6s
################################################################################
                     [1m Learning iteration 1074/2000 [0m                     

                       Computation: 1788 steps/s (collection: 3.262s, learning 0.764s)
               Value function loss: 21.0402
                    Surrogate loss: 0.0089
             Mean action noise std: 0.91
                       Mean reward: -43.64
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7740000
                    Iteration time: 4.03s
                        Total time: 4104.95s
                               ETA: 3536.0s
################################################################################
                     [1m Learning iteration 1075/2000 [0m                     

                       Computation: 1781 steps/s (collection: 3.349s, learning 0.693s)
               Value function loss: 23.4186
                    Surrogate loss: -0.0034
             Mean action noise std: 0.91
                       Mean reward: -43.67
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7747200
                    Iteration time: 4.04s
                        Total time: 4108.99s
                               ETA: 3532.4s
################################################################################
                     [1m Learning iteration 1076/2000 [0m                     

                       Computation: 1795 steps/s (collection: 3.270s, learning 0.740s)
               Value function loss: 22.1495
                    Surrogate loss: -0.0059
             Mean action noise std: 0.91
                       Mean reward: -43.85
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7754400
                    Iteration time: 4.01s
                        Total time: 4113.00s
                               ETA: 3528.7s
################################################################################
                     [1m Learning iteration 1077/2000 [0m                     

                       Computation: 1799 steps/s (collection: 3.307s, learning 0.695s)
               Value function loss: 23.3394
                    Surrogate loss: -0.0038
             Mean action noise std: 0.91
                       Mean reward: -44.38
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7761600
                    Iteration time: 4.00s
                        Total time: 4117.00s
                               ETA: 3525.0s
################################################################################
                     [1m Learning iteration 1078/2000 [0m                     

                       Computation: 1767 steps/s (collection: 3.290s, learning 0.784s)
               Value function loss: 20.7360
                    Surrogate loss: -0.0026
             Mean action noise std: 0.91
                       Mean reward: -44.65
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7768800
                    Iteration time: 4.07s
                        Total time: 4121.08s
                               ETA: 3521.4s
################################################################################
                     [1m Learning iteration 1079/2000 [0m                     

                       Computation: 1790 steps/s (collection: 3.234s, learning 0.786s)
               Value function loss: 21.7128
                    Surrogate loss: -0.0080
             Mean action noise std: 0.91
                       Mean reward: -44.85
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7776000
                    Iteration time: 4.02s
                        Total time: 4125.10s
                               ETA: 3517.8s
################################################################################
                     [1m Learning iteration 1080/2000 [0m                     

                       Computation: 1776 steps/s (collection: 3.352s, learning 0.700s)
               Value function loss: 22.6069
                    Surrogate loss: -0.0086
             Mean action noise std: 0.91
                       Mean reward: -44.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7783200
                    Iteration time: 4.05s
                        Total time: 4129.15s
                               ETA: 3514.2s
################################################################################
                     [1m Learning iteration 1081/2000 [0m                     

                       Computation: 1769 steps/s (collection: 3.302s, learning 0.766s)
               Value function loss: 23.9839
                    Surrogate loss: -0.0085
             Mean action noise std: 0.91
                       Mean reward: -44.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7790400
                    Iteration time: 4.07s
                        Total time: 4133.22s
                               ETA: 3510.6s
################################################################################
                     [1m Learning iteration 1082/2000 [0m                     

                       Computation: 1749 steps/s (collection: 3.344s, learning 0.772s)
               Value function loss: 23.4527
                    Surrogate loss: -0.0061
             Mean action noise std: 0.91
                       Mean reward: -44.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7797600
                    Iteration time: 4.12s
                        Total time: 4137.33s
                               ETA: 3507.0s
################################################################################
                     [1m Learning iteration 1083/2000 [0m                     

                       Computation: 1742 steps/s (collection: 3.372s, learning 0.760s)
               Value function loss: 21.3234
                    Surrogate loss: -0.0036
             Mean action noise std: 0.91
                       Mean reward: -44.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7804800
                    Iteration time: 4.13s
                        Total time: 4141.47s
                               ETA: 3503.4s
################################################################################
                     [1m Learning iteration 1084/2000 [0m                     

                       Computation: 1791 steps/s (collection: 3.257s, learning 0.763s)
               Value function loss: 21.5610
                    Surrogate loss: -0.0054
             Mean action noise std: 0.91
                       Mean reward: -45.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7812000
                    Iteration time: 4.02s
                        Total time: 4145.49s
                               ETA: 3499.8s
################################################################################
                     [1m Learning iteration 1085/2000 [0m                     

                       Computation: 1768 steps/s (collection: 3.349s, learning 0.722s)
               Value function loss: 21.4386
                    Surrogate loss: -0.0023
             Mean action noise std: 0.91
                       Mean reward: -44.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7819200
                    Iteration time: 4.07s
                        Total time: 4149.56s
                               ETA: 3496.2s
################################################################################
                     [1m Learning iteration 1086/2000 [0m                     

                       Computation: 1833 steps/s (collection: 3.270s, learning 0.658s)
               Value function loss: 21.8446
                    Surrogate loss: 0.0038
             Mean action noise std: 0.91
                       Mean reward: -44.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7826400
                    Iteration time: 3.93s
                        Total time: 4153.48s
                               ETA: 3492.4s
################################################################################
                     [1m Learning iteration 1087/2000 [0m                     

                       Computation: 1817 steps/s (collection: 3.242s, learning 0.719s)
               Value function loss: 21.0774
                    Surrogate loss: -0.0033
             Mean action noise std: 0.91
                       Mean reward: -44.32
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7833600
                    Iteration time: 3.96s
                        Total time: 4157.45s
                               ETA: 3488.7s
################################################################################
                     [1m Learning iteration 1088/2000 [0m                     

                       Computation: 1813 steps/s (collection: 3.352s, learning 0.620s)
               Value function loss: 22.7469
                    Surrogate loss: -0.0056
             Mean action noise std: 0.91
                       Mean reward: -44.26
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7840800
                    Iteration time: 3.97s
                        Total time: 4161.42s
                               ETA: 3485.0s
################################################################################
                     [1m Learning iteration 1089/2000 [0m                     

                       Computation: 1779 steps/s (collection: 3.300s, learning 0.747s)
               Value function loss: 19.7384
                    Surrogate loss: -0.0052
             Mean action noise std: 0.90
                       Mean reward: -44.38
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7848000
                    Iteration time: 4.05s
                        Total time: 4165.46s
                               ETA: 3481.4s
################################################################################
                     [1m Learning iteration 1090/2000 [0m                     

                       Computation: 1752 steps/s (collection: 3.376s, learning 0.732s)
               Value function loss: 23.7395
                    Surrogate loss: -0.0070
             Mean action noise std: 0.90
                       Mean reward: -44.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7855200
                    Iteration time: 4.11s
                        Total time: 4169.57s
                               ETA: 3477.8s
################################################################################
                     [1m Learning iteration 1091/2000 [0m                     

                       Computation: 1828 steps/s (collection: 3.295s, learning 0.642s)
               Value function loss: 22.9463
                    Surrogate loss: -0.0009
             Mean action noise std: 0.90
                       Mean reward: -44.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7862400
                    Iteration time: 3.94s
                        Total time: 4173.51s
                               ETA: 3474.1s
################################################################################
                     [1m Learning iteration 1092/2000 [0m                     

                       Computation: 1855 steps/s (collection: 3.216s, learning 0.663s)
               Value function loss: 22.3158
                    Surrogate loss: -0.0021
             Mean action noise std: 0.90
                       Mean reward: -44.65
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7869600
                    Iteration time: 3.88s
                        Total time: 4177.39s
                               ETA: 3470.3s
################################################################################
                     [1m Learning iteration 1093/2000 [0m                     

                       Computation: 1808 steps/s (collection: 3.360s, learning 0.620s)
               Value function loss: 24.2454
                    Surrogate loss: -0.0077
             Mean action noise std: 0.90
                       Mean reward: -44.45
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7876800
                    Iteration time: 3.98s
                        Total time: 4181.37s
                               ETA: 3466.6s
################################################################################
                     [1m Learning iteration 1094/2000 [0m                     

                       Computation: 1854 steps/s (collection: 3.266s, learning 0.616s)
               Value function loss: 21.8976
                    Surrogate loss: -0.0065
             Mean action noise std: 0.90
                       Mean reward: -44.37
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7884000
                    Iteration time: 3.88s
                        Total time: 4185.25s
                               ETA: 3462.9s
################################################################################
                     [1m Learning iteration 1095/2000 [0m                     

                       Computation: 1778 steps/s (collection: 3.362s, learning 0.685s)
               Value function loss: 22.2168
                    Surrogate loss: -0.0043
             Mean action noise std: 0.90
                       Mean reward: -45.13
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7891200
                    Iteration time: 4.05s
                        Total time: 4189.30s
                               ETA: 3459.2s
################################################################################
                     [1m Learning iteration 1096/2000 [0m                     

                       Computation: 1753 steps/s (collection: 3.320s, learning 0.786s)
               Value function loss: 20.5302
                    Surrogate loss: -0.0033
             Mean action noise std: 0.90
                       Mean reward: -44.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7898400
                    Iteration time: 4.11s
                        Total time: 4193.40s
                               ETA: 3455.6s
################################################################################
                     [1m Learning iteration 1097/2000 [0m                     

                       Computation: 1834 steps/s (collection: 3.314s, learning 0.611s)
               Value function loss: 21.2033
                    Surrogate loss: 0.0071
             Mean action noise std: 0.90
                       Mean reward: -44.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7905600
                    Iteration time: 3.93s
                        Total time: 4197.33s
                               ETA: 3451.9s
################################################################################
                     [1m Learning iteration 1098/2000 [0m                     

                       Computation: 1692 steps/s (collection: 3.405s, learning 0.848s)
               Value function loss: 21.4573
                    Surrogate loss: -0.0060
             Mean action noise std: 0.90
                       Mean reward: -44.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7912800
                    Iteration time: 4.25s
                        Total time: 4201.58s
                               ETA: 3448.4s
################################################################################
                     [1m Learning iteration 1099/2000 [0m                     

                       Computation: 1780 steps/s (collection: 3.267s, learning 0.777s)
               Value function loss: 22.2948
                    Surrogate loss: -0.0065
             Mean action noise std: 0.90
                       Mean reward: -43.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7920000
                    Iteration time: 4.04s
                        Total time: 4205.63s
                               ETA: 3444.8s
################################################################################
                     [1m Learning iteration 1100/2000 [0m                     

                       Computation: 1755 steps/s (collection: 3.342s, learning 0.759s)
               Value function loss: 22.1990
                    Surrogate loss: -0.0062
             Mean action noise std: 0.90
                       Mean reward: -43.72
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7927200
                    Iteration time: 4.10s
                        Total time: 4209.73s
                               ETA: 3441.2s
################################################################################
                     [1m Learning iteration 1101/2000 [0m                     

                       Computation: 1756 steps/s (collection: 3.310s, learning 0.789s)
               Value function loss: 22.1792
                    Surrogate loss: -0.0054
             Mean action noise std: 0.90
                       Mean reward: -44.16
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7934400
                    Iteration time: 4.10s
                        Total time: 4213.83s
                               ETA: 3437.6s
################################################################################
                     [1m Learning iteration 1102/2000 [0m                     

                       Computation: 1833 steps/s (collection: 3.277s, learning 0.651s)
               Value function loss: 23.4071
                    Surrogate loss: -0.0041
             Mean action noise std: 0.90
                       Mean reward: -44.12
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7941600
                    Iteration time: 3.93s
                        Total time: 4217.75s
                               ETA: 3433.9s
################################################################################
                     [1m Learning iteration 1103/2000 [0m                     

                       Computation: 1809 steps/s (collection: 3.359s, learning 0.619s)
               Value function loss: 23.9297
                    Surrogate loss: -0.0089
             Mean action noise std: 0.90
                       Mean reward: -44.14
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7948800
                    Iteration time: 3.98s
                        Total time: 4221.73s
                               ETA: 3430.2s
################################################################################
                     [1m Learning iteration 1104/2000 [0m                     

                       Computation: 1846 steps/s (collection: 3.260s, learning 0.638s)
               Value function loss: 22.9087
                    Surrogate loss: -0.0070
             Mean action noise std: 0.90
                       Mean reward: -44.36
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7956000
                    Iteration time: 3.90s
                        Total time: 4225.63s
                               ETA: 3426.4s
################################################################################
                     [1m Learning iteration 1105/2000 [0m                     

                       Computation: 1810 steps/s (collection: 3.350s, learning 0.627s)
               Value function loss: 23.5076
                    Surrogate loss: -0.0071
             Mean action noise std: 0.90
                       Mean reward: -44.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7963200
                    Iteration time: 3.98s
                        Total time: 4229.61s
                               ETA: 3422.7s
################################################################################
                     [1m Learning iteration 1106/2000 [0m                     

                       Computation: 1824 steps/s (collection: 3.326s, learning 0.619s)
               Value function loss: 23.4202
                    Surrogate loss: -0.0095
             Mean action noise std: 0.90
                       Mean reward: -43.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7970400
                    Iteration time: 3.95s
                        Total time: 4233.55s
                               ETA: 3419.0s
################################################################################
                     [1m Learning iteration 1107/2000 [0m                     

                       Computation: 1846 steps/s (collection: 3.262s, learning 0.638s)
               Value function loss: 22.5349
                    Surrogate loss: -0.0094
             Mean action noise std: 0.91
                       Mean reward: -43.63
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7977600
                    Iteration time: 3.90s
                        Total time: 4237.45s
                               ETA: 3415.2s
################################################################################
                     [1m Learning iteration 1108/2000 [0m                     

                       Computation: 1804 steps/s (collection: 3.374s, learning 0.616s)
               Value function loss: 22.7625
                    Surrogate loss: -0.0032
             Mean action noise std: 0.90
                       Mean reward: -43.61
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7984800
                    Iteration time: 3.99s
                        Total time: 4241.44s
                               ETA: 3411.5s
################################################################################
                     [1m Learning iteration 1109/2000 [0m                     

                       Computation: 1846 steps/s (collection: 3.280s, learning 0.619s)
               Value function loss: 23.9659
                    Surrogate loss: -0.0062
             Mean action noise std: 0.90
                       Mean reward: -43.51
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7992000
                    Iteration time: 3.90s
                        Total time: 4245.34s
                               ETA: 3407.7s
################################################################################
                     [1m Learning iteration 1110/2000 [0m                     

                       Computation: 1799 steps/s (collection: 3.385s, learning 0.615s)
               Value function loss: 22.8289
                    Surrogate loss: -0.0003
             Mean action noise std: 0.90
                       Mean reward: -43.81
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 7999200
                    Iteration time: 4.00s
                        Total time: 4249.34s
                               ETA: 3404.1s
################################################################################
                     [1m Learning iteration 1111/2000 [0m                     

                       Computation: 1842 steps/s (collection: 3.304s, learning 0.604s)
               Value function loss: 23.0339
                    Surrogate loss: -0.0030
             Mean action noise std: 0.90
                       Mean reward: -44.36
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8006400
                    Iteration time: 3.91s
                        Total time: 4253.25s
                               ETA: 3400.3s
################################################################################
                     [1m Learning iteration 1112/2000 [0m                     

                       Computation: 1853 steps/s (collection: 3.273s, learning 0.612s)
               Value function loss: 23.8099
                    Surrogate loss: -0.0062
             Mean action noise std: 0.90
                       Mean reward: -44.45
               Mean episode length: 45.00
                 Mean success rate: 2.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8013600
                    Iteration time: 3.88s
                        Total time: 4257.14s
                               ETA: 3396.5s
################################################################################
                     [1m Learning iteration 1113/2000 [0m                     

                       Computation: 1785 steps/s (collection: 3.417s, learning 0.615s)
               Value function loss: 24.5132
                    Surrogate loss: -0.0041
             Mean action noise std: 0.90
                       Mean reward: -44.39
               Mean episode length: 45.00
                 Mean success rate: 2.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8020800
                    Iteration time: 4.03s
                        Total time: 4261.17s
                               ETA: 3392.9s
################################################################################
                     [1m Learning iteration 1114/2000 [0m                     

                       Computation: 1855 steps/s (collection: 3.267s, learning 0.613s)
               Value function loss: 25.8311
                    Surrogate loss: -0.0050
             Mean action noise std: 0.90
                       Mean reward: -44.63
               Mean episode length: 45.00
                 Mean success rate: 1.50
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8028000
                    Iteration time: 3.88s
                        Total time: 4265.05s
                               ETA: 3389.1s
################################################################################
                     [1m Learning iteration 1115/2000 [0m                     

                       Computation: 1795 steps/s (collection: 3.397s, learning 0.613s)
               Value function loss: 22.4551
                    Surrogate loss: -0.0041
             Mean action noise std: 0.90
                       Mean reward: -44.89
               Mean episode length: 45.00
                 Mean success rate: 1.50
                  Mean reward/step: -1.02
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8035200
                    Iteration time: 4.01s
                        Total time: 4269.06s
                               ETA: 3385.4s
################################################################################
                     [1m Learning iteration 1116/2000 [0m                     

                       Computation: 1862 steps/s (collection: 3.251s, learning 0.614s)
               Value function loss: 22.6162
                    Surrogate loss: -0.0082
             Mean action noise std: 0.90
                       Mean reward: -44.26
               Mean episode length: 45.00
                 Mean success rate: 1.50
                  Mean reward/step: -0.92
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8042400
                    Iteration time: 3.86s
                        Total time: 4272.92s
                               ETA: 3381.6s
################################################################################
                     [1m Learning iteration 1117/2000 [0m                     

                       Computation: 1757 steps/s (collection: 3.306s, learning 0.791s)
               Value function loss: 20.7231
                    Surrogate loss: -0.0025
             Mean action noise std: 0.90
                       Mean reward: -43.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8049600
                    Iteration time: 4.10s
                        Total time: 4277.02s
                               ETA: 3378.0s
################################################################################
                     [1m Learning iteration 1118/2000 [0m                     

                       Computation: 1726 steps/s (collection: 3.386s, learning 0.784s)
               Value function loss: 21.9685
                    Surrogate loss: -0.0073
             Mean action noise std: 0.90
                       Mean reward: -43.86
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8056800
                    Iteration time: 4.17s
                        Total time: 4281.19s
                               ETA: 3374.5s
################################################################################
                     [1m Learning iteration 1119/2000 [0m                     

                       Computation: 1784 steps/s (collection: 3.282s, learning 0.754s)
               Value function loss: 19.7451
                    Surrogate loss: -0.0066
             Mean action noise std: 0.90
                       Mean reward: -43.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8064000
                    Iteration time: 4.04s
                        Total time: 4285.23s
                               ETA: 3370.8s
################################################################################
                     [1m Learning iteration 1120/2000 [0m                     

                       Computation: 1656 steps/s (collection: 3.410s, learning 0.937s)
               Value function loss: 20.3806
                    Surrogate loss: -0.0070
             Mean action noise std: 0.90
                       Mean reward: -42.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8071200
                    Iteration time: 4.35s
                        Total time: 4289.57s
                               ETA: 3367.4s
################################################################################
                     [1m Learning iteration 1121/2000 [0m                     

                       Computation: 1781 steps/s (collection: 3.239s, learning 0.804s)
               Value function loss: 22.6131
                    Surrogate loss: -0.0058
             Mean action noise std: 0.90
                       Mean reward: -43.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8078400
                    Iteration time: 4.04s
                        Total time: 4293.61s
                               ETA: 3363.7s
################################################################################
                     [1m Learning iteration 1122/2000 [0m                     

                       Computation: 1790 steps/s (collection: 3.257s, learning 0.764s)
               Value function loss: 20.8391
                    Surrogate loss: -0.0084
             Mean action noise std: 0.90
                       Mean reward: -43.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8085600
                    Iteration time: 4.02s
                        Total time: 4297.64s
                               ETA: 3360.0s
################################################################################
                     [1m Learning iteration 1123/2000 [0m                     

                       Computation: 1730 steps/s (collection: 3.349s, learning 0.811s)
               Value function loss: 22.2062
                    Surrogate loss: -0.0066
             Mean action noise std: 0.90
                       Mean reward: -43.93
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8092800
                    Iteration time: 4.16s
                        Total time: 4301.80s
                               ETA: 3356.5s
################################################################################
                     [1m Learning iteration 1124/2000 [0m                     

                       Computation: 1807 steps/s (collection: 3.257s, learning 0.727s)
               Value function loss: 21.6371
                    Surrogate loss: -0.0066
             Mean action noise std: 0.90
                       Mean reward: -44.03
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8100000
                    Iteration time: 3.98s
                        Total time: 4305.78s
                               ETA: 3352.8s
################################################################################
                     [1m Learning iteration 1125/2000 [0m                     

                       Computation: 1752 steps/s (collection: 3.388s, learning 0.720s)
               Value function loss: 23.7631
                    Surrogate loss: -0.0077
             Mean action noise std: 0.90
                       Mean reward: -44.19
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8107200
                    Iteration time: 4.11s
                        Total time: 4309.89s
                               ETA: 3349.2s
################################################################################
                     [1m Learning iteration 1126/2000 [0m                     

                       Computation: 1778 steps/s (collection: 3.286s, learning 0.763s)
               Value function loss: 21.4262
                    Surrogate loss: -0.0042
             Mean action noise std: 0.90
                       Mean reward: -44.61
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8114400
                    Iteration time: 4.05s
                        Total time: 4313.94s
                               ETA: 3345.5s
################################################################################
                     [1m Learning iteration 1127/2000 [0m                     

                       Computation: 1751 steps/s (collection: 3.255s, learning 0.855s)
               Value function loss: 22.9728
                    Surrogate loss: -0.0016
             Mean action noise std: 0.90
                       Mean reward: -44.19
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8121600
                    Iteration time: 4.11s
                        Total time: 4318.05s
                               ETA: 3341.9s
################################################################################
                     [1m Learning iteration 1128/2000 [0m                     

                       Computation: 1736 steps/s (collection: 3.384s, learning 0.763s)
               Value function loss: 23.1185
                    Surrogate loss: -0.0050
             Mean action noise std: 0.90
                       Mean reward: -44.06
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8128800
                    Iteration time: 4.15s
                        Total time: 4322.19s
                               ETA: 3338.3s
################################################################################
                     [1m Learning iteration 1129/2000 [0m                     

                       Computation: 1793 steps/s (collection: 3.258s, learning 0.757s)
               Value function loss: 24.9520
                    Surrogate loss: -0.0085
             Mean action noise std: 0.90
                       Mean reward: -44.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8136000
                    Iteration time: 4.01s
                        Total time: 4326.21s
                               ETA: 3334.6s
################################################################################
                     [1m Learning iteration 1130/2000 [0m                     

                       Computation: 1812 steps/s (collection: 3.319s, learning 0.653s)
               Value function loss: 19.7866
                    Surrogate loss: -0.0047
             Mean action noise std: 0.90
                       Mean reward: -44.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8143200
                    Iteration time: 3.97s
                        Total time: 4330.18s
                               ETA: 3330.9s
################################################################################
                     [1m Learning iteration 1131/2000 [0m                     

                       Computation: 1818 steps/s (collection: 3.334s, learning 0.625s)
               Value function loss: 22.9977
                    Surrogate loss: -0.0071
             Mean action noise std: 0.90
                       Mean reward: -43.77
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8150400
                    Iteration time: 3.96s
                        Total time: 4334.14s
                               ETA: 3327.2s
################################################################################
                     [1m Learning iteration 1132/2000 [0m                     

                       Computation: 1831 steps/s (collection: 3.319s, learning 0.612s)
               Value function loss: 22.9847
                    Surrogate loss: -0.0034
             Mean action noise std: 0.90
                       Mean reward: -44.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8157600
                    Iteration time: 3.93s
                        Total time: 4338.07s
                               ETA: 3323.4s
################################################################################
                     [1m Learning iteration 1133/2000 [0m                     

                       Computation: 1754 steps/s (collection: 3.399s, learning 0.704s)
               Value function loss: 22.4360
                    Surrogate loss: -0.0080
             Mean action noise std: 0.90
                       Mean reward: -44.07
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8164800
                    Iteration time: 4.10s
                        Total time: 4342.17s
                               ETA: 3319.8s
################################################################################
                     [1m Learning iteration 1134/2000 [0m                     

                       Computation: 1781 steps/s (collection: 3.260s, learning 0.781s)
               Value function loss: 21.5488
                    Surrogate loss: -0.0064
             Mean action noise std: 0.90
                       Mean reward: -43.69
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8172000
                    Iteration time: 4.04s
                        Total time: 4346.21s
                               ETA: 3316.1s
################################################################################
                     [1m Learning iteration 1135/2000 [0m                     

                       Computation: 1779 steps/s (collection: 3.298s, learning 0.749s)
               Value function loss: 20.3609
                    Surrogate loss: -0.0060
             Mean action noise std: 0.90
                       Mean reward: -43.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8179200
                    Iteration time: 4.05s
                        Total time: 4350.26s
                               ETA: 3312.5s
################################################################################
                     [1m Learning iteration 1136/2000 [0m                     

                       Computation: 1739 steps/s (collection: 3.351s, learning 0.789s)
               Value function loss: 22.1202
                    Surrogate loss: -0.0021
             Mean action noise std: 0.90
                       Mean reward: -43.76
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8186400
                    Iteration time: 4.14s
                        Total time: 4354.40s
                               ETA: 3308.9s
################################################################################
                     [1m Learning iteration 1137/2000 [0m                     

                       Computation: 1791 steps/s (collection: 3.247s, learning 0.772s)
               Value function loss: 20.8986
                    Surrogate loss: -0.0071
             Mean action noise std: 0.90
                       Mean reward: -42.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.91
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8193600
                    Iteration time: 4.02s
                        Total time: 4358.42s
                               ETA: 3305.2s
################################################################################
                     [1m Learning iteration 1138/2000 [0m                     

                       Computation: 1736 steps/s (collection: 3.378s, learning 0.767s)
               Value function loss: 21.4407
                    Surrogate loss: -0.0070
             Mean action noise std: 0.90
                       Mean reward: -43.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8200800
                    Iteration time: 4.15s
                        Total time: 4362.57s
                               ETA: 3301.6s
################################################################################
                     [1m Learning iteration 1139/2000 [0m                     

                       Computation: 1777 steps/s (collection: 3.331s, learning 0.718s)
               Value function loss: 21.8014
                    Surrogate loss: -0.0062
             Mean action noise std: 0.90
                       Mean reward: -43.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8208000
                    Iteration time: 4.05s
                        Total time: 4366.62s
                               ETA: 3297.9s
################################################################################
                     [1m Learning iteration 1140/2000 [0m                     

                       Computation: 1830 steps/s (collection: 3.271s, learning 0.663s)
               Value function loss: 23.0735
                    Surrogate loss: -0.0051
             Mean action noise std: 0.90
                       Mean reward: -43.47
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8215200
                    Iteration time: 3.93s
                        Total time: 4370.55s
                               ETA: 3294.2s
################################################################################
                     [1m Learning iteration 1141/2000 [0m                     

                       Computation: 1770 steps/s (collection: 3.372s, learning 0.694s)
               Value function loss: 20.9565
                    Surrogate loss: -0.0032
             Mean action noise std: 0.89
                       Mean reward: -43.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8222400
                    Iteration time: 4.07s
                        Total time: 4374.62s
                               ETA: 3290.5s
################################################################################
                     [1m Learning iteration 1142/2000 [0m                     

                       Computation: 1794 steps/s (collection: 3.272s, learning 0.741s)
               Value function loss: 20.4330
                    Surrogate loss: -0.0058
             Mean action noise std: 0.89
                       Mean reward: -43.81
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8229600
                    Iteration time: 4.01s
                        Total time: 4378.63s
                               ETA: 3286.8s
################################################################################
                     [1m Learning iteration 1143/2000 [0m                     

                       Computation: 1739 steps/s (collection: 3.345s, learning 0.794s)
               Value function loss: 19.1975
                    Surrogate loss: -0.0062
             Mean action noise std: 0.89
                       Mean reward: -43.48
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8236800
                    Iteration time: 4.14s
                        Total time: 4382.77s
                               ETA: 3283.2s
################################################################################
                     [1m Learning iteration 1144/2000 [0m                     

                       Computation: 1736 steps/s (collection: 3.367s, learning 0.780s)
               Value function loss: 19.4849
                    Surrogate loss: -0.0065
             Mean action noise std: 0.89
                       Mean reward: -43.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8244000
                    Iteration time: 4.15s
                        Total time: 4386.91s
                               ETA: 3279.6s
################################################################################
                     [1m Learning iteration 1145/2000 [0m                     

                       Computation: 1754 steps/s (collection: 3.365s, learning 0.738s)
               Value function loss: 21.0698
                    Surrogate loss: -0.0041
             Mean action noise std: 0.89
                       Mean reward: -42.83
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8251200
                    Iteration time: 4.10s
                        Total time: 4391.02s
                               ETA: 3276.0s
################################################################################
                     [1m Learning iteration 1146/2000 [0m                     

                       Computation: 1740 steps/s (collection: 3.374s, learning 0.763s)
               Value function loss: 19.4846
                    Surrogate loss: -0.0017
             Mean action noise std: 0.89
                       Mean reward: -42.73
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8258400
                    Iteration time: 4.14s
                        Total time: 4395.15s
                               ETA: 3272.4s
################################################################################
                     [1m Learning iteration 1147/2000 [0m                     

                       Computation: 1785 steps/s (collection: 3.279s, learning 0.755s)
               Value function loss: 20.3961
                    Surrogate loss: -0.0067
             Mean action noise std: 0.89
                       Mean reward: -42.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8265600
                    Iteration time: 4.03s
                        Total time: 4399.19s
                               ETA: 3268.7s
################################################################################
                     [1m Learning iteration 1148/2000 [0m                     

                       Computation: 1788 steps/s (collection: 3.262s, learning 0.764s)
               Value function loss: 19.9173
                    Surrogate loss: -0.0069
             Mean action noise std: 0.89
                       Mean reward: -42.88
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8272800
                    Iteration time: 4.03s
                        Total time: 4403.21s
                               ETA: 3265.0s
################################################################################
                     [1m Learning iteration 1149/2000 [0m                     

                       Computation: 1739 steps/s (collection: 3.375s, learning 0.764s)
               Value function loss: 21.5077
                    Surrogate loss: -0.0065
             Mean action noise std: 0.89
                       Mean reward: -43.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8280000
                    Iteration time: 4.14s
                        Total time: 4407.35s
                               ETA: 3261.4s
################################################################################
                     [1m Learning iteration 1150/2000 [0m                     

                       Computation: 1791 steps/s (collection: 3.265s, learning 0.754s)
               Value function loss: 21.1054
                    Surrogate loss: -0.0081
             Mean action noise std: 0.89
                       Mean reward: -42.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8287200
                    Iteration time: 4.02s
                        Total time: 4411.37s
                               ETA: 3257.7s
################################################################################
                     [1m Learning iteration 1151/2000 [0m                     

                       Computation: 1810 steps/s (collection: 3.332s, learning 0.645s)
               Value function loss: 20.3503
                    Surrogate loss: -0.0112
             Mean action noise std: 0.89
                       Mean reward: -43.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.00
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8294400
                    Iteration time: 3.98s
                        Total time: 4415.35s
                               ETA: 3254.0s
################################################################################
                     [1m Learning iteration 1152/2000 [0m                     

                       Computation: 1843 steps/s (collection: 3.296s, learning 0.610s)
               Value function loss: 18.3510
                    Surrogate loss: -0.0057
             Mean action noise std: 0.89
                       Mean reward: -42.85
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.90
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8301600
                    Iteration time: 3.91s
                        Total time: 4419.25s
                               ETA: 3250.2s
################################################################################
                     [1m Learning iteration 1153/2000 [0m                     

                       Computation: 1841 steps/s (collection: 3.297s, learning 0.613s)
               Value function loss: 21.5565
                    Surrogate loss: -0.0056
             Mean action noise std: 0.89
                       Mean reward: -42.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.92
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8308800
                    Iteration time: 3.91s
                        Total time: 4423.16s
                               ETA: 3246.5s
################################################################################
                     [1m Learning iteration 1154/2000 [0m                     

                       Computation: 1811 steps/s (collection: 3.364s, learning 0.610s)
               Value function loss: 20.9481
                    Surrogate loss: -0.0092
             Mean action noise std: 0.89
                       Mean reward: -42.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8316000
                    Iteration time: 3.97s
                        Total time: 4427.14s
                               ETA: 3242.7s
################################################################################
                     [1m Learning iteration 1155/2000 [0m                     

                       Computation: 1856 steps/s (collection: 3.216s, learning 0.661s)
               Value function loss: 17.9844
                    Surrogate loss: -0.0060
             Mean action noise std: 0.89
                       Mean reward: -42.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.92
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8323200
                    Iteration time: 3.88s
                        Total time: 4431.02s
                               ETA: 3238.9s
################################################################################
                     [1m Learning iteration 1156/2000 [0m                     

                       Computation: 1792 steps/s (collection: 3.383s, learning 0.633s)
               Value function loss: 20.4940
                    Surrogate loss: -0.0059
             Mean action noise std: 0.89
                       Mean reward: -41.67
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.91
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8330400
                    Iteration time: 4.02s
                        Total time: 4435.03s
                               ETA: 3235.2s
################################################################################
                     [1m Learning iteration 1157/2000 [0m                     

                       Computation: 1817 steps/s (collection: 3.261s, learning 0.700s)
               Value function loss: 18.7717
                    Surrogate loss: -0.0054
             Mean action noise std: 0.89
                       Mean reward: -42.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8337600
                    Iteration time: 3.96s
                        Total time: 4438.99s
                               ETA: 3231.5s
################################################################################
                     [1m Learning iteration 1158/2000 [0m                     

                       Computation: 1774 steps/s (collection: 3.293s, learning 0.764s)
               Value function loss: 19.4973
                    Surrogate loss: -0.0058
             Mean action noise std: 0.89
                       Mean reward: -42.31
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8344800
                    Iteration time: 4.06s
                        Total time: 4443.05s
                               ETA: 3227.8s
################################################################################
                     [1m Learning iteration 1159/2000 [0m                     

                       Computation: 1769 steps/s (collection: 3.360s, learning 0.709s)
               Value function loss: 20.5586
                    Surrogate loss: -0.0024
             Mean action noise std: 0.89
                       Mean reward: -41.97
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8352000
                    Iteration time: 4.07s
                        Total time: 4447.12s
                               ETA: 3224.2s
################################################################################
                     [1m Learning iteration 1160/2000 [0m                     

                       Computation: 1848 steps/s (collection: 3.270s, learning 0.625s)
               Value function loss: 21.0251
                    Surrogate loss: -0.0027
             Mean action noise std: 0.89
                       Mean reward: -42.24
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8359200
                    Iteration time: 3.90s
                        Total time: 4451.01s
                               ETA: 3220.4s
################################################################################
                     [1m Learning iteration 1161/2000 [0m                     

                       Computation: 1801 steps/s (collection: 3.379s, learning 0.619s)
               Value function loss: 21.5820
                    Surrogate loss: -0.0012
             Mean action noise std: 0.89
                       Mean reward: -42.59
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8366400
                    Iteration time: 4.00s
                        Total time: 4455.01s
                               ETA: 3216.7s
################################################################################
                     [1m Learning iteration 1162/2000 [0m                     

                       Computation: 1841 steps/s (collection: 3.290s, learning 0.620s)
               Value function loss: 20.5436
                    Surrogate loss: -0.0030
             Mean action noise std: 0.89
                       Mean reward: -42.77
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8373600
                    Iteration time: 3.91s
                        Total time: 4458.92s
                               ETA: 3212.9s
################################################################################
                     [1m Learning iteration 1163/2000 [0m                     

                       Computation: 1828 steps/s (collection: 3.300s, learning 0.638s)
               Value function loss: 20.6032
                    Surrogate loss: -0.0080
             Mean action noise std: 0.89
                       Mean reward: -42.71
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8380800
                    Iteration time: 3.94s
                        Total time: 4462.86s
                               ETA: 3209.1s
################################################################################
                     [1m Learning iteration 1164/2000 [0m                     

                       Computation: 1818 steps/s (collection: 3.343s, learning 0.615s)
               Value function loss: 20.2070
                    Surrogate loss: -0.0044
             Mean action noise std: 0.89
                       Mean reward: -43.02
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8388000
                    Iteration time: 3.96s
                        Total time: 4466.82s
                               ETA: 3205.4s
################################################################################
                     [1m Learning iteration 1165/2000 [0m                     

                       Computation: 1858 steps/s (collection: 3.261s, learning 0.613s)
               Value function loss: 22.9570
                    Surrogate loss: -0.0079
             Mean action noise std: 0.89
                       Mean reward: -42.86
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8395200
                    Iteration time: 3.87s
                        Total time: 4470.69s
                               ETA: 3201.6s
################################################################################
                     [1m Learning iteration 1166/2000 [0m                     

                       Computation: 1807 steps/s (collection: 3.369s, learning 0.615s)
               Value function loss: 19.3307
                    Surrogate loss: -0.0076
             Mean action noise std: 0.89
                       Mean reward: -42.88
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8402400
                    Iteration time: 3.98s
                        Total time: 4474.67s
                               ETA: 3197.8s
################################################################################
                     [1m Learning iteration 1167/2000 [0m                     

                       Computation: 1852 steps/s (collection: 3.266s, learning 0.620s)
               Value function loss: 21.3451
                    Surrogate loss: -0.0082
             Mean action noise std: 0.89
                       Mean reward: -42.39
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8409600
                    Iteration time: 3.89s
                        Total time: 4478.56s
                               ETA: 3194.0s
################################################################################
                     [1m Learning iteration 1168/2000 [0m                     

                       Computation: 1818 steps/s (collection: 3.336s, learning 0.622s)
               Value function loss: 20.7140
                    Surrogate loss: -0.0093
             Mean action noise std: 0.89
                       Mean reward: -42.74
               Mean episode length: 45.00
                 Mean success rate: 1.50
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8416800
                    Iteration time: 3.96s
                        Total time: 4482.52s
                               ETA: 3190.3s
################################################################################
                     [1m Learning iteration 1169/2000 [0m                     

                       Computation: 1813 steps/s (collection: 3.360s, learning 0.611s)
               Value function loss: 19.2561
                    Surrogate loss: -0.0077
             Mean action noise std: 0.89
                       Mean reward: -42.76
               Mean episode length: 45.00
                 Mean success rate: 1.50
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8424000
                    Iteration time: 3.97s
                        Total time: 4486.49s
                               ETA: 3186.6s
################################################################################
                     [1m Learning iteration 1170/2000 [0m                     

                       Computation: 1848 steps/s (collection: 3.274s, learning 0.621s)
               Value function loss: 23.2052
                    Surrogate loss: -0.0093
             Mean action noise std: 0.89
                       Mean reward: -42.81
               Mean episode length: 45.00
                 Mean success rate: 1.50
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8431200
                    Iteration time: 3.89s
                        Total time: 4490.38s
                               ETA: 3182.8s
################################################################################
                     [1m Learning iteration 1171/2000 [0m                     

                       Computation: 1787 steps/s (collection: 3.395s, learning 0.633s)
               Value function loss: 18.0047
                    Surrogate loss: -0.0052
             Mean action noise std: 0.89
                       Mean reward: -43.00
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8438400
                    Iteration time: 4.03s
                        Total time: 4494.41s
                               ETA: 3179.1s
################################################################################
                     [1m Learning iteration 1172/2000 [0m                     

                       Computation: 1819 steps/s (collection: 3.261s, learning 0.697s)
               Value function loss: 18.3703
                    Surrogate loss: -0.0062
             Mean action noise std: 0.89
                       Mean reward: -43.11
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8445600
                    Iteration time: 3.96s
                        Total time: 4498.37s
                               ETA: 3175.3s
################################################################################
                     [1m Learning iteration 1173/2000 [0m                     

                       Computation: 1749 steps/s (collection: 3.384s, learning 0.732s)
               Value function loss: 19.1332
                    Surrogate loss: -0.0046
             Mean action noise std: 0.89
                       Mean reward: -42.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8452800
                    Iteration time: 4.12s
                        Total time: 4502.49s
                               ETA: 3171.7s
################################################################################
                     [1m Learning iteration 1174/2000 [0m                     

                       Computation: 1784 steps/s (collection: 3.305s, learning 0.729s)
               Value function loss: 18.4633
                    Surrogate loss: -0.0062
             Mean action noise std: 0.89
                       Mean reward: -42.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8460000
                    Iteration time: 4.03s
                        Total time: 4506.52s
                               ETA: 3168.0s
################################################################################
                     [1m Learning iteration 1175/2000 [0m                     

                       Computation: 1838 steps/s (collection: 3.279s, learning 0.637s)
               Value function loss: 20.1717
                    Surrogate loss: -0.0078
             Mean action noise std: 0.89
                       Mean reward: -42.36
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.92
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8467200
                    Iteration time: 3.92s
                        Total time: 4510.44s
                               ETA: 3164.2s
################################################################################
                     [1m Learning iteration 1176/2000 [0m                     

                       Computation: 1800 steps/s (collection: 3.385s, learning 0.614s)
               Value function loss: 20.7605
                    Surrogate loss: -0.0039
             Mean action noise std: 0.89
                       Mean reward: -42.20
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8474400
                    Iteration time: 4.00s
                        Total time: 4514.43s
                               ETA: 3160.5s
################################################################################
                     [1m Learning iteration 1177/2000 [0m                     

                       Computation: 1849 steps/s (collection: 3.272s, learning 0.622s)
               Value function loss: 20.1064
                    Surrogate loss: -0.0010
             Mean action noise std: 0.89
                       Mean reward: -42.10
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8481600
                    Iteration time: 3.89s
                        Total time: 4518.33s
                               ETA: 3156.7s
################################################################################
                     [1m Learning iteration 1178/2000 [0m                     

                       Computation: 1808 steps/s (collection: 3.347s, learning 0.634s)
               Value function loss: 18.6977
                    Surrogate loss: 0.0009
             Mean action noise std: 0.89
                       Mean reward: -42.27
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8488800
                    Iteration time: 3.98s
                        Total time: 4522.31s
                               ETA: 3153.0s
################################################################################
                     [1m Learning iteration 1179/2000 [0m                     

                       Computation: 1832 steps/s (collection: 3.289s, learning 0.639s)
               Value function loss: 18.6953
                    Surrogate loss: -0.0045
             Mean action noise std: 0.89
                       Mean reward: -42.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8496000
                    Iteration time: 3.93s
                        Total time: 4526.24s
                               ETA: 3149.2s
################################################################################
                     [1m Learning iteration 1180/2000 [0m                     

                       Computation: 1848 steps/s (collection: 3.275s, learning 0.619s)
               Value function loss: 19.3978
                    Surrogate loss: -0.0008
             Mean action noise std: 0.89
                       Mean reward: -42.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8503200
                    Iteration time: 3.89s
                        Total time: 4530.13s
                               ETA: 3145.4s
################################################################################
                     [1m Learning iteration 1181/2000 [0m                     

                       Computation: 1802 steps/s (collection: 3.383s, learning 0.613s)
               Value function loss: 18.4494
                    Surrogate loss: -0.0063
             Mean action noise std: 0.89
                       Mean reward: -42.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.91
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8510400
                    Iteration time: 4.00s
                        Total time: 4534.13s
                               ETA: 3141.7s
################################################################################
                     [1m Learning iteration 1182/2000 [0m                     

                       Computation: 1842 steps/s (collection: 3.255s, learning 0.653s)
               Value function loss: 19.3074
                    Surrogate loss: -0.0061
             Mean action noise std: 0.89
                       Mean reward: -42.00
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.92
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8517600
                    Iteration time: 3.91s
                        Total time: 4538.04s
                               ETA: 3137.9s
################################################################################
                     [1m Learning iteration 1183/2000 [0m                     

                       Computation: 1801 steps/s (collection: 3.370s, learning 0.627s)
               Value function loss: 20.9360
                    Surrogate loss: -0.0012
             Mean action noise std: 0.89
                       Mean reward: -41.79
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8524800
                    Iteration time: 4.00s
                        Total time: 4542.03s
                               ETA: 3134.2s
################################################################################
                     [1m Learning iteration 1184/2000 [0m                     

                       Computation: 1806 steps/s (collection: 3.282s, learning 0.704s)
               Value function loss: 25.4487
                    Surrogate loss: -0.0068
             Mean action noise std: 0.89
                       Mean reward: -42.12
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8532000
                    Iteration time: 3.99s
                        Total time: 4546.02s
                               ETA: 3130.4s
################################################################################
                     [1m Learning iteration 1185/2000 [0m                     

                       Computation: 1846 steps/s (collection: 3.285s, learning 0.615s)
               Value function loss: 19.5810
                    Surrogate loss: -0.0083
             Mean action noise std: 0.89
                       Mean reward: -42.16
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8539200
                    Iteration time: 3.90s
                        Total time: 4549.92s
                               ETA: 3126.6s
################################################################################
                     [1m Learning iteration 1186/2000 [0m                     

                       Computation: 1789 steps/s (collection: 3.357s, learning 0.667s)
               Value function loss: 23.3058
                    Surrogate loss: -0.0047
             Mean action noise std: 0.89
                       Mean reward: -42.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8546400
                    Iteration time: 4.02s
                        Total time: 4553.94s
                               ETA: 3122.9s
################################################################################
                     [1m Learning iteration 1187/2000 [0m                     

                       Computation: 1819 steps/s (collection: 3.302s, learning 0.656s)
               Value function loss: 19.1388
                    Surrogate loss: -0.0074
             Mean action noise std: 0.89
                       Mean reward: -42.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.91
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8553600
                    Iteration time: 3.96s
                        Total time: 4557.90s
                               ETA: 3119.2s
################################################################################
                     [1m Learning iteration 1188/2000 [0m                     

                       Computation: 1745 steps/s (collection: 3.442s, learning 0.684s)
               Value function loss: 20.0841
                    Surrogate loss: -0.0047
             Mean action noise std: 0.89
                       Mean reward: -42.21
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8560800
                    Iteration time: 4.13s
                        Total time: 4562.02s
                               ETA: 3115.5s
################################################################################
                     [1m Learning iteration 1189/2000 [0m                     

                       Computation: 1794 steps/s (collection: 3.303s, learning 0.709s)
               Value function loss: 21.3766
                    Surrogate loss: -0.0074
             Mean action noise std: 0.89
                       Mean reward: -42.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8568000
                    Iteration time: 4.01s
                        Total time: 4566.04s
                               ETA: 3111.8s
################################################################################
                     [1m Learning iteration 1190/2000 [0m                     

                       Computation: 1824 steps/s (collection: 3.181s, learning 0.765s)
               Value function loss: 21.4543
                    Surrogate loss: -0.0045
             Mean action noise std: 0.89
                       Mean reward: -42.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8575200
                    Iteration time: 3.95s
                        Total time: 4569.98s
                               ETA: 3108.0s
################################################################################
                     [1m Learning iteration 1191/2000 [0m                     

                       Computation: 1748 steps/s (collection: 3.392s, learning 0.727s)
               Value function loss: 21.1722
                    Surrogate loss: -0.0051
             Mean action noise std: 0.89
                       Mean reward: -42.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.91
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8582400
                    Iteration time: 4.12s
                        Total time: 4574.10s
                               ETA: 3104.4s
################################################################################
                     [1m Learning iteration 1192/2000 [0m                     

                       Computation: 1862 steps/s (collection: 3.248s, learning 0.617s)
               Value function loss: 21.5822
                    Surrogate loss: -0.0100
             Mean action noise std: 0.89
                       Mean reward: -43.10
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8589600
                    Iteration time: 3.87s
                        Total time: 4577.97s
                               ETA: 3100.6s
################################################################################
                     [1m Learning iteration 1193/2000 [0m                     

                       Computation: 1809 steps/s (collection: 3.353s, learning 0.626s)
               Value function loss: 21.9640
                    Surrogate loss: -0.0073
             Mean action noise std: 0.89
                       Mean reward: -43.36
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8596800
                    Iteration time: 3.98s
                        Total time: 4581.95s
                               ETA: 3096.8s
################################################################################
                     [1m Learning iteration 1194/2000 [0m                     

                       Computation: 1827 steps/s (collection: 3.317s, learning 0.623s)
               Value function loss: 22.0579
                    Surrogate loss: -0.0055
             Mean action noise std: 0.89
                       Mean reward: -43.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8604000
                    Iteration time: 3.94s
                        Total time: 4585.89s
                               ETA: 3093.1s
################################################################################
                     [1m Learning iteration 1195/2000 [0m                     

                       Computation: 1829 steps/s (collection: 3.228s, learning 0.706s)
               Value function loss: 22.8351
                    Surrogate loss: -0.0074
             Mean action noise std: 0.89
                       Mean reward: -43.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8611200
                    Iteration time: 3.93s
                        Total time: 4589.82s
                               ETA: 3089.3s
################################################################################
                     [1m Learning iteration 1196/2000 [0m                     

                       Computation: 1804 steps/s (collection: 3.365s, learning 0.625s)
               Value function loss: 20.6697
                    Surrogate loss: -0.0085
             Mean action noise std: 0.89
                       Mean reward: -43.53
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8618400
                    Iteration time: 3.99s
                        Total time: 4593.81s
                               ETA: 3085.6s
################################################################################
                     [1m Learning iteration 1197/2000 [0m                     

                       Computation: 1851 steps/s (collection: 3.214s, learning 0.675s)
               Value function loss: 21.3643
                    Surrogate loss: -0.0064
             Mean action noise std: 0.89
                       Mean reward: -43.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8625600
                    Iteration time: 3.89s
                        Total time: 4597.70s
                               ETA: 3081.8s
################################################################################
                     [1m Learning iteration 1198/2000 [0m                     

                       Computation: 1785 steps/s (collection: 3.355s, learning 0.678s)
               Value function loss: 20.5700
                    Surrogate loss: -0.0100
             Mean action noise std: 0.89
                       Mean reward: -43.14
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8632800
                    Iteration time: 4.03s
                        Total time: 4601.73s
                               ETA: 3078.1s
################################################################################
                     [1m Learning iteration 1199/2000 [0m                     

                       Computation: 1838 steps/s (collection: 3.308s, learning 0.609s)
               Value function loss: 21.3570
                    Surrogate loss: -0.0059
             Mean action noise std: 0.89
                       Mean reward: -42.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8640000
                    Iteration time: 3.92s
                        Total time: 4605.65s
                               ETA: 3074.3s
################################################################################
                     [1m Learning iteration 1200/2000 [0m                     

                       Computation: 1861 steps/s (collection: 3.262s, learning 0.607s)
               Value function loss: 21.7822
                    Surrogate loss: -0.0056
             Mean action noise std: 0.89
                       Mean reward: -43.66
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -1.03
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8647200
                    Iteration time: 3.87s
                        Total time: 4609.52s
                               ETA: 3070.5s
################################################################################
                     [1m Learning iteration 1201/2000 [0m                     

                       Computation: 1795 steps/s (collection: 3.399s, learning 0.611s)
               Value function loss: 20.8105
                    Surrogate loss: -0.0040
             Mean action noise std: 0.89
                       Mean reward: -43.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8654400
                    Iteration time: 4.01s
                        Total time: 4613.53s
                               ETA: 3066.7s
################################################################################
                     [1m Learning iteration 1202/2000 [0m                     

                       Computation: 1854 steps/s (collection: 3.264s, learning 0.620s)
               Value function loss: 21.2260
                    Surrogate loss: -0.0050
             Mean action noise std: 0.89
                       Mean reward: -43.46
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8661600
                    Iteration time: 3.88s
                        Total time: 4617.41s
                               ETA: 3062.9s
################################################################################
                     [1m Learning iteration 1203/2000 [0m                     

                       Computation: 1784 steps/s (collection: 3.364s, learning 0.670s)
               Value function loss: 20.9238
                    Surrogate loss: -0.0068
             Mean action noise std: 0.89
                       Mean reward: -43.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8668800
                    Iteration time: 4.03s
                        Total time: 4621.45s
                               ETA: 3059.2s
################################################################################
                     [1m Learning iteration 1204/2000 [0m                     

                       Computation: 1826 steps/s (collection: 3.292s, learning 0.650s)
               Value function loss: 21.7599
                    Surrogate loss: -0.0085
             Mean action noise std: 0.89
                       Mean reward: -43.35
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8676000
                    Iteration time: 3.94s
                        Total time: 4625.39s
                               ETA: 3055.4s
################################################################################
                     [1m Learning iteration 1205/2000 [0m                     

                       Computation: 1855 steps/s (collection: 3.267s, learning 0.613s)
               Value function loss: 22.1749
                    Surrogate loss: -0.0061
             Mean action noise std: 0.89
                       Mean reward: -42.91
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8683200
                    Iteration time: 3.88s
                        Total time: 4629.27s
                               ETA: 3051.6s
################################################################################
                     [1m Learning iteration 1206/2000 [0m                     

                       Computation: 1804 steps/s (collection: 3.364s, learning 0.626s)
               Value function loss: 22.2960
                    Surrogate loss: -0.0004
             Mean action noise std: 0.89
                       Mean reward: -43.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8690400
                    Iteration time: 3.99s
                        Total time: 4633.26s
                               ETA: 3047.9s
################################################################################
                     [1m Learning iteration 1207/2000 [0m                     

                       Computation: 1858 steps/s (collection: 3.250s, learning 0.624s)
               Value function loss: 21.2204
                    Surrogate loss: -0.0055
             Mean action noise std: 0.89
                       Mean reward: -43.38
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8697600
                    Iteration time: 3.87s
                        Total time: 4637.13s
                               ETA: 3044.1s
################################################################################
                     [1m Learning iteration 1208/2000 [0m                     

                       Computation: 1802 steps/s (collection: 3.359s, learning 0.635s)
               Value function loss: 21.2480
                    Surrogate loss: -0.0030
             Mean action noise std: 0.89
                       Mean reward: -43.92
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -1.01
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8704800
                    Iteration time: 3.99s
                        Total time: 4641.12s
                               ETA: 3040.3s
################################################################################
                     [1m Learning iteration 1209/2000 [0m                     

                       Computation: 1862 steps/s (collection: 3.259s, learning 0.606s)
               Value function loss: 19.8637
                    Surrogate loss: -0.0062
             Mean action noise std: 0.89
                       Mean reward: -43.96
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8712000
                    Iteration time: 3.86s
                        Total time: 4644.99s
                               ETA: 3036.5s
################################################################################
                     [1m Learning iteration 1210/2000 [0m                     

                       Computation: 1826 steps/s (collection: 3.320s, learning 0.621s)
               Value function loss: 18.4616
                    Surrogate loss: -0.0087
             Mean action noise std: 0.89
                       Mean reward: -43.64
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8719200
                    Iteration time: 3.94s
                        Total time: 4648.93s
                               ETA: 3032.7s
################################################################################
                     [1m Learning iteration 1211/2000 [0m                     

                       Computation: 1813 steps/s (collection: 3.360s, learning 0.610s)
               Value function loss: 20.6799
                    Surrogate loss: -0.0037
             Mean action noise std: 0.89
                       Mean reward: -43.32
               Mean episode length: 45.00
                 Mean success rate: 1.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8726400
                    Iteration time: 3.97s
                        Total time: 4652.90s
                               ETA: 3029.0s
################################################################################
                     [1m Learning iteration 1212/2000 [0m                     

                       Computation: 1853 steps/s (collection: 3.261s, learning 0.622s)
               Value function loss: 20.0107
                    Surrogate loss: -0.0098
             Mean action noise std: 0.89
                       Mean reward: -42.89
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8733600
                    Iteration time: 3.88s
                        Total time: 4656.78s
                               ETA: 3025.2s
################################################################################
                     [1m Learning iteration 1213/2000 [0m                     

                       Computation: 1766 steps/s (collection: 3.421s, learning 0.654s)
               Value function loss: 17.3420
                    Surrogate loss: -0.0057
             Mean action noise std: 0.89
                       Mean reward: -41.98
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.91
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8740800
                    Iteration time: 4.08s
                        Total time: 4660.86s
                               ETA: 3021.5s
################################################################################
                     [1m Learning iteration 1214/2000 [0m                     

                       Computation: 1802 steps/s (collection: 3.261s, learning 0.734s)
               Value function loss: 19.4351
                    Surrogate loss: -0.0053
             Mean action noise std: 0.89
                       Mean reward: -41.83
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8748000
                    Iteration time: 3.99s
                        Total time: 4664.85s
                               ETA: 3017.8s
################################################################################
                     [1m Learning iteration 1215/2000 [0m                     

                       Computation: 1731 steps/s (collection: 3.385s, learning 0.773s)
               Value function loss: 19.7707
                    Surrogate loss: -0.0029
             Mean action noise std: 0.89
                       Mean reward: -41.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.92
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8755200
                    Iteration time: 4.16s
                        Total time: 4669.01s
                               ETA: 3014.1s
################################################################################
                     [1m Learning iteration 1216/2000 [0m                     

                       Computation: 1821 steps/s (collection: 3.338s, learning 0.614s)
               Value function loss: 22.1435
                    Surrogate loss: -0.0077
             Mean action noise std: 0.89
                       Mean reward: -41.78
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8762400
                    Iteration time: 3.95s
                        Total time: 4672.96s
                               ETA: 3010.4s
################################################################################
                     [1m Learning iteration 1217/2000 [0m                     

                       Computation: 1839 steps/s (collection: 3.236s, learning 0.679s)
               Value function loss: 19.1078
                    Surrogate loss: -0.0053
             Mean action noise std: 0.89
                       Mean reward: -42.25
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8769600
                    Iteration time: 3.91s
                        Total time: 4676.88s
                               ETA: 3006.6s
################################################################################
                     [1m Learning iteration 1218/2000 [0m                     

                       Computation: 1771 steps/s (collection: 3.365s, learning 0.700s)
               Value function loss: 21.6498
                    Surrogate loss: -0.0071
             Mean action noise std: 0.89
                       Mean reward: -42.79
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8776800
                    Iteration time: 4.06s
                        Total time: 4680.94s
                               ETA: 3002.9s
################################################################################
                     [1m Learning iteration 1219/2000 [0m                     

                       Computation: 1836 steps/s (collection: 3.276s, learning 0.645s)
               Value function loss: 18.5100
                    Surrogate loss: -0.0079
             Mean action noise std: 0.89
                       Mean reward: -42.83
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8784000
                    Iteration time: 3.92s
                        Total time: 4684.86s
                               ETA: 2999.1s
################################################################################
                     [1m Learning iteration 1220/2000 [0m                     

                       Computation: 1815 steps/s (collection: 3.316s, learning 0.649s)
               Value function loss: 22.1341
                    Surrogate loss: -0.0027
             Mean action noise std: 0.89
                       Mean reward: -42.65
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.90
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8791200
                    Iteration time: 3.97s
                        Total time: 4688.83s
                               ETA: 2995.3s
################################################################################
                     [1m Learning iteration 1221/2000 [0m                     

                       Computation: 1810 steps/s (collection: 3.279s, learning 0.698s)
               Value function loss: 18.1448
                    Surrogate loss: -0.0053
             Mean action noise std: 0.89
                       Mean reward: -42.92
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8798400
                    Iteration time: 3.98s
                        Total time: 4692.80s
                               ETA: 2991.6s
################################################################################
                     [1m Learning iteration 1222/2000 [0m                     

                       Computation: 1844 steps/s (collection: 3.249s, learning 0.655s)
               Value function loss: 18.6348
                    Surrogate loss: -0.0083
             Mean action noise std: 0.89
                       Mean reward: -42.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8805600
                    Iteration time: 3.90s
                        Total time: 4696.71s
                               ETA: 2987.8s
################################################################################
                     [1m Learning iteration 1223/2000 [0m                     

                       Computation: 1805 steps/s (collection: 3.376s, learning 0.613s)
               Value function loss: 22.3973
                    Surrogate loss: -0.0053
             Mean action noise std: 0.89
                       Mean reward: -42.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8812800
                    Iteration time: 3.99s
                        Total time: 4700.70s
                               ETA: 2984.0s
################################################################################
                     [1m Learning iteration 1224/2000 [0m                     

                       Computation: 1845 steps/s (collection: 3.282s, learning 0.619s)
               Value function loss: 22.6412
                    Surrogate loss: -0.0070
             Mean action noise std: 0.89
                       Mean reward: -42.57
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8820000
                    Iteration time: 3.90s
                        Total time: 4704.60s
                               ETA: 2980.2s
################################################################################
                     [1m Learning iteration 1225/2000 [0m                     

                       Computation: 1807 steps/s (collection: 3.345s, learning 0.639s)
               Value function loss: 20.4541
                    Surrogate loss: -0.0045
             Mean action noise std: 0.89
                       Mean reward: -43.31
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8827200
                    Iteration time: 3.98s
                        Total time: 4708.58s
                               ETA: 2976.5s
################################################################################
                     [1m Learning iteration 1226/2000 [0m                     

                       Computation: 1794 steps/s (collection: 3.323s, learning 0.688s)
               Value function loss: 20.8364
                    Surrogate loss: -0.0063
             Mean action noise std: 0.89
                       Mean reward: -42.94
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8834400
                    Iteration time: 4.01s
                        Total time: 4712.59s
                               ETA: 2972.7s
################################################################################
                     [1m Learning iteration 1227/2000 [0m                     

                       Computation: 1858 steps/s (collection: 3.258s, learning 0.615s)
               Value function loss: 20.1905
                    Surrogate loss: -0.0054
             Mean action noise std: 0.89
                       Mean reward: -43.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8841600
                    Iteration time: 3.87s
                        Total time: 4716.47s
                               ETA: 2968.9s
################################################################################
                     [1m Learning iteration 1228/2000 [0m                     

                       Computation: 1802 steps/s (collection: 3.372s, learning 0.621s)
               Value function loss: 20.1489
                    Surrogate loss: -0.0083
             Mean action noise std: 0.89
                       Mean reward: -43.36
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8848800
                    Iteration time: 3.99s
                        Total time: 4720.46s
                               ETA: 2965.2s
################################################################################
                     [1m Learning iteration 1229/2000 [0m                     

                       Computation: 1863 steps/s (collection: 3.249s, learning 0.614s)
               Value function loss: 19.6442
                    Surrogate loss: -0.0057
             Mean action noise std: 0.89
                       Mean reward: -42.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.92
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8856000
                    Iteration time: 3.86s
                        Total time: 4724.32s
                               ETA: 2961.3s
################################################################################
                     [1m Learning iteration 1230/2000 [0m                     

                       Computation: 1794 steps/s (collection: 3.343s, learning 0.668s)
               Value function loss: 20.2334
                    Surrogate loss: -0.0076
             Mean action noise std: 0.89
                       Mean reward: -42.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8863200
                    Iteration time: 4.01s
                        Total time: 4728.34s
                               ETA: 2957.6s
################################################################################
                     [1m Learning iteration 1231/2000 [0m                     

                       Computation: 1829 steps/s (collection: 3.317s, learning 0.618s)
               Value function loss: 18.4979
                    Surrogate loss: -0.0100
             Mean action noise std: 0.89
                       Mean reward: -42.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8870400
                    Iteration time: 3.93s
                        Total time: 4732.27s
                               ETA: 2953.8s
################################################################################
                     [1m Learning iteration 1232/2000 [0m                     

                       Computation: 1856 steps/s (collection: 3.260s, learning 0.619s)
               Value function loss: 21.5978
                    Surrogate loss: -0.0060
             Mean action noise std: 0.89
                       Mean reward: -42.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8877600
                    Iteration time: 3.88s
                        Total time: 4736.15s
                               ETA: 2950.0s
################################################################################
                     [1m Learning iteration 1233/2000 [0m                     

                       Computation: 1795 steps/s (collection: 3.384s, learning 0.627s)
               Value function loss: 20.6177
                    Surrogate loss: 0.0033
             Mean action noise std: 0.89
                       Mean reward: -42.64
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8884800
                    Iteration time: 4.01s
                        Total time: 4740.16s
                               ETA: 2946.3s
################################################################################
                     [1m Learning iteration 1234/2000 [0m                     

                       Computation: 1858 steps/s (collection: 3.250s, learning 0.624s)
               Value function loss: 20.9902
                    Surrogate loss: -0.0028
             Mean action noise std: 0.89
                       Mean reward: -42.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8892000
                    Iteration time: 3.87s
                        Total time: 4744.03s
                               ETA: 2942.5s
################################################################################
                     [1m Learning iteration 1235/2000 [0m                     

                       Computation: 1809 steps/s (collection: 3.314s, learning 0.664s)
               Value function loss: 20.3435
                    Surrogate loss: -0.0106
             Mean action noise std: 0.89
                       Mean reward: -42.71
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8899200
                    Iteration time: 3.98s
                        Total time: 4748.01s
                               ETA: 2938.7s
################################################################################
                     [1m Learning iteration 1236/2000 [0m                     

                       Computation: 1849 steps/s (collection: 3.283s, learning 0.610s)
               Value function loss: 19.9017
                    Surrogate loss: -0.0063
             Mean action noise std: 0.89
                       Mean reward: -42.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8906400
                    Iteration time: 3.89s
                        Total time: 4751.91s
                               ETA: 2934.9s
################################################################################
                     [1m Learning iteration 1237/2000 [0m                     

                       Computation: 1856 steps/s (collection: 3.247s, learning 0.632s)
               Value function loss: 18.0557
                    Surrogate loss: -0.0044
             Mean action noise std: 0.89
                       Mean reward: -43.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8913600
                    Iteration time: 3.88s
                        Total time: 4755.78s
                               ETA: 2931.1s
################################################################################
                     [1m Learning iteration 1238/2000 [0m                     

                       Computation: 1801 steps/s (collection: 3.372s, learning 0.624s)
               Value function loss: 19.8548
                    Surrogate loss: -0.0087
             Mean action noise std: 0.89
                       Mean reward: -42.51
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.92
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8920800
                    Iteration time: 4.00s
                        Total time: 4759.78s
                               ETA: 2927.3s
################################################################################
                     [1m Learning iteration 1239/2000 [0m                     

                       Computation: 1840 steps/s (collection: 3.287s, learning 0.626s)
               Value function loss: 19.1159
                    Surrogate loss: -0.0050
             Mean action noise std: 0.89
                       Mean reward: -42.41
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8928000
                    Iteration time: 3.91s
                        Total time: 4763.69s
                               ETA: 2923.5s
################################################################################
                     [1m Learning iteration 1240/2000 [0m                     

                       Computation: 1779 steps/s (collection: 3.428s, learning 0.617s)
               Value function loss: 21.0127
                    Surrogate loss: 0.0017
             Mean action noise std: 0.89
                       Mean reward: -42.22
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8935200
                    Iteration time: 4.05s
                        Total time: 4767.74s
                               ETA: 2919.8s
################################################################################
                     [1m Learning iteration 1241/2000 [0m                     

                       Computation: 1785 steps/s (collection: 3.345s, learning 0.687s)
               Value function loss: 21.1527
                    Surrogate loss: -0.0056
             Mean action noise std: 0.89
                       Mean reward: -42.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8942400
                    Iteration time: 4.03s
                        Total time: 4771.77s
                               ETA: 2916.1s
################################################################################
                     [1m Learning iteration 1242/2000 [0m                     

                       Computation: 1856 steps/s (collection: 3.255s, learning 0.623s)
               Value function loss: 17.9235
                    Surrogate loss: -0.0076
             Mean action noise std: 0.89
                       Mean reward: -41.97
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8949600
                    Iteration time: 3.88s
                        Total time: 4775.65s
                               ETA: 2912.3s
################################################################################
                     [1m Learning iteration 1243/2000 [0m                     

                       Computation: 1791 steps/s (collection: 3.405s, learning 0.614s)
               Value function loss: 20.1290
                    Surrogate loss: -0.0074
             Mean action noise std: 0.89
                       Mean reward: -41.96
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.92
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8956800
                    Iteration time: 4.02s
                        Total time: 4779.67s
                               ETA: 2908.5s
################################################################################
                     [1m Learning iteration 1244/2000 [0m                     

                       Computation: 1809 steps/s (collection: 3.273s, learning 0.706s)
               Value function loss: 21.5286
                    Surrogate loss: -0.0095
             Mean action noise std: 0.89
                       Mean reward: -41.93
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8964000
                    Iteration time: 3.98s
                        Total time: 4783.65s
                               ETA: 2904.8s
################################################################################
                     [1m Learning iteration 1245/2000 [0m                     

                       Computation: 1758 steps/s (collection: 3.347s, learning 0.748s)
               Value function loss: 21.2387
                    Surrogate loss: -0.0082
             Mean action noise std: 0.89
                       Mean reward: -42.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8971200
                    Iteration time: 4.09s
                        Total time: 4787.74s
                               ETA: 2901.1s
################################################################################
                     [1m Learning iteration 1246/2000 [0m                     

                       Computation: 1779 steps/s (collection: 3.307s, learning 0.738s)
               Value function loss: 19.9665
                    Surrogate loss: -0.0107
             Mean action noise std: 0.89
                       Mean reward: -42.54
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8978400
                    Iteration time: 4.05s
                        Total time: 4791.79s
                               ETA: 2897.4s
################################################################################
                     [1m Learning iteration 1247/2000 [0m                     

                       Computation: 1857 steps/s (collection: 3.264s, learning 0.612s)
               Value function loss: 18.9323
                    Surrogate loss: -0.0063
             Mean action noise std: 0.89
                       Mean reward: -42.50
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8985600
                    Iteration time: 3.88s
                        Total time: 4795.66s
                               ETA: 2893.5s
################################################################################
                     [1m Learning iteration 1248/2000 [0m                     

                       Computation: 1752 steps/s (collection: 3.363s, learning 0.746s)
               Value function loss: 19.9648
                    Surrogate loss: -0.0036
             Mean action noise std: 0.89
                       Mean reward: -42.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.91
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 8992800
                    Iteration time: 4.11s
                        Total time: 4799.77s
                               ETA: 2889.9s
################################################################################
                     [1m Learning iteration 1249/2000 [0m                     

                       Computation: 1844 steps/s (collection: 3.252s, learning 0.653s)
               Value function loss: 21.6648
                    Surrogate loss: -0.0041
             Mean action noise std: 0.89
                       Mean reward: -42.65
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9000000
                    Iteration time: 3.90s
                        Total time: 4803.68s
                               ETA: 2886.0s
################################################################################
                     [1m Learning iteration 1250/2000 [0m                     

                       Computation: 1813 steps/s (collection: 3.328s, learning 0.642s)
               Value function loss: 20.6997
                    Surrogate loss: 0.0001
             Mean action noise std: 0.89
                       Mean reward: -42.89
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9007200
                    Iteration time: 3.97s
                        Total time: 4807.64s
                               ETA: 2882.3s
################################################################################
                     [1m Learning iteration 1251/2000 [0m                     

                       Computation: 1835 steps/s (collection: 3.323s, learning 0.600s)
               Value function loss: 20.7900
                    Surrogate loss: -0.0055
             Mean action noise std: 0.89
                       Mean reward: -42.24
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.90
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9014400
                    Iteration time: 3.92s
                        Total time: 4811.57s
                               ETA: 2878.5s
################################################################################
                     [1m Learning iteration 1252/2000 [0m                     

                       Computation: 1835 steps/s (collection: 3.306s, learning 0.617s)
               Value function loss: 21.3100
                    Surrogate loss: -0.0077
             Mean action noise std: 0.89
                       Mean reward: -42.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9021600
                    Iteration time: 3.92s
                        Total time: 4815.49s
                               ETA: 2874.7s
################################################################################
                     [1m Learning iteration 1253/2000 [0m                     

                       Computation: 1718 steps/s (collection: 3.425s, learning 0.766s)
               Value function loss: 18.0107
                    Surrogate loss: -0.0065
             Mean action noise std: 0.89
                       Mean reward: -42.95
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9028800
                    Iteration time: 4.19s
                        Total time: 4819.68s
                               ETA: 2871.1s
################################################################################
                     [1m Learning iteration 1254/2000 [0m                     

                       Computation: 1793 steps/s (collection: 3.252s, learning 0.762s)
               Value function loss: 19.1294
                    Surrogate loss: -0.0074
             Mean action noise std: 0.89
                       Mean reward: -42.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.91
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9036000
                    Iteration time: 4.01s
                        Total time: 4823.69s
                               ETA: 2867.3s
################################################################################
                     [1m Learning iteration 1255/2000 [0m                     

                       Computation: 1753 steps/s (collection: 3.328s, learning 0.778s)
               Value function loss: 19.1378
                    Surrogate loss: -0.0080
             Mean action noise std: 0.89
                       Mean reward: -42.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9043200
                    Iteration time: 4.11s
                        Total time: 4827.80s
                               ETA: 2863.6s
################################################################################
                     [1m Learning iteration 1256/2000 [0m                     

                       Computation: 1769 steps/s (collection: 3.318s, learning 0.752s)
               Value function loss: 19.9078
                    Surrogate loss: -0.0040
             Mean action noise std: 0.89
                       Mean reward: -42.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9050400
                    Iteration time: 4.07s
                        Total time: 4831.87s
                               ETA: 2859.9s
################################################################################
                     [1m Learning iteration 1257/2000 [0m                     

                       Computation: 1792 steps/s (collection: 3.251s, learning 0.766s)
               Value function loss: 22.7337
                    Surrogate loss: -0.0066
             Mean action noise std: 0.89
                       Mean reward: -42.59
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9057600
                    Iteration time: 4.02s
                        Total time: 4835.89s
                               ETA: 2856.2s
################################################################################
                     [1m Learning iteration 1258/2000 [0m                     

                       Computation: 1736 steps/s (collection: 3.365s, learning 0.781s)
               Value function loss: 20.6904
                    Surrogate loss: -0.0063
             Mean action noise std: 0.89
                       Mean reward: -42.37
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9064800
                    Iteration time: 4.15s
                        Total time: 4840.03s
                               ETA: 2852.5s
################################################################################
                     [1m Learning iteration 1259/2000 [0m                     

                       Computation: 1798 steps/s (collection: 3.230s, learning 0.773s)
               Value function loss: 21.2666
                    Surrogate loss: -0.0083
             Mean action noise std: 0.89
                       Mean reward: -42.72
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9072000
                    Iteration time: 4.00s
                        Total time: 4844.04s
                               ETA: 2848.8s
################################################################################
                     [1m Learning iteration 1260/2000 [0m                     

                       Computation: 1779 steps/s (collection: 3.317s, learning 0.729s)
               Value function loss: 20.1385
                    Surrogate loss: -0.0080
             Mean action noise std: 0.89
                       Mean reward: -42.64
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9079200
                    Iteration time: 4.05s
                        Total time: 4848.08s
                               ETA: 2845.0s
################################################################################
                     [1m Learning iteration 1261/2000 [0m                     

                       Computation: 1755 steps/s (collection: 3.342s, learning 0.760s)
               Value function loss: 19.5184
                    Surrogate loss: -0.0054
             Mean action noise std: 0.89
                       Mean reward: -42.61
               Mean episode length: 45.00
                 Mean success rate: 0.50
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9086400
                    Iteration time: 4.10s
                        Total time: 4852.18s
                               ETA: 2841.3s
################################################################################
                     [1m Learning iteration 1262/2000 [0m                     

                       Computation: 1792 steps/s (collection: 3.249s, learning 0.768s)
               Value function loss: 21.3585
                    Surrogate loss: -0.0046
             Mean action noise std: 0.89
                       Mean reward: -42.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9093600
                    Iteration time: 4.02s
                        Total time: 4856.20s
                               ETA: 2837.6s
################################################################################
                     [1m Learning iteration 1263/2000 [0m                     

                       Computation: 1756 steps/s (collection: 3.360s, learning 0.739s)
               Value function loss: 18.7894
                    Surrogate loss: -0.0028
             Mean action noise std: 0.89
                       Mean reward: -42.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9100800
                    Iteration time: 4.10s
                        Total time: 4860.30s
                               ETA: 2833.9s
################################################################################
                     [1m Learning iteration 1264/2000 [0m                     

                       Computation: 1792 steps/s (collection: 3.268s, learning 0.750s)
               Value function loss: 22.5322
                    Surrogate loss: -0.0035
             Mean action noise std: 0.89
                       Mean reward: -41.92
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.90
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9108000
                    Iteration time: 4.02s
                        Total time: 4864.32s
                               ETA: 2830.1s
################################################################################
                     [1m Learning iteration 1265/2000 [0m                     

                       Computation: 1756 steps/s (collection: 3.317s, learning 0.781s)
               Value function loss: 19.9328
                    Surrogate loss: -0.0038
             Mean action noise std: 0.89
                       Mean reward: -42.19
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9115200
                    Iteration time: 4.10s
                        Total time: 4868.42s
                               ETA: 2826.5s
################################################################################
                     [1m Learning iteration 1266/2000 [0m                     

                       Computation: 1751 steps/s (collection: 3.351s, learning 0.761s)
               Value function loss: 20.7708
                    Surrogate loss: -0.0062
             Mean action noise std: 0.90
                       Mean reward: -42.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9122400
                    Iteration time: 4.11s
                        Total time: 4872.53s
                               ETA: 2822.8s
################################################################################
                     [1m Learning iteration 1267/2000 [0m                     

                       Computation: 1852 steps/s (collection: 3.263s, learning 0.623s)
               Value function loss: 20.4184
                    Surrogate loss: -0.0085
             Mean action noise std: 0.90
                       Mean reward: -42.73
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9129600
                    Iteration time: 3.89s
                        Total time: 4876.41s
                               ETA: 2818.9s
################################################################################
                     [1m Learning iteration 1268/2000 [0m                     

                       Computation: 1775 steps/s (collection: 3.368s, learning 0.688s)
               Value function loss: 22.6142
                    Surrogate loss: -0.0067
             Mean action noise std: 0.89
                       Mean reward: -42.74
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9136800
                    Iteration time: 4.06s
                        Total time: 4880.47s
                               ETA: 2815.2s
################################################################################
                     [1m Learning iteration 1269/2000 [0m                     

                       Computation: 1788 steps/s (collection: 3.261s, learning 0.766s)
               Value function loss: 22.0243
                    Surrogate loss: -0.0103
             Mean action noise std: 0.89
                       Mean reward: -43.42
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9144000
                    Iteration time: 4.03s
                        Total time: 4884.50s
                               ETA: 2811.5s
################################################################################
                     [1m Learning iteration 1270/2000 [0m                     

                       Computation: 1763 steps/s (collection: 3.303s, learning 0.781s)
               Value function loss: 18.5612
                    Surrogate loss: -0.0085
             Mean action noise std: 0.89
                       Mean reward: -42.78
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.90
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9151200
                    Iteration time: 4.08s
                        Total time: 4888.58s
                               ETA: 2807.8s
################################################################################
                     [1m Learning iteration 1271/2000 [0m                     

                       Computation: 1712 steps/s (collection: 3.367s, learning 0.839s)
               Value function loss: 17.9930
                    Surrogate loss: -0.0040
             Mean action noise std: 0.89
                       Mean reward: -42.26
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.91
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9158400
                    Iteration time: 4.21s
                        Total time: 4892.78s
                               ETA: 2804.1s
################################################################################
                     [1m Learning iteration 1272/2000 [0m                     

                       Computation: 1789 steps/s (collection: 3.265s, learning 0.759s)
               Value function loss: 19.5417
                    Surrogate loss: -0.0080
             Mean action noise std: 0.89
                       Mean reward: -41.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.89
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9165600
                    Iteration time: 4.02s
                        Total time: 4896.81s
                               ETA: 2800.4s
################################################################################
                     [1m Learning iteration 1273/2000 [0m                     

                       Computation: 1741 steps/s (collection: 3.370s, learning 0.763s)
               Value function loss: 18.5302
                    Surrogate loss: -0.0008
             Mean action noise std: 0.89
                       Mean reward: -41.57
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9172800
                    Iteration time: 4.13s
                        Total time: 4900.94s
                               ETA: 2796.7s
################################################################################
                     [1m Learning iteration 1274/2000 [0m                     

                       Computation: 1828 steps/s (collection: 3.305s, learning 0.632s)
               Value function loss: 18.4155
                    Surrogate loss: -0.0016
             Mean action noise std: 0.89
                       Mean reward: -41.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.92
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9180000
                    Iteration time: 3.94s
                        Total time: 4904.88s
                               ETA: 2792.9s
################################################################################
                     [1m Learning iteration 1275/2000 [0m                     

                       Computation: 1831 steps/s (collection: 3.250s, learning 0.682s)
               Value function loss: 20.4627
                    Surrogate loss: -0.0072
             Mean action noise std: 0.89
                       Mean reward: -41.08
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.90
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9187200
                    Iteration time: 3.93s
                        Total time: 4908.81s
                               ETA: 2789.1s
################################################################################
                     [1m Learning iteration 1276/2000 [0m                     

                       Computation: 1789 steps/s (collection: 3.373s, learning 0.651s)
               Value function loss: 22.6913
                    Surrogate loss: -0.0098
             Mean action noise std: 0.89
                       Mean reward: -41.15
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.92
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9194400
                    Iteration time: 4.02s
                        Total time: 4912.84s
                               ETA: 2785.4s
################################################################################
                     [1m Learning iteration 1277/2000 [0m                     

                       Computation: 1831 steps/s (collection: 3.254s, learning 0.678s)
               Value function loss: 21.0807
                    Surrogate loss: -0.0046
             Mean action noise std: 0.89
                       Mean reward: -41.90
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.98
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9201600
                    Iteration time: 3.93s
                        Total time: 4916.77s
                               ETA: 2781.6s
################################################################################
                     [1m Learning iteration 1278/2000 [0m                     

                       Computation: 1748 steps/s (collection: 3.335s, learning 0.782s)
               Value function loss: 17.8944
                    Surrogate loss: -0.0053
             Mean action noise std: 0.89
                       Mean reward: -41.87
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9208800
                    Iteration time: 4.12s
                        Total time: 4920.88s
                               ETA: 2777.9s
################################################################################
                     [1m Learning iteration 1279/2000 [0m                     

                       Computation: 1793 steps/s (collection: 3.315s, learning 0.699s)
               Value function loss: 20.0938
                    Surrogate loss: -0.0055
             Mean action noise std: 0.89
                       Mean reward: -41.73
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.90
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9216000
                    Iteration time: 4.01s
                        Total time: 4924.90s
                               ETA: 2774.1s
################################################################################
                     [1m Learning iteration 1280/2000 [0m                     

                       Computation: 1850 steps/s (collection: 3.281s, learning 0.609s)
               Value function loss: 19.6205
                    Surrogate loss: -0.0076
             Mean action noise std: 0.89
                       Mean reward: -41.99
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9223200
                    Iteration time: 3.89s
                        Total time: 4928.79s
                               ETA: 2770.3s
################################################################################
                     [1m Learning iteration 1281/2000 [0m                     

                       Computation: 1790 steps/s (collection: 3.401s, learning 0.621s)
               Value function loss: 21.1838
                    Surrogate loss: -0.0080
             Mean action noise std: 0.89
                       Mean reward: -42.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9230400
                    Iteration time: 4.02s
                        Total time: 4932.81s
                               ETA: 2766.5s
################################################################################
                     [1m Learning iteration 1282/2000 [0m                     

                       Computation: 1832 steps/s (collection: 3.313s, learning 0.616s)
               Value function loss: 21.7704
                    Surrogate loss: -0.0074
             Mean action noise std: 0.89
                       Mean reward: -42.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9237600
                    Iteration time: 3.93s
                        Total time: 4936.74s
                               ETA: 2762.7s
################################################################################
                     [1m Learning iteration 1283/2000 [0m                     

                       Computation: 1814 steps/s (collection: 3.342s, learning 0.627s)
               Value function loss: 21.4914
                    Surrogate loss: -0.0011
             Mean action noise std: 0.89
                       Mean reward: -42.04
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9244800
                    Iteration time: 3.97s
                        Total time: 4940.71s
                               ETA: 2758.9s
################################################################################
                     [1m Learning iteration 1284/2000 [0m                     

                       Computation: 1802 steps/s (collection: 3.363s, learning 0.632s)
               Value function loss: 18.9801
                    Surrogate loss: -0.0078
             Mean action noise std: 0.89
                       Mean reward: -42.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9252000
                    Iteration time: 3.99s
                        Total time: 4944.70s
                               ETA: 2755.2s
################################################################################
                     [1m Learning iteration 1285/2000 [0m                     

                       Computation: 1831 steps/s (collection: 3.309s, learning 0.622s)
               Value function loss: 21.2738
                    Surrogate loss: -0.0062
             Mean action noise std: 0.89
                       Mean reward: -42.30
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.90
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9259200
                    Iteration time: 3.93s
                        Total time: 4948.63s
                               ETA: 2751.4s
################################################################################
                     [1m Learning iteration 1286/2000 [0m                     

                       Computation: 1804 steps/s (collection: 3.381s, learning 0.609s)
               Value function loss: 19.6356
                    Surrogate loss: -0.0037
             Mean action noise std: 0.89
                       Mean reward: -42.12
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9266400
                    Iteration time: 3.99s
                        Total time: 4952.62s
                               ETA: 2747.6s
################################################################################
                     [1m Learning iteration 1287/2000 [0m                     

                       Computation: 1832 steps/s (collection: 3.217s, learning 0.713s)
               Value function loss: 20.9308
                    Surrogate loss: -0.0042
             Mean action noise std: 0.89
                       Mean reward: -41.82
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.92
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9273600
                    Iteration time: 3.93s
                        Total time: 4956.55s
                               ETA: 2743.8s
################################################################################
                     [1m Learning iteration 1288/2000 [0m                     

                       Computation: 1807 steps/s (collection: 3.359s, learning 0.625s)
               Value function loss: 21.8044
                    Surrogate loss: -0.0035
             Mean action noise std: 0.89
                       Mean reward: -41.98
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.95
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9280800
                    Iteration time: 3.98s
                        Total time: 4960.54s
                               ETA: 2740.0s
################################################################################
                     [1m Learning iteration 1289/2000 [0m                     

                       Computation: 1838 steps/s (collection: 3.302s, learning 0.615s)
               Value function loss: 19.5020
                    Surrogate loss: -0.0077
             Mean action noise std: 0.89
                       Mean reward: -41.43
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.90
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9288000
                    Iteration time: 3.92s
                        Total time: 4964.45s
                               ETA: 2736.2s
################################################################################
                     [1m Learning iteration 1290/2000 [0m                     

                       Computation: 1839 steps/s (collection: 3.270s, learning 0.645s)
               Value function loss: 20.4342
                    Surrogate loss: -0.0081
             Mean action noise std: 0.89
                       Mean reward: -41.55
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.91
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9295200
                    Iteration time: 3.91s
                        Total time: 4968.37s
                               ETA: 2732.4s
################################################################################
                     [1m Learning iteration 1291/2000 [0m                     

                       Computation: 1787 steps/s (collection: 3.364s, learning 0.664s)
               Value function loss: 21.1802
                    Surrogate loss: -0.0069
             Mean action noise std: 0.90
                       Mean reward: -41.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9302400
                    Iteration time: 4.03s
                        Total time: 4972.40s
                               ETA: 2728.7s
################################################################################
                     [1m Learning iteration 1292/2000 [0m                     

                       Computation: 1792 steps/s (collection: 3.276s, learning 0.740s)
               Value function loss: 18.6989
                    Surrogate loss: -0.0066
             Mean action noise std: 0.90
                       Mean reward: -41.70
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9309600
                    Iteration time: 4.02s
                        Total time: 4976.41s
                               ETA: 2724.9s
################################################################################
                     [1m Learning iteration 1293/2000 [0m                     

                       Computation: 1805 steps/s (collection: 3.369s, learning 0.620s)
               Value function loss: 20.2410
                    Surrogate loss: -0.0067
             Mean action noise std: 0.90
                       Mean reward: -41.26
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.90
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9316800
                    Iteration time: 3.99s
                        Total time: 4980.40s
                               ETA: 2721.1s
################################################################################
                     [1m Learning iteration 1294/2000 [0m                     

                       Computation: 1840 steps/s (collection: 3.289s, learning 0.624s)
               Value function loss: 18.9865
                    Surrogate loss: -0.0064
             Mean action noise std: 0.90
                       Mean reward: -41.49
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9324000
                    Iteration time: 3.91s
                        Total time: 4984.32s
                               ETA: 2717.3s
################################################################################
                     [1m Learning iteration 1295/2000 [0m                     

                       Computation: 1840 steps/s (collection: 3.304s, learning 0.609s)
               Value function loss: 21.7083
                    Surrogate loss: -0.0086
             Mean action noise std: 0.90
                       Mean reward: -41.58
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.92
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9331200
                    Iteration time: 3.91s
                        Total time: 4988.23s
                               ETA: 2713.5s
################################################################################
                     [1m Learning iteration 1296/2000 [0m                     

                       Computation: 1810 steps/s (collection: 3.362s, learning 0.615s)
               Value function loss: 20.7233
                    Surrogate loss: -0.0064
             Mean action noise std: 0.89
                       Mean reward: -41.63
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9338400
                    Iteration time: 3.98s
                        Total time: 4992.20s
                               ETA: 2709.7s
################################################################################
                     [1m Learning iteration 1297/2000 [0m                     

                       Computation: 1847 steps/s (collection: 3.262s, learning 0.636s)
               Value function loss: 21.9358
                    Surrogate loss: -0.0094
             Mean action noise std: 0.89
                       Mean reward: -42.11
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.99
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9345600
                    Iteration time: 3.90s
                        Total time: 4996.10s
                               ETA: 2705.9s
################################################################################
                     [1m Learning iteration 1298/2000 [0m                     

                       Computation: 1795 steps/s (collection: 3.368s, learning 0.643s)
               Value function loss: 20.1161
                    Surrogate loss: -0.0067
             Mean action noise std: 0.89
                       Mean reward: -42.52
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9352800
                    Iteration time: 4.01s
                        Total time: 5000.11s
                               ETA: 2702.1s
################################################################################
                     [1m Learning iteration 1299/2000 [0m                     

                       Computation: 1853 steps/s (collection: 3.268s, learning 0.617s)
               Value function loss: 19.8932
                    Surrogate loss: -0.0057
             Mean action noise std: 0.89
                       Mean reward: -42.75
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.96
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9360000
                    Iteration time: 3.88s
                        Total time: 5004.00s
                               ETA: 2698.3s
################################################################################
                     [1m Learning iteration 1300/2000 [0m                     

                       Computation: 1791 steps/s (collection: 3.289s, learning 0.729s)
               Value function loss: 21.0259
                    Surrogate loss: -0.0060
             Mean action noise std: 0.90
                       Mean reward: -42.84
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9367200
                    Iteration time: 4.02s
                        Total time: 5008.02s
                               ETA: 2694.6s
################################################################################
                     [1m Learning iteration 1301/2000 [0m                     

                       Computation: 1760 steps/s (collection: 3.393s, learning 0.697s)
               Value function loss: 23.3043
                    Surrogate loss: -0.0091
             Mean action noise std: 0.89
                       Mean reward: -43.09
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9374400
                    Iteration time: 4.09s
                        Total time: 5012.11s
                               ETA: 2690.8s
################################################################################
                     [1m Learning iteration 1302/2000 [0m                     

                       Computation: 1846 steps/s (collection: 3.265s, learning 0.634s)
               Value function loss: 20.6822
                    Surrogate loss: -0.0089
             Mean action noise std: 0.90
                       Mean reward: -42.61
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9381600
                    Iteration time: 3.90s
                        Total time: 5016.01s
                               ETA: 2687.0s
################################################################################
                     [1m Learning iteration 1303/2000 [0m                     

                       Computation: 1785 steps/s (collection: 3.338s, learning 0.694s)
               Value function loss: 20.4232
                    Surrogate loss: -0.0060
             Mean action noise std: 0.90
                       Mean reward: -42.56
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.94
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9388800
                    Iteration time: 4.03s
                        Total time: 5020.04s
                               ETA: 2683.3s
################################################################################
                     [1m Learning iteration 1304/2000 [0m                     

                       Computation: 1846 steps/s (collection: 3.278s, learning 0.621s)
               Value function loss: 18.5286
                    Surrogate loss: -0.0074
             Mean action noise std: 0.90
                       Mean reward: -42.29
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.93
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9396000
                    Iteration time: 3.90s
                        Total time: 5023.94s
                               ETA: 2679.4s
################################################################################
                     [1m Learning iteration 1305/2000 [0m                     

                       Computation: 1820 steps/s (collection: 3.311s, learning 0.643s)
               Value function loss: 18.1095
                    Surrogate loss: -0.0050
             Mean action noise std: 0.90
                       Mean reward: -42.01
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.90
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9403200
                    Iteration time: 3.95s
                        Total time: 5027.89s
                               ETA: 2675.6s
################################################################################
                     [1m Learning iteration 1306/2000 [0m                     

                       Computation: 1802 steps/s (collection: 3.377s, learning 0.618s)
               Value function loss: 18.6445
                    Surrogate loss: -0.0079
             Mean action noise std: 0.90
                       Mean reward: -41.44
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.91
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9410400
                    Iteration time: 3.99s
                        Total time: 5031.89s
                               ETA: 2671.9s
################################################################################
                     [1m Learning iteration 1307/2000 [0m                     

                       Computation: 1847 steps/s (collection: 3.275s, learning 0.623s)
               Value function loss: 21.1091
                    Surrogate loss: -0.0074
             Mean action noise std: 0.90
                       Mean reward: -41.18
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.91
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9417600
                    Iteration time: 3.90s
                        Total time: 5035.79s
                               ETA: 2668.0s
################################################################################
                     [1m Learning iteration 1308/2000 [0m                     

                       Computation: 1799 steps/s (collection: 3.354s, learning 0.646s)
               Value function loss: 21.1132
                    Surrogate loss: -0.0064
             Mean action noise std: 0.90
                       Mean reward: -41.40
               Mean episode length: 45.00
                 Mean success rate: 0.00
                  Mean reward/step: -0.97
       Mean episode length/episode: 22.50
                  Mean dist2expert: 0.00
--------------------------------------------------------------------------------
                   Total timesteps: 9424800
                    Iteration time: 4.00s
                        Total time: 5039.79s
                               ETA: 2664.3s
